{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03426497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3eb5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: HI_Small_Trans (shape: (5078345, 11))\n",
      "Loaded: LI_Small_Trans (shape: (6924049, 11))\n"
     ]
    }
   ],
   "source": [
    "# (My Code from ITMD 522 - HW#2)\n",
    "\n",
    "# import pandas as pd.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder path: '/Users/harshpatel/Desktop/MS-ITM/ITMD 524/project_dataset'\n",
    "folder_path = Path('/Users/harshpatel/Desktop/MS-ITM/ITMD 524/project_dataset')  \n",
    "\n",
    "# Read the excel file and specific 'Data' spreadsheet from CSV file. Get all CSV files in the folder.\n",
    "# pandas.read_csv(filepath_or_buffer, *, sep=<no_default>, delimiter=None, header='infer', names=<no_default>, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=<no_default>, skip_blank_lines=True, parse_dates=None, infer_datetime_format=<no_default>, keep_date_col=<no_default>, date_parser=<no_default>, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=<no_default>, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=<no_default>)\n",
    "# csv_files = [f for f in folder_path.glob('*.csv') if 'Small' in f.name]\n",
    "csv_files = [f for f in folder_path.glob('*.csv') if 'Small' in f.name]\n",
    "\n",
    "# To assign names for each datafile as a dataframe.\n",
    "for file in csv_files:\n",
    "    var_name = file.stem.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_csv(file)\n",
    "    print(f\"Loaded: {var_name} (shape: {globals()[var_name].shape})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef1c6c",
   "metadata": {},
   "source": [
    "# HI_Small_Trans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6c82ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:08</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:21</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>1120</td>\n",
       "      <td>8006AA910</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924044</th>\n",
       "      <td>2022/09/10 23:39</td>\n",
       "      <td>71696</td>\n",
       "      <td>81B2518F1</td>\n",
       "      <td>71528</td>\n",
       "      <td>81C0482E1</td>\n",
       "      <td>3.346900e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.346900e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924045</th>\n",
       "      <td>2022/09/10 23:48</td>\n",
       "      <td>271241</td>\n",
       "      <td>81B567481</td>\n",
       "      <td>173457</td>\n",
       "      <td>81C0DA751</td>\n",
       "      <td>1.313000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.313000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924046</th>\n",
       "      <td>2022/09/10 23:50</td>\n",
       "      <td>271241</td>\n",
       "      <td>81B567481</td>\n",
       "      <td>173457</td>\n",
       "      <td>81C0DA751</td>\n",
       "      <td>1.305800e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.305800e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924047</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>170558</td>\n",
       "      <td>81A2206B1</td>\n",
       "      <td>275798</td>\n",
       "      <td>81C1D5CA1</td>\n",
       "      <td>4.145370e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>4.145370e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924048</th>\n",
       "      <td>2022/09/10 23:31</td>\n",
       "      <td>170558</td>\n",
       "      <td>81A2206B1</td>\n",
       "      <td>275798</td>\n",
       "      <td>81C1D5CA1</td>\n",
       "      <td>3.427700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.427700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6924049 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0        2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
       "1        2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
       "2        2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
       "3        2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
       "4        2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
       "...                   ...        ...        ...      ...        ...   \n",
       "6924044  2022/09/10 23:39      71696  81B2518F1    71528  81C0482E1   \n",
       "6924045  2022/09/10 23:48     271241  81B567481   173457  81C0DA751   \n",
       "6924046  2022/09/10 23:50     271241  81B567481   173457  81C0DA751   \n",
       "6924047  2022/09/10 23:57     170558  81A2206B1   275798  81C1D5CA1   \n",
       "6924048  2022/09/10 23:31     170558  81A2206B1   275798  81C1D5CA1   \n",
       "\n",
       "         Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0           3.195403e+06          US Dollar  3.195403e+06        US Dollar   \n",
       "1           1.858960e+03          US Dollar  1.858960e+03        US Dollar   \n",
       "2           5.925710e+05          US Dollar  5.925710e+05        US Dollar   \n",
       "3           1.232000e+01          US Dollar  1.232000e+01        US Dollar   \n",
       "4           2.941560e+03          US Dollar  2.941560e+03        US Dollar   \n",
       "...                  ...                ...           ...              ...   \n",
       "6924044     3.346900e-02            Bitcoin  3.346900e-02          Bitcoin   \n",
       "6924045     1.313000e-03            Bitcoin  1.313000e-03          Bitcoin   \n",
       "6924046     1.305800e-02            Bitcoin  1.305800e-02          Bitcoin   \n",
       "6924047     4.145370e-01            Bitcoin  4.145370e-01          Bitcoin   \n",
       "6924048     3.427700e-02            Bitcoin  3.427700e-02          Bitcoin   \n",
       "\n",
       "        Payment Format  Is Laundering  \n",
       "0         Reinvestment              0  \n",
       "1         Reinvestment              0  \n",
       "2               Cheque              0  \n",
       "3         Reinvestment              0  \n",
       "4         Reinvestment              0  \n",
       "...                ...            ...  \n",
       "6924044        Bitcoin              0  \n",
       "6924045        Bitcoin              0  \n",
       "6924046        Bitcoin              0  \n",
       "6924047        Bitcoin              0  \n",
       "6924048        Bitcoin              0  \n",
       "\n",
       "[6924049 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LI_Small_Trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b89a8",
   "metadata": {},
   "source": [
    "# LI_Small_Trans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3978ffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.340000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.340000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.570000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.570000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078340</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>54219</td>\n",
       "      <td>8148A6631</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078341</th>\n",
       "      <td>2022/09/10 23:35</td>\n",
       "      <td>15</td>\n",
       "      <td>8148A8671</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.108128</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.108128</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078342</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>154365</td>\n",
       "      <td>8148A6771</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078343</th>\n",
       "      <td>2022/09/10 23:46</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A6311</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078344</th>\n",
       "      <td>2022/09/10 23:37</td>\n",
       "      <td>154518</td>\n",
       "      <td>8148A6091</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.281983</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.281983</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5078345 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0        2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1        2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2        2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3        2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4        2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "...                   ...        ...        ...      ...        ...   \n",
       "5078340  2022/09/10 23:57      54219  8148A6631   256398  8148A8711   \n",
       "5078341  2022/09/10 23:35         15  8148A8671   256398  8148A8711   \n",
       "5078342  2022/09/10 23:52     154365  8148A6771   256398  8148A8711   \n",
       "5078343  2022/09/10 23:46     256398  8148A6311   256398  8148A8711   \n",
       "5078344  2022/09/10 23:37     154518  8148A6091   256398  8148A8711   \n",
       "\n",
       "         Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0            3697.340000          US Dollar   3697.340000        US Dollar   \n",
       "1               0.010000          US Dollar      0.010000        US Dollar   \n",
       "2           14675.570000          US Dollar  14675.570000        US Dollar   \n",
       "3            2806.970000          US Dollar   2806.970000        US Dollar   \n",
       "4           36682.970000          US Dollar  36682.970000        US Dollar   \n",
       "...                  ...                ...           ...              ...   \n",
       "5078340         0.154978            Bitcoin      0.154978          Bitcoin   \n",
       "5078341         0.108128            Bitcoin      0.108128          Bitcoin   \n",
       "5078342         0.004988            Bitcoin      0.004988          Bitcoin   \n",
       "5078343         0.038417            Bitcoin      0.038417          Bitcoin   \n",
       "5078344         0.281983            Bitcoin      0.281983          Bitcoin   \n",
       "\n",
       "        Payment Format  Is Laundering  \n",
       "0         Reinvestment              0  \n",
       "1               Cheque              0  \n",
       "2         Reinvestment              0  \n",
       "3         Reinvestment              0  \n",
       "4         Reinvestment              0  \n",
       "...                ...            ...  \n",
       "5078340        Bitcoin              0  \n",
       "5078341        Bitcoin              0  \n",
       "5078342        Bitcoin              0  \n",
       "5078343        Bitcoin              0  \n",
       "5078344        Bitcoin              0  \n",
       "\n",
       "[5078345 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HI_Small_Trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f4376",
   "metadata": {},
   "source": [
    "# Merge two dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec4ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:08</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:21</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>1120</td>\n",
       "      <td>8006AA910</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002389</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>54219</td>\n",
       "      <td>8148A6631</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>1.549780e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.549780e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002390</th>\n",
       "      <td>2022/09/10 23:35</td>\n",
       "      <td>15</td>\n",
       "      <td>8148A8671</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>1.081280e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.081280e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002391</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>154365</td>\n",
       "      <td>8148A6771</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>4.988000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>4.988000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002392</th>\n",
       "      <td>2022/09/10 23:46</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A6311</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>3.841700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.841700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002393</th>\n",
       "      <td>2022/09/10 23:37</td>\n",
       "      <td>154518</td>\n",
       "      <td>8148A6091</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>2.819830e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>2.819830e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12002394 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0         2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
       "1         2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
       "2         2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
       "3         2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
       "4         2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
       "...                    ...        ...        ...      ...        ...   \n",
       "12002389  2022/09/10 23:57      54219  8148A6631   256398  8148A8711   \n",
       "12002390  2022/09/10 23:35         15  8148A8671   256398  8148A8711   \n",
       "12002391  2022/09/10 23:52     154365  8148A6771   256398  8148A8711   \n",
       "12002392  2022/09/10 23:46     256398  8148A6311   256398  8148A8711   \n",
       "12002393  2022/09/10 23:37     154518  8148A6091   256398  8148A8711   \n",
       "\n",
       "          Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0            3.195403e+06          US Dollar  3.195403e+06        US Dollar   \n",
       "1            1.858960e+03          US Dollar  1.858960e+03        US Dollar   \n",
       "2            5.925710e+05          US Dollar  5.925710e+05        US Dollar   \n",
       "3            1.232000e+01          US Dollar  1.232000e+01        US Dollar   \n",
       "4            2.941560e+03          US Dollar  2.941560e+03        US Dollar   \n",
       "...                   ...                ...           ...              ...   \n",
       "12002389     1.549780e-01            Bitcoin  1.549780e-01          Bitcoin   \n",
       "12002390     1.081280e-01            Bitcoin  1.081280e-01          Bitcoin   \n",
       "12002391     4.988000e-03            Bitcoin  4.988000e-03          Bitcoin   \n",
       "12002392     3.841700e-02            Bitcoin  3.841700e-02          Bitcoin   \n",
       "12002393     2.819830e-01            Bitcoin  2.819830e-01          Bitcoin   \n",
       "\n",
       "         Payment Format  Is Laundering  \n",
       "0          Reinvestment              0  \n",
       "1          Reinvestment              0  \n",
       "2                Cheque              0  \n",
       "3          Reinvestment              0  \n",
       "4          Reinvestment              0  \n",
       "...                 ...            ...  \n",
       "12002389        Bitcoin              0  \n",
       "12002390        Bitcoin              0  \n",
       "12002391        Bitcoin              0  \n",
       "12002392        Bitcoin              0  \n",
       "12002393        Bitcoin              0  \n",
       "\n",
       "[12002394 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12002394 entries, 0 to 12002393\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Timestamp           object \n",
      " 1   From Bank           int64  \n",
      " 2   Account             object \n",
      " 3   To Bank             int64  \n",
      " 4   Account.1           object \n",
      " 5   Amount Received     float64\n",
      " 6   Receiving Currency  object \n",
      " 7   Amount Paid         float64\n",
      " 8   Payment Currency    object \n",
      " 9   Payment Format      object \n",
      " 10  Is Laundering       int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 1007.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp               15133\n",
       "From Bank               57222\n",
       "Account               1166980\n",
       "To Bank                 33608\n",
       "Account.1              988911\n",
       "Amount Received       1835635\n",
       "Receiving Currency         15\n",
       "Amount Paid           1850741\n",
       "Payment Currency           15\n",
       "Payment Format              7\n",
       "Is Laundering               2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11993652\n",
      "1        8742\n",
      "Name: Is Laundering, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/09 08:09</td>\n",
       "      <td>8595</td>\n",
       "      <td>8067D10B0</td>\n",
       "      <td>13327</td>\n",
       "      <td>80A56F9A0</td>\n",
       "      <td>59.63</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>59.63</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/05 03:28</td>\n",
       "      <td>1362</td>\n",
       "      <td>80075DF40</td>\n",
       "      <td>11974</td>\n",
       "      <td>805837910</td>\n",
       "      <td>62.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>62.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 05:31</td>\n",
       "      <td>15</td>\n",
       "      <td>803A61820</td>\n",
       "      <td>15</td>\n",
       "      <td>803A61820</td>\n",
       "      <td>55.64</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5864.32</td>\n",
       "      <td>Yen</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/06 11:12</td>\n",
       "      <td>19229</td>\n",
       "      <td>807D437B0</td>\n",
       "      <td>26179</td>\n",
       "      <td>816D93DF0</td>\n",
       "      <td>167.19</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>167.19</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/08 10:33</td>\n",
       "      <td>16136</td>\n",
       "      <td>813336280</td>\n",
       "      <td>6803</td>\n",
       "      <td>8133099F0</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>2022/09/08 00:49</td>\n",
       "      <td>2692</td>\n",
       "      <td>8058DC1E0</td>\n",
       "      <td>28644</td>\n",
       "      <td>819732C60</td>\n",
       "      <td>279.70</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>279.70</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>2022/09/01 21:43</td>\n",
       "      <td>11047</td>\n",
       "      <td>803623930</td>\n",
       "      <td>24950</td>\n",
       "      <td>80386E260</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Wire</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>2022/09/06 07:27</td>\n",
       "      <td>11318</td>\n",
       "      <td>800A50A30</td>\n",
       "      <td>2845</td>\n",
       "      <td>803A0E1D0</td>\n",
       "      <td>87.74</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>87.74</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>2022/09/10 03:46</td>\n",
       "      <td>394</td>\n",
       "      <td>800528960</td>\n",
       "      <td>238579</td>\n",
       "      <td>8110143D0</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>2022/09/04 01:34</td>\n",
       "      <td>2439</td>\n",
       "      <td>804E5F010</td>\n",
       "      <td>22205</td>\n",
       "      <td>8064612A0</td>\n",
       "      <td>226.43</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>226.43</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0       2022/09/09 08:09       8595  8067D10B0    13327  80A56F9A0   \n",
       "1       2022/09/05 03:28       1362  80075DF40    11974  805837910   \n",
       "2       2022/09/01 05:31         15  803A61820       15  803A61820   \n",
       "3       2022/09/06 11:12      19229  807D437B0    26179  816D93DF0   \n",
       "4       2022/09/08 10:33      16136  813336280     6803  8133099F0   \n",
       "...                  ...        ...        ...      ...        ...   \n",
       "299995  2022/09/08 00:49       2692  8058DC1E0    28644  819732C60   \n",
       "299996  2022/09/01 21:43      11047  803623930    24950  80386E260   \n",
       "299997  2022/09/06 07:27      11318  800A50A30     2845  803A0E1D0   \n",
       "299998  2022/09/10 03:46        394  800528960   238579  8110143D0   \n",
       "299999  2022/09/04 01:34       2439  804E5F010    22205  8064612A0   \n",
       "\n",
       "        Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0                 59.63          US Dollar        59.63        US Dollar   \n",
       "1                 62.07          US Dollar        62.07        US Dollar   \n",
       "2                 55.64          US Dollar      5864.32              Yen   \n",
       "3                167.19          US Dollar       167.19        US Dollar   \n",
       "4               4766.10          US Dollar      4766.10        US Dollar   \n",
       "...                 ...                ...          ...              ...   \n",
       "299995           279.70          US Dollar       279.70        US Dollar   \n",
       "299996          5906.84          US Dollar      5906.84        US Dollar   \n",
       "299997            87.74          US Dollar        87.74        US Dollar   \n",
       "299998          1114.42          US Dollar      1114.42        US Dollar   \n",
       "299999           226.43          US Dollar       226.43        US Dollar   \n",
       "\n",
       "       Payment Format  Is Laundering  \n",
       "0              Cheque              0  \n",
       "1              Cheque              0  \n",
       "2                 ACH              0  \n",
       "3              Cheque              0  \n",
       "4                 ACH              0  \n",
       "...               ...            ...  \n",
       "299995         Cheque              0  \n",
       "299996           Wire              0  \n",
       "299997         Cheque              0  \n",
       "299998         Cheque              0  \n",
       "299999    Credit Card              0  \n",
       "\n",
       "[300000 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_Small_df = pd.concat([LI_Small_Trans, HI_Small_Trans], ignore_index=True)\n",
    "display(merged_Small_df)\n",
    "display(merged_Small_df.info())\n",
    "display(merged_Small_df.nunique())\n",
    "value_counts = merged_Small_df['Is Laundering'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "merged_Small_df = merged_Small_df[merged_Small_df['Receiving Currency'] == 'US Dollar']\n",
    "merged_Small_df = merged_Small_df.sample(n=300000, random_state=42)\n",
    "merged_Small_df = merged_Small_df.reset_index(drop=True)\n",
    "merged_Small_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ae0ee",
   "metadata": {},
   "source": [
    "# X independent and Y dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7f3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Account_Grouped</th>\n",
       "      <th>Account1_Grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/09 08:09</td>\n",
       "      <td>8595</td>\n",
       "      <td>8067D10B0</td>\n",
       "      <td>13327</td>\n",
       "      <td>80A56F9A0</td>\n",
       "      <td>59.63</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>59.63</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>10B0</td>\n",
       "      <td>F9A0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/05 03:28</td>\n",
       "      <td>1362</td>\n",
       "      <td>80075DF40</td>\n",
       "      <td>11974</td>\n",
       "      <td>805837910</td>\n",
       "      <td>62.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>62.07</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>DF40</td>\n",
       "      <td>7910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 05:31</td>\n",
       "      <td>15</td>\n",
       "      <td>803A61820</td>\n",
       "      <td>15</td>\n",
       "      <td>803A61820</td>\n",
       "      <td>55.64</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5864.32</td>\n",
       "      <td>Yen</td>\n",
       "      <td>ACH</td>\n",
       "      <td>1820</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/06 11:12</td>\n",
       "      <td>19229</td>\n",
       "      <td>807D437B0</td>\n",
       "      <td>26179</td>\n",
       "      <td>816D93DF0</td>\n",
       "      <td>167.19</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>167.19</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>37B0</td>\n",
       "      <td>3DF0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/08 10:33</td>\n",
       "      <td>16136</td>\n",
       "      <td>813336280</td>\n",
       "      <td>6803</td>\n",
       "      <td>8133099F0</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>6280</td>\n",
       "      <td>99F0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>2022/09/08 00:49</td>\n",
       "      <td>2692</td>\n",
       "      <td>8058DC1E0</td>\n",
       "      <td>28644</td>\n",
       "      <td>819732C60</td>\n",
       "      <td>279.70</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>279.70</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>C1E0</td>\n",
       "      <td>2C60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>2022/09/01 21:43</td>\n",
       "      <td>11047</td>\n",
       "      <td>803623930</td>\n",
       "      <td>24950</td>\n",
       "      <td>80386E260</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Wire</td>\n",
       "      <td>3930</td>\n",
       "      <td>E260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>2022/09/06 07:27</td>\n",
       "      <td>11318</td>\n",
       "      <td>800A50A30</td>\n",
       "      <td>2845</td>\n",
       "      <td>803A0E1D0</td>\n",
       "      <td>87.74</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>87.74</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0A30</td>\n",
       "      <td>E1D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>2022/09/10 03:46</td>\n",
       "      <td>394</td>\n",
       "      <td>800528960</td>\n",
       "      <td>238579</td>\n",
       "      <td>8110143D0</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>8960</td>\n",
       "      <td>43D0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>2022/09/04 01:34</td>\n",
       "      <td>2439</td>\n",
       "      <td>804E5F010</td>\n",
       "      <td>22205</td>\n",
       "      <td>8064612A0</td>\n",
       "      <td>226.43</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>226.43</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>F010</td>\n",
       "      <td>12A0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0       2022/09/09 08:09       8595  8067D10B0    13327  80A56F9A0   \n",
       "1       2022/09/05 03:28       1362  80075DF40    11974  805837910   \n",
       "2       2022/09/01 05:31         15  803A61820       15  803A61820   \n",
       "3       2022/09/06 11:12      19229  807D437B0    26179  816D93DF0   \n",
       "4       2022/09/08 10:33      16136  813336280     6803  8133099F0   \n",
       "...                  ...        ...        ...      ...        ...   \n",
       "299995  2022/09/08 00:49       2692  8058DC1E0    28644  819732C60   \n",
       "299996  2022/09/01 21:43      11047  803623930    24950  80386E260   \n",
       "299997  2022/09/06 07:27      11318  800A50A30     2845  803A0E1D0   \n",
       "299998  2022/09/10 03:46        394  800528960   238579  8110143D0   \n",
       "299999  2022/09/04 01:34       2439  804E5F010    22205  8064612A0   \n",
       "\n",
       "        Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "0                 59.63          US Dollar        59.63        US Dollar   \n",
       "1                 62.07          US Dollar        62.07        US Dollar   \n",
       "2                 55.64          US Dollar      5864.32              Yen   \n",
       "3                167.19          US Dollar       167.19        US Dollar   \n",
       "4               4766.10          US Dollar      4766.10        US Dollar   \n",
       "...                 ...                ...          ...              ...   \n",
       "299995           279.70          US Dollar       279.70        US Dollar   \n",
       "299996          5906.84          US Dollar      5906.84        US Dollar   \n",
       "299997            87.74          US Dollar        87.74        US Dollar   \n",
       "299998          1114.42          US Dollar      1114.42        US Dollar   \n",
       "299999           226.43          US Dollar       226.43        US Dollar   \n",
       "\n",
       "       Payment Format Account_Grouped Account1_Grouped  \n",
       "0              Cheque            10B0             F9A0  \n",
       "1              Cheque            DF40             7910  \n",
       "2                 ACH            1820             1820  \n",
       "3              Cheque            37B0             3DF0  \n",
       "4                 ACH            6280             99F0  \n",
       "...               ...             ...              ...  \n",
       "299995         Cheque            C1E0             2C60  \n",
       "299996           Wire            3930             E260  \n",
       "299997         Cheque            0A30             E1D0  \n",
       "299998         Cheque            8960             43D0  \n",
       "299999    Credit Card            F010             12A0  \n",
       "\n",
       "[300000 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "299995    0\n",
       "299996    0\n",
       "299997    0\n",
       "299998    0\n",
       "299999    0\n",
       "Name: Is Laundering, Length: 300000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to extract last 4 characters from account (as string)\n",
    "def last_4_digits(val):\n",
    "    if pd.isna(val):\n",
    "        return 'UNK'  # For missing values\n",
    "    return str(val)[-4:]\n",
    "\n",
    "# Apply it to high-cardinality object columns\n",
    "merged_Small_df['Account_Grouped'] = merged_Small_df['Account'].apply(last_4_digits)\n",
    "merged_Small_df['Account1_Grouped'] = merged_Small_df['Account.1'].apply(last_4_digits)\n",
    "\n",
    "X = merged_Small_df.drop(columns='Is Laundering')\n",
    "y = merged_Small_df['Is Laundering']\n",
    "\n",
    "print(\"X:\\n\")\n",
    "display(X)\n",
    "\n",
    "print(\"Y:\\n\")\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87c767",
   "metadata": {},
   "source": [
    "# Things I did for X.\n",
    "\n",
    "- Convert Timestamp into columns like i.e., {hour, day, weekday, and month}.\n",
    "- For Account_Grouped and Account1_Grouped columns,\n",
    "    - Extract first two letters (if present)\n",
    "    - Collect the digits at the end (whatever part is numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc00b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>timestamp_column_name</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>Payment Format_Cheque</th>\n",
       "      <th>Payment Format_Credit Card</th>\n",
       "      <th>Payment Format_Reinvestment</th>\n",
       "      <th>Payment Format_Wire</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8595</td>\n",
       "      <td>13327</td>\n",
       "      <td>59.63</td>\n",
       "      <td>59.63</td>\n",
       "      <td>2022-09-09 08:09:00</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1362</td>\n",
       "      <td>11974</td>\n",
       "      <td>62.07</td>\n",
       "      <td>62.07</td>\n",
       "      <td>2022-09-05 03:28:00</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>55.64</td>\n",
       "      <td>5864.32</td>\n",
       "      <td>2022-09-01 05:31:00</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1820</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19229</td>\n",
       "      <td>26179</td>\n",
       "      <td>167.19</td>\n",
       "      <td>167.19</td>\n",
       "      <td>2022-09-06 11:12:00</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16136</td>\n",
       "      <td>6803</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>2022-09-08 10:33:00</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6280</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>2692</td>\n",
       "      <td>28644</td>\n",
       "      <td>279.70</td>\n",
       "      <td>279.70</td>\n",
       "      <td>2022-09-08 00:49:00</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>11047</td>\n",
       "      <td>24950</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>2022-09-01 21:43:00</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3930</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>11318</td>\n",
       "      <td>2845</td>\n",
       "      <td>87.74</td>\n",
       "      <td>87.74</td>\n",
       "      <td>2022-09-06 07:27:00</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>394</td>\n",
       "      <td>238579</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>2022-09-10 03:46:00</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8960</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>2439</td>\n",
       "      <td>22205</td>\n",
       "      <td>226.43</td>\n",
       "      <td>226.43</td>\n",
       "      <td>2022-09-04 01:34:00</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank  To Bank  Amount Received  Amount Paid  \\\n",
       "0            8595    13327            59.63        59.63   \n",
       "1            1362    11974            62.07        62.07   \n",
       "2              15       15            55.64      5864.32   \n",
       "3           19229    26179           167.19       167.19   \n",
       "4           16136     6803          4766.10      4766.10   \n",
       "...           ...      ...              ...          ...   \n",
       "299995       2692    28644           279.70       279.70   \n",
       "299996      11047    24950          5906.84      5906.84   \n",
       "299997      11318     2845            87.74        87.74   \n",
       "299998        394   238579          1114.42      1114.42   \n",
       "299999       2439    22205           226.43       226.43   \n",
       "\n",
       "       timestamp_column_name  hour  day  weekday  month  \\\n",
       "0        2022-09-09 08:09:00     8    9        4      9   \n",
       "1        2022-09-05 03:28:00     3    5        0      9   \n",
       "2        2022-09-01 05:31:00     5    1        3      9   \n",
       "3        2022-09-06 11:12:00    11    6        1      9   \n",
       "4        2022-09-08 10:33:00    10    8        3      9   \n",
       "...                      ...   ...  ...      ...    ...   \n",
       "299995   2022-09-08 00:49:00     0    8        3      9   \n",
       "299996   2022-09-01 21:43:00    21    1        3      9   \n",
       "299997   2022-09-06 07:27:00     7    6        1      9   \n",
       "299998   2022-09-10 03:46:00     3   10        5      9   \n",
       "299999   2022-09-04 01:34:00     1    4        6      9   \n",
       "\n",
       "        Receiving Currency_US Dollar  ...  Payment Format_Cheque  \\\n",
       "0                                1.0  ...                    1.0   \n",
       "1                                1.0  ...                    1.0   \n",
       "2                                1.0  ...                    0.0   \n",
       "3                                1.0  ...                    1.0   \n",
       "4                                1.0  ...                    0.0   \n",
       "...                              ...  ...                    ...   \n",
       "299995                           1.0  ...                    1.0   \n",
       "299996                           1.0  ...                    0.0   \n",
       "299997                           1.0  ...                    1.0   \n",
       "299998                           1.0  ...                    1.0   \n",
       "299999                           1.0  ...                    0.0   \n",
       "\n",
       "        Payment Format_Credit Card  Payment Format_Reinvestment  \\\n",
       "0                              0.0                          0.0   \n",
       "1                              0.0                          0.0   \n",
       "2                              0.0                          0.0   \n",
       "3                              0.0                          0.0   \n",
       "4                              0.0                          0.0   \n",
       "...                            ...                          ...   \n",
       "299995                         0.0                          0.0   \n",
       "299996                         0.0                          0.0   \n",
       "299997                         0.0                          0.0   \n",
       "299998                         0.0                          0.0   \n",
       "299999                         1.0                          0.0   \n",
       "\n",
       "        Payment Format_Wire  AG_L1  AG_L2  AG_Num  AG1_L1  AG1_L2  AG1_Num  \n",
       "0                       0.0     -1     -1      10       5      -1        9  \n",
       "1                       0.0      3      5      40      -1      -1     7910  \n",
       "2                       0.0     -1     -1    1820      -1      -1     1820  \n",
       "3                       0.0     -1     -1      37      -1      -1        3  \n",
       "4                       0.0     -1     -1    6280      -1      -1       99  \n",
       "...                     ...    ...    ...     ...     ...     ...      ...  \n",
       "299995                  0.0      2     -1       1      -1      -1        2  \n",
       "299996                  1.0     -1     -1    3930       4      -1      260  \n",
       "299997                  0.0     -1     -1       0       4      -1        1  \n",
       "299998                  0.0     -1     -1    8960      -1      -1       43  \n",
       "299999                  0.0      5     -1      10      -1      -1       12  \n",
       "\n",
       "[300000 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "# Drop redundant columns\n",
    "X = X.drop(columns=['Account', 'Account.1'])\n",
    "\n",
    "# Convert string to datetime\n",
    "X['timestamp_column_name'] = pd.to_datetime(X['Timestamp'])\n",
    "\n",
    "# Extract datetime features\n",
    "X['hour'] = X['timestamp_column_name'].dt.hour\n",
    "X['day'] = X['timestamp_column_name'].dt.day\n",
    "X['weekday'] = X['timestamp_column_name'].dt.weekday\n",
    "X['month'] = X['timestamp_column_name'].dt.month\n",
    "\n",
    "X = X.drop(['Timestamp'], axis=1)\n",
    "\n",
    "# One-hot encode selected categorical columns\n",
    "categorical_cols = ['Receiving Currency', 'Payment Currency', 'Payment Format']\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_array = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_array,\n",
    "    columns=encoder.get_feature_names_out(categorical_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "X = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "\n",
    "def fast_encode_account_grouped(df, column_name, prefix):\n",
    "    col = df[column_name].astype(str).str.strip()\n",
    "\n",
    "    # Extract first two letters\n",
    "    letters = col.str.extract(r'([A-Za-z])?([A-Za-z])?')\n",
    "    digits = col.str.extract(r'(\\d+)')\n",
    "\n",
    "    l1 = letters[0].str.upper().apply(lambda x: ord(x) - ord('A') if pd.notnull(x) else -1)\n",
    "    l2 = letters[1].str.upper().apply(lambda x: ord(x) - ord('A') if pd.notnull(x) else -1)\n",
    "    num = digits[0].fillna(-1).astype(int)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        f'{prefix}_L1': l1,\n",
    "        f'{prefix}_L2': l2,\n",
    "        f'{prefix}_Num': num\n",
    "    }, index=df.index)\n",
    "\n",
    "# Apply vectorized encoding\n",
    "X = pd.concat([\n",
    "    X,\n",
    "    fast_encode_account_grouped(X, 'Account_Grouped', 'AG'),\n",
    "    fast_encode_account_grouped(X, 'Account1_Grouped', 'AG1')\n",
    "], axis=1)\n",
    "\n",
    "X.drop(columns=['Account_Grouped', 'Account1_Grouped'], inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f1307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "299995    0\n",
       "299996    0\n",
       "299997    0\n",
       "299998    0\n",
       "299999    0\n",
       "Name: Is Laundering, Length: 300000, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33222f07",
   "metadata": {},
   "source": [
    "# Now, Oversample (SMOTE) and Undersample Majority Class.\n",
    "\n",
    "- We will get new balanced data -- X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf0c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp_column_name'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8595</td>\n",
       "      <td>13327</td>\n",
       "      <td>59.63</td>\n",
       "      <td>59.63</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>9</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1362</td>\n",
       "      <td>11974</td>\n",
       "      <td>62.07</td>\n",
       "      <td>62.07</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>40</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7910</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>55.64</td>\n",
       "      <td>5864.32</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1820</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1820</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19229</td>\n",
       "      <td>26179</td>\n",
       "      <td>167.19</td>\n",
       "      <td>167.19</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>37</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16136</td>\n",
       "      <td>6803</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>4766.10</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>6280</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>99</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>2692</td>\n",
       "      <td>28644</td>\n",
       "      <td>279.70</td>\n",
       "      <td>279.70</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>11047</td>\n",
       "      <td>24950</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>5906.84</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>3930</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>260</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>11318</td>\n",
       "      <td>2845</td>\n",
       "      <td>87.74</td>\n",
       "      <td>87.74</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>394</td>\n",
       "      <td>238579</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>1114.42</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>8960</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>43</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>2439</td>\n",
       "      <td>22205</td>\n",
       "      <td>226.43</td>\n",
       "      <td>226.43</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>10</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>12</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank  To Bank  Amount Received  Amount Paid  hour  day  weekday  \\\n",
       "0            8595    13327            59.63        59.63     8    9        4   \n",
       "1            1362    11974            62.07        62.07     3    5        0   \n",
       "2              15       15            55.64      5864.32     5    1        3   \n",
       "3           19229    26179           167.19       167.19    11    6        1   \n",
       "4           16136     6803          4766.10      4766.10    10    8        3   \n",
       "...           ...      ...              ...          ...   ...  ...      ...   \n",
       "299995       2692    28644           279.70       279.70     0    8        3   \n",
       "299996      11047    24950          5906.84      5906.84    21    1        3   \n",
       "299997      11318     2845            87.74        87.74     7    6        1   \n",
       "299998        394   238579          1114.42      1114.42     3   10        5   \n",
       "299999       2439    22205           226.43       226.43     1    4        6   \n",
       "\n",
       "        month  Receiving Currency_US Dollar  \\\n",
       "0           9                           1.0   \n",
       "1           9                           1.0   \n",
       "2           9                           1.0   \n",
       "3           9                           1.0   \n",
       "4           9                           1.0   \n",
       "...       ...                           ...   \n",
       "299995      9                           1.0   \n",
       "299996      9                           1.0   \n",
       "299997      9                           1.0   \n",
       "299998      9                           1.0   \n",
       "299999      9                           1.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...  AG_L1  AG_L2  AG_Num  AG1_L1  \\\n",
       "0                                      0.0  ...     -1     -1      10       5   \n",
       "1                                      0.0  ...      3      5      40      -1   \n",
       "2                                      0.0  ...     -1     -1    1820      -1   \n",
       "3                                      0.0  ...     -1     -1      37      -1   \n",
       "4                                      0.0  ...     -1     -1    6280      -1   \n",
       "...                                    ...  ...    ...    ...     ...     ...   \n",
       "299995                                 0.0  ...      2     -1       1      -1   \n",
       "299996                                 0.0  ...     -1     -1    3930       4   \n",
       "299997                                 0.0  ...     -1     -1       0       4   \n",
       "299998                                 0.0  ...     -1     -1    8960      -1   \n",
       "299999                                 0.0  ...      5     -1      10      -1   \n",
       "\n",
       "        AG1_L2  AG1_Num  timestamp_column_name_year  \\\n",
       "0           -1        9                        2022   \n",
       "1           -1     7910                        2022   \n",
       "2           -1     1820                        2022   \n",
       "3           -1        3                        2022   \n",
       "4           -1       99                        2022   \n",
       "...        ...      ...                         ...   \n",
       "299995      -1        2                        2022   \n",
       "299996      -1      260                        2022   \n",
       "299997      -1        1                        2022   \n",
       "299998      -1       43                        2022   \n",
       "299999      -1       12                        2022   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                                 9                          9   \n",
       "1                                 9                          5   \n",
       "2                                 9                          1   \n",
       "3                                 9                          6   \n",
       "4                                 9                          8   \n",
       "...                             ...                        ...   \n",
       "299995                            9                          8   \n",
       "299996                            9                          1   \n",
       "299997                            9                          6   \n",
       "299998                            9                         10   \n",
       "299999                            9                          4   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                                  9  \n",
       "1                                 28  \n",
       "2                                 31  \n",
       "3                                 12  \n",
       "4                                 33  \n",
       "...                              ...  \n",
       "299995                            49  \n",
       "299996                            43  \n",
       "299997                            27  \n",
       "299998                            46  \n",
       "299999                            34  \n",
       "\n",
       "[300000 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify datetime columns\n",
    "datetime_cols = X.select_dtypes(include=['datetime64']).columns\n",
    "print(datetime_cols)\n",
    "\n",
    "# Convert them into numeric features (like year, month, etc.)\n",
    "for col in datetime_cols:\n",
    "    X[f'{col}_year'] = X[col].dt.year\n",
    "    X[f'{col}_month'] = X[col].dt.month\n",
    "    X[f'{col}_day'] = X[col].dt.day\n",
    "    X[f'{col}_minute'] = X[col].dt.minute\n",
    "    # drop original datetime column\n",
    "    X.drop(columns=col, inplace=True)\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc194708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Bank                               int64\n",
      "To Bank                                 int64\n",
      "Amount Received                       float64\n",
      "Amount Paid                           float64\n",
      "hour                                    int64\n",
      "day                                     int64\n",
      "weekday                                 int64\n",
      "month                                   int64\n",
      "Receiving Currency_US Dollar          float64\n",
      "Payment Currency_Australian Dollar    float64\n",
      "Payment Currency_Bitcoin              float64\n",
      "Payment Currency_Brazil Real          float64\n",
      "Payment Currency_Canadian Dollar      float64\n",
      "Payment Currency_Euro                 float64\n",
      "Payment Currency_Mexican Peso         float64\n",
      "Payment Currency_Ruble                float64\n",
      "Payment Currency_Rupee                float64\n",
      "Payment Currency_Saudi Riyal          float64\n",
      "Payment Currency_Shekel               float64\n",
      "Payment Currency_Swiss Franc          float64\n",
      "Payment Currency_UK Pound             float64\n",
      "Payment Currency_US Dollar            float64\n",
      "Payment Currency_Yen                  float64\n",
      "Payment Currency_Yuan                 float64\n",
      "Payment Format_ACH                    float64\n",
      "Payment Format_Bitcoin                float64\n",
      "Payment Format_Cash                   float64\n",
      "Payment Format_Cheque                 float64\n",
      "Payment Format_Credit Card            float64\n",
      "Payment Format_Reinvestment           float64\n",
      "Payment Format_Wire                   float64\n",
      "AG_L1                                   int64\n",
      "AG_L2                                   int64\n",
      "AG_Num                                  int64\n",
      "AG1_L1                                  int64\n",
      "AG1_L2                                  int64\n",
      "AG1_Num                                 int64\n",
      "timestamp_column_name_year              int64\n",
      "timestamp_column_name_month             int64\n",
      "timestamp_column_name_day               int64\n",
      "timestamp_column_name_minute            int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.035392</td>\n",
       "      <td>1.842286e-08</td>\n",
       "      <td>1.842569e-08</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.031799</td>\n",
       "      <td>1.917683e-08</td>\n",
       "      <td>1.917966e-08</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.718993e-08</td>\n",
       "      <td>1.812102e-06</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.069523</td>\n",
       "      <td>5.165939e-08</td>\n",
       "      <td>5.166223e-08</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.203390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>1.472744e-06</td>\n",
       "      <td>1.472747e-06</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.076069</td>\n",
       "      <td>8.642551e-08</td>\n",
       "      <td>8.642834e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.066259</td>\n",
       "      <td>1.825238e-06</td>\n",
       "      <td>1.825241e-06</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393393</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>2.710898e-08</td>\n",
       "      <td>2.711181e-08</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>3.443579e-07</td>\n",
       "      <td>3.443607e-07</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.058969</td>\n",
       "      <td>6.996483e-08</td>\n",
       "      <td>6.996766e-08</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid      hour  \\\n",
       "0        0.022805  0.035392     1.842286e-08  1.842569e-08  0.347826   \n",
       "1        0.003614  0.031799     1.917683e-08  1.917966e-08  0.130435   \n",
       "2        0.000040  0.000040     1.718993e-08  1.812102e-06  0.217391   \n",
       "3        0.051019  0.069523     5.165939e-08  5.166223e-08  0.478261   \n",
       "4        0.042813  0.018067     1.472744e-06  1.472747e-06  0.434783   \n",
       "...           ...       ...              ...           ...       ...   \n",
       "299995   0.007142  0.076069     8.642551e-08  8.642834e-08  0.000000   \n",
       "299996   0.029310  0.066259     1.825238e-06  1.825241e-06  0.913043   \n",
       "299997   0.030029  0.007555     2.710898e-08  2.711181e-08  0.304348   \n",
       "299998   0.001045  0.633588     3.443579e-07  3.443607e-07  0.130435   \n",
       "299999   0.006471  0.058969     6.996483e-08  6.996766e-08  0.043478   \n",
       "\n",
       "             day   weekday  month  Receiving Currency_US Dollar  \\\n",
       "0       0.533333  0.666667    0.0                           0.0   \n",
       "1       0.266667  0.000000    0.0                           0.0   \n",
       "2       0.000000  0.500000    0.0                           0.0   \n",
       "3       0.333333  0.166667    0.0                           0.0   \n",
       "4       0.466667  0.500000    0.0                           0.0   \n",
       "...          ...       ...    ...                           ...   \n",
       "299995  0.466667  0.500000    0.0                           0.0   \n",
       "299996  0.000000  0.500000    0.0                           0.0   \n",
       "299997  0.333333  0.166667    0.0                           0.0   \n",
       "299998  0.600000  0.833333    0.0                           0.0   \n",
       "299999  0.200000  1.000000    0.0                           0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...  0.000000    0.0  0.001001   \n",
       "1                                      0.0  ...  0.666667    1.0  0.004004   \n",
       "2                                      0.0  ...  0.000000    0.0  0.182182   \n",
       "3                                      0.0  ...  0.000000    0.0  0.003704   \n",
       "4                                      0.0  ...  0.000000    0.0  0.628629   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "299995                                 0.0  ...  0.500000    0.0  0.000100   \n",
       "299996                                 0.0  ...  0.000000    0.0  0.393393   \n",
       "299997                                 0.0  ...  0.000000    0.0  0.000000   \n",
       "299998                                 0.0  ...  0.000000    0.0  0.896897   \n",
       "299999                                 0.0  ...  1.000000    0.0  0.001001   \n",
       "\n",
       "          AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0       1.000000     0.0  0.000901                         0.0   \n",
       "1       0.000000     0.0  0.791792                         0.0   \n",
       "2       0.000000     0.0  0.182182                         0.0   \n",
       "3       0.000000     0.0  0.000300                         0.0   \n",
       "4       0.000000     0.0  0.009910                         0.0   \n",
       "...          ...     ...       ...                         ...   \n",
       "299995  0.000000     0.0  0.000200                         0.0   \n",
       "299996  0.833333     0.0  0.026026                         0.0   \n",
       "299997  0.833333     0.0  0.000100                         0.0   \n",
       "299998  0.000000     0.0  0.004304                         0.0   \n",
       "299999  0.000000     0.0  0.001201                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                   0.533333   \n",
       "1                               0.0                   0.266667   \n",
       "2                               0.0                   0.000000   \n",
       "3                               0.0                   0.333333   \n",
       "4                               0.0                   0.466667   \n",
       "...                             ...                        ...   \n",
       "299995                          0.0                   0.466667   \n",
       "299996                          0.0                   0.000000   \n",
       "299997                          0.0                   0.333333   \n",
       "299998                          0.0                   0.600000   \n",
       "299999                          0.0                   0.200000   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.152542  \n",
       "1                           0.474576  \n",
       "2                           0.525424  \n",
       "3                           0.203390  \n",
       "4                           0.559322  \n",
       "...                              ...  \n",
       "299995                      0.830508  \n",
       "299996                      0.728814  \n",
       "299997                      0.457627  \n",
       "299998                      0.779661  \n",
       "299999                      0.576271  \n",
       "\n",
       "[300000 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.dtypes)\n",
    "\n",
    "# Normalization on X\n",
    "# y is already normalized.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "original_columns = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)  # Returns a NumPy array\n",
    "\n",
    "# Optionally convert back to DataFrame (to keep column names)\n",
    "X = pd.DataFrame(X, columns=original_columns)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332d481",
   "metadata": {},
   "source": [
    "# Split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ecfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Source: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "# Example: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # X scalered data.\n",
    "                                                    y, # y\n",
    "                                                    test_size=0.25, # test_size : float or int, default=None\n",
    "                                                    random_state=42, # random_state : int, RandomState instance or None, default=None\n",
    "                                                    shuffle=True, # shuffle : bool, default=True\n",
    "                                                    stratify=y) # stratify : array-like, default=None\n",
    "\n",
    "# Sort the index of X_train\n",
    "X_train = X_train.sort_index()\n",
    "\n",
    "# Sort the index of X_test\n",
    "X_test = X_test.sort_index()\n",
    "\n",
    "# Sort the index of y_train\n",
    "y_train = y_train.sort_index()\n",
    "\n",
    "# Sort the index of y_test\n",
    "y_test = y_test.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7e7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The predict_cols_scaled_df_X_train dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.022805</td>\n",
       "      <td>0.035392</td>\n",
       "      <td>1.842286e-08</td>\n",
       "      <td>1.842569e-08</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003614</td>\n",
       "      <td>0.031799</td>\n",
       "      <td>1.917683e-08</td>\n",
       "      <td>1.917966e-08</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.004004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.791792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051019</td>\n",
       "      <td>0.069523</td>\n",
       "      <td>5.165939e-08</td>\n",
       "      <td>5.166223e-08</td>\n",
       "      <td>0.478261</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003704</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.203390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.042813</td>\n",
       "      <td>0.018067</td>\n",
       "      <td>1.472744e-06</td>\n",
       "      <td>1.472747e-06</td>\n",
       "      <td>0.434783</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.628629</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.001860</td>\n",
       "      <td>0.005452</td>\n",
       "      <td>2.287808e-07</td>\n",
       "      <td>2.287837e-07</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299993</th>\n",
       "      <td>0.000594</td>\n",
       "      <td>0.003702</td>\n",
       "      <td>9.274434e-07</td>\n",
       "      <td>9.274462e-07</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.501502</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.685686</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.491525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299995</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.076069</td>\n",
       "      <td>8.642551e-08</td>\n",
       "      <td>8.642834e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.830508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299997</th>\n",
       "      <td>0.030029</td>\n",
       "      <td>0.007555</td>\n",
       "      <td>2.710898e-08</td>\n",
       "      <td>2.711181e-08</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.457627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299998</th>\n",
       "      <td>0.001045</td>\n",
       "      <td>0.633588</td>\n",
       "      <td>3.443579e-07</td>\n",
       "      <td>3.443607e-07</td>\n",
       "      <td>0.130435</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896897</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004304</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299999</th>\n",
       "      <td>0.006471</td>\n",
       "      <td>0.058969</td>\n",
       "      <td>6.996483e-08</td>\n",
       "      <td>6.996766e-08</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.576271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid      hour  \\\n",
       "0        0.022805  0.035392     1.842286e-08  1.842569e-08  0.347826   \n",
       "1        0.003614  0.031799     1.917683e-08  1.917966e-08  0.130435   \n",
       "3        0.051019  0.069523     5.165939e-08  5.166223e-08  0.478261   \n",
       "4        0.042813  0.018067     1.472744e-06  1.472747e-06  0.434783   \n",
       "6        0.001860  0.005452     2.287808e-07  2.287837e-07  0.173913   \n",
       "...           ...       ...              ...           ...       ...   \n",
       "299993   0.000594  0.003702     9.274434e-07  9.274462e-07  0.260870   \n",
       "299995   0.007142  0.076069     8.642551e-08  8.642834e-08  0.000000   \n",
       "299997   0.030029  0.007555     2.710898e-08  2.711181e-08  0.304348   \n",
       "299998   0.001045  0.633588     3.443579e-07  3.443607e-07  0.130435   \n",
       "299999   0.006471  0.058969     6.996483e-08  6.996766e-08  0.043478   \n",
       "\n",
       "             day   weekday  month  Receiving Currency_US Dollar  \\\n",
       "0       0.533333  0.666667    0.0                           0.0   \n",
       "1       0.266667  0.000000    0.0                           0.0   \n",
       "3       0.333333  0.166667    0.0                           0.0   \n",
       "4       0.466667  0.500000    0.0                           0.0   \n",
       "6       0.333333  0.166667    0.0                           0.0   \n",
       "...          ...       ...    ...                           ...   \n",
       "299993  0.000000  0.500000    0.0                           0.0   \n",
       "299995  0.466667  0.500000    0.0                           0.0   \n",
       "299997  0.333333  0.166667    0.0                           0.0   \n",
       "299998  0.600000  0.833333    0.0                           0.0   \n",
       "299999  0.200000  1.000000    0.0                           0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...  0.000000    0.0  0.001001   \n",
       "1                                      0.0  ...  0.666667    1.0  0.004004   \n",
       "3                                      0.0  ...  0.000000    0.0  0.003704   \n",
       "4                                      0.0  ...  0.000000    0.0  0.628629   \n",
       "6                                      0.0  ...  0.000000    0.0  0.000701   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "299993                                 0.0  ...  0.000000    0.0  0.501502   \n",
       "299995                                 0.0  ...  0.500000    0.0  0.000100   \n",
       "299997                                 0.0  ...  0.000000    0.0  0.000000   \n",
       "299998                                 0.0  ...  0.000000    0.0  0.896897   \n",
       "299999                                 0.0  ...  1.000000    0.0  0.001001   \n",
       "\n",
       "          AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0       1.000000     0.0  0.000901                         0.0   \n",
       "1       0.000000     0.0  0.791792                         0.0   \n",
       "3       0.000000     0.0  0.000300                         0.0   \n",
       "4       0.000000     0.0  0.009910                         0.0   \n",
       "6       0.333333     0.0  0.000701                         0.0   \n",
       "...          ...     ...       ...                         ...   \n",
       "299993  0.000000     0.0  0.685686                         0.0   \n",
       "299995  0.000000     0.0  0.000200                         0.0   \n",
       "299997  0.833333     0.0  0.000100                         0.0   \n",
       "299998  0.000000     0.0  0.004304                         0.0   \n",
       "299999  0.000000     0.0  0.001201                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                   0.533333   \n",
       "1                               0.0                   0.266667   \n",
       "3                               0.0                   0.333333   \n",
       "4                               0.0                   0.466667   \n",
       "6                               0.0                   0.333333   \n",
       "...                             ...                        ...   \n",
       "299993                          0.0                   0.000000   \n",
       "299995                          0.0                   0.466667   \n",
       "299997                          0.0                   0.333333   \n",
       "299998                          0.0                   0.600000   \n",
       "299999                          0.0                   0.200000   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.152542  \n",
       "1                           0.474576  \n",
       "3                           0.203390  \n",
       "4                           0.559322  \n",
       "6                           1.000000  \n",
       "...                              ...  \n",
       "299993                      0.491525  \n",
       "299995                      0.830508  \n",
       "299997                      0.457627  \n",
       "299998                      0.779661  \n",
       "299999                      0.576271  \n",
       "\n",
       "[225000 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe predict_cols_scaled_df_y_train dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "3         0\n",
       "4         0\n",
       "6         0\n",
       "         ..\n",
       "299993    0\n",
       "299995    0\n",
       "299997    0\n",
       "299998    0\n",
       "299999    0\n",
       "Name: Is Laundering, Length: 225000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    224836\n",
       "1       164\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the training dataset. X_train and y_train.\n",
    "display(\"The predict_cols_scaled_df_X_train dataset: \\n\", X_train)\n",
    "# y_train\n",
    "display(\"\\n\\nThe predict_cols_scaled_df_y_train dataset: \\n\", y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d2d33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The predict_cols_scaled_df_X_test dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000040</td>\n",
       "      <td>0.000040</td>\n",
       "      <td>1.718993e-08</td>\n",
       "      <td>1.812102e-06</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.182182</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.525424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.236019e-09</td>\n",
       "      <td>1.238852e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.254237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>7.298380e-08</td>\n",
       "      <td>7.298664e-08</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000901</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.898305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.041884</td>\n",
       "      <td>0.049544</td>\n",
       "      <td>7.776040e-07</td>\n",
       "      <td>7.776068e-07</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.988989</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055055</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.003266</td>\n",
       "      <td>0.623383</td>\n",
       "      <td>2.101231e-10</td>\n",
       "      <td>2.129570e-10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.008008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.474576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299979</th>\n",
       "      <td>0.058862</td>\n",
       "      <td>0.022090</td>\n",
       "      <td>1.937675e-07</td>\n",
       "      <td>1.937704e-07</td>\n",
       "      <td>0.304348</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.014014</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299982</th>\n",
       "      <td>0.043147</td>\n",
       "      <td>0.058263</td>\n",
       "      <td>9.041785e-08</td>\n",
       "      <td>9.042068e-08</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220220</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.983051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299991</th>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.584968</td>\n",
       "      <td>1.773374e-06</td>\n",
       "      <td>1.773377e-06</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000400</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.739740</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299994</th>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.450987</td>\n",
       "      <td>1.019000e-04</td>\n",
       "      <td>1.019000e-04</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.663664</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.169492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299996</th>\n",
       "      <td>0.029310</td>\n",
       "      <td>0.066259</td>\n",
       "      <td>1.825238e-06</td>\n",
       "      <td>1.825241e-06</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.393393</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.026026</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.728814</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75000 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid      hour  \\\n",
       "2        0.000040  0.000040     1.718993e-08  1.812102e-06  0.217391   \n",
       "5        0.000003  0.000003     1.236019e-09  1.238852e-09  0.000000   \n",
       "7        0.003428  0.003771     7.298380e-08  7.298664e-08  0.652174   \n",
       "13       0.041884  0.049544     7.776040e-07  7.776068e-07  0.913043   \n",
       "15       0.003266  0.623383     2.101231e-10  2.129570e-10  0.000000   \n",
       "...           ...       ...              ...           ...       ...   \n",
       "299979   0.058862  0.022090     1.937675e-07  1.937704e-07  0.304348   \n",
       "299982   0.043147  0.058263     9.041785e-08  9.042068e-08  0.347826   \n",
       "299991   0.000032  0.584968     1.773374e-06  1.773377e-06  0.782609   \n",
       "299994   0.059647  0.450987     1.019000e-04  1.019000e-04  0.652174   \n",
       "299996   0.029310  0.066259     1.825238e-06  1.825241e-06  0.913043   \n",
       "\n",
       "             day   weekday  month  Receiving Currency_US Dollar  \\\n",
       "2       0.000000  0.500000    0.0                           0.0   \n",
       "5       0.000000  0.500000    0.0                           0.0   \n",
       "7       0.333333  0.166667    0.0                           0.0   \n",
       "13      0.266667  0.000000    0.0                           0.0   \n",
       "15      0.000000  0.500000    0.0                           0.0   \n",
       "...          ...       ...    ...                           ...   \n",
       "299979  0.333333  0.166667    0.0                           0.0   \n",
       "299982  0.533333  0.666667    0.0                           0.0   \n",
       "299991  0.066667  0.666667    0.0                           0.0   \n",
       "299994  0.400000  0.333333    0.0                           0.0   \n",
       "299996  0.000000  0.500000    0.0                           0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "2                                      0.0  ...  0.000000    0.0  0.182182   \n",
       "5                                      0.0  ...  0.500000    0.0  0.000701   \n",
       "7                                      0.0  ...  0.500000    0.0  0.000901   \n",
       "13                                     0.0  ...  0.000000    0.0  0.988989   \n",
       "15                                     0.0  ...  0.000000    0.0  0.008008   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "299979                                 0.0  ...  0.000000    0.0  0.000701   \n",
       "299982                                 0.0  ...  0.000000    0.0  0.000501   \n",
       "299991                                 0.0  ...  0.833333    0.0  0.000400   \n",
       "299994                                 0.0  ...  0.000000    0.0  0.148148   \n",
       "299996                                 0.0  ...  0.000000    0.0  0.393393   \n",
       "\n",
       "          AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "2       0.000000     0.0  0.182182                         0.0   \n",
       "5       0.500000     0.0  0.000701                         0.0   \n",
       "7       0.000000     0.0  0.000100                         0.0   \n",
       "13      0.666667     0.0  0.055055                         0.0   \n",
       "15      0.000000     0.0  0.000601                         0.0   \n",
       "...          ...     ...       ...                         ...   \n",
       "299979  1.000000     0.0  0.014014                         0.0   \n",
       "299982  0.000000     0.0  0.220220                         0.0   \n",
       "299991  0.000000     0.0  0.739740                         0.0   \n",
       "299994  0.000000     0.0  0.663664                         0.0   \n",
       "299996  0.833333     0.0  0.026026                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "2                               0.0                   0.000000   \n",
       "5                               0.0                   0.000000   \n",
       "7                               0.0                   0.333333   \n",
       "13                              0.0                   0.266667   \n",
       "15                              0.0                   0.000000   \n",
       "...                             ...                        ...   \n",
       "299979                          0.0                   0.333333   \n",
       "299982                          0.0                   0.533333   \n",
       "299991                          0.0                   0.066667   \n",
       "299994                          0.0                   0.400000   \n",
       "299996                          0.0                   0.000000   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "2                           0.525424  \n",
       "5                           0.254237  \n",
       "7                           0.898305  \n",
       "13                          0.152542  \n",
       "15                          0.474576  \n",
       "...                              ...  \n",
       "299979                      0.305085  \n",
       "299982                      0.983051  \n",
       "299991                      0.000000  \n",
       "299994                      0.169492  \n",
       "299996                      0.728814  \n",
       "\n",
       "[75000 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe predict_cols_scaled_df_y_test dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2         0\n",
       "5         0\n",
       "7         0\n",
       "13        0\n",
       "15        0\n",
       "         ..\n",
       "299979    0\n",
       "299982    0\n",
       "299991    0\n",
       "299994    0\n",
       "299996    0\n",
       "Name: Is Laundering, Length: 75000, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    74946\n",
       "1       54\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the testing dataset. X_test and y_test.\n",
    "display(\"The predict_cols_scaled_df_X_test dataset: \\n\", X_test)\n",
    "# y_test\n",
    "display(\"\\n\\nThe predict_cols_scaled_df_y_test dataset: \\n\", y_test)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c24c2",
   "metadata": {},
   "source": [
    "# Balance the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754c9a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel processing with 2 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 done\n",
      "All batches processed and combined.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_US Dollar</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004349</td>\n",
       "      <td>0.067035</td>\n",
       "      <td>3.651570e-07</td>\n",
       "      <td>3.651598e-07</td>\n",
       "      <td>0.565217</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.400400</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.342399</td>\n",
       "      <td>0.343650</td>\n",
       "      <td>1.495502e-06</td>\n",
       "      <td>1.495505e-06</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.211211</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.677966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.300380</td>\n",
       "      <td>0.300657</td>\n",
       "      <td>4.264264e-09</td>\n",
       "      <td>4.267098e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.322034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.563859</td>\n",
       "      <td>0.635875</td>\n",
       "      <td>7.424238e-07</td>\n",
       "      <td>7.424266e-07</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.065065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.966102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.056402</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>4.017060e-11</td>\n",
       "      <td>4.300448e-11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533333</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449667</th>\n",
       "      <td>0.010467</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>2.375555e-06</td>\n",
       "      <td>2.375557e-06</td>\n",
       "      <td>0.770161</td>\n",
       "      <td>0.430981</td>\n",
       "      <td>0.410786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.105913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.430981</td>\n",
       "      <td>0.260286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449668</th>\n",
       "      <td>0.006533</td>\n",
       "      <td>0.445949</td>\n",
       "      <td>2.698246e-06</td>\n",
       "      <td>2.698249e-06</td>\n",
       "      <td>0.774102</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.746377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.884384</td>\n",
       "      <td>0.626812</td>\n",
       "      <td>0.159421</td>\n",
       "      <td>0.045850</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098551</td>\n",
       "      <td>0.624908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449669</th>\n",
       "      <td>0.007849</td>\n",
       "      <td>0.058979</td>\n",
       "      <td>5.923684e-07</td>\n",
       "      <td>5.923712e-07</td>\n",
       "      <td>0.743075</td>\n",
       "      <td>0.331821</td>\n",
       "      <td>0.162886</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.136730</td>\n",
       "      <td>0.651544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000623</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.331821</td>\n",
       "      <td>0.089359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449670</th>\n",
       "      <td>0.000012</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>2.217248e-06</td>\n",
       "      <td>2.217251e-06</td>\n",
       "      <td>0.656942</td>\n",
       "      <td>0.441462</td>\n",
       "      <td>0.436989</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.441462</td>\n",
       "      <td>0.334336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449671</th>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000679</td>\n",
       "      <td>7.200506e-07</td>\n",
       "      <td>7.200534e-07</td>\n",
       "      <td>0.389968</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>0.232309</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.359590</td>\n",
       "      <td>0.594523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>449672 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid      hour  \\\n",
       "0        0.004349  0.067035     3.651570e-07  3.651598e-07  0.565217   \n",
       "1        0.342399  0.343650     1.495502e-06  1.495505e-06  0.260870   \n",
       "2        0.300380  0.300657     4.264264e-09  4.267098e-09  0.000000   \n",
       "3        0.563859  0.635875     7.424238e-07  7.424266e-07  0.869565   \n",
       "4        0.056402  0.000032     4.017060e-11  4.300448e-11  0.000000   \n",
       "...           ...       ...              ...           ...       ...   \n",
       "449667   0.010467  0.005295     2.375555e-06  2.375557e-06  0.770161   \n",
       "449668   0.006533  0.445949     2.698246e-06  2.698249e-06  0.774102   \n",
       "449669   0.007849  0.058979     5.923684e-07  5.923712e-07  0.743075   \n",
       "449670   0.000012  0.002631     2.217248e-06  2.217251e-06  0.656942   \n",
       "449671   0.000043  0.000679     7.200506e-07  7.200534e-07  0.389968   \n",
       "\n",
       "             day   weekday  month  Receiving Currency_US Dollar  \\\n",
       "0       0.400000  0.333333    0.0                           0.0   \n",
       "1       0.533333  0.666667    0.0                           0.0   \n",
       "2       0.000000  0.500000    0.0                           0.0   \n",
       "3       0.333333  0.166667    0.0                           0.0   \n",
       "4       0.533333  0.666667    0.0                           0.0   \n",
       "...          ...       ...    ...                           ...   \n",
       "449667  0.430981  0.410786    0.0                           0.0   \n",
       "449668  0.098551  0.746377    0.0                           0.0   \n",
       "449669  0.331821  0.162886    0.0                           0.0   \n",
       "449670  0.441462  0.436989    0.0                           0.0   \n",
       "449671  0.359590  0.232309    0.0                           0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...  AG_L1     AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...    0.0  0.000000  0.400400   \n",
       "1                                      0.0  ...    0.0  0.000000  0.211211   \n",
       "2                                      0.0  ...    0.0  0.000000  0.000000   \n",
       "3                                      0.0  ...    1.0  0.000000  0.000501   \n",
       "4                                      0.0  ...    0.5  0.333333  0.000000   \n",
       "...                                    ...  ...    ...       ...       ...   \n",
       "449667                                 0.0  ...    0.0  0.000000  0.105913   \n",
       "449668                                 0.0  ...    0.0  0.000000  0.884384   \n",
       "449669                                 0.0  ...    0.0  0.000000  0.136730   \n",
       "449670                                 0.0  ...    0.0  0.000000  0.000076   \n",
       "449671                                 0.0  ...    0.0  0.000000  0.000322   \n",
       "\n",
       "          AG1_L1    AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0       0.833333  0.000000  0.056056                         0.0   \n",
       "1       1.000000  0.000000  0.032032                         0.0   \n",
       "2       0.000000  0.000000  0.000000                         0.0   \n",
       "3       0.833333  0.000000  0.065065                         0.0   \n",
       "4       0.000000  0.000000  0.000000                         0.0   \n",
       "...          ...       ...       ...                         ...   \n",
       "449667  0.000000  0.000000  0.001054                         0.0   \n",
       "449668  0.626812  0.159421  0.045850                         0.0   \n",
       "449669  0.651544  0.000000  0.000623                         0.0   \n",
       "449670  0.000000  0.000000  0.000057                         0.0   \n",
       "449671  0.000000  0.000000  0.000241                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                   0.400000   \n",
       "1                               0.0                   0.533333   \n",
       "2                               0.0                   0.000000   \n",
       "3                               0.0                   0.333333   \n",
       "4                               0.0                   0.533333   \n",
       "...                             ...                        ...   \n",
       "449667                          0.0                   0.430981   \n",
       "449668                          0.0                   0.098551   \n",
       "449669                          0.0                   0.331821   \n",
       "449670                          0.0                   0.441462   \n",
       "449671                          0.0                   0.359590   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.559322  \n",
       "1                           0.677966  \n",
       "2                           0.322034  \n",
       "3                           0.966102  \n",
       "4                           0.152542  \n",
       "...                              ...  \n",
       "449667                      0.260286  \n",
       "449668                      0.624908  \n",
       "449669                      0.089359  \n",
       "449670                      0.334336  \n",
       "449671                      0.594523  \n",
       "\n",
       "[449672 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a valid SMOTEENN instance with actual SMOTE\n",
    "def create_smoteenn():\n",
    "    return SMOTEENN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42,\n",
    "        smote=SMOTE(k_neighbors=3, n_jobs=-1),\n",
    "        enn=EditedNearestNeighbours(n_neighbors=3, n_jobs=-1),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Process one batch safely\n",
    "def process_batch(X_batch, y_batch, i):\n",
    "    try:\n",
    "        sme = create_smoteenn()\n",
    "        X_res, y_res = sme.fit_resample(X_batch, y_batch)\n",
    "        print(f\"Batch {i+1} done\")\n",
    "        return X_res, y_res\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping batch {i+1}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function: parallel + SMOTEENN\n",
    "def batchwise_smoteenn_fast(X, y, batch_size=200000, n_jobs=-1):\n",
    "    # Optional shuffle to randomize order\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    # Convert to NumPy for slicing\n",
    "    X_np = X.values if isinstance(X, pd.DataFrame) else X\n",
    "    y_np = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "    num_rows = len(X_np)\n",
    "    num_batches = (num_rows + batch_size - 1) // batch_size\n",
    "\n",
    "    # Prepare batches\n",
    "    batches = [\n",
    "        (X_np[i * batch_size : min((i + 1) * batch_size, num_rows)],\n",
    "         y_np[i * batch_size : min((i + 1) * batch_size, num_rows)], i)\n",
    "        for i in range(num_batches)\n",
    "    ]\n",
    "\n",
    "    print(f\"Starting parallel processing with {num_batches} batches...\")\n",
    "\n",
    "    # Run in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_batch)(*args) for args in batches\n",
    "    )\n",
    "\n",
    "    # Filter out failed batches\n",
    "    X_resampled_list = [r[0] for r in results if r is not None]\n",
    "    y_resampled_list = [r[1] for r in results if r is not None]\n",
    "\n",
    "    if not X_resampled_list:\n",
    "        raise ValueError(\"All batches failed. Nothing to concatenate.\")\n",
    "\n",
    "    # Combine\n",
    "    X_final = np.vstack(X_resampled_list)\n",
    "    y_final = np.hstack(y_resampled_list)\n",
    "\n",
    "    # Convert back to DataFrame/Series if needed\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_final = pd.DataFrame(X_final, columns=X.columns)\n",
    "    if isinstance(y, pd.Series):\n",
    "        y_final = pd.Series(y_final, name=y.name)\n",
    "\n",
    "    print(\"All batches processed and combined.\")\n",
    "    return X_final, y_final\n",
    "\n",
    "X_train, y_train = batchwise_smoteenn_fast(X_train, y_train, batch_size=200000, n_jobs=4)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932abf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "449667    1\n",
       "449668    1\n",
       "449669    1\n",
       "449670    1\n",
       "449671    1\n",
       "Name: Is Laundering, Length: 449672, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    224836\n",
       "1    224836\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b490f",
   "metadata": {},
   "source": [
    "# Compute the weight to y_train as we already balanced it in the earlier code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "125b5b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 1.0, 1: 1.0}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# numpy.ravel(a, order='C') : Return a contiguous flattened array.\n",
    "# A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "# sklearn.utils.class_weight.compute_class_weight(class_weight, *, classes, y)\n",
    "# Returns: class_weight_vect : ndarray of shape (n_classes,) : Array with class_weight_vect[i] the weight for i-th class.\n",
    "temp_compute_class_weight = compute_class_weight(class_weight=\"balanced\", # class_weight : dict, “balanced” or None\n",
    "                                                 classes=np.unique(y_train), # classes : ndarray\n",
    "                                                 y=y_train) # y : array-like of shape (n_samples,)\n",
    "\n",
    "# Classification and weighting.\n",
    "tempResClassWeight = {tempIdx: tempData1 for tempIdx, tempData1 in zip(np.unique(y_train, \n",
    "                                                                                 return_index=False, \n",
    "                                                                                 return_inverse=False, \n",
    "                                                                                 return_counts=False, \n",
    "                                                                                 axis=None, \n",
    "                                                                                 equal_nan=True), \n",
    "                                                                      temp_compute_class_weight)}\n",
    "\n",
    "# Show weight.\n",
    "tempResClassWeight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec5a38",
   "metadata": {},
   "source": [
    "# So, now, Data Processing work over. It's the most important step. Otherwise, we won't get best results. Now, off to 5 models to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacf8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.htmls\n",
    "# sklearn.metrics.make_scorer(score_func, *, response_method='default', greater_is_better=True, **kwargs)\n",
    "# Make a scorer from a performance metric or loss function.\n",
    "# A scorer is a wrapper around an arbitrary metric or loss function that is called with the signature scorer(estimator, X, y_true, **kwargs).\n",
    "# It is accepted in all scikit-learn estimators or functions allowing a scoring parameter.\n",
    "# The parameter response_method allows to specify which method of the estimator should be used to feed the scoring/loss function.\n",
    "# response_method{“predict_proba”, “decision_function”, “predict”} or list/tuple of such str, default=None\n",
    "# metrics_score_list = {\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "#     'accuracy_score' : make_scorer(accuracy_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "#     'precision_score' : make_scorer(precision_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.htmls\n",
    "#     'recall_scores' : make_scorer(recall_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "#     'roc_auc_score' : make_scorer(roc_auc_score),\n",
    "# }\n",
    "\n",
    "metrics_score_list = ['accuracy', # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "                      'precision', \n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.htmls\n",
    "                      'recall', \n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "                      'roc_auc',\n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "                     'f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afd834",
   "metadata": {},
   "source": [
    "# Model-1: Logistic Regression (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b65ce254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 done\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "\n",
      " The clf_LR_grid_search's results are: \n",
      " {'mean_fit_time': array([ 11.00436611,  10.94534891,  12.31549182,  20.01644452,\n",
      "       184.36612711]), 'std_fit_time': array([ 1.1820409 ,  0.4237284 ,  0.50728812,  3.79379417, 42.75363091]), 'mean_score_time': array([0.16799016, 0.16265452, 0.16800206, 0.35712171, 0.35973287]), 'std_score_time': array([0.01218819, 0.00751093, 0.02314737, 0.09462985, 0.06614076]), 'param_clf_LR__C': masked_array(data=[0.01, 0.1, 0.2, 1, 10],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_LR__C': 0.01}, {'clf_LR__C': 0.1}, {'clf_LR__C': 0.2}, {'clf_LR__C': 1}, {'clf_LR__C': 10}], 'split0_test_accuracy': array([0.87804661, 0.87882494, 0.87882494, 0.8788027 , 0.87882494]), 'split1_test_accuracy': array([0.87969223, 0.88018146, 0.88018146, 0.88024818, 0.88029265]), 'split2_test_accuracy': array([0.87964507, 0.88008984, 0.88011208, 0.88011208, 0.88020104]), 'split3_test_accuracy': array([0.8789112 , 0.87962283, 0.87973403, 0.87973403, 0.87975627]), 'split4_test_accuracy': array([0.87915583, 0.88020104, 0.88022327, 0.88022327, 0.88024551]), 'split5_test_accuracy': array([0.87873329, 0.87951164, 0.8794894 , 0.8794894 , 0.87951164]), 'split6_test_accuracy': array([0.88164654, 0.88224698, 0.88235817, 0.88244713, 0.88253608]), 'split7_test_accuracy': array([0.88091267, 0.88153535, 0.88155759, 0.88151311, 0.88157983]), 'split8_test_accuracy': array([0.87928926, 0.88004537, 0.88015656, 0.88015656, 0.88026775]), 'split9_test_accuracy': array([0.90806592, 0.90811039, 0.90811039, 0.90813263, 0.90819935]), 'mean_test_accuracy': array([0.88240986, 0.88303698, 0.88307479, 0.88308591, 0.88314151]), 'std_test_accuracy': array([0.00860935, 0.00840959, 0.00839923, 0.00840481, 0.00841057]), 'rank_test_accuracy': array([5, 4, 3, 2, 1], dtype=int32), 'split0_test_precision': array([0.88405928, 0.88344663, 0.88334308, 0.88323434, 0.88327409]), 'split1_test_precision': array([0.88534802, 0.88438709, 0.88414525, 0.88416086, 0.8842058 ]), 'split2_test_precision': array([0.88679929, 0.88574911, 0.88561502, 0.88547587, 0.8855313 ]), 'split3_test_precision': array([0.88484821, 0.8844941 , 0.88455475, 0.88441623, 0.88445605]), 'split4_test_precision': array([0.88591607, 0.88577489, 0.88571042, 0.88560603, 0.88561119]), 'split5_test_precision': array([0.88567805, 0.88481486, 0.88477496, 0.88470556, 0.88474546]), 'split6_test_precision': array([0.88782428, 0.88708733, 0.88711275, 0.88706338, 0.88711855]), 'split7_test_precision': array([0.88664169, 0.88629711, 0.88605886, 0.88584023, 0.88589034]), 'split8_test_precision': array([0.88553345, 0.88456346, 0.88462404, 0.88448563, 0.88464999]), 'split9_test_precision': array([0.88992775, 0.88907734, 0.88901136, 0.88895011, 0.8889972 ]), 'mean_test_precision': array([0.88625761, 0.88556919, 0.88549505, 0.88539382, 0.885448  ]), 'std_test_precision': array([0.00158078, 0.00154452, 0.00154837, 0.00155317, 0.0015492 ]), 'rank_test_precision': array([1, 2, 3, 5, 4], dtype=int32), 'split0_test_recall': array([0.87021882, 0.87279843, 0.87293186, 0.87302081, 0.87302081]), 'split1_test_recall': array([0.87235367, 0.87471091, 0.87502224, 0.87515567, 0.87520014]), 'split2_test_recall': array([0.87039096, 0.8727483 , 0.87297069, 0.8731486 , 0.87328204]), 'split3_test_recall': array([0.87119157, 0.87328204, 0.87345995, 0.87363786, 0.87363786]), 'split4_test_recall': array([0.87039096, 0.87297069, 0.87310412, 0.87323756, 0.87328204]), 'split5_test_recall': array([0.86972379, 0.87261486, 0.87261486, 0.87270382, 0.87270382]), 'split6_test_recall': array([0.87368796, 0.87600071, 0.87622309, 0.87648995, 0.87662338]), 'split7_test_recall': array([0.87351005, 0.87537805, 0.87573386, 0.87591176, 0.87600071]), 'split8_test_recall': array([0.8711973 , 0.87417719, 0.8743551 , 0.874533  , 0.87457748]), 'split9_test_recall': array([0.93132895, 0.93257428, 0.93266323, 0.93279666, 0.93288561]), 'mean_test_recall': array([0.8773994 , 0.87972555, 0.8799079 , 0.88006357, 0.88012139]), 'std_test_recall': array([0.01802352, 0.01765239, 0.01762576, 0.01762081, 0.0176331 ]), 'rank_test_recall': array([5, 4, 3, 2, 1], dtype=int32), 'split0_test_roc_auc': array([0.93239823, 0.93242605, 0.93241048, 0.93239995, 0.93244597]), 'split1_test_roc_auc': array([0.93329645, 0.93324724, 0.93323815, 0.93324513, 0.93332642]), 'split2_test_roc_auc': array([0.93170903, 0.93162553, 0.93160545, 0.9315903 , 0.93163286]), 'split3_test_roc_auc': array([0.93279835, 0.93281321, 0.93280429, 0.93280456, 0.93284708]), 'split4_test_roc_auc': array([0.93337488, 0.93334634, 0.93333192, 0.93332572, 0.93337219]), 'split5_test_roc_auc': array([0.9326419 , 0.93270455, 0.93270737, 0.93271571, 0.93275581]), 'split6_test_roc_auc': array([0.93382449, 0.93385562, 0.93384233, 0.93383096, 0.93386846]), 'split7_test_roc_auc': array([0.93405785, 0.93401977, 0.93400685, 0.93399688, 0.93403666]), 'split8_test_roc_auc': array([0.93214538, 0.93213391, 0.93212326, 0.93212692, 0.93220074]), 'split9_test_roc_auc': array([0.94066665, 0.94076915, 0.94078133, 0.94080712, 0.9408839 ]), 'mean_test_roc_auc': array([0.93369132, 0.93369414, 0.93368514, 0.93368433, 0.93373701]), 'std_test_roc_auc': array([0.00242804, 0.00246141, 0.0024684 , 0.00247684, 0.00248386]), 'rank_test_roc_auc': array([3, 2, 4, 5, 1], dtype=int32), 'split0_test_f1': array([0.87708445, 0.87809025, 0.87810661, 0.87809788, 0.87811752]), 'split1_test_f1': array([0.87880281, 0.87952238, 0.87956009, 0.87963522, 0.87967992]), 'split2_test_f1': array([0.87851852, 0.87920065, 0.8792474 , 0.87926903, 0.87936401]), 'split3_test_f1': array([0.87796679, 0.87885231, 0.87897234, 0.878994  , 0.87901367]), 'split4_test_f1': array([0.8780849 , 0.87932618, 0.87936209, 0.8793783 , 0.8794034 ]), 'split5_test_f1': array([0.87762842, 0.87867252, 0.87865284, 0.87866371, 0.87868339]), 'split6_test_f1': array([0.88069939, 0.88150916, 0.8816343 , 0.88174497, 0.88183974]), 'split7_test_f1': array([0.88002688, 0.88080374, 0.8808661 , 0.88084802, 0.88091777]), 'split8_test_f1': array([0.87830688, 0.87933966, 0.87945959, 0.87948116, 0.8795849 ]), 'split9_test_f1': array([0.91015778, 0.9103065 , 0.91031429, 0.91034573, 0.91041278]), 'mean_test_f1': array([0.88172768, 0.88256234, 0.88261757, 0.8826458 , 0.88270171]), 'std_test_f1': array([0.00953181, 0.00929643, 0.00928319, 0.00928635, 0.00929224]), 'rank_test_f1': array([5, 4, 3, 2, 1], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON LOGISTIC REGRESSION CLASSIFIER's BEST AUC-ROC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_LR__C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     74946\n",
      "           1       0.01      0.87      0.01        54\n",
      "\n",
      "    accuracy                           0.89     75000\n",
      "   macro avg       0.50      0.88      0.48     75000\n",
      "weighted avg       1.00      0.89      0.94     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.9225\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8892\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0112\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RLOGISTIC REGRESSION CLASSIFIER's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_LR__C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     74946\n",
      "           1       0.01      0.87      0.01        54\n",
      "\n",
      "    accuracy                           0.89     75000\n",
      "   macro avg       0.50      0.88      0.48     75000\n",
      "weighted avg       1.00      0.89      0.94     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.9225\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8892\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0112\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON LOGISTIC REGRESSION CLASSIFIER's BEST F-1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_LR__C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94     74946\n",
      "           1       0.01      0.87      0.01        54\n",
      "\n",
      "    accuracy                           0.89     75000\n",
      "   macro avg       0.50      0.88      0.48     75000\n",
      "weighted avg       1.00      0.89      0.94     75000\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.9225\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8892\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0112\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "clf_LR = LogisticRegression(penalty='l2', \n",
    "                            dual=False, \n",
    "                            tol=0.0001, \n",
    "                            fit_intercept=True, \n",
    "                            intercept_scaling=1, \n",
    "                            solver='sag', \n",
    "                            max_iter=10000, \n",
    "                            multi_class='auto', \n",
    "                            warm_start=False, \n",
    "                            l1_ratio=None,\n",
    "                            class_weight='balanced', \n",
    "                            random_state=42)\n",
    "\n",
    "# estimator details for LogisticRegressions.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline_LR = Pipeline([\n",
    "    ('clf_LR', \n",
    "     clf_LR) # LogisticRegression\n",
    "])\n",
    "\n",
    "# Inverse of regularization strength; must be a positive float.\n",
    "# C : float, default=1.0\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_LR_param_grid = {'clf_LR__C': [0.01, \n",
    "                                   0.1, \n",
    "                                   0.2, \n",
    "                                   1, \n",
    "                                   10]}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_LR_grid_search = GridSearchCV(estimator=pipeline_LR,\n",
    "                                   param_grid=clf_LR_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_LR_grid_search.fit(X_train, # X\n",
    "                       y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_LR_grid_search.cv_results_\n",
    "print(\"\\n The clf_LR_grid_search's results are: \\n\", clf_LR_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON LOGISTIC REGRESSION CLASSIFIER's BEST AUC-ROC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = pipeline_LR.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RLOGISTIC REGRESSION CLASSIFIER's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = pipeline_LR.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON LOGISTIC REGRESSION CLASSIFIER's BEST F-1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = pipeline_LR.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54eef8",
   "metadata": {},
   "source": [
    "# Model-2: RandomForestClassifier (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9d2fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "\n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([ 21.89838028, 107.89512942, 197.57426372,  20.3150816 ,\n",
      "       100.23748775, 201.93045537,  20.60036287,  99.26345825,\n",
      "       193.57870457,  20.43930793,  98.5413269 , 195.04241877,\n",
      "        26.48233249, 127.89690733, 252.9454947 ,  26.72844448,\n",
      "       131.4623271 , 258.59117734,  26.73580742, 127.04229829,\n",
      "       256.76197898,  26.77275465, 131.06667023, 237.5279151 ]), 'std_fit_time': array([ 0.30147852,  2.50154542,  1.49050078,  0.6204098 ,  1.42311228,\n",
      "        2.09530336,  0.63529684,  1.07470709,  1.25791756,  0.57033445,\n",
      "        0.73210912,  2.22810556,  0.69760926,  1.4924642 ,  2.38972353,\n",
      "        0.52336274,  2.48049383,  2.23645332,  0.90513975,  1.58689168,\n",
      "        2.98607633,  1.0687917 ,  1.53582783, 26.52234844]), 'mean_score_time': array([0.37241688, 1.2185761 , 1.88922086, 0.35173063, 1.12817488,\n",
      "       2.45709381, 0.46796324, 1.20767674, 2.26280582, 0.4103292 ,\n",
      "       1.09473789, 2.04437742, 0.48870153, 1.40092833, 2.55886564,\n",
      "       0.4779897 , 1.2894249 , 2.33060045, 0.50624216, 1.26582141,\n",
      "       2.13799968, 0.50512316, 1.33412881, 2.14603946]), 'std_score_time': array([0.0304526 , 0.24770443, 0.28681419, 0.02139581, 0.24741993,\n",
      "       0.39770724, 0.11945031, 0.27242864, 0.34060459, 0.12323736,\n",
      "       0.20645498, 0.3045512 , 0.13502891, 0.25756996, 0.35658377,\n",
      "       0.16390736, 0.27354928, 0.45936712, 0.13322376, 0.26931431,\n",
      "       0.41645018, 0.1292779 , 0.20178426, 0.68832539]), 'param_clf_RFC__max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__min_samples_split': masked_array(data=[2, 2, 2, 5, 5, 5, 2, 2, 2, 5, 5, 5, 2, 2, 2, 5, 5, 5,\n",
      "                   2, 2, 2, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10,\n",
      "                   50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}], 'split0_test_accuracy': array([0.96679861, 0.96833304, 0.96935599, 0.96381872, 0.96855542,\n",
      "       0.96933375, 0.96648728, 0.96891123, 0.96902242, 0.96497509,\n",
      "       0.96928927, 0.9694227 , 0.97858477, 0.97776196, 0.9777842 ,\n",
      "       0.97800658, 0.97894058, 0.97834015, 0.97851806, 0.9796522 ,\n",
      "       0.97920744, 0.97847358, 0.97925191, 0.9788961 ]), 'split1_test_accuracy': array([0.96624266, 0.96997865, 0.97057908, 0.96457481, 0.97049013,\n",
      "       0.9710016 , 0.96715442, 0.96991194, 0.97040117, 0.96659847,\n",
      "       0.96995641, 0.97031222, 0.98000801, 0.98045277, 0.98078634,\n",
      "       0.98087529, 0.98114215, 0.98069738, 0.97900729, 0.98016367,\n",
      "       0.98007472, 0.97756182, 0.98025262, 0.98036381]), 'split2_test_accuracy': array([0.96737608, 0.97064514, 0.97064514, 0.96802099, 0.96968888,\n",
      "       0.97015589, 0.966064  , 0.97011142, 0.97102319, 0.96624191,\n",
      "       0.96935531, 0.970912  , 0.98058576, 0.97991861, 0.98114173,\n",
      "       0.98249828, 0.98038562, 0.980608  , 0.98136411, 0.98045233,\n",
      "       0.98085263, 0.9814753 , 0.97996308, 0.9803189 ]), 'split3_test_accuracy': array([0.9688883 , 0.96986679, 0.96991127, 0.96755398, 0.96951097,\n",
      "       0.96937754, 0.96650877, 0.96915516, 0.9700447 , 0.9664643 ,\n",
      "       0.96962217, 0.97017813, 0.98154202, 0.98094158, 0.97978518,\n",
      "       0.98205351, 0.98018547, 0.98018547, 0.97929593, 0.98078591,\n",
      "       0.98056352, 0.97940712, 0.97962951, 0.97998532]), 'split4_test_accuracy': array([0.96706474, 0.96928859, 0.9691774 , 0.96879934, 0.9688883 ,\n",
      "       0.9694665 , 0.96706474, 0.96959993, 0.97022261, 0.96846576,\n",
      "       0.9687771 , 0.96964441, 0.97985189, 0.97980741, 0.97962951,\n",
      "       0.97853982, 0.98022995, 0.97980741, 0.98051905, 0.98171993,\n",
      "       0.97967398, 0.97989637, 0.9800298 , 0.98022995]), 'split5_test_accuracy': array([0.96541909, 0.9688883 , 0.96957769, 0.96977784, 0.96971112,\n",
      "       0.96973336, 0.96670892, 0.96862143, 0.96933307, 0.96775413,\n",
      "       0.96982231, 0.96984455, 0.97740565, 0.9797407 , 0.97991861,\n",
      "       0.97894011, 0.97925145, 0.97860653, 0.97791714, 0.97940712,\n",
      "       0.97967398, 0.97956279, 0.97853982, 0.97942936]), 'split6_test_accuracy': array([0.96895501, 0.97100096, 0.97080081, 0.96831009, 0.96966664,\n",
      "       0.97031156, 0.96697578, 0.97044499, 0.97035604, 0.96955545,\n",
      "       0.97088976, 0.97129006, 0.97965174, 0.97982965, 0.97991861,\n",
      "       0.98249828, 0.98074143, 0.97985189, 0.98067472, 0.97898459,\n",
      "       0.98000756, 0.98207574, 0.98029666, 0.98045233]), 'split7_test_accuracy': array([0.96919964, 0.9706229 , 0.97002246, 0.96659773, 0.96944426,\n",
      "       0.96931083, 0.96806547, 0.96911068, 0.96966664, 0.96839905,\n",
      "       0.96911068, 0.96997798, 0.9815865 , 0.98009652, 0.98018547,\n",
      "       0.98200903, 0.98176441, 0.98080815, 0.97896235, 0.97940712,\n",
      "       0.97942936, 0.98143083, 0.9811862 , 0.98058576]), 'split8_test_accuracy': array([0.96779861, 0.96942202, 0.97075633, 0.96886606, 0.97026708,\n",
      "       0.97053395, 0.96933307, 0.97002246, 0.97073409, 0.96977784,\n",
      "       0.97002246, 0.97044499, 0.97987413, 0.980608  , 0.98005204,\n",
      "       0.98103053, 0.97998532, 0.98078591, 0.97969622, 0.97907354,\n",
      "       0.97958503, 0.97942936, 0.9800298 , 0.98078591]), 'split9_test_accuracy': array([0.93054907, 0.93101608, 0.93192786, 0.92721329, 0.93350679,\n",
      "       0.93575289, 0.92634599, 0.92954834, 0.93317322, 0.93735406,\n",
      "       0.93023773, 0.93461872, 0.9784731 , 0.98011875, 0.97971846,\n",
      "       0.97914026, 0.97840639, 0.97947384, 0.97684969, 0.97791714,\n",
      "       0.97765028, 0.97969622, 0.97934041, 0.97853982]), 'mean_test_accuracy': array([0.96382918, 0.96590625, 0.9662754 , 0.96335328, 0.96597296,\n",
      "       0.96649779, 0.96307084, 0.96554376, 0.96639772, 0.96455861,\n",
      "       0.96570832, 0.96666458, 0.97975636, 0.9799276 , 0.97989201,\n",
      "       0.98055917, 0.98010328, 0.97991647, 0.97928046, 0.97975636,\n",
      "       0.97967185, 0.97990091, 0.97985198, 0.97995873]), 'std_test_accuracy': array([0.01115461, 0.01165692, 0.011463  , 0.01218057, 0.01083539,\n",
      "       0.01026295, 0.0122737 , 0.01201135, 0.01109001, 0.00918326,\n",
      "       0.01183651, 0.01069529, 0.0012597 , 0.00081123, 0.00083833,\n",
      "       0.00165547, 0.00096536, 0.00084404, 0.00128519, 0.00101318,\n",
      "       0.00082663, 0.00132967, 0.00067875, 0.00071497]), 'rank_test_accuracy': array([22, 18, 16, 23, 17, 14, 24, 20, 15, 21, 19, 13,  9,  4,  7,  1,  2,\n",
      "        5, 12, 10, 11,  6,  8,  3], dtype=int32), 'split0_test_precision': array([0.93883012, 0.94150943, 0.94332885, 0.9361017 , 0.9420527 ,\n",
      "       0.94336372, 0.94078588, 0.94302042, 0.94303239, 0.94087631,\n",
      "       0.94369455, 0.94363415, 0.96053927, 0.95894215, 0.95894391,\n",
      "       0.95927524, 0.96100004, 0.95996921, 0.96025838, 0.96231834,\n",
      "       0.96161261, 0.96013687, 0.9616159 , 0.9609967 ]), 'split1_test_precision': array([0.93946508, 0.94384241, 0.94483918, 0.94075699, 0.94460556,\n",
      "       0.9454446 , 0.94481853, 0.94364896, 0.9445215 , 0.94381927,\n",
      "       0.94365369, 0.9442134 , 0.96159275, 0.96237641, 0.96303435,\n",
      "       0.96327877, 0.96377433, 0.96294868, 0.95978484, 0.96195978,\n",
      "       0.96179516, 0.95716779, 0.96212445, 0.96233038]), 'split2_test_precision': array([0.94132717, 0.9455556 , 0.94495606, 0.94006942, 0.94310171,\n",
      "       0.94385891, 0.93866957, 0.94452622, 0.94540713, 0.9386901 ,\n",
      "       0.94258273, 0.94524581, 0.96266164, 0.96142662, 0.96369326,\n",
      "       0.9662197 , 0.9622908 , 0.96270286, 0.96422597, 0.96245398,\n",
      "       0.96315654, 0.96439296, 0.96154833, 0.96220681]), 'split3_test_precision': array([0.94256927, 0.94356735, 0.94353484, 0.94534825, 0.94300823,\n",
      "       0.9426594 , 0.94482378, 0.94252391, 0.94388441, 0.94470593,\n",
      "       0.9433178 , 0.94397312, 0.96439755, 0.96328192, 0.96114056,\n",
      "       0.9653899 , 0.96188072, 0.96192025, 0.96027678, 0.9629931 ,\n",
      "       0.96258081, 0.96048191, 0.96089242, 0.96154998]), 'split4_test_precision': array([0.93966672, 0.94220453, 0.94200712, 0.94259679, 0.94167924,\n",
      "       0.94259477, 0.93937238, 0.94301779, 0.94408973, 0.94222614,\n",
      "       0.94137108, 0.94291107, 0.96130329, 0.96122109, 0.96089242,\n",
      "       0.95892339, 0.96204211, 0.96126053, 0.962538  , 0.96480838,\n",
      "       0.96101398, 0.96142497, 0.96167173, 0.96204211]), 'split5_test_precision': array([0.94241502, 0.94234642, 0.94316417, 0.94419211, 0.94355076,\n",
      "       0.94310649, 0.93944216, 0.94194631, 0.94284036, 0.94151728,\n",
      "       0.94401009, 0.94345326, 0.95676412, 0.96105839, 0.96138715,\n",
      "       0.95962097, 0.96019476, 0.95900695, 0.95770148, 0.96048191,\n",
      "       0.96097457, 0.96076923, 0.95888424, 0.96052294]), 'split6_test_precision': array([0.94194819, 0.94518244, 0.94486237, 0.94065704, 0.94280443,\n",
      "       0.94402687, 0.93984332, 0.9444888 , 0.94436741, 0.94271816,\n",
      "       0.94528326, 0.94588681, 0.96097457, 0.96130329, 0.96146773,\n",
      "       0.96622115, 0.96295186, 0.96130494, 0.96282814, 0.95970461,\n",
      "       0.96155327, 0.96547282, 0.96216725, 0.96245558]), 'split7_test_precision': array([0.94368507, 0.94548057, 0.94366079, 0.94191238, 0.94248344,\n",
      "       0.94239477, 0.94352664, 0.94222464, 0.94280443, 0.94434834,\n",
      "       0.94207637, 0.94346987, 0.96452166, 0.96171778, 0.96188235,\n",
      "       0.96526854, 0.96481291, 0.96303594, 0.95970289, 0.96044425,\n",
      "       0.96048528, 0.96423211, 0.96373768, 0.96262362]), 'split8_test_precision': array([0.94263951, 0.94314985, 0.94526945, 0.94492277, 0.94461965,\n",
      "       0.9449468 , 0.94362467, 0.94410825, 0.94530461, 0.9441571 ,\n",
      "       0.94433232, 0.94475045, 0.96189905, 0.96314075, 0.96214943,\n",
      "       0.96392571, 0.96206542, 0.9635506 , 0.96153023, 0.96037954,\n",
      "       0.96132455, 0.96107618, 0.96214781, 0.9635506 ]), 'split9_test_precision': array([0.93690482, 0.9366889 , 0.93696288, 0.93734918, 0.93933111,\n",
      "       0.94055488, 0.93525245, 0.93535882, 0.9364553 , 0.93768638,\n",
      "       0.93924533, 0.93915154, 0.96330749, 0.9626693 , 0.96192719,\n",
      "       0.96319546, 0.96076248, 0.96167188, 0.95985417, 0.96044907,\n",
      "       0.9609821 , 0.96303611, 0.96213713, 0.96100947]), 'mean_test_precision': array([0.9409451 , 0.94295275, 0.94325857, 0.94139066, 0.94272368,\n",
      "       0.94329512, 0.94101594, 0.94248641, 0.94327073, 0.9420745 ,\n",
      "       0.94295672, 0.94366895, 0.96179614, 0.96171377, 0.96165184,\n",
      "       0.96313188, 0.96217754, 0.96173718, 0.96087009, 0.9615993 ,\n",
      "       0.96154789, 0.96181909, 0.9616927 , 0.96192882]), 'std_test_precision': array([0.00202363, 0.00248175, 0.00231191, 0.00291042, 0.00145461,\n",
      "       0.00132122, 0.00295631, 0.00252753, 0.00243772, 0.00228844,\n",
      "       0.00163642, 0.001733  , 0.00212367, 0.00120219, 0.00121368,\n",
      "       0.00272598, 0.00132464, 0.00135673, 0.00180699, 0.00150339,\n",
      "       0.00076374, 0.00235245, 0.00116418, 0.00086463]), 'rank_test_precision': array([24, 18, 16, 22, 19, 14, 23, 20, 15, 21, 17, 13,  5,  7,  9,  1,  2,\n",
      "        6, 12, 10, 11,  4,  8,  3], dtype=int32), 'split0_test_recall': array([0.99866572, 0.99871019, 0.99871019, 0.99559687, 0.99853229,\n",
      "       0.99862124, 0.99564134, 0.998132  , 0.99835439, 0.99230564,\n",
      "       0.998132  , 0.99848781, 0.99817648, 0.99826543, 0.99830991,\n",
      "       0.99839886, 0.99839886, 0.99830991, 0.99835439, 0.99839886,\n",
      "       0.99826543, 0.99839886, 0.99835439, 0.99830991]), 'split1_test_recall': array([0.99670877, 0.99942181, 0.99951076, 0.99159402, 0.99959972,\n",
      "       0.99968867, 0.99226116, 0.99951076, 0.99951076, 0.99226116,\n",
      "       0.99959972, 0.99968867, 0.99995552, 1.        , 0.99995552,\n",
      "       0.99986657, 0.99986657, 0.99986657, 0.99991105, 0.99986657,\n",
      "       0.99986657, 0.99986657, 0.99986657, 0.99986657]), 'split2_test_recall': array([0.99688654, 0.99879909, 0.99951074, 0.99977761, 0.99968865,\n",
      "       0.99977761, 0.99728684, 0.99888805, 0.99977761, 0.99764266,\n",
      "       0.9995997 , 0.99973313, 0.99995552, 0.99995552, 0.99995552,\n",
      "       0.99995552, 0.99995552, 0.99995552, 0.99982209, 0.99991104,\n",
      "       0.99995552, 0.99986657, 0.99991104, 0.99991104]), 'split3_test_recall': array([0.99862118, 0.99951074, 0.99964418, 0.99248321, 0.99942179,\n",
      "       0.99955522, 0.990882  , 0.99924387, 0.99951074, 0.99092648,\n",
      "       0.99928835, 0.99968865, 1.        , 1.        , 1.        ,\n",
      "       0.99995552, 1.        , 0.99995552, 0.99995552, 1.        ,\n",
      "       1.        , 0.99995552, 0.99995552, 0.99995552]), 'split4_test_recall': array([0.99822088, 0.99991104, 0.99991104, 0.99839879, 0.99968865,\n",
      "       0.99982209, 0.9985767 , 0.9995997 , 0.99964418, 0.99813192,\n",
      "       0.99982209, 0.99982209, 0.99995552, 0.99995552, 0.99995552,\n",
      "       0.99991104, 0.99991104, 0.99991104, 0.99995552, 0.99991104,\n",
      "       0.99991104, 0.99991104, 0.99991104, 0.99991104]), 'split5_test_recall': array([0.99141574, 0.99888805, 0.99937731, 0.9985767 , 0.9991994 ,\n",
      "       0.99977761, 0.99773162, 0.99879909, 0.99924387, 0.99746475,\n",
      "       0.99888805, 0.9995997 , 1.        , 1.        , 1.        ,\n",
      "       0.99995552, 0.99995552, 0.99995552, 1.        , 0.99995552,\n",
      "       0.99995552, 0.99995552, 0.99995552, 0.99995552]), 'split6_test_recall': array([0.99951076, 1.        , 0.99995552, 0.99968867, 1.        ,\n",
      "       0.99991105, 0.99782067, 0.99964419, 0.99959972, 0.99986657,\n",
      "       0.99964419, 0.99977762, 0.99991105, 0.99991105, 0.99991105,\n",
      "       0.99995552, 0.99995552, 0.99995552, 0.99995552, 0.99995552,\n",
      "       1.        , 0.99991105, 0.99991105, 0.99991105]), 'split7_test_recall': array([0.9979541 , 0.99884362, 0.99973314, 0.99452944, 0.99991105,\n",
      "       0.99973314, 0.9957303 , 0.99951076, 1.        , 0.99546344,\n",
      "       0.99968867, 0.99986657, 0.99995552, 1.        , 1.        ,\n",
      "       1.        , 1.        , 1.        , 0.99991105, 1.        ,\n",
      "       1.        , 0.99995552, 1.        , 1.        ]), 'split8_test_recall': array([0.99621953, 0.999066  , 0.99937733, 0.99577477, 0.99911048,\n",
      "       0.99928838, 0.99830991, 0.99919943, 0.99928838, 0.99862124,\n",
      "       0.99893257, 0.99933286, 0.99933286, 0.99946629, 0.99942181,\n",
      "       0.99946629, 0.99937733, 0.99937733, 0.99937733, 0.99937733,\n",
      "       0.99937733, 0.99933286, 0.99937733, 0.99937733]), 'split9_test_recall': array([0.92327878, 0.92452411, 0.92616972, 0.91562889, 0.92688134,\n",
      "       0.930306  , 0.91611813, 0.92287849, 0.92941647, 0.93697741,\n",
      "       0.91998755, 0.92946095, 0.99484078, 0.99897705, 0.99897705,\n",
      "       0.99635296, 0.99755382, 0.99875467, 0.99533001, 0.99688667,\n",
      "       0.9957303 , 0.99768724, 0.9979541 , 0.99755382]), 'mean_test_recall': array([0.9897482 , 0.99176747, 0.99218999, 0.9882049 , 0.99220334,\n",
      "       0.9926481 , 0.98803587, 0.99154064, 0.99243461, 0.98996613,\n",
      "       0.99135829, 0.99254581, 0.99920833, 0.99965309, 0.99964864,\n",
      "       0.99938178, 0.99949742, 0.99960416, 0.99925725, 0.99942626,\n",
      "       0.99930617, 0.99948408, 0.99951966, 0.99947518]), 'std_test_recall': array([0.02225967, 0.02241874, 0.02200926, 0.024344  , 0.02177784,\n",
      "       0.0207838 , 0.02409805, 0.02289162, 0.0210102 , 0.017901  ,\n",
      "       0.02379527, 0.02103179, 0.00155358, 0.0005611 , 0.00054922,\n",
      "       0.0011118 , 0.00080256, 0.00057111, 0.00139432, 0.00096902,\n",
      "       0.00129779, 0.0007585 , 0.0007085 , 0.00080741]), 'rank_test_recall': array([22, 18, 17, 23, 16, 13, 24, 19, 15, 21, 20, 14, 12,  1,  2,  9,  5,\n",
      "        3, 11,  8, 10,  6,  4,  7], dtype=int32), 'split0_test_roc_auc': array([0.99081886, 0.99473194, 0.99486381, 0.99005644, 0.99397459,\n",
      "       0.99483174, 0.98811219, 0.99345437, 0.99434397, 0.98800602,\n",
      "       0.99331188, 0.99459482, 0.99692598, 0.99861033, 0.99885714,\n",
      "       0.99803307, 0.99875525, 0.99894947, 0.99675088, 0.99899479,\n",
      "       0.99903836, 0.99679128, 0.9987692 , 0.99893046]), 'split1_test_roc_auc': array([0.99099169, 0.9943441 , 0.99437514, 0.99232663, 0.99500511,\n",
      "       0.99513079, 0.99235527, 0.99468077, 0.99458581, 0.99171322,\n",
      "       0.99471088, 0.99460288, 0.99796281, 0.99913901, 0.99930629,\n",
      "       0.9984032 , 0.99907633, 0.99910678, 0.99736758, 0.99899655,\n",
      "       0.99911963, 0.99687302, 0.9991177 , 0.99902802]), 'split2_test_roc_auc': array([0.98948849, 0.99466056, 0.99524906, 0.99088954, 0.99522838,\n",
      "       0.99546288, 0.98850467, 0.99501741, 0.99535422, 0.98864428,\n",
      "       0.9939955 , 0.99486372, 0.99815233, 0.99896396, 0.99918373,\n",
      "       0.99880822, 0.99932126, 0.99952134, 0.99755323, 0.99933417,\n",
      "       0.99933831, 0.99754883, 0.99891657, 0.99919948]), 'split3_test_roc_auc': array([0.99188485, 0.99452306, 0.99514168, 0.99232463, 0.99403376,\n",
      "       0.99496143, 0.99175063, 0.99456124, 0.9948504 , 0.99106294,\n",
      "       0.99381996, 0.99506798, 0.99814226, 0.99888539, 0.99932685,\n",
      "       0.99874535, 0.99912007, 0.99947649, 0.99774865, 0.99903056,\n",
      "       0.99929954, 0.99866364, 0.99913586, 0.99927323]), 'split4_test_roc_auc': array([0.99039277, 0.99464983, 0.99515958, 0.99093674, 0.99458751,\n",
      "       0.99473642, 0.99139575, 0.99452667, 0.99460686, 0.99277339,\n",
      "       0.99485533, 0.9949102 , 0.998161  , 0.99909809, 0.99938656,\n",
      "       0.99793081, 0.99921324, 0.99924779, 0.99794997, 0.99892851,\n",
      "       0.99909673, 0.99842489, 0.99916358, 0.9991853 ]), 'split5_test_roc_auc': array([0.98958995, 0.99288374, 0.99446073, 0.99145989, 0.99395159,\n",
      "       0.99411264, 0.98834914, 0.99327868, 0.99424827, 0.99055834,\n",
      "       0.9940064 , 0.99389976, 0.99738055, 0.99929173, 0.99931298,\n",
      "       0.99773618, 0.99898311, 0.99916549, 0.99805224, 0.99914689,\n",
      "       0.99931693, 0.99811892, 0.99908697, 0.99917028]), 'split6_test_roc_auc': array([0.99075424, 0.99380044, 0.9949943 , 0.99096764, 0.99458983,\n",
      "       0.99490874, 0.98682299, 0.99351746, 0.99403189, 0.98738173,\n",
      "       0.99416717, 0.99436258, 0.99781028, 0.99932312, 0.99948719,\n",
      "       0.99805242, 0.9992492 , 0.99924306, 0.99853817, 0.99899092,\n",
      "       0.99916407, 0.99891408, 0.99908881, 0.99923349]), 'split7_test_roc_auc': array([0.99169776, 0.99403758, 0.99465085, 0.99291356, 0.99502147,\n",
      "       0.9947047 , 0.99170254, 0.9937587 , 0.99436136, 0.99135433,\n",
      "       0.99460152, 0.99430913, 0.99785019, 0.99912653, 0.99934016,\n",
      "       0.99816676, 0.99898083, 0.99926985, 0.99738488, 0.99888888,\n",
      "       0.9991604 , 0.99848363, 0.99942611, 0.99929673]), 'split8_test_roc_auc': array([0.99263323, 0.99390865, 0.99401006, 0.98769503, 0.99371167,\n",
      "       0.99383983, 0.98917009, 0.99373707, 0.99395235, 0.98984822,\n",
      "       0.99328947, 0.99367882, 0.99828507, 0.99929079, 0.99934669,\n",
      "       0.99817511, 0.99914886, 0.99911076, 0.99694023, 0.99885618,\n",
      "       0.99908679, 0.99696677, 0.99908246, 0.99912633]), 'split9_test_roc_auc': array([0.9827198 , 0.98401647, 0.98414513, 0.98080799, 0.98348398,\n",
      "       0.98425428, 0.98347589, 0.98418679, 0.9846889 , 0.98067954,\n",
      "       0.98430496, 0.98488345, 0.9934827 , 0.99613951, 0.99607534,\n",
      "       0.99518802, 0.99547261, 0.99592815, 0.99480251, 0.99477709,\n",
      "       0.9952566 , 0.99568473, 0.99629613, 0.99594425]), 'mean_test_roc_auc': array([0.99009716, 0.99315564, 0.99370504, 0.99003781, 0.99335879,\n",
      "       0.99369434, 0.98916392, 0.99307192, 0.9935024 , 0.9892022 ,\n",
      "       0.99310631, 0.99351733, 0.99741532, 0.99878685, 0.99896229,\n",
      "       0.99792391, 0.99873208, 0.99890192, 0.99730883, 0.99859445,\n",
      "       0.99878774, 0.99764698, 0.99880834, 0.99883876]), 'std_test_roc_auc': array([0.00262836, 0.0030923 , 0.00320886, 0.00337398, 0.00332893,\n",
      "       0.00317778, 0.00261419, 0.00301587, 0.00296315, 0.00327263,\n",
      "       0.00297732, 0.00290782, 0.00136876, 0.00090628, 0.00097544,\n",
      "       0.00096733, 0.0010972 , 0.00100428, 0.00097294, 0.00127909,\n",
      "       0.00118121, 0.00099101, 0.00085245, 0.00097054]), 'rank_test_roc_auc': array([21, 18, 13, 22, 17, 14, 24, 20, 16, 23, 19, 15, 11,  6,  1,  9,  7,\n",
      "        2, 12,  8,  5, 10,  4,  3], dtype=int32), 'split0_test_f1': array([0.96782397, 0.96926663, 0.97022987, 0.96493308, 0.96947059,\n",
      "       0.97020633, 0.96743663, 0.96979387, 0.96990516, 0.96590688,\n",
      "       0.97015022, 0.97028633, 0.97899627, 0.97820876, 0.97823103,\n",
      "       0.97844612, 0.97934254, 0.97876423, 0.97893589, 0.98002663,\n",
      "       0.97959629, 0.97889412, 0.97964082, 0.97929801]), 'split1_test_f1': array([0.96724071, 0.97083729, 0.97140634, 0.96550679, 0.97132485,\n",
      "       0.97181028, 0.96795887, 0.97077691, 0.97123841, 0.9674342 ,\n",
      "       0.97082136, 0.97115945, 0.980399  , 0.98082754, 0.98114772,\n",
      "       0.98123172, 0.98148876, 0.98106044, 0.97943714, 0.98054695,\n",
      "       0.98046142, 0.97805138, 0.9806325 , 0.98073945]), 'split2_test_f1': array([0.96831054, 0.97144835, 0.9714681 , 0.96900461, 0.97057109,\n",
      "       0.97101387, 0.96709079, 0.97094682, 0.97183251, 0.96726896,\n",
      "       0.97025428, 0.97172625, 0.98095425, 0.98031264, 0.98148957,\n",
      "       0.98279819, 0.98076168, 0.98097565, 0.98170146, 0.98082503,\n",
      "       0.98121113, 0.98180945, 0.98035453, 0.98069666]), 'split3_test_f1': array([0.96978597, 0.97073371, 0.97077943, 0.96834248, 0.9703958 ,\n",
      "       0.97027395, 0.96730494, 0.97005548, 0.97090147, 0.96726436,\n",
      "       0.97049676, 0.97103234, 0.98187615, 0.9812976 , 0.98018529,\n",
      "       0.98236875, 0.98057003, 0.98056919, 0.97971457, 0.98114772,\n",
      "       0.98093368, 0.97982131, 0.98003487, 0.98037677]), 'split4_test_f1': array([0.96805918, 0.97020046, 0.9700958 , 0.96969566, 0.96981726,\n",
      "       0.97036541, 0.9680702 , 0.97048472, 0.97107304, 0.96937365,\n",
      "       0.96971658, 0.970533  , 0.98024853, 0.98020579, 0.98003487,\n",
      "       0.97898839, 0.98061111, 0.98020493, 0.98089005, 0.98204613,\n",
      "       0.98007673, 0.98029041, 0.98041867, 0.98061111]), 'split5_test_f1': array([0.96629457, 0.9697938 , 0.97045739, 0.9706232 , 0.97057807,\n",
      "       0.97061554, 0.96770993, 0.96953997, 0.97022306, 0.96868386,\n",
      "       0.97067404, 0.97071527, 0.9779044 , 0.98014256, 0.9803135 ,\n",
      "       0.97937313, 0.97967187, 0.97905326, 0.97839379, 0.97982131,\n",
      "       0.9800776 , 0.9799708 , 0.97898931, 0.97984266]), 'split6_test_f1': array([0.96987614, 0.97181881, 0.9716286 , 0.96927489, 0.9705603 ,\n",
      "       0.97116568, 0.96796462, 0.97128411, 0.97119893, 0.97045175,\n",
      "       0.97170403, 0.97208588, 0.98005623, 0.98022716, 0.98031264,\n",
      "       0.98279894, 0.9811049 , 0.98024939, 0.98104069, 0.9794167 ,\n",
      "       0.98039985, 0.98239021, 0.98067612, 0.98082586]), 'split7_test_f1': array([0.97006117, 0.97142981, 0.97088804, 0.96750606, 0.97034831,\n",
      "       0.97021754, 0.96892582, 0.97002266, 0.9705603 , 0.96923243,\n",
      "       0.97002784, 0.97084989, 0.98191903, 0.98048536, 0.98057088,\n",
      "       0.98232737, 0.98209138, 0.98116995, 0.97939447, 0.97982307,\n",
      "       0.97984442, 0.98176896, 0.98153403, 0.98095591]), 'split8_test_f1': array([0.96868918, 0.97030302, 0.97157064, 0.96968253, 0.97110126,\n",
      "       0.97135816, 0.97019732, 0.97087295, 0.97154718, 0.97062574,\n",
      "       0.97086539, 0.97127542, 0.98025871, 0.98096735, 0.98043151,\n",
      "       0.98137433, 0.98036649, 0.98113702, 0.98008854, 0.97949042,\n",
      "       0.97998168, 0.97983124, 0.98040927, 0.98113702]), 'split9_test_f1': array([0.93004189, 0.93056675, 0.93153504, 0.92636173, 0.9330647 ,\n",
      "       0.93540237, 0.92558641, 0.92907674, 0.93292261, 0.93733176,\n",
      "       0.92951671, 0.93428112, 0.97882023, 0.98048717, 0.98010211,\n",
      "       0.97949368, 0.97881254, 0.97986255, 0.97727025, 0.97832871,\n",
      "       0.97804766, 0.98005549, 0.97971837, 0.97894071]), 'mean_test_f1': array([0.96461833, 0.96663986, 0.96700592, 0.9640931 , 0.96672322,\n",
      "       0.96724291, 0.96382455, 0.96628542, 0.96714027, 0.96535736,\n",
      "       0.96642272, 0.9673945 , 0.98014328, 0.98031619, 0.98028191,\n",
      "       0.98092006, 0.98048213, 0.98030466, 0.97968668, 0.98014727,\n",
      "       0.98006305, 0.98028834, 0.98024085, 0.98034242]), 'std_test_f1': array([0.01158236, 0.01204773, 0.01183566, 0.01269769, 0.01123111,\n",
      "       0.01062623, 0.01277487, 0.01241425, 0.01141933, 0.00945125,\n",
      "       0.0123131 , 0.01104952, 0.00122433, 0.00078728, 0.00081392,\n",
      "       0.00160373, 0.00094071, 0.00081733, 0.001254  , 0.0009861 ,\n",
      "       0.00081748, 0.00128272, 0.00065802, 0.00070024]), 'rank_test_f1': array([22, 18, 16, 23, 17, 14, 24, 20, 15, 21, 19, 13, 10,  4,  7,  1,  2,\n",
      "        5, 12,  9, 11,  6,  8,  3], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST AUC-ROC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     74946\n",
      "           1       0.01      0.48      0.02        54\n",
      "\n",
      "    accuracy                           0.96     75000\n",
      "   macro avg       0.50      0.72      0.50     75000\n",
      "weighted avg       1.00      0.96      0.98     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.9231\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9589\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0166\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     74946\n",
      "           1       0.01      0.48      0.02        54\n",
      "\n",
      "    accuracy                           0.96     75000\n",
      "   macro avg       0.50      0.72      0.50     75000\n",
      "weighted avg       1.00      0.96      0.98     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8719\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9571\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0159\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.96      0.98     74946\n",
      "           1       0.01      0.48      0.02        54\n",
      "\n",
      "    accuracy                           0.96     75000\n",
      "   macro avg       0.50      0.72      0.50     75000\n",
      "weighted avg       1.00      0.96      0.98     75000\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8719\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9571\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0159\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.svm.RandomForestClassifier(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "clf_RFC = RandomForestClassifier(n_estimators=100, \n",
    "                                 criterion='gini', \n",
    "                                 max_depth=None, \n",
    "                                 min_samples_split=10, \n",
    "                                 min_samples_leaf=5, \n",
    "                                 min_weight_fraction_leaf=0.0, \n",
    "                                 max_features='sqrt', \n",
    "                                 max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, \n",
    "                                 bootstrap=True, \n",
    "                                 oob_score=False, \n",
    "                                 random_state=42, \n",
    "                                 warm_start=False, \n",
    "                                 ccp_alpha=0.0, \n",
    "                                 max_samples=None, \n",
    "                                 class_weight='balanced')\n",
    "\n",
    "# estimator details for RandomForestClassifier.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_RFC_pipeline = Pipeline([\n",
    "    ('clf_RFC', \n",
    "     clf_RFC) # RandomForestClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for RandomForestClassifier.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_param_grid = {\n",
    "    # The number of trees in the forest.\n",
    "    'clf_RFC__n_estimators': [10, \n",
    "                              50, \n",
    "                              100], \n",
    "    # The maximum depth of the tree.\n",
    "    'clf_RFC__max_depth': [10, \n",
    "                           15], \n",
    "    # The minimum number of samples required to split an internal node:\n",
    "    'clf_RFC__min_samples_split': [2, \n",
    "                                   5], \n",
    "    # The minimum number of samples required to be at a leaf node. \n",
    "    'clf_RFC__min_samples_leaf': [1, \n",
    "                                  2]  \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_RFC_pipeline,\n",
    "                                   param_grid=clf_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                    y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST AUC-ROC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_RFC_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_RFC_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_RFC_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d6e47",
   "metadata": {},
   "source": [
    "# Model-3: Bagging (using Naïve Bayes as classifier) (Choosing the best AUC ROC parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d596634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:514: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:778: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 767, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 234, in __call__\n",
      "    return self._score(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 399, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 551, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 921, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 161, in _assert_all_finite\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.75371475 0.89861724 0.90055858 0.5        0.5        0.5\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The clf_grid_search_BGC's results are: \n",
      " {'mean_fit_time': array([ 8.77889278, 32.96666703, 62.39665623,  7.49835889, 26.86414261,\n",
      "       49.00565379,  2.72891135,  5.71560702,  8.88094537,  1.72044187,\n",
      "        4.27491629,  6.97597969]), 'std_fit_time': array([1.04636543, 1.135883  , 2.62019445, 0.52789487, 1.0775178 ,\n",
      "       3.25158588, 0.29658739, 0.3223887 , 0.91848926, 0.33170543,\n",
      "       0.22094695, 0.8208269 ]), 'mean_score_time': array([0.66272631, 3.17571306, 5.93749747, 0.6374532 , 2.79033639,\n",
      "       5.74390278, 0.10107687, 0.47095025, 0.85784996, 0.06210949,\n",
      "       0.42098961, 0.84165463]), 'std_score_time': array([0.19217855, 0.27817781, 0.50697922, 0.11290109, 0.24574964,\n",
      "       0.54762993, 0.04331545, 0.06471184, 0.14028003, 0.00672831,\n",
      "       0.03885671, 0.24505393]), 'param_clf_BGC__max_features': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_BGC__max_samples': masked_array(data=[0.5, 0.5, 0.5, 1, 1, 1, 0.5, 0.5, 0.5, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_BGC__n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 100}], 'split0_test_score': array([0.76197709, 0.8954241 , 0.89572568, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.76298632, 0.89632974, 0.89597281, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.76239472, 0.89535718, 0.89554965, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.7670322 , 0.89605502, 0.89625892, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.76544832, 0.89769129, 0.89787347, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split5_test_score': array([0.81130178, 0.89528712, 0.89536069, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split6_test_score': array([0.71207213, 0.8968905 , 0.89766421, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split7_test_score': array([0.71966066, 0.89764856, 0.89784683, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split8_test_score': array([0.75792026, 0.8970508 , 0.8982028 , 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split9_test_score': array([0.716354  , 0.91843813, 0.93513075, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.75371475, 0.89861724, 0.90055858, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.02858001, 0.00666191, 0.01157025, 0.        , 0.        ,\n",
      "       0.        ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([3, 2, 1, 4, 4, 4, 7, 7, 7, 7, 7, 7], dtype=int32)}\n",
      "\n",
      "The Best Parameters from tempBestClassifierModelBaggingClassifierRegression:\n",
      " {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04     74946\n",
      "           1       0.00      1.00      0.00        54\n",
      "\n",
      "    accuracy                           0.02     75000\n",
      "   macro avg       0.50      0.51      0.02     75000\n",
      "weighted avg       1.00      0.02      0.04     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8860\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.0222\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0015\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "clf = GaussianNB(priors=None, # priors : array-like of shape (n_classes,), default=None\n",
    "                 var_smoothing=1e-09) # var_smoothing : float, default=1e-9\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "# class sklearn.ensemble.BaggingClassifier(estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\n",
    "clf_BGC = BaggingClassifier(\n",
    "          estimator=clf, \n",
    "          n_estimators=10, \n",
    "          max_samples=1.0, \n",
    "          max_features=1.0,\n",
    "          bootstrap=True,  \n",
    "          bootstrap_features=False, \n",
    "          oob_score=False, \n",
    "          warm_start=False,\n",
    "          n_jobs=4,       \n",
    "          random_state=42,\n",
    "          verbose=0\n",
    ")\n",
    "\n",
    "# estimator details for RandomForestClassifier.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline_BGC = Pipeline([\n",
    "    ('clf_BGC', \n",
    "     clf_BGC) # BaggingClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for RandomForestClassifier.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_param_grid_BGC = {\n",
    "    # The number of base estimators in the ensemble.\n",
    "    'clf_BGC__n_estimators': [10,\n",
    "                              50,\n",
    "                              100], \n",
    "    # max_samplesint or float, default=1.0\n",
    "    'clf_BGC__max_samples': [0.5,\n",
    "                             1], \n",
    "    # The number of features to draw from X to train each base estimator.\n",
    "    'clf_BGC__max_features': [0.5,\n",
    "                              1], \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search_BGC = GridSearchCV(estimator=pipeline_BGC,\n",
    "                                   param_grid=clf_param_grid_BGC, \n",
    "                                   scoring='roc_auc', \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=True, \n",
    "                                   verbose=0, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search_BGC.fit(X_train, # X\n",
    "                        y_train) # y\n",
    "\n",
    "print(\"\\n The clf_grid_search_BGC's results are: \\n\", clf_grid_search_BGC.cv_results_)\n",
    "\n",
    "# best_estimator_ : estimator\n",
    "# Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.\n",
    "# See refit parameter for more information on allowed values.\n",
    "\n",
    "tempBestClassifierModelBaggingClassifieregression = clf_grid_search_BGC.best_estimator_\n",
    "\n",
    "# best_params_ : dict\n",
    "# Parameter setting that gave the best results on the hold out data.\n",
    "# For multi-metric evaluation, this is present only if refit is specified.\n",
    "\n",
    "# best_params_dict\n",
    "# Parameter setting that gave the best results on the hold out data.\n",
    "\n",
    "# For multi-metric evaluation, this is present only if refit is specified.\n",
    "\n",
    "print(f\"\\nThe Best Parameters from tempBestClassifierModelBaggingClassifierRegression:\\n {clf_grid_search_BGC.best_params_}\")\n",
    "\n",
    "# \n",
    "# predict(X)[source]\n",
    "# Call predict on the estimator with the best found parameters.\n",
    "\n",
    "# Only available if refit=True and the underlying estimator supports predict.\n",
    "\n",
    "# Parameters\n",
    "# :\n",
    "# X\n",
    "# indexable, length n_samples\n",
    "# Must fulfill the input assumptions of the underlying estimator.\n",
    "\n",
    "# Returns\n",
    "# :\n",
    "# tempYPred\n",
    "# ndarray of shape (n_samples,)\n",
    "# The predicted labels or values for X based on the estimator with the best found parameters.\n",
    "\n",
    "tempYPred = tempBestClassifierModelBaggingClassifieregression.predict(X_test)\n",
    "\n",
    "# Call predict_proba on the estimator with the best found parameters.\n",
    "\n",
    "# Only available if refit=True and the underlying estimator supports predict_proba.\n",
    "\n",
    "# Parameters\n",
    "# :\n",
    "# X\n",
    "# indexable, length n_samples\n",
    "# Must fulfill the input assumptions of the underlying estimator.\n",
    "\n",
    "# Returns\n",
    "# :\n",
    "# tempYPred\n",
    "# ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
    "# Predicted class probabilities for X based on the estimator with the \n",
    "\n",
    "tempYPred_probability = tempBestClassifierModelBaggingClassifieregression.predict_proba(X_test)[:, \n",
    "                                                                                             # Probability of the positive class (class 1)\n",
    "                                                                                             1]\n",
    "\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d345e",
   "metadata": {},
   "source": [
    "# Model-4: GradientBoostingClassifier techniques (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f39e6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: Binning 0.119 GB of training data: 3.293 s\n",
      "Binning 0.013 GB of validation data: 3.263 s\n",
      "Binning 0.013 GB of validation data: 3.261 s\n",
      "Binning 0.013 GB of validation data: 3.243 s\n",
      "Binning 0.013 GB of validation data: 3.259 s\n",
      "Binning 0.013 GB of validation data: 3.382 s\n",
      "Binning 0.013 GB of validation data: 3.397 s\n",
      "Binning 0.013 GB of validation data: 3.374 s\n",
      "Binning 0.013 GB of validation data: 0.308 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.344 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.347 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.338 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.348 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.228 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.246 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.220 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65600, val loss: 0.65596, in 0.353s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65588, in 0.348s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65604, val loss: 0.65586, in 0.348s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65588, in 0.362s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65604, val loss: 0.65602, in 0.364s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65602, val loss: 0.65590, in 0.353s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65599, in 0.338s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65601, val loss: 0.65586, in 0.372s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62239, val loss: 0.62233, in 0.350s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62246, val loss: 0.62214, in 0.337s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62217, in 0.354s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62216, in 0.353s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62243, val loss: 0.62220, in 0.334s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62247, val loss: 0.62244, in 0.357s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62241, val loss: 0.62213, in 0.331s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62237, in 0.347s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59186, val loss: 0.59178, in 0.392s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59197, val loss: 0.59150, in 0.399s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59194, val loss: 0.59154, in 0.405s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59195, val loss: 0.59153, in 0.384s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59190, val loss: 0.59149, in 0.375s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59192, val loss: 0.59159, in 0.397s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59198, val loss: 0.59193, in 0.389s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59195, val loss: 0.59183, in 0.384s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56401, val loss: 0.56388, in 0.344s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56417, val loss: 0.56355, in 0.352s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56413, val loss: 0.56358, in 0.352s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56411, val loss: 0.56356, in 0.364s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56417, val loss: 0.56408, in 0.337s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56406, val loss: 0.56352, in 0.356s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56410, val loss: 0.56365, in 0.361s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56413, val loss: 0.56396, in 0.354s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53853, val loss: 0.53838, in 0.350s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53872, val loss: 0.53798, in 0.368s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53867, val loss: 0.53801, in 0.359s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53866, val loss: 0.53800, in 0.356s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53872, val loss: 0.53862, in 0.358s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53859, val loss: 0.53794, in 0.357s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53863, val loss: 0.53810, in 0.354s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53868, val loss: 0.53847, in 0.349s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51515, val loss: 0.51495, in 0.382s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51539, val loss: 0.51451, in 0.340s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51529, val loss: 0.51451, in 0.340s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51537, val loss: 0.51523, in 0.337s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51532, val loss: 0.51453, in 0.348s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51528, val loss: 0.51465, in 0.328s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51523, val loss: 0.51445, in 0.340s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51532, val loss: 0.51507, in 0.342s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49365, val loss: 0.49344, in 0.237s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49391, val loss: 0.49293, in 0.229s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49384, val loss: 0.49295, in 0.222s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49381, val loss: 0.49293, in 0.226s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49379, val loss: 0.49308, in 0.227s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49374, val loss: 0.49286, in 0.281s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49384, val loss: 0.49356, in 0.312s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49389, val loss: 0.49373, in 0.351s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47377, val loss: 0.47363, in 0.331s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47409, val loss: 0.47307, in 0.329s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47399, val loss: 0.47308, in 0.331s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47394, val loss: 0.47302, in 0.335s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47389, val loss: 0.47299, in 0.274s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47405, val loss: 0.47392, in 0.218s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47397, val loss: 0.47321, in 0.332s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47399, val loss: 0.47377, in 0.233s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45537, val loss: 0.45523, in 0.216s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45570, val loss: 0.45459, in 0.224s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45561, val loss: 0.45466, in 0.225s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45559, val loss: 0.45460, in 0.223s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45557, val loss: 0.45473, in 0.216s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45567, val loss: 0.45557, in 0.220s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45554, val loss: 0.45451, in 0.223s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45561, val loss: 0.45540, in 0.221s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43833, val loss: 0.43831, in 0.218s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43860, val loss: 0.43763, in 0.213s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43865, val loss: 0.43750, in 0.222s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43853, val loss: 0.43740, in 0.210s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43855, val loss: 0.43753, in 0.225s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43865, val loss: 0.43861, in 0.220s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43859, val loss: 0.43845, in 0.216s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43857, val loss: 0.43765, in 0.227s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42249, val loss: 0.42245, in 0.213s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42276, val loss: 0.42175, in 0.201s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42271, val loss: 0.42148, in 0.204s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42283, val loss: 0.42163, in 0.211s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42270, val loss: 0.42163, in 0.208s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42275, val loss: 0.42174, in 0.206s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42283, val loss: 0.42277, in 0.210s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42277, val loss: 0.42263, in 0.215s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40778, val loss: 0.40778, in 0.202s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40805, val loss: 0.40701, in 0.203s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40799, val loss: 0.40666, in 0.199s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40813, val loss: 0.40688, in 0.199s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40800, val loss: 0.40688, in 0.191s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40813, val loss: 0.40811, in 0.191s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40804, val loss: 0.40694, in 0.194s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40806, val loss: 0.40793, in 0.193s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39407, val loss: 0.39415, in 0.182s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39436, val loss: 0.39331, in 0.213s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39443, val loss: 0.39315, in 0.214s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39429, val loss: 0.39296, in 0.214s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39424, val loss: 0.39315, in 0.220s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39435, val loss: 0.39428, in 0.210s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39435, val loss: 0.39323, in 0.219s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39442, val loss: 0.39446, in 0.227s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38122, val loss: 0.38133, in 0.220s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38158, val loss: 0.38049, in 0.207s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38166, val loss: 0.38033, in 0.199s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38150, val loss: 0.38005, in 0.207s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38147, val loss: 0.38034, in 0.200s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38165, val loss: 0.38170, in 0.196s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38157, val loss: 0.38037, in 0.202s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38155, val loss: 0.38147, in 0.212s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36926, val loss: 0.36948, in 0.194s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36972, val loss: 0.36838, in 0.220s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36963, val loss: 0.36858, in 0.225s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36951, val loss: 0.36840, in 0.217s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36956, val loss: 0.36803, in 0.225s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36971, val loss: 0.36977, in 0.224s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36963, val loss: 0.36835, in 0.228s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36966, val loss: 0.36961, in 0.230s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35810, val loss: 0.35833, in 0.237s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35858, val loss: 0.35720, in 0.238s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35849, val loss: 0.35739, in 0.236s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35841, val loss: 0.35686, in 0.228s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35836, val loss: 0.35725, in 0.237s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35854, val loss: 0.35862, in 0.241s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35849, val loss: 0.35719, in 0.238s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35846, val loss: 0.35844, in 0.234s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34763, val loss: 0.34794, in 0.225s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34813, val loss: 0.34675, in 0.201s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34804, val loss: 0.34698, in 0.201s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34796, val loss: 0.34636, in 0.204s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34794, val loss: 0.34684, in 0.204s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34804, val loss: 0.34672, in 0.192s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34811, val loss: 0.34822, in 0.196s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34801, val loss: 0.34800, in 0.201s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33786, val loss: 0.33820, in 0.327s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33835, val loss: 0.33698, in 0.402s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33827, val loss: 0.33722, in 0.405s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33817, val loss: 0.33650, in 0.408s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33815, val loss: 0.33703, in 0.412s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33825, val loss: 0.33688, in 0.421s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33825, val loss: 0.33824, in 0.407s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33833, val loss: 0.33847, in 0.418s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32868, val loss: 0.32910, in 0.322s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32920, val loss: 0.32783, in 0.333s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32901, val loss: 0.32735, in 0.330s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32911, val loss: 0.32807, in 0.344s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32890, val loss: 0.32782, in 0.333s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32905, val loss: 0.32912, in 0.334s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32909, val loss: 0.32929, in 0.336s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32910, val loss: 0.32772, in 0.343s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31998, val loss: 0.32047, in 0.344s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32049, val loss: 0.31910, in 0.333s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32044, val loss: 0.31943, in 0.324s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32037, val loss: 0.31867, in 0.332s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32032, val loss: 0.31921, in 0.329s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32049, val loss: 0.32071, in 0.319s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32037, val loss: 0.32046, in 0.342s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32047, val loss: 0.31906, in 0.333s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31180, val loss: 0.31233, in 0.315s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31236, val loss: 0.31094, in 0.342s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31217, val loss: 0.31105, in 0.330s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31235, val loss: 0.31259, in 0.327s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31220, val loss: 0.31045, in 0.342s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31231, val loss: 0.31130, in 0.348s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31229, val loss: 0.31238, in 0.322s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31231, val loss: 0.31086, in 0.349s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30420, val loss: 0.30473, in 0.336s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30471, val loss: 0.30326, in 0.325s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30461, val loss: 0.30285, in 0.326s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30472, val loss: 0.30326, in 0.289s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30449, val loss: 0.30336, in 0.341s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30472, val loss: 0.30369, in 0.332s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30462, val loss: 0.30474, in 0.328s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30470, val loss: 0.30493, in 0.354s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29696, val loss: 0.29759, in 0.337s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29740, val loss: 0.29557, in 0.317s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29757, val loss: 0.29612, in 0.335s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29734, val loss: 0.29622, in 0.319s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29753, val loss: 0.29601, in 0.333s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29751, val loss: 0.29652, in 0.329s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29756, val loss: 0.29783, in 0.326s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29742, val loss: 0.29757, in 0.341s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29016, val loss: 0.29084, in 0.325s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29063, val loss: 0.28875, in 0.305s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29079, val loss: 0.28935, in 0.299s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29054, val loss: 0.28943, in 0.300s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29076, val loss: 0.28923, in 0.294s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29069, val loss: 0.29082, in 0.280s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29074, val loss: 0.28977, in 0.299s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29077, val loss: 0.29112, in 0.289s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28378, val loss: 0.28450, in 0.245s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28417, val loss: 0.28305, in 0.185s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28442, val loss: 0.28297, in 0.190s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28429, val loss: 0.28245, in 0.194s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28441, val loss: 0.28341, in 0.193s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28439, val loss: 0.28470, in 0.191s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28443, val loss: 0.28291, in 0.201s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28430, val loss: 0.28447, in 0.199s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27779, val loss: 0.27852, in 0.181s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27826, val loss: 0.27638, in 0.316s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27844, val loss: 0.27698, in 0.321s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27819, val loss: 0.27707, in 0.322s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27838, val loss: 0.27739, in 0.311s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27842, val loss: 0.27874, in 0.313s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27840, val loss: 0.27686, in 0.315s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27828, val loss: 0.27847, in 0.316s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27211, val loss: 0.27286, in 0.320s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27277, val loss: 0.27127, in 0.184s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27260, val loss: 0.27066, in 0.188s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27251, val loss: 0.27139, in 0.193s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27273, val loss: 0.27118, in 0.187s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27273, val loss: 0.27311, in 0.196s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27272, val loss: 0.27173, in 0.206s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27264, val loss: 0.27282, in 0.204s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26671, val loss: 0.26752, in 0.182s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26709, val loss: 0.26589, in 0.195s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26715, val loss: 0.26515, in 0.203s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26735, val loss: 0.26581, in 0.213s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26731, val loss: 0.26773, in 0.197s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26732, val loss: 0.26632, in 0.200s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26730, val loss: 0.26567, in 0.214s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26719, val loss: 0.26731, in 0.193s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26165, val loss: 0.26243, in 0.189s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26231, val loss: 0.26074, in 0.200s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26204, val loss: 0.26086, in 0.210s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26210, val loss: 0.26012, in 0.212s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26227, val loss: 0.26122, in 0.196s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26227, val loss: 0.26264, in 0.207s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26225, val loss: 0.26063, in 0.207s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26210, val loss: 0.26230, in 0.210s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25678, val loss: 0.25758, in 0.209s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25746, val loss: 0.25586, in 0.193s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25723, val loss: 0.25520, in 0.189s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25719, val loss: 0.25596, in 0.195s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25741, val loss: 0.25777, in 0.194s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25744, val loss: 0.25637, in 0.198s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25739, val loss: 0.25573, in 0.190s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25723, val loss: 0.25741, in 0.200s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25220, val loss: 0.25298, in 0.199s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25289, val loss: 0.25121, in 0.209s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25262, val loss: 0.25133, in 0.209s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25287, val loss: 0.25180, in 0.199s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25264, val loss: 0.25055, in 0.217s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25283, val loss: 0.25317, in 0.205s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25274, val loss: 0.25291, in 0.187s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25280, val loss: 0.25109, in 0.212s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24765, val loss: 0.24845, in 0.193s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24861, val loss: 0.24695, in 0.186s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24857, val loss: 0.24891, in 0.190s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24809, val loss: 0.24604, in 0.195s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24831, val loss: 0.24724, in 0.198s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24807, val loss: 0.24682, in 0.205s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24824, val loss: 0.24655, in 0.192s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24837, val loss: 0.24851, in 0.208s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24353, val loss: 0.24433, in 0.194s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24449, val loss: 0.24282, in 0.200s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24428, val loss: 0.24320, in 0.188s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24394, val loss: 0.24264, in 0.193s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24444, val loss: 0.24478, in 0.205s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24396, val loss: 0.24184, in 0.203s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24404, val loss: 0.24421, in 0.190s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24411, val loss: 0.24234, in 0.202s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23946, val loss: 0.24033, in 0.191s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24066, val loss: 0.23902, in 0.187s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24009, val loss: 0.23883, in 0.188s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24058, val loss: 0.24090, in 0.190s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23988, val loss: 0.23778, in 0.191s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24037, val loss: 0.23927, in 0.206s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24002, val loss: 0.23826, in 0.191s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24011, val loss: 0.24023, in 0.202s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23582, val loss: 0.23669, in 0.194s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23703, val loss: 0.23539, in 0.197s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23647, val loss: 0.23524, in 0.192s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23666, val loss: 0.23702, in 0.196s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23674, val loss: 0.23562, in 0.194s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23614, val loss: 0.23401, in 0.206s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23622, val loss: 0.23642, in 0.195s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23629, val loss: 0.23450, in 0.200s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23226, val loss: 0.23313, in 0.196s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23347, val loss: 0.23181, in 0.390s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23292, val loss: 0.23163, in 0.409s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23311, val loss: 0.23347, in 0.404s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23320, val loss: 0.23207, in 0.411s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23248, val loss: 0.23040, in 0.411s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23262, val loss: 0.23086, in 0.410s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23266, val loss: 0.23286, in 0.423s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22889, val loss: 0.22974, in 0.427s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23010, val loss: 0.22839, in 0.328s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22959, val loss: 0.23000, in 0.315s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22958, val loss: 0.22832, in 0.324s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22994, val loss: 0.22881, in 0.311s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22911, val loss: 0.22701, in 0.319s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22925, val loss: 0.22747, in 0.324s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22917, val loss: 0.22940, in 0.317s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22529, val loss: 0.22618, in 0.297s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22637, val loss: 0.22473, in 0.320s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22597, val loss: 0.22474, in 0.335s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22588, val loss: 0.22629, in 0.339s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22623, val loss: 0.22512, in 0.336s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22537, val loss: 0.22334, in 0.330s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22551, val loss: 0.22380, in 0.332s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22210, val loss: 0.22301, in 0.332s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22541, val loss: 0.22564, in 0.339s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22313, val loss: 0.22150, in 0.333s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22276, val loss: 0.22311, in 0.319s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22235, val loss: 0.22066, in 0.303s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22301, val loss: 0.22190, in 0.327s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22286, val loss: 0.22157, in 0.332s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22238, val loss: 0.22261, in 0.308s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22222, val loss: 0.22022, in 0.332s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21913, val loss: 0.22004, in 0.332s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22017, val loss: 0.21856, in 0.327s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21972, val loss: 0.22008, in 0.332s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21936, val loss: 0.21763, in 0.328s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21924, val loss: 0.21720, in 0.317s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21977, val loss: 0.21851, in 0.333s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21593, val loss: 0.21686, in 0.306s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22005, val loss: 0.21890, in 0.338s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21943, val loss: 0.21967, in 0.325s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21690, val loss: 0.21534, in 0.304s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21637, val loss: 0.21676, in 0.314s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21603, val loss: 0.21437, in 0.315s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21668, val loss: 0.21558, in 0.315s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21607, val loss: 0.21636, in 0.321s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21315, val loss: 0.21406, in 0.323s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21588, val loss: 0.21381, in 0.328s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21648, val loss: 0.21519, in 0.334s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21408, val loss: 0.21253, in 0.318s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21324, val loss: 0.21154, in 0.298s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21364, val loss: 0.21402, in 0.307s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21403, val loss: 0.21292, in 0.291s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21313, val loss: 0.21109, in 0.289s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21368, val loss: 0.21239, in 0.287s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21332, val loss: 0.21354, in 0.298s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21013, val loss: 0.21105, in 0.301s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21106, val loss: 0.20950, in 0.190s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21015, val loss: 0.20819, in 0.180s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21107, val loss: 0.21146, in 0.191s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21142, val loss: 0.21023, in 0.199s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21021, val loss: 0.20849, in 0.204s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20765, val loss: 0.20861, in 0.191s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21069, val loss: 0.20944, in 0.196s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21029, val loss: 0.21055, in 0.196s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20860, val loss: 0.20701, in 0.301s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20811, val loss: 0.20851, in 0.293s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20854, val loss: 0.20738, in 0.301s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20762, val loss: 0.20561, in 0.316s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20815, val loss: 0.20686, in 0.296s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20783, val loss: 0.20806, in 0.297s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20774, val loss: 0.20605, in 0.308s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20523, val loss: 0.20620, in 0.306s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20614, val loss: 0.20460, in 0.229s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20568, val loss: 0.20609, in 0.241s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20522, val loss: 0.20330, in 0.232s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20571, val loss: 0.20446, in 0.238s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20609, val loss: 0.20498, in 0.246s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20542, val loss: 0.20565, in 0.241s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20254, val loss: 0.20352, in 0.236s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20535, val loss: 0.20365, in 0.246s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20350, val loss: 0.20198, in 0.215s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20046, val loss: 0.20149, in 0.178s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20250, val loss: 0.20055, in 0.200s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20331, val loss: 0.20379, in 0.216s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20301, val loss: 0.20173, in 0.203s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20263, val loss: 0.20094, in 0.198s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20341, val loss: 0.20229, in 0.208s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20269, val loss: 0.20293, in 0.209s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20140, val loss: 0.19995, in 0.182s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20040, val loss: 0.19853, in 0.180s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20118, val loss: 0.20175, in 0.182s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20056, val loss: 0.20089, in 0.168s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20133, val loss: 0.20025, in 0.173s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20093, val loss: 0.19971, in 0.181s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19836, val loss: 0.19938, in 0.203s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20057, val loss: 0.19896, in 0.181s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19924, val loss: 0.19781, in 0.186s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19844, val loss: 0.19662, in 0.171s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19920, val loss: 0.19981, in 0.172s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19647, val loss: 0.19753, in 0.170s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19880, val loss: 0.19756, in 0.203s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19916, val loss: 0.19809, in 0.209s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19841, val loss: 0.19686, in 0.205s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19840, val loss: 0.19878, in 0.216s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19730, val loss: 0.19592, in 0.172s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19469, val loss: 0.19579, in 0.178s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19711, val loss: 0.19770, in 0.203s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19632, val loss: 0.19454, in 0.217s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19689, val loss: 0.19569, in 0.176s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19621, in 0.171s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19650, val loss: 0.19503, in 0.178s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19645, val loss: 0.19689, in 0.182s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19551, val loss: 0.19417, in 0.175s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19528, val loss: 0.19595, in 0.174s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19511, val loss: 0.19395, in 0.171s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19264, val loss: 0.19371, in 0.202s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19453, val loss: 0.19281, in 0.176s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19545, val loss: 0.19446, in 0.181s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19473, val loss: 0.19334, in 0.173s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19461, val loss: 0.19514, in 0.169s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19346, val loss: 0.19210, in 0.211s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19100, val loss: 0.19211, in 0.183s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19326, val loss: 0.19391, in 0.207s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19256, val loss: 0.19083, in 0.206s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19315, val loss: 0.19198, in 0.214s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19271, val loss: 0.19133, in 0.205s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19343, val loss: 0.19242, in 0.212s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19257, val loss: 0.19308, in 0.209s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19166, val loss: 0.19029, in 0.162s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19151, val loss: 0.19221, in 0.164s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19077, val loss: 0.18903, in 0.166s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19090, val loss: 0.18953, in 0.165s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19138, val loss: 0.19019, in 0.167s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19171, val loss: 0.19065, in 0.163s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19085, val loss: 0.19137, in 0.166s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18914, val loss: 0.19030, in 0.213s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18973, val loss: 0.18833, in 0.221s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18991, val loss: 0.19068, in 0.185s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18748, val loss: 0.18861, in 0.169s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18882, val loss: 0.18707, in 0.218s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18905, val loss: 0.18770, in 0.215s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18981, val loss: 0.18876, in 0.212s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18947, val loss: 0.18827, in 0.219s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18894, val loss: 0.18945, in 0.213s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18821, val loss: 0.18680, in 0.159s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18729, val loss: 0.18555, in 0.163s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18741, val loss: 0.18606, in 0.164s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18797, val loss: 0.18676, in 0.164s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18735, val loss: 0.18794, in 0.168s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18829, val loss: 0.18722, in 0.173s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18806, val loss: 0.18886, in 0.221s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18564, val loss: 0.18673, in 0.208s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18672, val loss: 0.18535, in 0.332s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18573, val loss: 0.18397, in 0.356s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18658, val loss: 0.18742, in 0.365s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18679, val loss: 0.18577, in 0.373s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18583, val loss: 0.18643, in 0.376s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18648, val loss: 0.18531, in 0.386s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18425, val loss: 0.18534, in 0.378s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18558, val loss: 0.18421, in 0.455s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18499, val loss: 0.18365, in 0.356s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18397, val loss: 0.18223, in 0.360s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18490, val loss: 0.18578, in 0.361s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18510, val loss: 0.18405, in 0.355s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18413, val loss: 0.18479, in 0.353s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18260, val loss: 0.18371, in 0.353s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18479, val loss: 0.18361, in 0.358s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18399, val loss: 0.18270, in 0.328s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18350, val loss: 0.18214, in 0.289s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18250, in 0.294s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18345, val loss: 0.18437, in 0.300s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18073, in 0.329s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18119, val loss: 0.18231, in 0.301s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18253, val loss: 0.18321, in 0.320s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18308, val loss: 0.18190, in 0.320s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18260, val loss: 0.18134, in 0.300s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18186, val loss: 0.18053, in 0.321s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18105, val loss: 0.17938, in 0.310s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17980, val loss: 0.18089, in 0.315s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18104, val loss: 0.18174, in 0.320s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18192, val loss: 0.18288, in 0.347s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18169, val loss: 0.18053, in 0.321s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18193, val loss: 0.18084, in 0.398s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18097, val loss: 0.17972, in 0.387s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18023, val loss: 0.17888, in 0.355s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17962, val loss: 0.17795, in 0.296s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17827, val loss: 0.17935, in 0.314s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17972, val loss: 0.18043, in 0.300s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18022, val loss: 0.18107, in 0.342s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18009, val loss: 0.17893, in 0.358s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18030, val loss: 0.17923, in 0.320s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17966, val loss: 0.17844, in 0.307s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17826, val loss: 0.17698, in 0.349s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17645, val loss: 0.17754, in 0.354s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17812, val loss: 0.17648, in 0.418s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17885, val loss: 0.17976, in 0.352s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17815, val loss: 0.17887, in 0.428s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17830, val loss: 0.17705, in 0.340s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17871, val loss: 0.17756, in 0.369s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17888, val loss: 0.17787, in 0.366s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17694, val loss: 0.17570, in 0.299s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17523, val loss: 0.17629, in 0.301s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17681, val loss: 0.17518, in 0.291s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17747, val loss: 0.17843, in 0.284s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17693, val loss: 0.17576, in 0.286s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17736, val loss: 0.17620, in 0.287s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17683, val loss: 0.17758, in 0.304s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17757, val loss: 0.17653, in 0.298s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17570, val loss: 0.17443, in 0.289s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17406, val loss: 0.17512, in 0.245s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17555, val loss: 0.17391, in 0.246s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17618, val loss: 0.17717, in 0.241s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17574, val loss: 0.17453, in 0.222s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17608, val loss: 0.17492, in 0.226s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17551, val loss: 0.17630, in 0.229s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17629, val loss: 0.17526, in 0.227s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17440, val loss: 0.17319, in 0.198s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17440, val loss: 0.17274, in 0.168s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17492, val loss: 0.17594, in 0.183s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17430, val loss: 0.17512, in 0.165s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17431, val loss: 0.17315, in 0.183s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17259, val loss: 0.17366, in 0.230s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17511, val loss: 0.17404, in 0.168s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17467, val loss: 0.17355, in 0.195s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17323, val loss: 0.17202, in 0.336s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17376, val loss: 0.17480, in 0.348s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17312, val loss: 0.17398, in 0.347s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17289, val loss: 0.17128, in 0.392s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17148, val loss: 0.17249, in 0.360s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17345, val loss: 0.17230, in 0.360s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17375, val loss: 0.17271, in 0.413s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17284, val loss: 0.17164, in 0.418s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17189, val loss: 0.17070, in 0.245s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17265, val loss: 0.17371, in 0.190s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17165, val loss: 0.17002, in 0.192s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17176, val loss: 0.17266, in 0.214s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16985, val loss: 0.17090, in 0.204s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17167, val loss: 0.17047, in 0.178s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17164, val loss: 0.17058, in 0.221s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17241, val loss: 0.17140, in 0.198s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17074, val loss: 0.16956, in 0.185s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17142, val loss: 0.17251, in 0.200s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17031, val loss: 0.16870, in 0.225s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17009, val loss: 0.17100, in 0.237s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16853, val loss: 0.16961, in 0.231s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17058, val loss: 0.16935, in 0.204s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17052, val loss: 0.16943, in 0.220s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17119, val loss: 0.17014, in 0.210s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16942, val loss: 0.16830, in 0.243s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17032, val loss: 0.17143, in 0.208s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16869, val loss: 0.16716, in 0.215s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16897, val loss: 0.16988, in 0.199s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16943, val loss: 0.16825, in 0.198s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16745, val loss: 0.16848, in 0.209s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17011, val loss: 0.16908, in 0.190s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16935, val loss: 0.16832, in 0.202s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16836, val loss: 0.16726, in 0.182s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16888, val loss: 0.16999, in 0.189s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16765, val loss: 0.16608, in 0.175s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16786, val loss: 0.16672, in 0.202s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16912, val loss: 0.16810, in 0.189s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16623, val loss: 0.16728, in 0.213s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16758, val loss: 0.16842, in 0.245s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16788, val loss: 0.16682, in 0.241s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16725, val loss: 0.16613, in 0.184s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16725, val loss: 0.16838, in 0.202s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16659, val loss: 0.16504, in 0.180s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16777, val loss: 0.16677, in 0.182s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16484, val loss: 0.16589, in 0.182s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16661, val loss: 0.16551, in 0.209s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16654, val loss: 0.16739, in 0.171s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16681, val loss: 0.16572, in 0.168s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16587, val loss: 0.16475, in 0.180s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16627, val loss: 0.16742, in 0.187s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16554, val loss: 0.16397, in 0.184s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16681, val loss: 0.16579, in 0.174s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16385, val loss: 0.16488, in 0.164s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16566, val loss: 0.16455, in 0.174s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16541, val loss: 0.16628, in 0.191s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16576, val loss: 0.16470, in 0.181s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16483, val loss: 0.16370, in 0.177s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16509, val loss: 0.16625, in 0.186s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16281, in 0.181s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16579, val loss: 0.16475, in 0.157s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16471, val loss: 0.16361, in 0.160s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16377, in 0.198s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16479, val loss: 0.16371, in 0.161s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16415, val loss: 0.16504, in 0.183s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16375, val loss: 0.16264, in 0.206s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16326, val loss: 0.16218, in 0.175s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16373, val loss: 0.16489, in 0.229s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16467, val loss: 0.16365, in 0.206s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16292, val loss: 0.16137, in 0.216s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16168, val loss: 0.16272, in 0.187s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16318, val loss: 0.16410, in 0.169s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16365, val loss: 0.16259, in 0.199s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16264, val loss: 0.16158, in 0.206s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16278, val loss: 0.16390, in 0.206s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16150, val loss: 0.15995, in 0.208s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16319, val loss: 0.16220, in 0.212s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16216, val loss: 0.16112, in 0.221s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16069, val loss: 0.16172, in 0.197s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16174, val loss: 0.16263, in 0.202s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16231, val loss: 0.16126, in 0.193s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16136, val loss: 0.16032, in 0.213s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16133, val loss: 0.16245, in 0.191s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16224, val loss: 0.16123, in 0.183s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16099, val loss: 0.15999, in 0.179s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15952, val loss: 0.16058, in 0.177s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16054, val loss: 0.15896, in 0.192s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.16040, in 0.176s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16065, val loss: 0.16154, in 0.196s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16043, val loss: 0.15941, in 0.173s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16109, val loss: 0.16009, in 0.178s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16011, val loss: 0.16127, in 0.182s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16003, val loss: 0.15906, in 0.183s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15939, val loss: 0.15783, in 0.178s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16028, val loss: 0.15923, in 0.170s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15843, val loss: 0.15946, in 0.187s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15973, val loss: 0.16064, in 0.174s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15899, val loss: 0.15803, in 0.194s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15987, val loss: 0.15891, in 0.274s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15884, val loss: 0.16000, in 0.273s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15719, val loss: 0.15822, in 0.334s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15866, val loss: 0.15773, in 0.347s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15799, val loss: 0.15649, in 0.357s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15926, val loss: 0.15825, in 0.353s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15860, val loss: 0.15955, in 0.343s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15776, val loss: 0.15679, in 0.408s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15791, val loss: 0.15910, in 0.327s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15891, val loss: 0.15793, in 0.352s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15638, val loss: 0.15741, in 0.278s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15773, val loss: 0.15680, in 0.282s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15772, val loss: 0.15867, in 0.281s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15821, val loss: 0.15715, in 0.290s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15712, val loss: 0.15564, in 0.295s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15691, val loss: 0.15595, in 0.277s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15681, val loss: 0.15802, in 0.290s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15811, val loss: 0.15712, in 0.288s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15688, val loss: 0.15595, in 0.300s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15556, val loss: 0.15652, in 0.309s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15621, val loss: 0.15472, in 0.306s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15735, val loss: 0.15626, in 0.311s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15664, val loss: 0.15759, in 0.316s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15585, val loss: 0.15491, in 0.312s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15597, val loss: 0.15720, in 0.300s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15471, val loss: 0.15566, in 0.293s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15677, val loss: 0.15582, in 0.320s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15541, val loss: 0.15393, in 0.285s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15535, val loss: 0.15627, in 0.297s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15591, val loss: 0.15498, in 0.342s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15596, val loss: 0.15493, in 0.314s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15481, val loss: 0.15389, in 0.291s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15512, val loss: 0.15637, in 0.283s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15574, val loss: 0.15480, in 0.270s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15440, val loss: 0.15293, in 0.292s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15492, val loss: 0.15389, in 0.285s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15513, val loss: 0.15418, in 0.296s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15374, val loss: 0.15469, in 0.350s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15440, val loss: 0.15536, in 0.322s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15367, val loss: 0.15274, in 0.307s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15395, val loss: 0.15521, in 0.307s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15462, val loss: 0.15371, in 0.334s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15312, val loss: 0.15165, in 0.312s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15372, val loss: 0.15269, in 0.312s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15411, val loss: 0.15320, in 0.308s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15260, val loss: 0.15354, in 0.311s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15347, val loss: 0.15443, in 0.303s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15294, val loss: 0.15198, in 0.279s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15301, val loss: 0.15426, in 0.331s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15231, val loss: 0.15087, in 0.299s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15297, val loss: 0.15192, in 0.279s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15366, val loss: 0.15278, in 0.332s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15282, val loss: 0.15194, in 0.296s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15247, val loss: 0.15344, in 0.289s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15131, val loss: 0.15225, in 0.319s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15217, val loss: 0.15121, in 0.291s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15227, val loss: 0.15352, in 0.294s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15221, val loss: 0.15117, in 0.312s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15164, val loss: 0.15262, in 0.297s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15268, val loss: 0.15175, in 0.321s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15106, val loss: 0.14970, in 0.340s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15159, val loss: 0.15077, in 0.331s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15055, val loss: 0.15144, in 0.309s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15128, val loss: 0.15036, in 0.308s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15129, val loss: 0.15257, in 0.251s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15125, val loss: 0.15022, in 0.218s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15090, val loss: 0.15190, in 0.221s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15033, val loss: 0.14895, in 0.208s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15063, val loss: 0.14978, in 0.211s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15174, val loss: 0.15081, in 0.247s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14966, val loss: 0.15058, in 0.225s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15044, val loss: 0.14953, in 0.170s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15003, val loss: 0.15130, in 0.310s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15051, val loss: 0.14944, in 0.301s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15008, val loss: 0.15105, in 0.299s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14949, val loss: 0.14812, in 0.332s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14989, val loss: 0.14904, in 0.342s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14892, val loss: 0.14984, in 0.324s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15053, val loss: 0.14962, in 0.333s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14950, val loss: 0.14864, in 0.334s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14908, val loss: 0.15040, in 0.223s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14942, val loss: 0.14835, in 0.213s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14891, val loss: 0.14986, in 0.209s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14871, val loss: 0.14734, in 0.200s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14898, val loss: 0.14814, in 0.176s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14798, val loss: 0.14888, in 0.184s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14975, val loss: 0.14881, in 0.184s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14870, val loss: 0.14781, in 0.167s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14823, val loss: 0.14919, in 0.154s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14813, val loss: 0.14944, in 0.185s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14816, val loss: 0.14713, in 0.180s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14753, val loss: 0.14617, in 0.171s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14781, val loss: 0.14698, in 0.175s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14883, val loss: 0.14789, in 0.171s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14682, val loss: 0.14773, in 0.182s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14794, val loss: 0.14706, in 0.179s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14743, val loss: 0.14839, in 0.175s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14744, val loss: 0.14876, in 0.174s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14738, val loss: 0.14634, in 0.190s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14669, val loss: 0.14537, in 0.193s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14781, val loss: 0.14690, in 0.172s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14579, val loss: 0.14670, in 0.177s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14695, val loss: 0.14617, in 0.200s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14691, val loss: 0.14603, in 0.180s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14671, val loss: 0.14767, in 0.171s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14639, val loss: 0.14770, in 0.164s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14670, val loss: 0.14567, in 0.190s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14705, val loss: 0.14610, in 0.184s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14623, val loss: 0.14545, in 0.173s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14487, val loss: 0.14576, in 0.179s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14583, val loss: 0.14454, in 0.197s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14618, val loss: 0.14534, in 0.164s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14563, val loss: 0.14658, in 0.185s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14550, val loss: 0.14683, in 0.188s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14610, val loss: 0.14506, in 0.156s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14622, val loss: 0.14528, in 0.186s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14510, val loss: 0.14382, in 0.179s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14547, val loss: 0.14471, in 0.187s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14421, val loss: 0.14508, in 0.187s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14451, in 0.173s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14620, in 0.164s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14495, val loss: 0.14590, in 0.185s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14430, in 0.185s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14449, val loss: 0.14319, in 0.167s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14482, val loss: 0.14404, in 0.176s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14542, val loss: 0.14447, in 0.183s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14469, val loss: 0.14385, in 0.171s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14358, val loss: 0.14443, in 0.176s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14400, val loss: 0.14532, in 0.183s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14425, val loss: 0.14518, in 0.178s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14420, val loss: 0.14321, in 0.193s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14397, val loss: 0.14323, in 0.161s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14364, val loss: 0.14236, in 0.174s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14473, val loss: 0.14378, in 0.181s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14388, val loss: 0.14308, in 0.186s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14278, val loss: 0.14365, in 0.194s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14340, val loss: 0.14435, in 0.163s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14336, val loss: 0.14468, in 0.171s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14364, val loss: 0.14263, in 0.155s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14339, val loss: 0.14264, in 0.167s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14180, in 0.167s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14328, val loss: 0.14248, in 0.165s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14391, val loss: 0.14299, in 0.176s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14220, val loss: 0.14305, in 0.161s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14239, val loss: 0.14371, in 0.177s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14373, in 0.182s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14180, in 0.173s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14201, val loss: 0.14075, in 0.165s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14271, val loss: 0.14195, in 0.175s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14262, val loss: 0.14179, in 0.172s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14135, val loss: 0.14218, in 0.169s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14332, val loss: 0.14237, in 0.170s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14164, val loss: 0.14297, in 0.190s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14180, val loss: 0.14082, in 0.174s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14195, val loss: 0.14286, in 0.206s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14134, val loss: 0.14009, in 0.174s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14197, val loss: 0.14124, in 0.176s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14186, val loss: 0.14104, in 0.167s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14261, val loss: 0.14163, in 0.175s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14040, val loss: 0.14125, in 0.185s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14126, val loss: 0.14024, in 0.162s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14100, val loss: 0.14230, in 0.183s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14074, val loss: 0.13948, in 0.165s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14133, val loss: 0.14221, in 0.182s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14112, val loss: 0.14030, in 0.162s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14091, val loss: 0.14018, in 0.179s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14196, val loss: 0.14097, in 0.164s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13977, val loss: 0.14062, in 0.166s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14032, val loss: 0.13933, in 0.176s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14023, val loss: 0.14159, in 0.176s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13995, val loss: 0.13870, in 0.173s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14042, val loss: 0.13962, in 0.164s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14022, val loss: 0.13951, in 0.170s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14069, val loss: 0.14158, in 0.190s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14103, val loss: 0.14007, in 0.182s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13907, val loss: 0.13991, in 0.187s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13944, val loss: 0.14081, in 0.214s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13951, val loss: 0.13854, in 0.348s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13920, val loss: 0.13797, in 0.350s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13963, val loss: 0.13893, in 0.350s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13971, val loss: 0.13894, in 0.373s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13959, val loss: 0.14047, in 0.380s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13845, val loss: 0.13933, in 0.351s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14031, val loss: 0.13936, in 0.387s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13888, val loss: 0.14023, in 0.400s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13876, val loss: 0.13778, in 0.275s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13857, val loss: 0.13734, in 0.270s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13909, val loss: 0.13832, in 0.300s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13790, val loss: 0.13876, in 0.278s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13893, val loss: 0.13826, in 0.322s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13860, val loss: 0.13946, in 0.298s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13960, val loss: 0.13868, in 0.290s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13824, val loss: 0.13961, in 0.284s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13822, val loss: 0.13723, in 0.291s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13787, val loss: 0.13667, in 0.318s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13838, val loss: 0.13770, in 0.291s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13839, val loss: 0.13763, in 0.308s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13780, val loss: 0.13868, in 0.297s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13907, val loss: 0.13814, in 0.286s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13718, val loss: 0.13801, in 0.340s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13754, val loss: 0.13653, in 0.299s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13734, val loss: 0.13877, in 0.348s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13710, val loss: 0.13589, in 0.307s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13860, val loss: 0.13766, in 0.255s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13763, val loss: 0.13700, in 0.294s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13709, val loss: 0.13800, in 0.291s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13784, val loss: 0.13709, in 0.296s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13642, val loss: 0.13725, in 0.297s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13695, val loss: 0.13594, in 0.286s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13659, val loss: 0.13798, in 0.268s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13656, val loss: 0.13531, in 0.278s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13783, val loss: 0.13689, in 0.291s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13700, val loss: 0.13638, in 0.283s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13730, val loss: 0.13653, in 0.281s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13655, in 0.276s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13654, val loss: 0.13743, in 0.316s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13628, val loss: 0.13531, in 0.291s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13600, val loss: 0.13737, in 0.284s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13449, in 0.274s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13640, val loss: 0.13576, in 0.279s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13715, val loss: 0.13621, in 0.301s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13653, val loss: 0.13577, in 0.290s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13553, val loss: 0.13642, in 0.307s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13500, val loss: 0.13581, in 0.347s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13547, val loss: 0.13685, in 0.281s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13596, val loss: 0.13531, in 0.255s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13557, val loss: 0.13456, in 0.350s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13590, val loss: 0.13516, in 0.283s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13630, val loss: 0.13539, in 0.292s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13501, val loss: 0.13377, in 0.359s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13585, in 0.286s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13446, val loss: 0.13525, in 0.295s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13482, val loss: 0.13620, in 0.276s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13518, val loss: 0.13453, in 0.274s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13455, val loss: 0.13332, in 0.256s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13496, val loss: 0.13393, in 0.298s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13523, val loss: 0.13449, in 0.280s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13477, in 0.327s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13444, val loss: 0.13536, in 0.282s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13390, val loss: 0.13472, in 0.272s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13411, val loss: 0.13552, in 0.256s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13469, val loss: 0.13402, in 0.236s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13398, val loss: 0.13276, in 0.228s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13432, val loss: 0.13332, in 0.245s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13375, in 0.242s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13354, val loss: 0.13443, in 0.197s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13512, val loss: 0.13420, in 0.219s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13341, val loss: 0.13421, in 0.190s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13340, val loss: 0.13481, in 0.192s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13397, val loss: 0.13329, in 0.193s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13319, val loss: 0.13195, in 0.172s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13289, val loss: 0.13379, in 0.272s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13284, in 0.295s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13448, val loss: 0.13359, in 0.302s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13337, in 0.304s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13239, in 0.363s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13280, val loss: 0.13422, in 0.290s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13249, val loss: 0.13125, in 0.287s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13235, in 0.309s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13229, in 0.179s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13407, val loss: 0.13319, in 0.163s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13219, val loss: 0.13311, in 0.223s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13178, val loss: 0.13258, in 0.171s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13271, val loss: 0.13172, in 0.157s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13211, val loss: 0.13349, in 0.174s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13231, val loss: 0.13166, in 0.161s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13193, val loss: 0.13071, in 0.165s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13252, val loss: 0.13182, in 0.168s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13334, val loss: 0.13246, in 0.163s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13153, val loss: 0.13247, in 0.164s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13219, val loss: 0.13120, in 0.166s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13121, val loss: 0.13201, in 0.184s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13157, val loss: 0.13297, in 0.168s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13174, val loss: 0.13111, in 0.168s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13118, val loss: 0.12996, in 0.169s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13275, val loss: 0.13188, in 0.156s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13194, val loss: 0.13121, in 0.172s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13078, val loss: 0.13177, in 0.175s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13171, val loss: 0.13071, in 0.167s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13063, val loss: 0.13139, in 0.180s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.13252, in 0.163s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13101, val loss: 0.13038, in 0.162s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13067, val loss: 0.12950, in 0.172s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13196, val loss: 0.13108, in 0.171s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13032, val loss: 0.13129, in 0.170s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13112, val loss: 0.13015, in 0.166s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13104, val loss: 0.13030, in 0.235s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12993, val loss: 0.13067, in 0.175s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13025, val loss: 0.13166, in 0.182s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13039, val loss: 0.12975, in 0.174s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12901, in 0.168s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13148, val loss: 0.13060, in 0.162s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13035, val loss: 0.12939, in 0.163s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13048, in 0.180s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12969, in 0.162s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12929, val loss: 0.13001, in 0.195s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12961, val loss: 0.13100, in 0.160s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12957, val loss: 0.12837, in 0.157s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12987, val loss: 0.12923, in 0.168s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13068, val loss: 0.12983, in 0.176s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12960, val loss: 0.12863, in 0.173s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12903, val loss: 0.12999, in 0.179s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12980, val loss: 0.12905, in 0.170s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12878, val loss: 0.12953, in 0.159s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12895, val loss: 0.12775, in 0.161s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12903, val loss: 0.13043, in 0.173s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12915, val loss: 0.12848, in 0.164s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13018, val loss: 0.12931, in 0.171s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12898, val loss: 0.12801, in 0.157s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12914, val loss: 0.12837, in 0.158s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12831, val loss: 0.12929, in 0.172s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12786, in 0.157s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12834, val loss: 0.12909, in 0.192s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12991, in 0.175s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12841, val loss: 0.12720, in 0.192s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12962, val loss: 0.12873, in 0.173s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12849, val loss: 0.12751, in 0.164s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12860, val loss: 0.12785, in 0.174s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12772, val loss: 0.12871, in 0.179s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12775, val loss: 0.12850, in 0.178s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12788, val loss: 0.12664, in 0.174s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12799, val loss: 0.12732, in 0.202s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12798, val loss: 0.12936, in 0.195s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12889, val loss: 0.12799, in 0.173s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12813, val loss: 0.12715, in 0.162s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12822, val loss: 0.12746, in 0.147s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12730, val loss: 0.12829, in 0.159s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12717, val loss: 0.12791, in 0.159s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12759, val loss: 0.12693, in 0.154s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12720, val loss: 0.12594, in 0.174s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12752, val loss: 0.12888, in 0.175s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12839, val loss: 0.12748, in 0.170s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12753, val loss: 0.12655, in 0.183s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12766, val loss: 0.12690, in 0.169s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12661, val loss: 0.12757, in 0.159s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12650, val loss: 0.12724, in 0.169s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12700, val loss: 0.12633, in 0.168s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12652, val loss: 0.12527, in 0.174s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12690, val loss: 0.12826, in 0.195s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12783, val loss: 0.12693, in 0.186s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12672, val loss: 0.12576, in 0.172s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12719, val loss: 0.12642, in 0.172s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12692, in 0.193s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12634, val loss: 0.12567, in 0.161s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12597, val loss: 0.12669, in 0.180s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12613, val loss: 0.12488, in 0.185s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12612, val loss: 0.12748, in 0.195s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12600, val loss: 0.12508, in 0.178s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12667, val loss: 0.12590, in 0.208s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12697, val loss: 0.12611, in 0.222s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12515, val loss: 0.12608, in 0.180s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12537, val loss: 0.12608, in 0.161s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12577, val loss: 0.12513, in 0.196s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12551, val loss: 0.12426, in 0.188s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12552, val loss: 0.12686, in 0.156s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12544, val loss: 0.12452, in 0.176s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12643, val loss: 0.12560, in 0.176s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12585, val loss: 0.12510, in 0.179s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12449, val loss: 0.12546, in 0.179s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12474, val loss: 0.12543, in 0.160s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12517, val loss: 0.12450, in 0.194s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12488, val loss: 0.12624, in 0.320s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12462, val loss: 0.12338, in 0.333s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12482, val loss: 0.12389, in 0.372s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12388, val loss: 0.12486, in 0.356s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12577, val loss: 0.12496, in 0.372s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12515, val loss: 0.12438, in 0.373s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12506, in 0.389s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12453, val loss: 0.12384, in 0.424s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12573, in 0.265s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12392, val loss: 0.12269, in 0.297s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12428, val loss: 0.12337, in 0.298s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12452, val loss: 0.12375, in 0.273s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12516, val loss: 0.12434, in 0.293s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12313, val loss: 0.12413, in 0.303s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12372, val loss: 0.12441, in 0.280s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12401, val loss: 0.12330, in 0.273s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12385, val loss: 0.12522, in 0.273s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12336, val loss: 0.12216, in 0.285s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12378, val loss: 0.12286, in 0.266s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12279, val loss: 0.12378, in 0.253s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12477, val loss: 0.12392, in 0.258s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12410, val loss: 0.12334, in 0.277s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12314, val loss: 0.12382, in 0.316s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12327, val loss: 0.12465, in 0.255s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12355, val loss: 0.12286, in 0.284s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12294, val loss: 0.12174, in 0.278s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12340, val loss: 0.12249, in 0.300s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12214, val loss: 0.12311, in 0.293s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12353, val loss: 0.12276, in 0.304s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12432, val loss: 0.12348, in 0.330s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12276, val loss: 0.12342, in 0.328s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12258, val loss: 0.12400, in 0.345s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12310, val loss: 0.12244, in 0.342s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12232, val loss: 0.12111, in 0.335s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12275, val loss: 0.12184, in 0.295s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12155, val loss: 0.12255, in 0.308s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12361, val loss: 0.12279, in 0.296s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12293, val loss: 0.12216, in 0.323s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12228, val loss: 0.12294, in 0.329s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12257, val loss: 0.12190, in 0.267s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12218, val loss: 0.12357, in 0.282s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12179, val loss: 0.12057, in 0.274s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12219, val loss: 0.12129, in 0.263s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12098, val loss: 0.12202, in 0.273s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12245, val loss: 0.12169, in 0.277s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12303, val loss: 0.12221, in 0.338s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12162, val loss: 0.12302, in 0.275s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12153, val loss: 0.12221, in 0.292s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12208, val loss: 0.12142, in 0.287s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12144, val loss: 0.12022, in 0.267s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12155, val loss: 0.12065, in 0.287s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12191, val loss: 0.12118, in 0.286s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12041, val loss: 0.12144, in 0.337s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12174, in 0.271s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12125, val loss: 0.12264, in 0.268s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12097, val loss: 0.12165, in 0.273s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12147, val loss: 0.12083, in 0.289s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12083, val loss: 0.11961, in 0.273s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12109, val loss: 0.12017, in 0.347s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11990, val loss: 0.12094, in 0.289s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12194, val loss: 0.12113, in 0.301s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12140, val loss: 0.12069, in 0.364s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12072, val loss: 0.12208, in 0.306s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12044, val loss: 0.12114, in 0.320s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12038, val loss: 0.11914, in 0.299s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12102, val loss: 0.12037, in 0.327s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12057, val loss: 0.11966, in 0.235s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11950, val loss: 0.12055, in 0.244s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12096, val loss: 0.12023, in 0.223s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.12064, in 0.247s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12023, val loss: 0.12160, in 0.211s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11988, val loss: 0.11863, in 0.185s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11985, val loss: 0.12056, in 0.207s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12047, val loss: 0.11981, in 0.239s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12012, val loss: 0.11918, in 0.226s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11899, val loss: 0.12005, in 0.206s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12085, val loss: 0.12004, in 0.191s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12059, val loss: 0.11986, in 0.198s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11940, val loss: 0.11814, in 0.303s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11929, val loss: 0.11998, in 0.304s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11969, val loss: 0.12106, in 0.336s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12013, val loss: 0.11946, in 0.278s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11963, val loss: 0.11870, in 0.267s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11841, val loss: 0.11943, in 0.280s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12029, val loss: 0.11948, in 0.274s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12011, val loss: 0.11938, in 0.279s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11902, val loss: 0.11776, in 0.160s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11888, val loss: 0.11955, in 0.171s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11957, val loss: 0.11891, in 0.167s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11913, val loss: 0.12053, in 0.182s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11923, val loss: 0.11831, in 0.181s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11795, val loss: 0.11897, in 0.175s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11995, val loss: 0.11914, in 0.157s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11870, val loss: 0.11746, in 0.149s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11969, val loss: 0.11897, in 0.187s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11837, val loss: 0.11904, in 0.164s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11908, val loss: 0.11841, in 0.170s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11853, val loss: 0.11995, in 0.210s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11863, val loss: 0.11774, in 0.175s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11744, val loss: 0.11846, in 0.210s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11940, val loss: 0.11856, in 0.213s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11919, val loss: 0.11845, in 0.174s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11813, val loss: 0.11690, in 0.179s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11789, val loss: 0.11857, in 0.215s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11853, val loss: 0.11785, in 0.188s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11803, val loss: 0.11943, in 0.160s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11809, val loss: 0.11719, in 0.199s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11872, val loss: 0.11799, in 0.155s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11694, val loss: 0.11798, in 0.163s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11872, val loss: 0.11787, in 0.192s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11632, in 0.204s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11816, val loss: 0.11752, in 0.171s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11737, val loss: 0.11804, in 0.179s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11774, val loss: 0.11914, in 0.168s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11761, val loss: 0.11671, in 0.151s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11829, val loss: 0.11755, in 0.161s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11657, val loss: 0.11760, in 0.159s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11817, val loss: 0.11734, in 0.149s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11694, val loss: 0.11574, in 0.159s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11707, val loss: 0.11774, in 0.147s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11724, val loss: 0.11867, in 0.147s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11760, val loss: 0.11695, in 0.164s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11729, val loss: 0.11641, in 0.150s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11694, in 0.159s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11626, val loss: 0.11732, in 0.164s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11780, val loss: 0.11698, in 0.160s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11652, val loss: 0.11529, in 0.166s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11654, val loss: 0.11719, in 0.156s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11667, val loss: 0.11810, in 0.164s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11716, val loss: 0.11651, in 0.162s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11681, val loss: 0.11593, in 0.188s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11574, val loss: 0.11682, in 0.145s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11722, val loss: 0.11638, in 0.160s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11726, val loss: 0.11650, in 0.189s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11608, val loss: 0.11485, in 0.132s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11623, val loss: 0.11691, in 0.152s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11636, val loss: 0.11779, in 0.148s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11673, val loss: 0.11607, in 0.163s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11639, val loss: 0.11551, in 0.160s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11532, val loss: 0.11639, in 0.153s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11684, val loss: 0.11599, in 0.141s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11691, val loss: 0.11617, in 0.142s\n",
      "[140/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11559, val loss: 0.11436, in 0.191s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11556, val loss: 0.11627, in 0.168s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11581, val loss: 0.11725, in 0.162s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11630, val loss: 0.11563, in 0.154s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11607, val loss: 0.11520, in 0.143s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11487, val loss: 0.11594, in 0.176s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11646, val loss: 0.11561, in 0.161s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11639, val loss: 0.11565, in 0.192s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11507, val loss: 0.11384, in 0.153s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11509, val loss: 0.11580, in 0.147s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11539, val loss: 0.11683, in 0.163s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11585, val loss: 0.11518, in 0.152s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11553, val loss: 0.11466, in 0.149s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11444, val loss: 0.11550, in 0.151s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11594, val loss: 0.11512, in 0.166s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11594, val loss: 0.11522, in 0.140s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11467, val loss: 0.11344, in 0.163s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11460, val loss: 0.11529, in 0.162s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11492, val loss: 0.11637, in 0.142s\n",
      "[142/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11548, val loss: 0.11481, in 0.169s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11514, val loss: 0.11426, in 0.175s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11545, val loss: 0.11461, in 0.164s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11397, val loss: 0.11500, in 0.189s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11550, val loss: 0.11478, in 0.189s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11430, val loss: 0.11312, in 0.159s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11461, val loss: 0.11609, in 0.154s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11379, val loss: 0.11448, in 0.175s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11521, val loss: 0.11453, in 0.149s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11443, val loss: 0.11357, in 0.154s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11494, val loss: 0.11411, in 0.143s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11445, in 0.146s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11400, val loss: 0.11283, in 0.149s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11506, val loss: 0.11433, in 0.156s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11416, val loss: 0.11561, in 0.151s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11352, val loss: 0.11420, in 0.150s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11470, val loss: 0.11403, in 0.148s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11392, val loss: 0.11305, in 0.153s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11437, val loss: 0.11354, in 0.304s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11302, val loss: 0.11405, in 0.339s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11457, val loss: 0.11385, in 0.318s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11376, in 0.335s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11369, val loss: 0.11514, in 0.361s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11355, val loss: 0.11240, in 0.373s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11422, val loss: 0.11358, in 0.403s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11349, val loss: 0.11262, in 0.367s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11397, val loss: 0.11310, in 0.276s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11263, val loss: 0.11366, in 0.279s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11338, in 0.259s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11342, val loss: 0.11487, in 0.259s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11262, val loss: 0.11331, in 0.319s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11296, val loss: 0.11182, in 0.307s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11379, val loss: 0.11315, in 0.256s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11301, val loss: 0.11213, in 0.306s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11348, val loss: 0.11259, in 0.256s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11229, val loss: 0.11333, in 0.262s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11370, val loss: 0.11298, in 0.297s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11303, val loss: 0.11445, in 0.254s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11236, val loss: 0.11304, in 0.228s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11272, in 0.252s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11252, val loss: 0.11140, in 0.262s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11224, val loss: 0.11137, in 0.296s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11184, val loss: 0.11289, in 0.263s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11306, val loss: 0.11219, in 0.327s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11346, val loss: 0.11275, in 0.260s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11253, val loss: 0.11397, in 0.281s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11206, val loss: 0.11275, in 0.262s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11310, val loss: 0.11246, in 0.244s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11216, val loss: 0.11104, in 0.265s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11199, val loss: 0.11111, in 0.250s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11259, val loss: 0.11172, in 0.261s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11129, val loss: 0.11233, in 0.304s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11211, val loss: 0.11356, in 0.252s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11276, val loss: 0.11207, in 0.271s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11166, val loss: 0.11235, in 0.258s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11248, val loss: 0.11187, in 0.289s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11183, val loss: 0.11071, in 0.266s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11163, val loss: 0.11076, in 0.245s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11222, val loss: 0.11134, in 0.228s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11205, val loss: 0.11138, in 0.282s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11118, val loss: 0.11188, in 0.277s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11174, val loss: 0.11319, in 0.292s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11086, val loss: 0.11189, in 0.313s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11221, val loss: 0.11160, in 0.267s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11107, val loss: 0.10996, in 0.265s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11120, val loss: 0.11034, in 0.256s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11192, val loss: 0.11105, in 0.272s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11065, val loss: 0.11135, in 0.256s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11162, val loss: 0.11097, in 0.273s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11146, val loss: 0.11294, in 0.259s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11045, val loss: 0.11148, in 0.254s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11142, val loss: 0.11083, in 0.267s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11064, val loss: 0.10952, in 0.311s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11086, val loss: 0.11002, in 0.280s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11155, val loss: 0.11067, in 0.302s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11006, val loss: 0.11114, in 0.253s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11105, val loss: 0.11250, in 0.268s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11113, val loss: 0.11047, in 0.275s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.11091, in 0.285s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11064, val loss: 0.11007, in 0.275s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11025, val loss: 0.10913, in 0.236s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11036, val loss: 0.10955, in 0.250s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11100, val loss: 0.11013, in 0.241s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11071, val loss: 0.11217, in 0.214s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10984, val loss: 0.11052, in 0.207s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10920, val loss: 0.11025, in 0.233s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11067, val loss: 0.11001, in 0.223s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11019, val loss: 0.10962, in 0.195s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10946, val loss: 0.10837, in 0.198s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10969, val loss: 0.10892, in 0.178s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11060, val loss: 0.10970, in 0.158s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11036, val loss: 0.11182, in 0.143s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10893, val loss: 0.10999, in 0.143s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10952, val loss: 0.11021, in 0.168s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10980, val loss: 0.10921, in 0.149s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11034, val loss: 0.10964, in 0.163s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10904, val loss: 0.10796, in 0.152s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10931, val loss: 0.10852, in 0.166s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11015, val loss: 0.10927, in 0.258s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10997, val loss: 0.11146, in 0.260s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10913, val loss: 0.10982, in 0.250s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10949, in 0.270s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11002, val loss: 0.10932, in 0.255s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10957, val loss: 0.10898, in 0.256s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.10765, in 0.277s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.10784, in 0.290s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10972, val loss: 0.10885, in 0.146s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10924, val loss: 0.11074, in 0.173s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10925, val loss: 0.10865, in 0.147s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10814, val loss: 0.10917, in 0.158s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10937, val loss: 0.10869, in 0.153s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10879, val loss: 0.10951, in 0.169s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10804, val loss: 0.10702, in 0.168s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10818, val loss: 0.10738, in 0.150s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10949, val loss: 0.10861, in 0.143s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10895, val loss: 0.10826, in 0.147s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10849, val loss: 0.10920, in 0.152s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.11038, in 0.170s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10880, val loss: 0.10823, in 0.184s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10776, val loss: 0.10879, in 0.196s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10770, val loss: 0.10667, in 0.164s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10777, val loss: 0.10697, in 0.191s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10915, val loss: 0.10827, in 0.177s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10856, val loss: 0.10789, in 0.156s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.11018, in 0.144s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10806, val loss: 0.10874, in 0.167s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10746, val loss: 0.10849, in 0.165s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10843, val loss: 0.10786, in 0.185s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10735, val loss: 0.10631, in 0.168s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10662, in 0.182s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10866, val loss: 0.10778, in 0.183s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10800, val loss: 0.10949, in 0.166s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10821, val loss: 0.10755, in 0.179s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10766, val loss: 0.10834, in 0.187s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10810, in 0.160s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10810, val loss: 0.10754, in 0.159s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10592, in 0.147s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10708, val loss: 0.10630, in 0.145s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10834, val loss: 0.10746, in 0.153s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10767, val loss: 0.10916, in 0.168s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10788, val loss: 0.10722, in 0.164s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10800, in 0.139s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10685, val loss: 0.10787, in 0.134s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10775, val loss: 0.10718, in 0.148s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10555, in 0.150s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10667, val loss: 0.10586, in 0.164s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10774, val loss: 0.10689, in 0.155s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10880, in 0.143s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10755, val loss: 0.10691, in 0.154s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10701, val loss: 0.10770, in 0.158s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10624, val loss: 0.10731, in 0.167s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10704, val loss: 0.10648, in 0.154s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10614, val loss: 0.10510, in 0.150s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10632, val loss: 0.10549, in 0.143s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10736, val loss: 0.10652, in 0.158s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10700, val loss: 0.10852, in 0.161s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10719, val loss: 0.10652, in 0.171s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10604, in 0.148s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10578, val loss: 0.10474, in 0.167s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10546, val loss: 0.10651, in 0.177s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10640, val loss: 0.10706, in 0.197s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10705, val loss: 0.10621, in 0.144s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10570, val loss: 0.10487, in 0.179s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10655, val loss: 0.10807, in 0.162s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10551, val loss: 0.10447, in 0.132s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10617, val loss: 0.10563, in 0.157s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10647, val loss: 0.10578, in 0.164s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10504, val loss: 0.10606, in 0.143s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10605, val loss: 0.10673, in 0.142s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10665, val loss: 0.10581, in 0.145s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10593, val loss: 0.10744, in 0.143s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10456, val loss: 0.10377, in 0.176s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10626, val loss: 0.10557, in 0.132s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10482, val loss: 0.10585, in 0.143s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10520, val loss: 0.10420, in 0.161s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10575, val loss: 0.10642, in 0.145s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10586, val loss: 0.10532, in 0.166s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10628, val loss: 0.10544, in 0.185s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10558, val loss: 0.10712, in 0.152s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10420, val loss: 0.10341, in 0.152s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10597, val loss: 0.10530, in 0.147s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10494, val loss: 0.10393, in 0.145s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10504, in 0.140s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10417, val loss: 0.10518, in 0.152s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10540, val loss: 0.10607, in 0.170s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10521, val loss: 0.10674, in 0.145s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10598, val loss: 0.10515, in 0.151s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10395, val loss: 0.10317, in 0.143s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10559, val loss: 0.10493, in 0.159s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10470, in 0.143s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10426, val loss: 0.10327, in 0.158s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10385, val loss: 0.10485, in 0.170s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10478, val loss: 0.10547, in 0.147s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10362, val loss: 0.10284, in 0.144s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10473, in 0.151s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10456, val loss: 0.10609, in 0.170s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10484, val loss: 0.10430, in 0.143s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10293, in 0.135s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10457, in 0.157s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10348, val loss: 0.10452, in 0.134s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10442, val loss: 0.10511, in 0.142s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10286, val loss: 0.10209, in 0.157s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10498, val loss: 0.10419, in 0.159s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10423, val loss: 0.10577, in 0.147s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10351, val loss: 0.10250, in 0.159s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10416, val loss: 0.10487, in 0.138s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10491, val loss: 0.10422, in 0.159s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10452, val loss: 0.10396, in 0.173s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10313, val loss: 0.10420, in 0.166s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10400, val loss: 0.10555, in 0.363s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10453, val loss: 0.10374, in 0.368s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10320, val loss: 0.10220, in 0.376s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10431, val loss: 0.10375, in 0.374s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10105, in 0.418s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10365, val loss: 0.10436, in 0.384s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10449, val loss: 0.10381, in 0.387s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10249, val loss: 0.10357, in 0.406s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10380, val loss: 0.10534, in 0.237s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10390, val loss: 0.10333, in 0.249s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10425, val loss: 0.10358, in 0.244s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10421, val loss: 0.10340, in 0.295s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10326, val loss: 0.10397, in 0.252s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10278, val loss: 0.10177, in 0.270s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10114, val loss: 0.10042, in 0.297s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10214, val loss: 0.10319, in 0.313s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10359, val loss: 0.10515, in 0.228s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10384, val loss: 0.10304, in 0.230s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10272, val loss: 0.10345, in 0.276s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10220, val loss: 0.10124, in 0.274s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10358, val loss: 0.10301, in 0.290s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10389, val loss: 0.10323, in 0.295s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10083, val loss: 0.10010, in 0.288s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10175, val loss: 0.10277, in 0.234s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10465, in 0.252s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10356, val loss: 0.10275, in 0.231s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10248, val loss: 0.10322, in 0.248s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10319, val loss: 0.10263, in 0.265s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10066, val loss: 0.09993, in 0.232s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10324, val loss: 0.10256, in 0.284s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10183, val loss: 0.10089, in 0.295s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10120, val loss: 0.10224, in 0.276s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10271, val loss: 0.10427, in 0.258s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10230, in 0.259s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10023, val loss: 0.09953, in 0.237s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10288, val loss: 0.10220, in 0.231s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10163, val loss: 0.10070, in 0.238s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10290, val loss: 0.10236, in 0.272s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10194, val loss: 0.10265, in 0.314s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10096, val loss: 0.10201, in 0.254s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10231, val loss: 0.10387, in 0.250s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10275, val loss: 0.10195, in 0.247s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09992, val loss: 0.09923, in 0.231s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10118, val loss: 0.10027, in 0.256s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10225, val loss: 0.10172, in 0.268s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10221, val loss: 0.10155, in 0.287s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10063, val loss: 0.10166, in 0.230s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10167, val loss: 0.10239, in 0.260s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10189, val loss: 0.10346, in 0.249s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10243, val loss: 0.10162, in 0.238s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09972, val loss: 0.09904, in 0.246s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10141, val loss: 0.10213, in 0.230s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10185, val loss: 0.10118, in 0.242s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10088, val loss: 0.09996, in 0.278s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10186, val loss: 0.10133, in 0.299s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10025, val loss: 0.10130, in 0.307s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10155, val loss: 0.10312, in 0.277s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10208, val loss: 0.10129, in 0.287s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10108, val loss: 0.10180, in 0.233s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10158, val loss: 0.10090, in 0.233s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09964, in 0.235s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09920, val loss: 0.09852, in 0.313s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09994, val loss: 0.10100, in 0.214s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10110, val loss: 0.10058, in 0.246s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10185, val loss: 0.10105, in 0.181s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10047, val loss: 0.10205, in 0.244s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10051, val loss: 0.10124, in 0.156s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10115, val loss: 0.10047, in 0.158s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09995, val loss: 0.09903, in 0.154s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09815, in 0.156s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10070, val loss: 0.10018, in 0.149s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.10071, in 0.166s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10119, val loss: 0.10042, in 0.155s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10014, val loss: 0.10169, in 0.146s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10015, val loss: 0.10088, in 0.154s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10074, val loss: 0.10007, in 0.151s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09860, val loss: 0.09791, in 0.195s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09868, in 0.278s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10040, val loss: 0.09987, in 0.251s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09931, val loss: 0.10037, in 0.285s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10097, val loss: 0.10023, in 0.250s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09997, val loss: 0.10152, in 0.248s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09991, in 0.250s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09980, val loss: 0.10053, in 0.294s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09698, in 0.242s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09998, val loss: 0.09948, in 0.156s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09918, val loss: 0.09825, in 0.179s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09985, in 0.148s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09877, val loss: 0.09985, in 0.194s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.10118, in 0.177s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10025, val loss: 0.09959, in 0.179s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09951, val loss: 0.10023, in 0.173s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09968, val loss: 0.09917, in 0.156s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09742, val loss: 0.09674, in 0.164s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09888, val loss: 0.09795, in 0.179s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10003, val loss: 0.09933, in 0.219s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09996, val loss: 0.09931, in 0.169s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09820, val loss: 0.09928, in 0.218s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09923, val loss: 0.10080, in 0.215s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09927, val loss: 0.09999, in 0.162s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09939, val loss: 0.09887, in 0.171s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09673, val loss: 0.09606, in 0.183s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09819, val loss: 0.09729, in 0.167s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09962, val loss: 0.09892, in 0.153s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09794, val loss: 0.09902, in 0.134s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09936, val loss: 0.09875, in 0.150s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09923, val loss: 0.09872, in 0.137s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09957, in 0.158s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09863, val loss: 0.10020, in 0.177s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09651, val loss: 0.09585, in 0.146s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09792, val loss: 0.09705, in 0.154s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09859, in 0.154s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09895, val loss: 0.09844, in 0.147s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09695, val loss: 0.09804, in 0.192s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09833, val loss: 0.09991, in 0.146s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09832, val loss: 0.09773, in 0.193s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09823, val loss: 0.09896, in 0.175s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09774, val loss: 0.09687, in 0.146s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09600, val loss: 0.09534, in 0.187s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09913, val loss: 0.09842, in 0.140s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09804, val loss: 0.09961, in 0.150s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09631, val loss: 0.09741, in 0.158s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09795, val loss: 0.09733, in 0.150s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09796, val loss: 0.09869, in 0.140s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09859, val loss: 0.09809, in 0.183s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09707, val loss: 0.09624, in 0.168s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09491, in 0.157s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09811, in 0.153s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09743, val loss: 0.09900, in 0.150s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09801, val loss: 0.09751, in 0.148s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09575, val loss: 0.09685, in 0.173s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09704, in 0.169s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09769, val loss: 0.09842, in 0.173s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09678, val loss: 0.09593, in 0.139s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09513, val loss: 0.09449, in 0.152s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09857, val loss: 0.09785, in 0.161s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09715, in 0.153s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09712, val loss: 0.09871, in 0.183s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09659, in 0.157s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09738, val loss: 0.09812, in 0.155s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09710, val loss: 0.09649, in 0.172s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09553, in 0.166s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09463, val loss: 0.09397, in 0.200s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09804, val loss: 0.09729, in 0.190s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09627, in 0.146s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09728, val loss: 0.09679, in 0.156s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09676, val loss: 0.09836, in 0.150s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09688, val loss: 0.09764, in 0.153s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09611, val loss: 0.09525, in 0.150s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09683, val loss: 0.09624, in 0.163s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09762, val loss: 0.09689, in 0.159s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09377, val loss: 0.09313, in 0.184s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09649, val loss: 0.09811, in 0.146s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09485, val loss: 0.09597, in 0.151s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09677, val loss: 0.09630, in 0.155s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09648, val loss: 0.09724, in 0.155s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09652, val loss: 0.09593, in 0.157s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09473, in 0.179s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09738, val loss: 0.09665, in 0.140s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09350, val loss: 0.09284, in 0.162s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09783, in 0.159s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09634, val loss: 0.09587, in 0.153s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09570, in 0.159s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09613, val loss: 0.09687, in 0.146s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09540, val loss: 0.09453, in 0.139s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09618, val loss: 0.09558, in 0.153s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09703, val loss: 0.09630, in 0.146s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09266, in 0.130s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09598, val loss: 0.09550, in 0.150s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09625, in 0.152s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09585, val loss: 0.09524, in 0.136s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09545, in 0.173s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09587, val loss: 0.09745, in 0.179s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09515, val loss: 0.09428, in 0.143s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09294, val loss: 0.09228, in 0.142s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09609, val loss: 0.09539, in 0.183s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09549, val loss: 0.09504, in 0.157s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09416, val loss: 0.09528, in 0.143s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09555, val loss: 0.09493, in 0.157s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09478, val loss: 0.09392, in 0.153s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09456, val loss: 0.09531, in 0.191s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09536, val loss: 0.09695, in 0.184s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09267, val loss: 0.09201, in 0.302s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09575, val loss: 0.09504, in 0.348s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09381, val loss: 0.09492, in 0.367s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09418, val loss: 0.09335, in 0.409s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09499, val loss: 0.09451, in 0.435s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09448, in 0.455s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09479, in 0.440s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09229, val loss: 0.09163, in 0.258s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09483, val loss: 0.09641, in 0.453s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09546, val loss: 0.09476, in 0.297s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09356, val loss: 0.09467, in 0.265s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09297, in 0.261s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09476, val loss: 0.09428, in 0.289s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09375, val loss: 0.09451, in 0.246s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09455, val loss: 0.09614, in 0.253s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09484, val loss: 0.09424, in 0.286s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09150, val loss: 0.09085, in 0.343s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09339, val loss: 0.09449, in 0.244s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09439, in 0.315s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09361, val loss: 0.09279, in 0.250s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09412, in 0.265s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09434, val loss: 0.09593, in 0.230s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09407, in 0.255s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09328, val loss: 0.09404, in 0.321s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09125, val loss: 0.09059, in 0.263s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09298, val loss: 0.09407, in 0.275s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09241, in 0.259s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09463, val loss: 0.09390, in 0.330s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09432, val loss: 0.09387, in 0.283s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09372, in 0.260s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09388, val loss: 0.09547, in 0.298s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09304, val loss: 0.09379, in 0.255s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09097, val loss: 0.09033, in 0.252s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09262, val loss: 0.09371, in 0.267s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09219, in 0.274s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09401, val loss: 0.09355, in 0.273s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09350, val loss: 0.09510, in 0.296s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09344, in 0.308s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09274, val loss: 0.09350, in 0.295s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09430, val loss: 0.09358, in 0.363s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09061, val loss: 0.08998, in 0.305s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09336, in 0.318s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09272, val loss: 0.09194, in 0.335s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09249, val loss: 0.09325, in 0.273s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09347, val loss: 0.09303, in 0.334s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09316, val loss: 0.09476, in 0.298s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09322, in 0.306s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09379, val loss: 0.09310, in 0.321s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08986, val loss: 0.08926, in 0.338s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09310, in 0.263s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09315, val loss: 0.09271, in 0.262s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09284, val loss: 0.09444, in 0.278s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09222, val loss: 0.09296, in 0.289s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09152, in 0.356s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09348, val loss: 0.09279, in 0.260s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09331, val loss: 0.09270, in 0.324s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08908, in 0.264s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09180, val loss: 0.09291, in 0.265s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09208, val loss: 0.09282, in 0.243s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09254, val loss: 0.09412, in 0.269s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09252, val loss: 0.09211, in 0.292s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09210, val loss: 0.09134, in 0.267s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09266, in 0.247s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09236, in 0.269s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09275, in 0.221s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08939, val loss: 0.08880, in 0.262s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09173, val loss: 0.09247, in 0.179s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09233, val loss: 0.09193, in 0.168s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09312, val loss: 0.09243, in 0.168s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09283, val loss: 0.09222, in 0.156s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09133, val loss: 0.09058, in 0.210s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09160, val loss: 0.09318, in 0.229s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09113, val loss: 0.09220, in 0.178s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08919, val loss: 0.08859, in 0.168s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09277, val loss: 0.09208, in 0.181s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09055, val loss: 0.09163, in 0.312s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08895, val loss: 0.08834, in 0.295s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09200, val loss: 0.09162, in 0.176s\n",
      "Fit 200 trees in 52.490 s, (1591 total leaves)\n",
      "Time spent computing histograms: 30.596s\n",
      "Time spent finding best splits:  0.232s\n",
      "Time spent applying splits:      4.088s\n",
      "Time spent predicting:           0.310s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09261, val loss: 0.09200, in 0.284s\n",
      "Fit 200 trees in 52.608 s, (1595 total leaves)\n",
      "Time spent computing histograms: 30.586s\n",
      "Time spent finding best splits:  0.169s\n",
      "Time spent applying splits:      4.217s\n",
      "Time spent predicting:           0.407s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09125, val loss: 0.09199, in 0.210s\n",
      "Fit 200 trees in 52.542 s, (1596 total leaves)\n",
      "Time spent computing histograms: 30.053s\n",
      "Time spent finding best splits:  0.297s\n",
      "Time spent applying splits:      4.275s\n",
      "Time spent predicting:           0.474s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09136, val loss: 0.09294, in 0.288s\n",
      "Fit 200 trees in 52.659 s, (1595 total leaves)\n",
      "Time spent computing histograms: 29.887s\n",
      "Time spent finding best splits:  0.172s\n",
      "Time spent applying splits:      4.334s\n",
      "Time spent predicting:           0.398s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09086, val loss: 0.09008, in 0.355s\n",
      "Fit 200 trees in 52.711 s, (1593 total leaves)\n",
      "Time spent computing histograms: 29.904s\n",
      "Time spent finding best splits:  0.176s\n",
      "Time spent applying splits:      4.284s\n",
      "Time spent predicting:           0.536s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09250, val loss: 0.09182, in 0.301s\n",
      "Fit 200 trees in 52.793 s, (1596 total leaves)\n",
      "Time spent computing histograms: 30.415s\n",
      "Time spent finding best splits:  0.221s\n",
      "Time spent applying splits:      3.989s\n",
      "Time spent predicting:           0.521s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08860, val loss: 0.08799, in 0.205s\n",
      "Fit 200 trees in 52.929 s, (1594 total leaves)\n",
      "Time spent computing histograms: 30.425s\n",
      "Time spent finding best splits:  0.201s\n",
      "Time spent applying splits:      4.099s\n",
      "Time spent predicting:           0.425s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08962, val loss: 0.09071, in 0.225s\n",
      "Fit 200 trees in 52.887 s, (1593 total leaves)\n",
      "Time spent computing histograms: 30.273s\n",
      "Time spent finding best splits:  0.177s\n",
      "Time spent applying splits:      4.329s\n",
      "Time spent predicting:           0.529s\n",
      "Binning 0.119 GB of training data: 3.120 s\n",
      "Binning 0.013 GB of validation data: 3.179 s\n",
      "Binning 0.013 GB of validation data: 3.200 s\n",
      "Binning 0.013 GB of validation data: 3.243 s\n",
      "Binning 0.013 GB of validation data: 3.288 s\n",
      "Binning 0.013 GB of validation data: 3.287 s\n",
      "Binning 0.013 GB of validation data: 0.222 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.234 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.232 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 3.342 s\n",
      "Binning 0.013 GB of validation data: 0.224 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 3.255 s\n",
      "Binning 0.013 GB of validation data: 0.227 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.235 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65620, val loss: 0.65624, in 0.366s\n",
      "[2/200] 0.229 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65600, val loss: 0.65603, in 0.378s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65601, val loss: 0.65586, in 0.385s\n",
      "[2/200] 0.229 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65602, val loss: 0.65590, in 0.393s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65604, val loss: 0.65586, in 0.377s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65588, in 0.373s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62278, val loss: 0.62285, in 0.390s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65588, in 0.390s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62241, val loss: 0.62213, in 0.379s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62240, val loss: 0.62245, in 0.382s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65600, val loss: 0.65596, in 0.386s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62243, val loss: 0.62220, in 0.404s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62246, val loss: 0.62214, in 0.396s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62217, in 0.404s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59242, val loss: 0.59252, in 0.395s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59190, val loss: 0.59149, in 0.407s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59188, val loss: 0.59195, in 0.423s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62216, in 0.457s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62239, val loss: 0.62233, in 0.453s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59192, val loss: 0.59159, in 0.428s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59197, val loss: 0.59150, in 0.409s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59194, val loss: 0.59154, in 0.403s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56472, val loss: 0.56488, in 0.377s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56404, val loss: 0.56413, in 0.365s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56406, val loss: 0.56352, in 0.393s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59195, val loss: 0.59153, in 0.365s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56410, val loss: 0.56365, in 0.368s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59186, val loss: 0.59178, in 0.382s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56417, val loss: 0.56355, in 0.379s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56411, val loss: 0.56356, in 0.370s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53938, val loss: 0.53959, in 0.417s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53859, val loss: 0.53794, in 0.351s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53857, val loss: 0.53868, in 0.365s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56413, val loss: 0.56358, in 0.353s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56401, val loss: 0.56388, in 0.300s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53863, val loss: 0.53810, in 0.311s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53872, val loss: 0.53798, in 0.272s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53866, val loss: 0.53800, in 0.254s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51611, val loss: 0.51635, in 0.208s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51520, val loss: 0.51532, in 0.203s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51523, val loss: 0.51445, in 0.209s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53867, val loss: 0.53801, in 0.206s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53853, val loss: 0.53838, in 0.205s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51528, val loss: 0.51465, in 0.204s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51539, val loss: 0.51451, in 0.335s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51529, val loss: 0.51451, in 0.330s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49466, val loss: 0.49498, in 0.327s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49371, val loss: 0.49383, in 0.334s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49374, val loss: 0.49286, in 0.336s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51532, val loss: 0.51453, in 0.331s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51515, val loss: 0.51495, in 0.334s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49379, val loss: 0.49308, in 0.336s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49391, val loss: 0.49293, in 0.206s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49381, val loss: 0.49293, in 0.209s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47486, val loss: 0.47522, in 0.208s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47386, val loss: 0.47404, in 0.212s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47389, val loss: 0.47299, in 0.222s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49384, val loss: 0.49295, in 0.211s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47397, val loss: 0.47321, in 0.202s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49365, val loss: 0.49344, in 0.208s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47409, val loss: 0.47307, in 0.220s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47394, val loss: 0.47302, in 0.214s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45655, val loss: 0.45699, in 0.237s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45545, val loss: 0.45566, in 0.211s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45554, val loss: 0.45451, in 0.215s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47399, val loss: 0.47308, in 0.214s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47377, val loss: 0.47363, in 0.209s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45557, val loss: 0.45473, in 0.221s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45570, val loss: 0.45459, in 0.222s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45559, val loss: 0.45460, in 0.220s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43957, val loss: 0.44006, in 0.202s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43840, val loss: 0.43871, in 0.216s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45561, val loss: 0.45466, in 0.215s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43853, val loss: 0.43740, in 0.217s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45537, val loss: 0.45523, in 0.226s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43857, val loss: 0.43765, in 0.225s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43865, val loss: 0.43750, in 0.208s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43855, val loss: 0.43753, in 0.226s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42378, val loss: 0.42437, in 0.223s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42257, val loss: 0.42291, in 0.221s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42271, val loss: 0.42148, in 0.217s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43860, val loss: 0.43763, in 0.225s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43833, val loss: 0.43831, in 0.212s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42275, val loss: 0.42174, in 0.218s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42283, val loss: 0.42163, in 0.209s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42270, val loss: 0.42163, in 0.221s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40909, val loss: 0.40972, in 0.220s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40786, val loss: 0.40825, in 0.226s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40799, val loss: 0.40666, in 0.213s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42276, val loss: 0.42175, in 0.224s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42249, val loss: 0.42245, in 0.225s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40804, val loss: 0.40694, in 0.216s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40813, val loss: 0.40688, in 0.235s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40800, val loss: 0.40688, in 0.223s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39543, val loss: 0.39610, in 0.221s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39429, val loss: 0.39296, in 0.223s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39415, val loss: 0.39462, in 0.226s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40805, val loss: 0.40701, in 0.223s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40778, val loss: 0.40778, in 0.220s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39435, val loss: 0.39323, in 0.243s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39443, val loss: 0.39315, in 0.226s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39424, val loss: 0.39315, in 0.228s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38267, val loss: 0.38343, in 0.235s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38135, val loss: 0.38184, in 0.229s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38150, val loss: 0.38005, in 0.254s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39436, val loss: 0.39331, in 0.238s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39407, val loss: 0.39415, in 0.245s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38157, val loss: 0.38037, in 0.234s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38166, val loss: 0.38033, in 0.241s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38147, val loss: 0.38034, in 0.245s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37077, val loss: 0.37159, in 0.250s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36941, val loss: 0.36999, in 0.244s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36956, val loss: 0.36803, in 0.228s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38158, val loss: 0.38049, in 0.234s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38122, val loss: 0.38133, in 0.234s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36963, val loss: 0.36835, in 0.244s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36972, val loss: 0.36838, in 0.237s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36951, val loss: 0.36840, in 0.209s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35966, val loss: 0.36054, in 0.241s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35825, val loss: 0.35886, in 0.220s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35841, val loss: 0.35686, in 0.227s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36963, val loss: 0.36858, in 0.228s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36926, val loss: 0.36948, in 0.226s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35849, val loss: 0.35719, in 0.224s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35858, val loss: 0.35720, in 0.226s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35836, val loss: 0.35725, in 0.296s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34924, val loss: 0.35016, in 0.351s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34779, val loss: 0.34847, in 0.398s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35849, val loss: 0.35739, in 0.402s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34796, val loss: 0.34636, in 0.425s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35810, val loss: 0.35833, in 0.420s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34804, val loss: 0.34672, in 0.433s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34813, val loss: 0.34675, in 0.463s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34794, val loss: 0.34684, in 0.436s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33950, val loss: 0.34044, in 0.366s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33803, val loss: 0.33874, in 0.352s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34804, val loss: 0.34698, in 0.385s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33817, val loss: 0.33650, in 0.380s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34763, val loss: 0.34794, in 0.409s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33825, val loss: 0.33688, in 0.398s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33835, val loss: 0.33698, in 0.413s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33815, val loss: 0.33703, in 0.417s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33032, val loss: 0.33131, in 0.435s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32884, val loss: 0.32963, in 0.413s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33827, val loss: 0.33722, in 0.390s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32901, val loss: 0.32735, in 0.389s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33786, val loss: 0.33820, in 0.361s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32910, val loss: 0.32772, in 0.374s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32920, val loss: 0.32783, in 0.357s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32890, val loss: 0.32782, in 0.359s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32172, val loss: 0.32280, in 0.366s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32014, val loss: 0.32099, in 0.381s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32037, val loss: 0.31867, in 0.345s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32911, val loss: 0.32807, in 0.365s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32868, val loss: 0.32910, in 0.369s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32047, val loss: 0.31906, in 0.352s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32049, val loss: 0.31910, in 0.365s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32032, val loss: 0.31921, in 0.381s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31367, val loss: 0.31478, in 0.387s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31200, val loss: 0.31291, in 0.395s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32044, val loss: 0.31943, in 0.400s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31220, val loss: 0.31045, in 0.419s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31998, val loss: 0.32047, in 0.405s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31231, val loss: 0.31086, in 0.411s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31236, val loss: 0.31094, in 0.402s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31217, val loss: 0.31105, in 0.388s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30603, val loss: 0.30720, in 0.386s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30440, val loss: 0.30534, in 0.374s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31231, val loss: 0.31130, in 0.378s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30461, val loss: 0.30285, in 0.376s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31180, val loss: 0.31233, in 0.377s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30472, val loss: 0.30326, in 0.358s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30471, val loss: 0.30326, in 0.371s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30449, val loss: 0.30336, in 0.364s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29884, val loss: 0.30010, in 0.385s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29719, val loss: 0.29816, in 0.367s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30472, val loss: 0.30369, in 0.358s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29740, val loss: 0.29557, in 0.356s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30420, val loss: 0.30473, in 0.335s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29753, val loss: 0.29601, in 0.332s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29757, val loss: 0.29612, in 0.297s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29734, val loss: 0.29622, in 0.269s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29207, val loss: 0.29337, in 0.233s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29041, val loss: 0.29141, in 0.230s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29063, val loss: 0.28875, in 0.224s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29751, val loss: 0.29652, in 0.236s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29696, val loss: 0.29759, in 0.224s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29076, val loss: 0.28923, in 0.368s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29079, val loss: 0.28935, in 0.382s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29054, val loss: 0.28943, in 0.376s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28576, val loss: 0.28704, in 0.382s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28407, val loss: 0.28509, in 0.380s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28429, val loss: 0.28245, in 0.377s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29074, val loss: 0.28977, in 0.375s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29016, val loss: 0.29084, in 0.384s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28443, val loss: 0.28291, in 0.238s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28442, val loss: 0.28297, in 0.227s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28417, val loss: 0.28305, in 0.225s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27974, val loss: 0.28109, in 0.219s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27803, val loss: 0.27913, in 0.210s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27826, val loss: 0.27638, in 0.219s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28441, val loss: 0.28341, in 0.219s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28378, val loss: 0.28450, in 0.214s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27840, val loss: 0.27686, in 0.214s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27844, val loss: 0.27698, in 0.209s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27819, val loss: 0.27707, in 0.215s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27413, val loss: 0.27553, in 0.228s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27236, val loss: 0.27350, in 0.222s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27260, val loss: 0.27066, in 0.215s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27838, val loss: 0.27739, in 0.219s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27779, val loss: 0.27852, in 0.223s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27273, val loss: 0.27118, in 0.231s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27277, val loss: 0.27127, in 0.221s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27251, val loss: 0.27139, in 0.212s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26875, val loss: 0.27021, in 0.219s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26704, val loss: 0.26824, in 0.213s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26715, val loss: 0.26515, in 0.224s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27272, val loss: 0.27173, in 0.222s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27211, val loss: 0.27286, in 0.217s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26730, val loss: 0.26567, in 0.213s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26735, val loss: 0.26581, in 0.213s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26709, val loss: 0.26589, in 0.219s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26359, val loss: 0.26508, in 0.207s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26187, val loss: 0.26303, in 0.218s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26210, val loss: 0.26012, in 0.202s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26732, val loss: 0.26632, in 0.212s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26671, val loss: 0.26752, in 0.206s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26225, val loss: 0.26063, in 0.210s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26231, val loss: 0.26074, in 0.204s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26204, val loss: 0.26086, in 0.202s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25871, val loss: 0.26019, in 0.207s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25702, val loss: 0.25819, in 0.218s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25723, val loss: 0.25520, in 0.219s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26227, val loss: 0.26122, in 0.211s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26165, val loss: 0.26243, in 0.215s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25739, val loss: 0.25573, in 0.210s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25746, val loss: 0.25586, in 0.203s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25719, val loss: 0.25596, in 0.206s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25381, val loss: 0.25531, in 0.217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25245, val loss: 0.25365, in 0.218s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25264, val loss: 0.25055, in 0.208s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25744, val loss: 0.25637, in 0.205s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25678, val loss: 0.25758, in 0.213s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25280, val loss: 0.25109, in 0.218s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25289, val loss: 0.25121, in 0.218s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25262, val loss: 0.25133, in 0.222s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24956, val loss: 0.25108, in 0.198s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24788, val loss: 0.24911, in 0.194s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24809, val loss: 0.24604, in 0.211s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25287, val loss: 0.25180, in 0.225s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25220, val loss: 0.25298, in 0.214s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24824, val loss: 0.24655, in 0.207s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24861, val loss: 0.24695, in 0.198s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24807, val loss: 0.24682, in 0.202s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24538, val loss: 0.24696, in 0.217s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24384, val loss: 0.24511, in 0.211s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24396, val loss: 0.24184, in 0.208s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24831, val loss: 0.24724, in 0.203s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24765, val loss: 0.24845, in 0.202s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24411, val loss: 0.24234, in 0.212s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24449, val loss: 0.24282, in 0.217s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24394, val loss: 0.24264, in 0.213s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23991, val loss: 0.24120, in 0.206s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24142, val loss: 0.24303, in 0.220s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23988, val loss: 0.23778, in 0.215s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24428, val loss: 0.24320, in 0.201s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24353, val loss: 0.24433, in 0.217s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24002, val loss: 0.23826, in 0.212s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24066, val loss: 0.23902, in 0.200s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24009, val loss: 0.23883, in 0.209s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23732, val loss: 0.23891, in 0.371s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23627, val loss: 0.23752, in 0.394s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23614, val loss: 0.23401, in 0.393s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24037, val loss: 0.23927, in 0.409s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23946, val loss: 0.24033, in 0.423s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23629, val loss: 0.23450, in 0.428s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23703, val loss: 0.23539, in 0.432s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23647, val loss: 0.23524, in 0.460s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23377, val loss: 0.23534, in 0.338s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23273, val loss: 0.23394, in 0.355s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23248, val loss: 0.23040, in 0.347s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23674, val loss: 0.23562, in 0.355s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23582, val loss: 0.23669, in 0.350s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23262, val loss: 0.23086, in 0.363s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23347, val loss: 0.23181, in 0.370s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23292, val loss: 0.23163, in 0.341s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23035, val loss: 0.23191, in 0.357s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22932, val loss: 0.23055, in 0.361s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22911, val loss: 0.22701, in 0.359s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23320, val loss: 0.23207, in 0.343s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23226, val loss: 0.23313, in 0.351s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22925, val loss: 0.22747, in 0.342s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23010, val loss: 0.22839, in 0.334s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22958, val loss: 0.22832, in 0.348s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22642, val loss: 0.22801, in 0.343s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22573, val loss: 0.22691, in 0.330s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22537, val loss: 0.22334, in 0.334s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22994, val loss: 0.22881, in 0.356s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22889, val loss: 0.22974, in 0.341s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22551, val loss: 0.22380, in 0.339s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22637, val loss: 0.22473, in 0.338s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22597, val loss: 0.22474, in 0.347s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22336, val loss: 0.22498, in 0.343s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22251, val loss: 0.22374, in 0.347s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22222, val loss: 0.22022, in 0.351s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22623, val loss: 0.22512, in 0.344s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22529, val loss: 0.22618, in 0.352s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22235, val loss: 0.22066, in 0.365s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22313, val loss: 0.22150, in 0.381s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22286, val loss: 0.22157, in 0.390s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22036, val loss: 0.22202, in 0.407s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21953, val loss: 0.22078, in 0.405s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21924, val loss: 0.21720, in 0.409s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22301, val loss: 0.22190, in 0.409s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22210, val loss: 0.22301, in 0.414s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21936, val loss: 0.21763, in 0.407s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22017, val loss: 0.21856, in 0.409s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21977, val loss: 0.21851, in 0.366s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21692, val loss: 0.21858, in 0.349s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21617, val loss: 0.21745, in 0.338s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21588, val loss: 0.21381, in 0.327s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22005, val loss: 0.21890, in 0.345s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21913, val loss: 0.22004, in 0.319s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21603, val loss: 0.21437, in 0.304s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21690, val loss: 0.21534, in 0.284s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21648, val loss: 0.21519, in 0.283s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21420, val loss: 0.21584, in 0.225s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21337, val loss: 0.21464, in 0.224s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21313, val loss: 0.21109, in 0.216s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21668, val loss: 0.21558, in 0.195s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21593, val loss: 0.21686, in 0.184s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21324, val loss: 0.21154, in 0.187s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21408, val loss: 0.21253, in 0.308s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21368, val loss: 0.21239, in 0.311s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21171, val loss: 0.21334, in 0.308s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21015, val loss: 0.20819, in 0.309s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21035, val loss: 0.21166, in 0.317s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21403, val loss: 0.21292, in 0.321s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21315, val loss: 0.21406, in 0.329s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21021, val loss: 0.20849, in 0.325s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21106, val loss: 0.20950, in 0.210s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21069, val loss: 0.20944, in 0.203s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20877, val loss: 0.21042, in 0.219s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20787, val loss: 0.20919, in 0.204s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20762, val loss: 0.20561, in 0.213s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21142, val loss: 0.21023, in 0.204s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20774, val loss: 0.20605, in 0.183s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21013, val loss: 0.21105, in 0.204s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20860, val loss: 0.20701, in 0.193s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20815, val loss: 0.20686, in 0.182s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20621, val loss: 0.20783, in 0.194s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20543, val loss: 0.20677, in 0.198s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20522, val loss: 0.20330, in 0.197s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20854, val loss: 0.20738, in 0.202s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20765, val loss: 0.20861, in 0.204s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20535, val loss: 0.20365, in 0.219s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20614, val loss: 0.20460, in 0.202s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20571, val loss: 0.20446, in 0.208s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20388, val loss: 0.20552, in 0.170s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20250, val loss: 0.20055, in 0.189s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20271, val loss: 0.20406, in 0.198s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20609, val loss: 0.20498, in 0.198s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20263, val loss: 0.20094, in 0.185s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20523, val loss: 0.20620, in 0.187s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20350, val loss: 0.20198, in 0.195s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20301, val loss: 0.20173, in 0.204s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20154, val loss: 0.20316, in 0.216s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20061, val loss: 0.20202, in 0.177s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20040, val loss: 0.19853, in 0.180s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20057, val loss: 0.19896, in 0.167s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20140, val loss: 0.19995, in 0.168s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20341, val loss: 0.20229, in 0.207s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20254, val loss: 0.20352, in 0.209s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20093, val loss: 0.19971, in 0.164s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19941, val loss: 0.20106, in 0.171s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19844, val loss: 0.19662, in 0.173s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19839, val loss: 0.19983, in 0.211s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20133, val loss: 0.20025, in 0.175s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19841, val loss: 0.19686, in 0.209s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19924, val loss: 0.19781, in 0.197s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20046, val loss: 0.20149, in 0.173s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19880, val loss: 0.19756, in 0.192s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19645, val loss: 0.19793, in 0.168s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19632, val loss: 0.19454, in 0.205s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19893, in 0.221s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19650, val loss: 0.19503, in 0.174s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19730, val loss: 0.19592, in 0.184s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19916, val loss: 0.19809, in 0.193s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19836, val loss: 0.19938, in 0.195s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19689, val loss: 0.19569, in 0.170s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19530, val loss: 0.19702, in 0.161s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19453, val loss: 0.19281, in 0.182s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19465, val loss: 0.19619, in 0.182s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19473, val loss: 0.19334, in 0.175s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19551, val loss: 0.19417, in 0.166s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19621, in 0.179s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19647, val loss: 0.19753, in 0.177s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19511, val loss: 0.19395, in 0.176s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19347, val loss: 0.19517, in 0.178s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19261, val loss: 0.19413, in 0.198s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19256, val loss: 0.19083, in 0.200s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19545, val loss: 0.19446, in 0.172s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19469, val loss: 0.19579, in 0.171s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19271, val loss: 0.19133, in 0.203s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19346, val loss: 0.19210, in 0.208s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19315, val loss: 0.19198, in 0.207s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19149, val loss: 0.19316, in 0.190s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19089, val loss: 0.19239, in 0.154s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19077, val loss: 0.18903, in 0.161s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19090, val loss: 0.18953, in 0.157s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19166, val loss: 0.19029, in 0.162s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19343, val loss: 0.19242, in 0.207s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19264, val loss: 0.19371, in 0.198s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19138, val loss: 0.19019, in 0.162s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18980, val loss: 0.19144, in 0.166s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18903, val loss: 0.19053, in 0.219s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18882, val loss: 0.18707, in 0.231s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19171, val loss: 0.19065, in 0.172s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18905, val loss: 0.18770, in 0.223s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19100, val loss: 0.19211, in 0.191s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18973, val loss: 0.18833, in 0.233s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18947, val loss: 0.18827, in 0.226s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18799, val loss: 0.18966, in 0.381s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18746, val loss: 0.18900, in 0.350s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18729, val loss: 0.18555, in 0.345s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18741, val loss: 0.18606, in 0.361s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18821, val loss: 0.18680, in 0.383s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18981, val loss: 0.18876, in 0.423s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18914, val loss: 0.19030, in 0.434s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18797, val loss: 0.18676, in 0.397s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18617, val loss: 0.18787, in 0.299s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18603, val loss: 0.18759, in 0.284s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18573, val loss: 0.18397, in 0.278s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18829, val loss: 0.18722, in 0.280s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18672, val loss: 0.18535, in 0.291s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18748, val loss: 0.18861, in 0.278s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18648, val loss: 0.18531, in 0.281s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18558, val loss: 0.18421, in 0.365s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18472, val loss: 0.18644, in 0.272s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18431, val loss: 0.18585, in 0.343s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18397, val loss: 0.18223, in 0.339s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18679, val loss: 0.18577, in 0.296s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18399, val loss: 0.18270, in 0.304s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18499, val loss: 0.18365, in 0.358s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18479, val loss: 0.18361, in 0.350s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18564, val loss: 0.18673, in 0.354s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18295, val loss: 0.18462, in 0.341s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18281, val loss: 0.18434, in 0.283s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18073, in 0.308s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18510, val loss: 0.18405, in 0.309s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18260, val loss: 0.18134, in 0.265s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18350, val loss: 0.18214, in 0.267s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18425, val loss: 0.18534, in 0.270s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18308, val loss: 0.18190, in 0.309s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18152, val loss: 0.18321, in 0.272s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18105, val loss: 0.17938, in 0.275s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18116, val loss: 0.18272, in 0.363s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18250, in 0.285s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18186, val loss: 0.18053, in 0.287s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18097, val loss: 0.17972, in 0.350s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18169, val loss: 0.18053, in 0.254s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18260, val loss: 0.18371, in 0.352s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17957, val loss: 0.18130, in 0.287s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17962, val loss: 0.17795, in 0.270s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17979, val loss: 0.18137, in 0.271s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17966, val loss: 0.17844, in 0.282s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18023, val loss: 0.17888, in 0.325s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18193, val loss: 0.18084, in 0.366s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18119, val loss: 0.18231, in 0.271s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18009, val loss: 0.17893, in 0.348s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17811, val loss: 0.17981, in 0.259s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17838, val loss: 0.17999, in 0.260s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17812, val loss: 0.17648, in 0.359s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17830, val loss: 0.17705, in 0.295s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18030, val loss: 0.17923, in 0.287s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17826, val loss: 0.17698, in 0.318s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17871, val loss: 0.17756, in 0.270s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17980, val loss: 0.18089, in 0.290s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17663, val loss: 0.17837, in 0.301s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17681, val loss: 0.17518, in 0.230s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17652, val loss: 0.17816, in 0.277s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17693, val loss: 0.17576, in 0.213s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17694, val loss: 0.17570, in 0.186s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17736, val loss: 0.17620, in 0.197s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17888, val loss: 0.17787, in 0.222s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17827, val loss: 0.17935, in 0.205s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17529, val loss: 0.17702, in 0.158s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17555, val loss: 0.17391, in 0.166s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17516, val loss: 0.17681, in 0.189s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17574, val loss: 0.17453, in 0.148s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17757, val loss: 0.17653, in 0.147s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17570, val loss: 0.17443, in 0.172s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17608, val loss: 0.17492, in 0.267s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17645, val loss: 0.17754, in 0.277s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17375, val loss: 0.17547, in 0.307s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17440, val loss: 0.17274, in 0.251s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17391, val loss: 0.17560, in 0.267s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17431, val loss: 0.17315, in 0.276s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17629, val loss: 0.17526, in 0.275s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17440, val loss: 0.17319, in 0.275s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17467, val loss: 0.17355, in 0.184s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17523, val loss: 0.17629, in 0.169s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17249, val loss: 0.17421, in 0.152s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17289, val loss: 0.17128, in 0.216s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17275, val loss: 0.17447, in 0.187s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17511, val loss: 0.17404, in 0.167s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17323, val loss: 0.17202, in 0.180s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17406, val loss: 0.17512, in 0.173s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17284, val loss: 0.17164, in 0.228s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17345, val loss: 0.17230, in 0.192s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17123, val loss: 0.17299, in 0.219s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17165, val loss: 0.17002, in 0.187s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17142, val loss: 0.17314, in 0.181s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17167, val loss: 0.17047, in 0.173s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17375, val loss: 0.17271, in 0.230s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17189, val loss: 0.17070, in 0.213s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17164, val loss: 0.17058, in 0.188s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17259, val loss: 0.17366, in 0.207s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16980, val loss: 0.17159, in 0.177s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17031, val loss: 0.16870, in 0.173s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16999, val loss: 0.17164, in 0.199s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17058, val loss: 0.16935, in 0.151s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17074, val loss: 0.16956, in 0.158s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17241, val loss: 0.17140, in 0.172s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17148, val loss: 0.17249, in 0.169s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17052, val loss: 0.16943, in 0.176s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16876, val loss: 0.17058, in 0.153s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16869, val loss: 0.16716, in 0.170s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16893, val loss: 0.17061, in 0.150s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16943, val loss: 0.16825, in 0.167s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17119, val loss: 0.17014, in 0.171s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16942, val loss: 0.16830, in 0.185s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16935, val loss: 0.16832, in 0.167s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16774, val loss: 0.16958, in 0.150s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16985, val loss: 0.17090, in 0.174s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16765, val loss: 0.16608, in 0.153s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16780, val loss: 0.16946, in 0.153s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16786, val loss: 0.16672, in 0.172s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17011, val loss: 0.16908, in 0.151s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16617, val loss: 0.16797, in 0.152s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16836, val loss: 0.16726, in 0.159s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16853, val loss: 0.16961, in 0.173s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16788, val loss: 0.16682, in 0.198s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16659, val loss: 0.16504, in 0.161s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16641, val loss: 0.16805, in 0.163s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16912, val loss: 0.16810, in 0.158s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16661, val loss: 0.16551, in 0.178s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16725, val loss: 0.16613, in 0.155s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16497, val loss: 0.16676, in 0.186s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16745, val loss: 0.16848, in 0.165s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16681, val loss: 0.16572, in 0.159s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16554, val loss: 0.16397, in 0.148s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16535, val loss: 0.16695, in 0.157s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16566, val loss: 0.16455, in 0.155s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16777, val loss: 0.16677, in 0.165s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16587, val loss: 0.16475, in 0.163s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16391, val loss: 0.16571, in 0.167s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16576, val loss: 0.16470, in 0.162s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16623, val loss: 0.16728, in 0.187s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16281, in 0.174s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16418, val loss: 0.16578, in 0.170s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16471, val loss: 0.16361, in 0.148s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16681, val loss: 0.16579, in 0.151s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16483, val loss: 0.16370, in 0.163s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16285, val loss: 0.16466, in 0.163s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16479, val loss: 0.16371, in 0.156s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16484, val loss: 0.16589, in 0.155s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16292, val loss: 0.16137, in 0.198s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16269, val loss: 0.16429, in 0.182s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16579, val loss: 0.16475, in 0.165s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16326, val loss: 0.16218, in 0.173s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16375, val loss: 0.16264, in 0.181s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16385, val loss: 0.16488, in 0.166s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16365, val loss: 0.16259, in 0.178s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.16324, in 0.218s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16150, val loss: 0.15995, in 0.169s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16170, val loss: 0.16329, in 0.159s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16216, val loss: 0.16112, in 0.175s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16467, val loss: 0.16365, in 0.184s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16264, val loss: 0.16158, in 0.180s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16231, val loss: 0.16126, in 0.163s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16377, in 0.176s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16044, val loss: 0.16221, in 0.157s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16075, val loss: 0.16236, in 0.147s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16054, val loss: 0.15896, in 0.171s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16099, val loss: 0.15999, in 0.162s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16319, val loss: 0.16220, in 0.169s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.16040, in 0.150s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16136, val loss: 0.16032, in 0.189s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16168, val loss: 0.16272, in 0.166s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15951, val loss: 0.16130, in 0.161s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15950, val loss: 0.16110, in 0.170s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15939, val loss: 0.15783, in 0.155s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16003, val loss: 0.15906, in 0.325s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16224, val loss: 0.16123, in 0.310s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16028, val loss: 0.15923, in 0.350s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16043, val loss: 0.15941, in 0.376s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16069, val loss: 0.16172, in 0.382s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15835, val loss: 0.16011, in 0.375s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15799, val loss: 0.15649, in 0.434s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15847, val loss: 0.16007, in 0.451s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16109, val loss: 0.16009, in 0.296s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15866, val loss: 0.15773, in 0.316s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15926, val loss: 0.15825, in 0.313s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15952, val loss: 0.16058, in 0.284s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15899, val loss: 0.15803, in 0.301s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15696, val loss: 0.15867, in 0.292s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15712, val loss: 0.15564, in 0.280s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15755, val loss: 0.15911, in 0.279s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15987, val loss: 0.15891, in 0.264s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15773, val loss: 0.15680, in 0.273s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15821, val loss: 0.15715, in 0.276s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15776, val loss: 0.15679, in 0.260s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15843, val loss: 0.15946, in 0.285s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15595, val loss: 0.15764, in 0.273s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15621, val loss: 0.15472, in 0.258s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15621, val loss: 0.15778, in 0.301s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15891, val loss: 0.15793, in 0.275s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15688, val loss: 0.15595, in 0.264s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15691, val loss: 0.15595, in 0.256s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15735, val loss: 0.15626, in 0.304s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15507, val loss: 0.15677, in 0.276s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15719, val loss: 0.15822, in 0.294s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15541, val loss: 0.15393, in 0.319s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15513, val loss: 0.15672, in 0.313s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15811, val loss: 0.15712, in 0.318s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15591, val loss: 0.15498, in 0.426s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15585, val loss: 0.15491, in 0.388s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15638, val loss: 0.15741, in 0.343s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15596, val loss: 0.15493, in 0.385s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15409, val loss: 0.15580, in 0.388s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15440, val loss: 0.15293, in 0.331s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15427, val loss: 0.15583, in 0.351s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15677, val loss: 0.15582, in 0.373s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15513, val loss: 0.15418, in 0.290s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15481, val loss: 0.15389, in 0.300s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15335, val loss: 0.15506, in 0.297s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15492, val loss: 0.15389, in 0.318s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15556, val loss: 0.15652, in 0.334s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15312, val loss: 0.15165, in 0.313s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15314, val loss: 0.15468, in 0.316s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15574, val loss: 0.15480, in 0.283s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15411, val loss: 0.15320, in 0.310s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15367, val loss: 0.15274, in 0.313s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15372, val loss: 0.15269, in 0.295s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15471, val loss: 0.15566, in 0.303s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15231, val loss: 0.15087, in 0.306s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15205, val loss: 0.15382, in 0.387s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15243, val loss: 0.15398, in 0.270s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15462, val loss: 0.15371, in 0.317s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15282, val loss: 0.15194, in 0.301s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15294, val loss: 0.15198, in 0.277s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15297, val loss: 0.15192, in 0.308s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15374, val loss: 0.15469, in 0.353s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15098, val loss: 0.15278, in 0.295s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15106, val loss: 0.14970, in 0.320s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15120, val loss: 0.15277, in 0.338s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15366, val loss: 0.15278, in 0.312s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15159, val loss: 0.15077, in 0.286s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15217, val loss: 0.15121, in 0.257s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15221, val loss: 0.15117, in 0.229s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15260, val loss: 0.15354, in 0.215s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14973, val loss: 0.15149, in 0.199s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15033, val loss: 0.14895, in 0.190s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15014, val loss: 0.15170, in 0.184s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15268, val loss: 0.15175, in 0.191s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15063, val loss: 0.14978, in 0.196s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15128, val loss: 0.15036, in 0.208s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15125, val loss: 0.15022, in 0.183s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14872, val loss: 0.15046, in 0.310s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14949, val loss: 0.14812, in 0.307s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15131, val loss: 0.15225, in 0.316s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14918, val loss: 0.15073, in 0.300s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14989, val loss: 0.14904, in 0.297s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15174, val loss: 0.15081, in 0.336s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15044, val loss: 0.14953, in 0.288s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15051, val loss: 0.14944, in 0.293s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14871, val loss: 0.14734, in 0.193s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14782, val loss: 0.14957, in 0.198s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15055, val loss: 0.15144, in 0.203s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14845, val loss: 0.14998, in 0.181s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14898, val loss: 0.14814, in 0.187s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14950, val loss: 0.14864, in 0.185s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15053, val loss: 0.14962, in 0.195s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14942, val loss: 0.14835, in 0.195s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14685, val loss: 0.14860, in 0.172s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14753, val loss: 0.14617, in 0.177s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14747, val loss: 0.14901, in 0.174s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14966, val loss: 0.15058, in 0.197s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14781, val loss: 0.14698, in 0.178s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14870, val loss: 0.14781, in 0.187s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14975, val loss: 0.14881, in 0.178s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14816, val loss: 0.14713, in 0.186s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14612, val loss: 0.14783, in 0.193s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14669, val loss: 0.14537, in 0.210s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14892, val loss: 0.14984, in 0.186s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14670, val loss: 0.14826, in 0.195s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14794, val loss: 0.14706, in 0.184s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14883, val loss: 0.14789, in 0.194s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14695, val loss: 0.14617, in 0.212s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14738, val loss: 0.14634, in 0.184s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14704, in 0.181s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14798, val loss: 0.14888, in 0.182s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14602, val loss: 0.14758, in 0.181s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14583, val loss: 0.14454, in 0.201s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14781, val loss: 0.14690, in 0.174s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14691, val loss: 0.14603, in 0.195s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14623, val loss: 0.14545, in 0.189s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14670, val loss: 0.14567, in 0.207s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14447, val loss: 0.14621, in 0.182s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14513, val loss: 0.14671, in 0.165s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14510, val loss: 0.14382, in 0.173s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14682, val loss: 0.14773, in 0.189s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14618, val loss: 0.14534, in 0.169s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14705, val loss: 0.14610, in 0.198s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14547, val loss: 0.14471, in 0.181s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14610, val loss: 0.14506, in 0.171s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14368, val loss: 0.14543, in 0.182s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14449, val loss: 0.14319, in 0.165s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14417, val loss: 0.14573, in 0.189s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14579, val loss: 0.14670, in 0.182s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14451, in 0.175s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14482, val loss: 0.14404, in 0.174s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14430, in 0.175s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14622, val loss: 0.14528, in 0.191s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14364, val loss: 0.14236, in 0.192s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14466, in 0.199s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14487, val loss: 0.14576, in 0.185s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14265, val loss: 0.14438, in 0.227s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14469, val loss: 0.14385, in 0.179s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14397, val loss: 0.14323, in 0.177s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14542, val loss: 0.14447, in 0.183s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14420, val loss: 0.14321, in 0.201s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14180, in 0.163s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14236, val loss: 0.14392, in 0.175s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14421, val loss: 0.14508, in 0.179s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14185, val loss: 0.14357, in 0.179s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14339, val loss: 0.14264, in 0.161s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14388, val loss: 0.14308, in 0.185s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14364, val loss: 0.14263, in 0.164s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14473, val loss: 0.14378, in 0.188s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14201, val loss: 0.14075, in 0.196s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14118, val loss: 0.14289, in 0.169s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14358, val loss: 0.14443, in 0.184s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14160, val loss: 0.14319, in 0.199s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14328, val loss: 0.14248, in 0.165s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14271, val loss: 0.14195, in 0.182s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14391, val loss: 0.14299, in 0.183s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14134, val loss: 0.14009, in 0.163s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14006, val loss: 0.14175, in 0.174s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14069, val loss: 0.14228, in 0.163s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14278, val loss: 0.14365, in 0.180s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14180, in 0.271s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14262, val loss: 0.14179, in 0.178s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14197, val loss: 0.14124, in 0.180s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14332, val loss: 0.14237, in 0.171s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14074, val loss: 0.13948, in 0.164s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14180, val loss: 0.14082, in 0.134s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13941, val loss: 0.14112, in 0.172s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14220, val loss: 0.14305, in 0.163s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13993, val loss: 0.14148, in 0.185s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14186, val loss: 0.14104, in 0.152s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14091, val loss: 0.14018, in 0.163s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14261, val loss: 0.14163, in 0.168s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14126, val loss: 0.14024, in 0.148s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13995, val loss: 0.13870, in 0.174s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13874, val loss: 0.14045, in 0.154s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14135, val loss: 0.14218, in 0.155s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13924, val loss: 0.14079, in 0.159s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14112, val loss: 0.14030, in 0.159s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14022, val loss: 0.13951, in 0.156s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14196, val loss: 0.14097, in 0.146s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14032, val loss: 0.13933, in 0.160s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13920, val loss: 0.13797, in 0.160s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13793, val loss: 0.13964, in 0.149s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14040, val loss: 0.14125, in 0.156s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13862, val loss: 0.14013, in 0.308s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14042, val loss: 0.13962, in 0.304s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13963, val loss: 0.13893, in 0.333s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14103, val loss: 0.14007, in 0.369s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13857, val loss: 0.13734, in 0.384s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13951, val loss: 0.13854, in 0.403s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13977, val loss: 0.14062, in 0.387s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13719, val loss: 0.13887, in 0.435s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13805, val loss: 0.13955, in 0.286s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13971, val loss: 0.13894, in 0.312s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13893, val loss: 0.13826, in 0.293s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14031, val loss: 0.13936, in 0.301s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13876, val loss: 0.13778, in 0.284s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13787, val loss: 0.13667, in 0.312s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13658, val loss: 0.13825, in 0.261s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13907, val loss: 0.13991, in 0.322s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13750, val loss: 0.13900, in 0.271s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13838, val loss: 0.13770, in 0.262s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13909, val loss: 0.13832, in 0.305s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13960, val loss: 0.13868, in 0.275s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13822, val loss: 0.13723, in 0.255s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13710, val loss: 0.13589, in 0.276s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13592, val loss: 0.13759, in 0.275s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13845, val loss: 0.13933, in 0.256s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13673, val loss: 0.13824, in 0.265s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13763, val loss: 0.13700, in 0.268s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13839, val loss: 0.13763, in 0.273s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13907, val loss: 0.13814, in 0.267s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13754, val loss: 0.13653, in 0.278s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13656, val loss: 0.13531, in 0.274s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13790, val loss: 0.13876, in 0.277s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13520, val loss: 0.13687, in 0.289s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13604, val loss: 0.13755, in 0.292s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13700, val loss: 0.13638, in 0.280s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13784, val loss: 0.13709, in 0.273s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13860, val loss: 0.13766, in 0.250s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13695, val loss: 0.13594, in 0.290s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13449, in 0.266s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13435, val loss: 0.13604, in 0.261s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13544, val loss: 0.13693, in 0.259s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13718, val loss: 0.13801, in 0.304s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13640, val loss: 0.13576, in 0.248s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13730, val loss: 0.13653, in 0.282s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13783, val loss: 0.13689, in 0.259s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13628, val loss: 0.13531, in 0.258s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13369, val loss: 0.13539, in 0.278s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13501, val loss: 0.13377, in 0.303s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13642, val loss: 0.13725, in 0.281s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13481, val loss: 0.13634, in 0.288s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13596, val loss: 0.13531, in 0.263s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13653, val loss: 0.13577, in 0.270s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13715, val loss: 0.13621, in 0.269s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13455, val loss: 0.13332, in 0.239s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13557, val loss: 0.13456, in 0.323s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13289, val loss: 0.13455, in 0.288s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13655, in 0.267s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13518, val loss: 0.13453, in 0.252s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13415, val loss: 0.13566, in 0.300s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13590, val loss: 0.13516, in 0.273s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13630, val loss: 0.13539, in 0.280s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13496, val loss: 0.13393, in 0.258s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13398, val loss: 0.13276, in 0.284s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13231, val loss: 0.13393, in 0.270s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13469, val loss: 0.13402, in 0.246s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13507, in 0.238s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13500, val loss: 0.13581, in 0.289s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13523, val loss: 0.13449, in 0.218s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13477, in 0.232s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13319, val loss: 0.13195, in 0.160s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13157, val loss: 0.13320, in 0.151s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13432, val loss: 0.13332, in 0.191s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13397, val loss: 0.13329, in 0.176s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13302, val loss: 0.13452, in 0.174s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13446, val loss: 0.13525, in 0.167s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13375, in 0.184s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13512, val loss: 0.13420, in 0.176s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13249, val loss: 0.13125, in 0.163s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13103, val loss: 0.13264, in 0.153s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13235, in 0.172s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13390, val loss: 0.13472, in 0.274s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13284, in 0.279s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13210, val loss: 0.13362, in 0.312s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13239, in 0.346s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13448, val loss: 0.13359, in 0.278s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13193, val loss: 0.13071, in 0.273s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13031, val loss: 0.13195, in 0.296s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13231, val loss: 0.13166, in 0.289s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13341, val loss: 0.13421, in 0.196s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13271, val loss: 0.13172, in 0.176s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13162, val loss: 0.13314, in 0.184s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13229, in 0.197s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13407, val loss: 0.13319, in 0.175s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13118, val loss: 0.12996, in 0.181s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13174, val loss: 0.13111, in 0.148s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.13117, in 0.191s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13337, in 0.153s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13219, val loss: 0.13120, in 0.161s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13252, val loss: 0.13182, in 0.149s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13082, val loss: 0.13234, in 0.160s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13334, val loss: 0.13246, in 0.141s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13067, val loss: 0.12950, in 0.159s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13101, val loss: 0.13038, in 0.154s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12892, val loss: 0.13054, in 0.167s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13178, val loss: 0.13258, in 0.164s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13171, val loss: 0.13071, in 0.174s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13275, val loss: 0.13188, in 0.168s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13001, val loss: 0.13156, in 0.179s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13194, val loss: 0.13121, in 0.183s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12901, in 0.175s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13039, val loss: 0.12975, in 0.180s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12843, val loss: 0.13005, in 0.181s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13121, val loss: 0.13201, in 0.212s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13112, val loss: 0.13015, in 0.181s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13100, in 0.192s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13196, val loss: 0.13108, in 0.196s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12957, val loss: 0.12837, in 0.166s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13104, val loss: 0.13030, in 0.232s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12987, val loss: 0.12923, in 0.162s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12777, val loss: 0.12940, in 0.152s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13035, val loss: 0.12939, in 0.153s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13063, val loss: 0.13139, in 0.163s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13148, val loss: 0.13060, in 0.145s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12902, val loss: 0.13050, in 0.160s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12895, val loss: 0.12775, in 0.157s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12969, in 0.147s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12719, val loss: 0.12881, in 0.146s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12915, val loss: 0.12848, in 0.162s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12993, val loss: 0.13067, in 0.147s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12960, val loss: 0.12863, in 0.159s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13068, val loss: 0.12983, in 0.154s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12980, val loss: 0.12905, in 0.155s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12839, val loss: 0.12988, in 0.191s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12841, val loss: 0.12720, in 0.169s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12786, in 0.144s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12660, val loss: 0.12821, in 0.154s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12898, val loss: 0.12801, in 0.147s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13018, val loss: 0.12931, in 0.160s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12929, val loss: 0.13001, in 0.192s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12914, val loss: 0.12837, in 0.153s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12771, val loss: 0.12919, in 0.153s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12788, val loss: 0.12664, in 0.152s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12609, val loss: 0.12774, in 0.146s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12799, val loss: 0.12732, in 0.170s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12849, val loss: 0.12751, in 0.164s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12962, val loss: 0.12873, in 0.158s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12878, val loss: 0.12953, in 0.153s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12860, val loss: 0.12785, in 0.165s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12531, val loss: 0.12692, in 0.156s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12720, val loss: 0.12594, in 0.175s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12694, val loss: 0.12846, in 0.182s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12759, val loss: 0.12693, in 0.159s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12813, val loss: 0.12715, in 0.149s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12889, val loss: 0.12799, in 0.163s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12834, val loss: 0.12909, in 0.174s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12822, val loss: 0.12746, in 0.163s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12474, val loss: 0.12635, in 0.166s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12652, val loss: 0.12527, in 0.153s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12700, val loss: 0.12633, in 0.157s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12621, val loss: 0.12773, in 0.166s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12753, val loss: 0.12655, in 0.164s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12839, val loss: 0.12748, in 0.153s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12775, val loss: 0.12850, in 0.168s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12766, val loss: 0.12690, in 0.151s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12405, val loss: 0.12565, in 0.153s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12613, val loss: 0.12488, in 0.156s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12572, val loss: 0.12726, in 0.145s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12634, val loss: 0.12567, in 0.158s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12672, val loss: 0.12576, in 0.166s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12783, val loss: 0.12693, in 0.164s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12719, val loss: 0.12642, in 0.149s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12717, val loss: 0.12791, in 0.159s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12350, val loss: 0.12510, in 0.156s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12516, val loss: 0.12671, in 0.168s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12551, val loss: 0.12426, in 0.185s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12577, val loss: 0.12513, in 0.168s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12600, val loss: 0.12508, in 0.140s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12650, val loss: 0.12724, in 0.157s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12667, val loss: 0.12590, in 0.182s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12287, val loss: 0.12449, in 0.165s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12697, val loss: 0.12611, in 0.213s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12470, val loss: 0.12623, in 0.180s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12462, val loss: 0.12338, in 0.176s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12517, val loss: 0.12450, in 0.201s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12544, val loss: 0.12452, in 0.184s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12597, val loss: 0.12669, in 0.309s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12643, val loss: 0.12560, in 0.332s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12585, val loss: 0.12510, in 0.335s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12223, val loss: 0.12384, in 0.350s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12407, val loss: 0.12560, in 0.316s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12392, val loss: 0.12269, in 0.347s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12453, val loss: 0.12384, in 0.353s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12482, val loss: 0.12389, in 0.409s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12537, val loss: 0.12608, in 0.269s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12577, val loss: 0.12496, in 0.265s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12515, val loss: 0.12438, in 0.282s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12168, val loss: 0.12330, in 0.277s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12335, val loss: 0.12485, in 0.274s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12336, val loss: 0.12216, in 0.302s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12401, val loss: 0.12330, in 0.282s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12428, val loss: 0.12337, in 0.275s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12474, val loss: 0.12543, in 0.264s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12452, val loss: 0.12375, in 0.263s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12516, val loss: 0.12434, in 0.282s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12298, val loss: 0.12448, in 0.268s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12119, val loss: 0.12277, in 0.288s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12294, val loss: 0.12174, in 0.265s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12355, val loss: 0.12286, in 0.282s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12378, val loss: 0.12286, in 0.276s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12506, in 0.276s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12477, val loss: 0.12392, in 0.257s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12410, val loss: 0.12334, in 0.302s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12069, val loss: 0.12228, in 0.292s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12232, val loss: 0.12111, in 0.288s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12235, val loss: 0.12387, in 0.356s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12310, val loss: 0.12244, in 0.282s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12340, val loss: 0.12249, in 0.273s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12372, val loss: 0.12441, in 0.262s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12432, val loss: 0.12348, in 0.302s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12353, val loss: 0.12276, in 0.263s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11999, val loss: 0.12154, in 0.274s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12179, val loss: 0.12057, in 0.257s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12175, val loss: 0.12329, in 0.273s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12257, val loss: 0.12190, in 0.269s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12275, val loss: 0.12184, in 0.267s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12314, val loss: 0.12382, in 0.324s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12361, val loss: 0.12279, in 0.294s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11950, val loss: 0.12106, in 0.264s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12293, val loss: 0.12216, in 0.310s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12144, val loss: 0.12022, in 0.263s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12208, val loss: 0.12142, in 0.279s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12117, val loss: 0.12270, in 0.314s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12219, val loss: 0.12129, in 0.273s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12276, val loss: 0.12342, in 0.265s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11901, val loss: 0.12057, in 0.250s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12245, val loss: 0.12169, in 0.282s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12083, val loss: 0.11961, in 0.277s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12303, val loss: 0.12221, in 0.346s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12147, val loss: 0.12083, in 0.289s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12079, val loss: 0.12231, in 0.287s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12155, val loss: 0.12065, in 0.267s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12228, val loss: 0.12294, in 0.334s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11810, val loss: 0.11964, in 0.296s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12038, val loss: 0.11914, in 0.263s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12191, val loss: 0.12118, in 0.269s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12174, in 0.262s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12013, val loss: 0.12162, in 0.261s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12102, val loss: 0.12037, in 0.329s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12109, val loss: 0.12017, in 0.338s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12153, val loss: 0.12221, in 0.241s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11909, in 0.242s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11988, val loss: 0.11863, in 0.238s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12194, val loss: 0.12113, in 0.210s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12140, val loss: 0.12069, in 0.265s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11948, val loss: 0.12096, in 0.213s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12057, val loss: 0.11966, in 0.155s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12047, val loss: 0.11981, in 0.199s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12097, val loss: 0.12165, in 0.160s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11940, val loss: 0.11814, in 0.158s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11711, val loss: 0.11861, in 0.172s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12096, val loss: 0.12023, in 0.170s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.12064, in 0.190s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11892, val loss: 0.12039, in 0.155s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12013, val loss: 0.11946, in 0.284s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12012, val loss: 0.11918, in 0.291s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11902, val loss: 0.11776, in 0.270s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12044, val loss: 0.12114, in 0.294s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11654, val loss: 0.11804, in 0.310s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12059, val loss: 0.11986, in 0.280s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12085, val loss: 0.12004, in 0.280s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11859, val loss: 0.12010, in 0.271s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11963, val loss: 0.11870, in 0.147s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11957, val loss: 0.11891, in 0.164s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11870, val loss: 0.11746, in 0.148s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11985, val loss: 0.12056, in 0.157s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12029, val loss: 0.11948, in 0.155s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12011, val loss: 0.11938, in 0.161s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11609, val loss: 0.11759, in 0.170s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11807, val loss: 0.11959, in 0.167s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11908, val loss: 0.11841, in 0.149s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11923, val loss: 0.11831, in 0.174s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11813, val loss: 0.11690, in 0.156s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11929, val loss: 0.11998, in 0.160s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11995, val loss: 0.11914, in 0.147s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11545, val loss: 0.11691, in 0.150s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11919, in 0.156s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11969, val loss: 0.11897, in 0.179s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11853, val loss: 0.11785, in 0.161s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11863, val loss: 0.11774, in 0.171s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11888, val loss: 0.11955, in 0.173s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11632, in 0.208s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11497, val loss: 0.11644, in 0.161s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11718, val loss: 0.11868, in 0.158s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11940, val loss: 0.11856, in 0.200s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11919, val loss: 0.11845, in 0.175s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11816, val loss: 0.11752, in 0.172s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11809, val loss: 0.11719, in 0.190s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11837, val loss: 0.11904, in 0.156s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11694, val loss: 0.11574, in 0.166s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11450, val loss: 0.11598, in 0.160s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11872, val loss: 0.11799, in 0.142s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11655, val loss: 0.11804, in 0.176s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11872, val loss: 0.11787, in 0.187s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11760, val loss: 0.11695, in 0.158s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11761, val loss: 0.11671, in 0.156s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11652, val loss: 0.11529, in 0.174s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11789, val loss: 0.11857, in 0.201s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11410, val loss: 0.11560, in 0.184s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11829, val loss: 0.11755, in 0.166s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11587, val loss: 0.11740, in 0.176s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11817, val loss: 0.11734, in 0.160s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11716, val loss: 0.11651, in 0.168s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11729, val loss: 0.11641, in 0.151s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11608, val loss: 0.11485, in 0.150s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11369, val loss: 0.11518, in 0.146s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11694, in 0.162s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11527, val loss: 0.11677, in 0.153s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11737, val loss: 0.11804, in 0.185s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11780, val loss: 0.11698, in 0.157s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11673, val loss: 0.11607, in 0.170s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11681, val loss: 0.11593, in 0.187s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11484, in 0.150s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11707, val loss: 0.11774, in 0.151s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11559, val loss: 0.11436, in 0.195s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11487, val loss: 0.11637, in 0.161s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11726, val loss: 0.11650, in 0.180s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11722, val loss: 0.11638, in 0.161s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11630, val loss: 0.11563, in 0.151s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11639, val loss: 0.11551, in 0.174s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11277, val loss: 0.11422, in 0.167s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11507, val loss: 0.11384, in 0.169s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11654, val loss: 0.11719, in 0.175s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11691, val loss: 0.11617, in 0.157s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11431, val loss: 0.11580, in 0.176s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11684, val loss: 0.11599, in 0.170s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11585, val loss: 0.11518, in 0.166s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11607, val loss: 0.11520, in 0.152s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11232, val loss: 0.11377, in 0.160s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11623, val loss: 0.11691, in 0.155s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11467, val loss: 0.11344, in 0.161s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11646, val loss: 0.11561, in 0.169s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11639, val loss: 0.11565, in 0.188s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11386, val loss: 0.11533, in 0.197s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11548, val loss: 0.11481, in 0.175s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11553, val loss: 0.11466, in 0.163s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11181, val loss: 0.11324, in 0.173s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11430, val loss: 0.11312, in 0.169s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11556, val loss: 0.11627, in 0.172s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11594, val loss: 0.11522, in 0.155s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11521, val loss: 0.11453, in 0.154s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11594, val loss: 0.11512, in 0.178s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11489, in 0.189s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11514, val loss: 0.11426, in 0.175s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11136, val loss: 0.11280, in 0.157s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11400, val loss: 0.11283, in 0.157s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11509, val loss: 0.11580, in 0.159s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11470, val loss: 0.11403, in 0.151s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11545, val loss: 0.11461, in 0.161s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11307, val loss: 0.11452, in 0.151s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11550, val loss: 0.11478, in 0.204s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11443, val loss: 0.11357, in 0.164s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11089, val loss: 0.11234, in 0.185s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11460, val loss: 0.11529, in 0.165s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11355, val loss: 0.11240, in 0.193s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11494, val loss: 0.11411, in 0.166s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11276, val loss: 0.11421, in 0.150s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11422, val loss: 0.11358, in 0.189s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11506, val loss: 0.11433, in 0.161s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11392, val loss: 0.11305, in 0.338s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11044, val loss: 0.11189, in 0.420s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11379, val loss: 0.11448, in 0.418s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11296, val loss: 0.11182, in 0.429s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11457, val loss: 0.11385, in 0.396s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11235, val loss: 0.11381, in 0.414s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11437, val loss: 0.11354, in 0.431s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11379, val loss: 0.11315, in 0.449s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11349, val loss: 0.11262, in 0.320s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11014, val loss: 0.11161, in 0.318s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11352, val loss: 0.11420, in 0.326s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11190, val loss: 0.11335, in 0.326s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11338, in 0.334s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11252, val loss: 0.11140, in 0.351s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11272, in 0.299s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11397, val loss: 0.11310, in 0.346s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11301, val loss: 0.11213, in 0.330s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11376, in 0.260s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10959, val loss: 0.11104, in 0.287s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11135, val loss: 0.11278, in 0.274s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11310, val loss: 0.11246, in 0.268s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11216, val loss: 0.11104, in 0.297s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11348, val loss: 0.11259, in 0.284s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11370, val loss: 0.11298, in 0.326s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11224, val loss: 0.11137, in 0.317s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10917, val loss: 0.11061, in 0.256s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11262, val loss: 0.11331, in 0.325s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11346, val loss: 0.11275, in 0.259s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11089, val loss: 0.11233, in 0.317s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11248, val loss: 0.11187, in 0.312s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11183, val loss: 0.11071, in 0.284s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11306, val loss: 0.11219, in 0.322s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11199, val loss: 0.11111, in 0.267s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11236, val loss: 0.11304, in 0.287s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.11007, in 0.368s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11221, val loss: 0.11160, in 0.276s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11276, val loss: 0.11207, in 0.292s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11107, val loss: 0.10996, in 0.297s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11259, val loss: 0.11172, in 0.274s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11049, val loss: 0.11192, in 0.357s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11163, val loss: 0.11076, in 0.266s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11206, val loss: 0.11275, in 0.279s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11142, val loss: 0.11083, in 0.326s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11205, val loss: 0.11138, in 0.329s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10812, val loss: 0.10957, in 0.375s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11222, val loss: 0.11134, in 0.320s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11064, val loss: 0.10952, in 0.384s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10990, val loss: 0.11131, in 0.344s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11120, val loss: 0.11034, in 0.312s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11166, val loss: 0.11235, in 0.298s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11162, val loss: 0.11097, in 0.295s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11192, val loss: 0.11105, in 0.288s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11064, val loss: 0.11007, in 0.325s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10769, val loss: 0.10915, in 0.312s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11025, val loss: 0.10913, in 0.277s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10963, val loss: 0.11106, in 0.276s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11086, val loss: 0.11002, in 0.325s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11118, val loss: 0.11188, in 0.291s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10734, val loss: 0.10879, in 0.279s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11019, val loss: 0.10962, in 0.306s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11113, val loss: 0.11047, in 0.332s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11155, val loss: 0.11067, in 0.331s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10946, val loss: 0.10837, in 0.301s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10921, val loss: 0.11066, in 0.292s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11036, val loss: 0.10955, in 0.267s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11065, val loss: 0.11135, in 0.245s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10980, val loss: 0.10921, in 0.185s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10839, in 0.224s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10904, val loss: 0.10796, in 0.188s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.11033, in 0.193s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11067, val loss: 0.11001, in 0.232s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11100, val loss: 0.11013, in 0.230s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10969, val loss: 0.10892, in 0.211s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.11091, in 0.213s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10957, val loss: 0.10898, in 0.286s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10646, val loss: 0.10786, in 0.319s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10856, val loss: 0.10999, in 0.315s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11034, val loss: 0.10964, in 0.320s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.10765, in 0.346s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11060, val loss: 0.10970, in 0.317s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10931, val loss: 0.10852, in 0.361s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10984, val loss: 0.11052, in 0.372s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10925, val loss: 0.10865, in 0.260s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10586, val loss: 0.10727, in 0.257s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11002, val loss: 0.10932, in 0.228s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10805, val loss: 0.10946, in 0.258s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10804, val loss: 0.10702, in 0.255s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11015, val loss: 0.10927, in 0.247s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.10784, in 0.260s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10952, val loss: 0.11021, in 0.213s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10880, val loss: 0.10823, in 0.260s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10937, val loss: 0.10869, in 0.209s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10764, val loss: 0.10905, in 0.202s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10972, val loss: 0.10885, in 0.187s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10770, val loss: 0.10667, in 0.205s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10497, val loss: 0.10636, in 0.242s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10818, val loss: 0.10738, in 0.184s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10913, val loss: 0.10982, in 0.192s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10895, val loss: 0.10826, in 0.171s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10949, val loss: 0.10861, in 0.190s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10843, val loss: 0.10786, in 0.211s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10464, val loss: 0.10603, in 0.181s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10728, val loss: 0.10871, in 0.212s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10735, val loss: 0.10631, in 0.208s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10777, val loss: 0.10697, in 0.232s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10879, val loss: 0.10951, in 0.210s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10856, val loss: 0.10789, in 0.198s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10430, val loss: 0.10571, in 0.193s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10810, val loss: 0.10754, in 0.206s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10915, val loss: 0.10827, in 0.216s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10592, in 0.180s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10691, val loss: 0.10832, in 0.214s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10849, val loss: 0.10920, in 0.173s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10662, in 0.211s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10821, val loss: 0.10755, in 0.199s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10775, val loss: 0.10718, in 0.170s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10555, in 0.183s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10535, in 0.194s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10658, val loss: 0.10798, in 0.180s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10866, val loss: 0.10778, in 0.211s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10806, val loss: 0.10874, in 0.181s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10708, val loss: 0.10630, in 0.161s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10788, val loss: 0.10722, in 0.181s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10614, val loss: 0.10510, in 0.164s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10704, val loss: 0.10648, in 0.180s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10373, val loss: 0.10514, in 0.183s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10610, val loss: 0.10746, in 0.177s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10834, val loss: 0.10746, in 0.186s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10667, val loss: 0.10586, in 0.203s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10766, val loss: 0.10834, in 0.222s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10604, in 0.177s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10755, val loss: 0.10691, in 0.203s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10326, val loss: 0.10466, in 0.170s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10578, val loss: 0.10474, in 0.198s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10553, val loss: 0.10692, in 0.193s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10774, val loss: 0.10689, in 0.175s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10800, in 0.156s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10632, val loss: 0.10549, in 0.162s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10551, val loss: 0.10447, in 0.150s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10617, val loss: 0.10563, in 0.172s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10719, val loss: 0.10652, in 0.168s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10296, val loss: 0.10437, in 0.170s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10736, val loss: 0.10652, in 0.166s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10492, val loss: 0.10632, in 0.208s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10701, val loss: 0.10770, in 0.165s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10570, val loss: 0.10487, in 0.177s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10520, val loss: 0.10420, in 0.173s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10586, val loss: 0.10532, in 0.171s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10647, val loss: 0.10578, in 0.190s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10705, val loss: 0.10621, in 0.161s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10209, val loss: 0.10349, in 0.202s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10470, val loss: 0.10611, in 0.149s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10640, val loss: 0.10706, in 0.211s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10456, val loss: 0.10377, in 0.203s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10494, val loss: 0.10393, in 0.156s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10504, in 0.154s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10626, val loss: 0.10557, in 0.145s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10665, val loss: 0.10581, in 0.161s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10182, val loss: 0.10324, in 0.162s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10576, in 0.160s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10605, val loss: 0.10673, in 0.160s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10470, in 0.165s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10420, val loss: 0.10341, in 0.174s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10597, val loss: 0.10530, in 0.157s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10426, val loss: 0.10327, in 0.174s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10142, val loss: 0.10287, in 0.156s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10628, val loss: 0.10544, in 0.187s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10400, val loss: 0.10542, in 0.185s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10575, val loss: 0.10642, in 0.152s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10484, val loss: 0.10430, in 0.162s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10395, val loss: 0.10317, in 0.161s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10293, in 0.162s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10559, val loss: 0.10493, in 0.170s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10082, val loss: 0.10228, in 0.362s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10598, val loss: 0.10515, in 0.347s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10346, val loss: 0.10487, in 0.340s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10362, val loss: 0.10284, in 0.384s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10540, val loss: 0.10607, in 0.427s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10351, val loss: 0.10250, in 0.404s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10457, in 0.417s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10452, val loss: 0.10396, in 0.441s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10473, in 0.268s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10448, in 0.260s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10049, val loss: 0.10196, in 0.289s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10286, val loss: 0.10209, in 0.286s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10478, val loss: 0.10547, in 0.292s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10320, val loss: 0.10220, in 0.300s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10491, val loss: 0.10422, in 0.286s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10431, val loss: 0.10375, in 0.284s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10274, val loss: 0.10414, in 0.258s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10020, val loss: 0.10167, in 0.281s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10498, val loss: 0.10419, in 0.312s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10442, val loss: 0.10511, in 0.254s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10278, val loss: 0.10177, in 0.261s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10390, val loss: 0.10333, in 0.267s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10449, val loss: 0.10381, in 0.291s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10105, in 0.353s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10236, val loss: 0.10377, in 0.283s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09977, val loss: 0.10122, in 0.277s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10453, val loss: 0.10374, in 0.286s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10416, val loss: 0.10487, in 0.259s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10425, val loss: 0.10358, in 0.259s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10220, val loss: 0.10124, in 0.305s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10358, val loss: 0.10301, in 0.314s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10114, val loss: 0.10042, in 0.332s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09944, val loss: 0.10088, in 0.280s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10203, val loss: 0.10342, in 0.339s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10421, val loss: 0.10340, in 0.301s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10365, val loss: 0.10436, in 0.341s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10389, val loss: 0.10323, in 0.410s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10319, val loss: 0.10263, in 0.386s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10183, val loss: 0.10089, in 0.432s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10320, in 0.341s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10083, val loss: 0.10010, in 0.393s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10384, val loss: 0.10304, in 0.352s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09907, val loss: 0.10052, in 0.406s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10326, val loss: 0.10397, in 0.346s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10163, val loss: 0.10070, in 0.313s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10290, val loss: 0.10236, in 0.380s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10324, val loss: 0.10256, in 0.403s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10066, val loss: 0.09993, in 0.334s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10356, val loss: 0.10275, in 0.344s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10134, val loss: 0.10273, in 0.372s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.10028, in 0.372s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10272, val loss: 0.10345, in 0.366s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10118, val loss: 0.10027, in 0.371s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10100, val loss: 0.10239, in 0.301s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10288, val loss: 0.10220, in 0.333s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10023, val loss: 0.09953, in 0.340s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09861, val loss: 0.10007, in 0.304s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10225, val loss: 0.10172, in 0.387s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10230, in 0.382s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10248, val loss: 0.10322, in 0.354s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09992, val loss: 0.09923, in 0.333s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10064, val loss: 0.10201, in 0.354s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10088, val loss: 0.09996, in 0.377s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10221, val loss: 0.10155, in 0.387s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10275, val loss: 0.10195, in 0.318s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09830, val loss: 0.09973, in 0.359s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10186, val loss: 0.10133, in 0.372s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10194, val loss: 0.10265, in 0.311s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10045, val loss: 0.10183, in 0.186s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09972, val loss: 0.09904, in 0.200s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09964, in 0.207s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10243, val loss: 0.10162, in 0.202s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10185, val loss: 0.10118, in 0.215s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09765, val loss: 0.09907, in 0.217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10110, val loss: 0.10058, in 0.250s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10167, val loss: 0.10239, in 0.337s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09974, val loss: 0.10110, in 0.356s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09995, val loss: 0.09903, in 0.338s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10158, val loss: 0.10090, in 0.329s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09920, val loss: 0.09852, in 0.407s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10208, val loss: 0.10129, in 0.374s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09732, val loss: 0.09877, in 0.361s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10070, val loss: 0.10018, in 0.316s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10141, val loss: 0.10213, in 0.207s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09938, val loss: 0.10075, in 0.229s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10115, val loss: 0.10047, in 0.198s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09868, in 0.246s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09815, in 0.197s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10185, val loss: 0.10105, in 0.192s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09702, val loss: 0.09846, in 0.192s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10040, val loss: 0.09987, in 0.199s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10108, val loss: 0.10180, in 0.182s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10074, val loss: 0.10007, in 0.183s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09889, val loss: 0.10027, in 0.200s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09860, val loss: 0.09791, in 0.174s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10119, val loss: 0.10042, in 0.186s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09918, val loss: 0.09825, in 0.202s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09998, val loss: 0.09948, in 0.182s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09634, val loss: 0.09779, in 0.197s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10051, val loss: 0.10124, in 0.168s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09991, in 0.149s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10097, val loss: 0.10023, in 0.153s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09968, val loss: 0.09917, in 0.161s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09698, in 0.203s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09888, val loss: 0.09795, in 0.179s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09837, val loss: 0.09977, in 0.212s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09568, val loss: 0.09711, in 0.173s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10015, val loss: 0.10088, in 0.169s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10025, val loss: 0.09959, in 0.192s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10057, val loss: 0.09985, in 0.166s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09939, val loss: 0.09887, in 0.158s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09742, val loss: 0.09674, in 0.154s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09819, val loss: 0.09729, in 0.172s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09533, val loss: 0.09678, in 0.165s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09775, val loss: 0.09916, in 0.182s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09980, val loss: 0.10053, in 0.180s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09996, val loss: 0.09931, in 0.147s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09923, val loss: 0.09872, in 0.150s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09504, val loss: 0.09648, in 0.143s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09673, val loss: 0.09606, in 0.168s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10003, val loss: 0.09933, in 0.202s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09792, val loss: 0.09705, in 0.170s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09745, val loss: 0.09888, in 0.181s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09951, val loss: 0.10023, in 0.177s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09936, val loss: 0.09875, in 0.159s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09895, val loss: 0.09844, in 0.145s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09651, val loss: 0.09585, in 0.153s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09774, val loss: 0.09687, in 0.154s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09962, val loss: 0.09892, in 0.161s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09471, val loss: 0.09615, in 0.194s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09720, val loss: 0.09862, in 0.172s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09927, val loss: 0.09999, in 0.149s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09832, val loss: 0.09773, in 0.203s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09859, val loss: 0.09809, in 0.191s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09859, in 0.158s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09707, val loss: 0.09624, in 0.188s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09600, val loss: 0.09534, in 0.221s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09701, val loss: 0.09844, in 0.158s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09416, val loss: 0.09558, in 0.206s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09957, in 0.173s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09795, val loss: 0.09733, in 0.171s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09801, val loss: 0.09751, in 0.172s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09913, val loss: 0.09842, in 0.168s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09678, val loss: 0.09593, in 0.161s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09670, val loss: 0.09815, in 0.164s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09491, in 0.176s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09391, val loss: 0.09535, in 0.160s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09823, val loss: 0.09896, in 0.185s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09715, in 0.158s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09704, in 0.186s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09884, val loss: 0.09811, in 0.178s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09640, val loss: 0.09785, in 0.153s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09553, in 0.185s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09513, val loss: 0.09449, in 0.171s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09796, val loss: 0.09869, in 0.149s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09312, val loss: 0.09456, in 0.186s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09728, val loss: 0.09679, in 0.166s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09768, in 0.150s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09710, val loss: 0.09649, in 0.180s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09857, val loss: 0.09785, in 0.168s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09611, val loss: 0.09525, in 0.163s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09286, val loss: 0.09429, in 0.151s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09769, val loss: 0.09842, in 0.191s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09463, val loss: 0.09397, in 0.209s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09677, val loss: 0.09630, in 0.167s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09683, val loss: 0.09624, in 0.177s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09804, val loss: 0.09729, in 0.198s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09577, val loss: 0.09723, in 0.213s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09472, in 0.192s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09738, val loss: 0.09812, in 0.153s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09260, val loss: 0.09407, in 0.189s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09377, val loss: 0.09313, in 0.204s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09634, val loss: 0.09587, in 0.169s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09652, val loss: 0.09593, in 0.167s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09540, val loss: 0.09453, in 0.162s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09762, val loss: 0.09689, in 0.309s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09521, val loss: 0.09668, in 0.333s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09688, val loss: 0.09764, in 0.334s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09233, val loss: 0.09378, in 0.333s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09350, val loss: 0.09284, in 0.354s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09598, val loss: 0.09550, in 0.354s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09618, val loss: 0.09558, in 0.393s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09515, val loss: 0.09428, in 0.380s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09738, val loss: 0.09665, in 0.265s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09498, val loss: 0.09644, in 0.267s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09648, val loss: 0.09724, in 0.269s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09212, val loss: 0.09358, in 0.274s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09266, in 0.262s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09549, val loss: 0.09504, in 0.279s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09585, val loss: 0.09524, in 0.255s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09478, val loss: 0.09392, in 0.310s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09703, val loss: 0.09630, in 0.317s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09451, val loss: 0.09596, in 0.361s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09169, val loss: 0.09317, in 0.347s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09613, val loss: 0.09687, in 0.354s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09294, val loss: 0.09228, in 0.371s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09555, val loss: 0.09493, in 0.425s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09499, val loss: 0.09451, in 0.502s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09418, val loss: 0.09335, in 0.447s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09415, val loss: 0.09560, in 0.373s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09136, val loss: 0.09282, in 0.388s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09609, val loss: 0.09539, in 0.485s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09625, in 0.401s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09267, val loss: 0.09201, in 0.363s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09476, val loss: 0.09428, in 0.333s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09297, in 0.298s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09448, in 0.400s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09393, val loss: 0.09538, in 0.301s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09575, val loss: 0.09504, in 0.293s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09105, val loss: 0.09252, in 0.350s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09229, val loss: 0.09163, in 0.313s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09456, val loss: 0.09531, in 0.368s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09412, in 0.272s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09361, val loss: 0.09279, in 0.289s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09484, val loss: 0.09424, in 0.315s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09306, val loss: 0.09453, in 0.351s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09546, val loss: 0.09476, in 0.348s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09046, val loss: 0.09194, in 0.330s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09479, in 0.338s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09150, val loss: 0.09085, in 0.369s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09432, val loss: 0.09387, in 0.303s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09241, in 0.284s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09407, in 0.267s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09268, val loss: 0.09413, in 0.260s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09021, val loss: 0.09169, in 0.251s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09439, in 0.337s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09375, val loss: 0.09451, in 0.284s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09125, val loss: 0.09059, in 0.311s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09401, val loss: 0.09355, in 0.299s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09372, in 0.285s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09219, in 0.307s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09240, val loss: 0.09385, in 0.280s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08998, val loss: 0.09144, in 0.311s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09097, val loss: 0.09033, in 0.270s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09463, val loss: 0.09390, in 0.381s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09347, val loss: 0.09303, in 0.321s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09328, val loss: 0.09404, in 0.386s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09272, val loss: 0.09194, in 0.304s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09344, in 0.331s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09218, val loss: 0.09364, in 0.291s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08978, val loss: 0.09126, in 0.277s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09061, val loss: 0.08998, in 0.264s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09315, val loss: 0.09271, in 0.221s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09304, val loss: 0.09379, in 0.230s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09322, in 0.211s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09430, val loss: 0.09358, in 0.298s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09191, val loss: 0.09335, in 0.237s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09152, in 0.273s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08941, val loss: 0.09087, in 0.193s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09274, val loss: 0.09350, in 0.263s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09252, val loss: 0.09211, in 0.297s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08986, val loss: 0.08926, in 0.346s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.09297, in 0.305s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09379, val loss: 0.09310, in 0.333s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09210, val loss: 0.09134, in 0.298s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09331, val loss: 0.09270, in 0.351s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08908, val loss: 0.09055, in 0.355s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09233, val loss: 0.09193, in 0.220s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08908, in 0.199s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09248, val loss: 0.09324, in 0.296s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09348, val loss: 0.09279, in 0.236s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09236, in 0.232s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09133, val loss: 0.09058, in 0.300s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09073, val loss: 0.09219, in 0.361s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08870, val loss: 0.09016, in 0.349s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09213, val loss: 0.09288, in 0.291s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08939, val loss: 0.08880, in 0.361s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09266, in 0.280s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09283, val loss: 0.09222, in 0.295s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09022, val loss: 0.09171, in 0.257s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09187, val loss: 0.09263, in 0.197s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08919, val loss: 0.08859, in 0.197s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09312, val loss: 0.09243, in 0.194s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09169, val loss: 0.09246, in 0.162s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08895, val loss: 0.08834, in 0.168s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09277, val loss: 0.09208, in 0.183s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09200, val loss: 0.09162, in 0.310s\n",
      "Fit 200 trees in 54.200 s, (1591 total leaves)\n",
      "Time spent computing histograms: 31.691s\n",
      "Time spent finding best splits:  0.172s\n",
      "Time spent applying splits:      4.259s\n",
      "Time spent predicting:           0.462s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08855, val loss: 0.09002, in 0.198s\n",
      "Fit 200 trees in 54.215 s, (1595 total leaves)\n",
      "Time spent computing histograms: 31.644s\n",
      "Time spent finding best splits:  0.184s\n",
      "Time spent applying splits:      4.392s\n",
      "Time spent predicting:           0.573s\n",
      "Binning 0.119 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.09109, val loss: 0.09033, in 0.311s\n",
      "Fit 200 trees in 54.403 s, (1592 total leaves)\n",
      "Time spent computing histograms: 32.256s\n",
      "Time spent finding best splits:  0.215s\n",
      "Time spent applying splits:      4.070s\n",
      "Time spent predicting:           0.452s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09261, val loss: 0.09200, in 0.185s\n",
      "Fit 200 trees in 54.213 s, (1595 total leaves)\n",
      "Time spent computing histograms: 31.772s\n",
      "Time spent finding best splits:  0.162s\n",
      "Time spent applying splits:      4.331s\n",
      "Time spent predicting:           0.400s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08959, val loss: 0.09108, in 0.185s\n",
      "Fit 200 trees in 54.602 s, (1593 total leaves)\n",
      "Time spent computing histograms: 31.763s\n",
      "Time spent finding best splits:  0.213s\n",
      "Time spent applying splits:      4.245s\n",
      "Time spent predicting:           0.550s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09146, val loss: 0.09222, in 0.156s\n",
      "Fit 200 trees in 54.358 s, (1596 total leaves)\n",
      "Time spent computing histograms: 31.425s\n",
      "Time spent finding best splits:  0.182s\n",
      "Time spent applying splits:      4.308s\n",
      "Time spent predicting:           0.420s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09250, val loss: 0.09182, in 0.135s\n",
      "Fit 200 trees in 54.435 s, (1596 total leaves)\n",
      "Time spent computing histograms: 31.671s\n",
      "Time spent finding best splits:  0.186s\n",
      "Time spent applying splits:      4.779s\n",
      "Time spent predicting:           0.426s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08860, val loss: 0.08799, in 0.157s\n",
      "Fit 200 trees in 54.615 s, (1594 total leaves)\n",
      "Time spent computing histograms: 32.382s\n",
      "Time spent finding best splits:  0.213s\n",
      "Time spent applying splits:      4.327s\n",
      "Time spent predicting:           0.421s\n",
      "Binning 0.119 GB of training data: 2.955 s\n",
      "Binning 0.013 GB of validation data: 3.073 s\n",
      "Binning 0.013 GB of validation data: 3.074 s\n",
      "Binning 0.013 GB of validation data: 0.201 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 3.124 s\n",
      "Binning 0.013 GB of validation data: 3.162 s\n",
      "Binning 0.013 GB of validation data: 0.205 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.209 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65604, val loss: 0.65602, in 0.326s\n",
      "[2/200] 0.213 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.211 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 3.272 s\n",
      "Binning 0.013 GB of validation data: 3.274 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.65600, val loss: 0.65603, in 0.338s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65603, val loss: 0.65599, in 0.342s\n",
      "[2/200] 3.350 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62247, val loss: 0.62244, in 0.335s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65620, val loss: 0.65624, in 0.334s\n",
      "[2/200] 0.208 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.215 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62240, val loss: 0.62245, in 0.328s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62245, val loss: 0.62237, in 0.321s\n",
      "[3/200] 0.210 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65048, val loss: 0.65047, in 0.431s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59198, val loss: 0.59193, in 0.308s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62278, val loss: 0.62285, in 0.285s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59188, val loss: 0.59195, in 0.226s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65052, in 0.363s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59195, val loss: 0.59183, in 0.229s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65049, val loss: 0.65049, in 0.367s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56417, val loss: 0.56408, in 0.223s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65046, in 0.312s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59242, val loss: 0.59252, in 0.227s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61187, val loss: 0.61185, in 0.339s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56404, val loss: 0.56413, in 0.200s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56413, val loss: 0.56396, in 0.192s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53872, val loss: 0.53862, in 0.296s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56472, val loss: 0.56488, in 0.285s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61192, val loss: 0.61194, in 0.406s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61192, val loss: 0.61191, in 0.400s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61194, val loss: 0.61186, in 0.389s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57679, val loss: 0.57679, in 0.361s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53868, val loss: 0.53847, in 0.295s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53857, val loss: 0.53868, in 0.301s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51537, val loss: 0.51523, in 0.186s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.53938, val loss: 0.53959, in 0.194s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51520, val loss: 0.51532, in 0.176s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57672, val loss: 0.57674, in 0.265s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51532, val loss: 0.51507, in 0.184s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57677, val loss: 0.57678, in 0.272s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49389, val loss: 0.49373, in 0.182s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57691, val loss: 0.57674, in 0.256s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54442, in 0.264s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51611, val loss: 0.51635, in 0.181s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49384, val loss: 0.49356, in 0.188s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49371, val loss: 0.49383, in 0.197s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47405, val loss: 0.47392, in 0.196s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54446, in 0.276s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54443, in 0.278s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49466, val loss: 0.49498, in 0.212s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54484, val loss: 0.54459, in 0.270s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51470, val loss: 0.51479, in 0.267s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47386, val loss: 0.47404, in 0.184s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47399, val loss: 0.47377, in 0.202s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45567, val loss: 0.45557, in 0.191s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47486, val loss: 0.47522, in 0.187s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51475, val loss: 0.51479, in 0.279s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51484, val loss: 0.51488, in 0.257s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45545, val loss: 0.45566, in 0.207s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45561, val loss: 0.45540, in 0.201s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51515, val loss: 0.51491, in 0.273s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48744, val loss: 0.48748, in 0.283s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43865, val loss: 0.43861, in 0.206s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45655, val loss: 0.45699, in 0.205s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43840, val loss: 0.43871, in 0.215s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43859, val loss: 0.43845, in 0.225s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48758, val loss: 0.48765, in 0.280s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48761, val loss: 0.48762, in 0.288s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42283, val loss: 0.42277, in 0.202s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48788, val loss: 0.48761, in 0.283s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46245, val loss: 0.46251, in 0.277s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43957, val loss: 0.44006, in 0.206s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42257, val loss: 0.42291, in 0.198s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42277, val loss: 0.42263, in 0.196s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40813, val loss: 0.40811, in 0.212s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42378, val loss: 0.42437, in 0.196s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46251, val loss: 0.46257, in 0.277s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46261, val loss: 0.46263, in 0.270s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46282, val loss: 0.46255, in 0.281s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43945, val loss: 0.43952, in 0.269s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40786, val loss: 0.40825, in 0.200s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40806, val loss: 0.40793, in 0.191s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39442, val loss: 0.39446, in 0.193s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40909, val loss: 0.40972, in 0.195s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43951, val loss: 0.43956, in 0.260s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43956, val loss: 0.43961, in 0.270s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39415, val loss: 0.39462, in 0.195s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39435, val loss: 0.39428, in 0.196s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43978, val loss: 0.43951, in 0.270s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41793, val loss: 0.41802, in 0.286s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38165, val loss: 0.38170, in 0.201s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39543, val loss: 0.39610, in 0.193s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38135, val loss: 0.38184, in 0.205s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38155, val loss: 0.38147, in 0.213s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36971, val loss: 0.36977, in 0.201s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41805, val loss: 0.41810, in 0.290s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41821, val loss: 0.41828, in 0.288s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38267, val loss: 0.38343, in 0.197s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41823, val loss: 0.41795, in 0.269s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39771, val loss: 0.39781, in 0.267s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36941, val loss: 0.36999, in 0.374s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36966, val loss: 0.36961, in 0.365s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35854, val loss: 0.35862, in 0.400s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37077, val loss: 0.37159, in 0.451s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39803, val loss: 0.39814, in 0.560s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39797, val loss: 0.39804, in 0.559s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39841, val loss: 0.39806, in 0.581s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37911, val loss: 0.37928, in 0.580s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35825, val loss: 0.35886, in 0.359s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35846, val loss: 0.35844, in 0.354s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34811, val loss: 0.34822, in 0.348s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35966, val loss: 0.36054, in 0.354s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34779, val loss: 0.34847, in 0.350s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37921, val loss: 0.37931, in 0.477s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34801, val loss: 0.34800, in 0.382s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37954, val loss: 0.37960, in 0.500s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33833, val loss: 0.33847, in 0.363s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37966, val loss: 0.37934, in 0.488s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36185, val loss: 0.36199, in 0.517s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34924, val loss: 0.35016, in 0.349s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33803, val loss: 0.33874, in 0.346s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33825, val loss: 0.33824, in 0.341s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32909, val loss: 0.32929, in 0.366s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33950, val loss: 0.34044, in 0.345s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36204, val loss: 0.36212, in 0.511s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36206, val loss: 0.36222, in 0.486s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36226, val loss: 0.36193, in 0.492s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34549, val loss: 0.34564, in 0.485s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32884, val loss: 0.32963, in 0.361s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32905, val loss: 0.32912, in 0.355s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32049, val loss: 0.32071, in 0.345s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33032, val loss: 0.33131, in 0.357s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34582, val loss: 0.34594, in 0.530s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34574, val loss: 0.34589, in 0.538s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32014, val loss: 0.32099, in 0.388s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34609, val loss: 0.34579, in 0.537s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32037, val loss: 0.32046, in 0.414s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33035, val loss: 0.33052, in 0.538s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31235, val loss: 0.31259, in 0.423s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32172, val loss: 0.32280, in 0.412s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31200, val loss: 0.31291, in 0.385s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31229, val loss: 0.31238, in 0.373s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30470, val loss: 0.30493, in 0.351s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33044, val loss: 0.33058, in 0.511s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33057, val loss: 0.33075, in 0.529s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31367, val loss: 0.31478, in 0.333s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33087, val loss: 0.33056, in 0.500s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31622, val loss: 0.31646, in 0.467s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30440, val loss: 0.30534, in 0.248s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30462, val loss: 0.30474, in 0.226s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29756, val loss: 0.29783, in 0.220s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30603, val loss: 0.30720, in 0.214s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31626, val loss: 0.31650, in 0.415s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31628, val loss: 0.31644, in 0.422s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31655, val loss: 0.31623, in 0.418s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30299, val loss: 0.30324, in 0.415s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29719, val loss: 0.29816, in 0.338s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29742, val loss: 0.29757, in 0.335s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29077, val loss: 0.29112, in 0.332s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29884, val loss: 0.30010, in 0.339s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29041, val loss: 0.29141, in 0.227s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29069, val loss: 0.29082, in 0.217s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30291, val loss: 0.30316, in 0.317s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30305, val loss: 0.30322, in 0.313s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30346, val loss: 0.30307, in 0.308s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28439, val loss: 0.28470, in 0.224s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29054, val loss: 0.29078, in 0.332s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29207, val loss: 0.29337, in 0.229s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28407, val loss: 0.28509, in 0.239s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28430, val loss: 0.28447, in 0.246s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27842, val loss: 0.27874, in 0.254s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28576, val loss: 0.28704, in 0.240s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29058, val loss: 0.29085, in 0.327s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29061, val loss: 0.29077, in 0.348s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29096, val loss: 0.29063, in 0.342s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27892, val loss: 0.27909, in 0.327s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27803, val loss: 0.27913, in 0.222s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27828, val loss: 0.27847, in 0.216s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27273, val loss: 0.27311, in 0.225s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27974, val loss: 0.28109, in 0.228s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27236, val loss: 0.27350, in 0.204s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27898, val loss: 0.27924, in 0.320s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27264, val loss: 0.27282, in 0.232s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27903, val loss: 0.27917, in 0.330s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27939, val loss: 0.27901, in 0.330s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26786, val loss: 0.26800, in 0.334s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26731, val loss: 0.26773, in 0.229s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27413, val loss: 0.27553, in 0.218s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26704, val loss: 0.26824, in 0.229s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26719, val loss: 0.26731, in 0.224s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26227, val loss: 0.26264, in 0.211s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26799, val loss: 0.26824, in 0.331s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26875, val loss: 0.27021, in 0.217s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26799, val loss: 0.26815, in 0.320s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26833, val loss: 0.26796, in 0.311s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25746, val loss: 0.25762, in 0.320s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26187, val loss: 0.26303, in 0.214s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26210, val loss: 0.26230, in 0.216s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25741, val loss: 0.25777, in 0.239s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26359, val loss: 0.26508, in 0.241s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25780, val loss: 0.25805, in 0.386s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25702, val loss: 0.25819, in 0.293s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25782, val loss: 0.25800, in 0.375s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25797, val loss: 0.25763, in 0.401s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25723, val loss: 0.25741, in 0.300s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24773, val loss: 0.24792, in 0.376s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25283, val loss: 0.25317, in 0.291s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25871, val loss: 0.26019, in 0.287s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25245, val loss: 0.25365, in 0.246s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25274, val loss: 0.25291, in 0.232s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24857, val loss: 0.24891, in 0.234s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24814, val loss: 0.24835, in 0.367s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25381, val loss: 0.25531, in 0.247s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24807, val loss: 0.24836, in 0.392s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24828, val loss: 0.24804, in 0.352s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23857, val loss: 0.23882, in 0.386s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24788, val loss: 0.24911, in 0.249s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24837, val loss: 0.24851, in 0.259s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24444, val loss: 0.24478, in 0.253s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24956, val loss: 0.25108, in 0.253s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23908, val loss: 0.23938, in 0.353s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23895, val loss: 0.23919, in 0.534s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24384, val loss: 0.24511, in 0.419s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23910, val loss: 0.23883, in 0.553s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24404, val loss: 0.24421, in 0.429s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23001, val loss: 0.23029, in 0.553s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24058, val loss: 0.24090, in 0.466s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24538, val loss: 0.24696, in 0.476s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23991, val loss: 0.24120, in 0.410s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24011, val loss: 0.24023, in 0.411s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23044, val loss: 0.23073, in 0.714s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23666, val loss: 0.23702, in 0.400s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23030, val loss: 0.23057, in 0.590s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24142, val loss: 0.24303, in 0.423s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23049, val loss: 0.23022, in 0.595s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22168, val loss: 0.22194, in 0.591s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23627, val loss: 0.23752, in 0.370s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23622, val loss: 0.23642, in 0.382s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23311, val loss: 0.23347, in 0.407s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23732, val loss: 0.23891, in 0.374s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22228, val loss: 0.22265, in 0.578s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22203, val loss: 0.22231, in 0.592s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22240, val loss: 0.22220, in 0.560s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23273, val loss: 0.23394, in 0.403s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21407, val loss: 0.21431, in 0.576s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23266, val loss: 0.23286, in 0.402s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22959, val loss: 0.23000, in 0.385s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23377, val loss: 0.23534, in 0.388s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22932, val loss: 0.23055, in 0.395s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22917, val loss: 0.22940, in 0.392s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21451, val loss: 0.21489, in 0.577s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22588, val loss: 0.22629, in 0.377s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21473, val loss: 0.21449, in 0.576s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21436, val loss: 0.21465, in 0.585s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23035, val loss: 0.23191, in 0.393s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20677, val loss: 0.20707, in 0.585s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22573, val loss: 0.22691, in 0.392s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22541, val loss: 0.22564, in 0.388s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22276, val loss: 0.22311, in 0.407s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22642, val loss: 0.22801, in 0.419s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20723, val loss: 0.20766, in 0.603s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20714, val loss: 0.20741, in 0.615s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20742, val loss: 0.20718, in 0.617s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22251, val loss: 0.22374, in 0.423s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19990, val loss: 0.20021, in 0.621s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22238, val loss: 0.22261, in 0.433s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21972, val loss: 0.22008, in 0.404s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22336, val loss: 0.22498, in 0.354s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21953, val loss: 0.22078, in 0.278s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21943, val loss: 0.21967, in 0.260s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20042, val loss: 0.20086, in 0.437s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21637, val loss: 0.21676, in 0.222s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20051, val loss: 0.20022, in 0.509s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20028, val loss: 0.20054, in 0.517s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22036, val loss: 0.22202, in 0.349s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19339, val loss: 0.19373, in 0.478s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21617, val loss: 0.21745, in 0.364s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21607, val loss: 0.21636, in 0.355s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21364, val loss: 0.21402, in 0.369s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21692, val loss: 0.21858, in 0.244s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19395, val loss: 0.19442, in 0.450s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21337, val loss: 0.21464, in 0.205s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19381, val loss: 0.19409, in 0.352s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19399, val loss: 0.19374, in 0.369s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18719, val loss: 0.18753, in 0.342s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21332, val loss: 0.21354, in 0.232s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21107, val loss: 0.21146, in 0.219s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21420, val loss: 0.21584, in 0.213s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21035, val loss: 0.21166, in 0.234s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21029, val loss: 0.21055, in 0.228s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18772, val loss: 0.18817, in 0.349s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20811, val loss: 0.20851, in 0.234s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18772, val loss: 0.18807, in 0.335s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21171, val loss: 0.21334, in 0.230s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18774, val loss: 0.18749, in 0.344s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18119, val loss: 0.18154, in 0.347s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20787, val loss: 0.20919, in 0.226s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20783, val loss: 0.20806, in 0.236s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20568, val loss: 0.20609, in 0.222s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20877, val loss: 0.21042, in 0.221s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18194, val loss: 0.18237, in 0.335s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18183, val loss: 0.18215, in 0.353s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18193, val loss: 0.18169, in 0.337s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20543, val loss: 0.20677, in 0.245s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17568, val loss: 0.17605, in 0.359s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20542, val loss: 0.20565, in 0.249s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20621, val loss: 0.20783, in 0.245s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20331, val loss: 0.20379, in 0.262s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20271, val loss: 0.20406, in 0.224s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17624, val loss: 0.17662, in 0.372s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20269, val loss: 0.20293, in 0.224s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20118, val loss: 0.20175, in 0.201s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20388, val loss: 0.20552, in 0.207s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17626, val loss: 0.17658, in 0.345s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17625, val loss: 0.17598, in 0.351s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17029, val loss: 0.17062, in 0.324s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20061, val loss: 0.20202, in 0.199s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20056, val loss: 0.20089, in 0.194s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19920, val loss: 0.19981, in 0.191s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20154, val loss: 0.20316, in 0.239s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.17091, val loss: 0.17130, in 0.329s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17107, val loss: 0.17138, in 0.319s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17095, val loss: 0.17071, in 0.316s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19839, val loss: 0.19983, in 0.246s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16494, val loss: 0.16526, in 0.334s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19711, val loss: 0.19770, in 0.223s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19840, val loss: 0.19878, in 0.241s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19941, val loss: 0.20106, in 0.190s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19645, val loss: 0.19793, in 0.193s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19528, val loss: 0.19595, in 0.205s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19645, val loss: 0.19689, in 0.211s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16583, val loss: 0.16622, in 0.365s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19893, in 0.255s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16597, val loss: 0.16572, in 0.342s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16615, val loss: 0.16649, in 0.351s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16017, val loss: 0.16043, in 0.335s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19465, val loss: 0.19619, in 0.198s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19461, val loss: 0.19514, in 0.189s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19326, val loss: 0.19391, in 0.241s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19530, val loss: 0.19702, in 0.210s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19261, val loss: 0.19413, in 0.418s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16088, val loss: 0.16127, in 0.537s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16130, val loss: 0.16163, in 0.562s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16121, val loss: 0.16100, in 0.580s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19257, val loss: 0.19308, in 0.469s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19151, val loss: 0.19221, in 0.433s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15552, val loss: 0.15576, in 0.595s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19347, val loss: 0.19517, in 0.450s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19089, val loss: 0.19239, in 0.314s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19085, val loss: 0.19137, in 0.318s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18991, val loss: 0.19068, in 0.331s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19149, val loss: 0.19316, in 0.391s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15632, val loss: 0.15670, in 0.576s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15664, val loss: 0.15694, in 0.576s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15125, val loss: 0.15147, in 0.537s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15657, val loss: 0.15632, in 0.589s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18903, val loss: 0.19053, in 0.396s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18894, val loss: 0.18945, in 0.431s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18806, val loss: 0.18886, in 0.429s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18980, val loss: 0.19144, in 0.321s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18746, val loss: 0.18900, in 0.385s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15203, val loss: 0.15245, in 0.601s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18735, val loss: 0.18794, in 0.367s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18658, val loss: 0.18742, in 0.358s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15219, val loss: 0.15201, in 0.578s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15204, val loss: 0.15235, in 0.607s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14713, val loss: 0.14736, in 0.614s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18799, val loss: 0.18966, in 0.442s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18603, val loss: 0.18759, in 0.359s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18583, val loss: 0.18643, in 0.382s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18490, val loss: 0.18578, in 0.483s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18617, val loss: 0.18787, in 0.410s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14789, val loss: 0.14827, in 0.682s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18431, val loss: 0.18585, in 0.456s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14786, val loss: 0.14766, in 0.646s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14791, val loss: 0.14825, in 0.656s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14313, val loss: 0.14333, in 0.665s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18413, val loss: 0.18479, in 0.411s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18345, val loss: 0.18437, in 0.312s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18472, val loss: 0.18644, in 0.328s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18281, val loss: 0.18434, in 0.316s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18253, val loss: 0.18321, in 0.324s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18192, val loss: 0.18288, in 0.337s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14396, val loss: 0.14433, in 0.515s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18295, val loss: 0.18462, in 0.357s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14392, val loss: 0.14372, in 0.523s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14391, val loss: 0.14422, in 0.518s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13925, val loss: 0.13936, in 0.508s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18116, val loss: 0.18272, in 0.314s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18104, val loss: 0.18174, in 0.235s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18022, val loss: 0.18107, in 0.240s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18152, val loss: 0.18321, in 0.201s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17979, val loss: 0.18137, in 0.318s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14022, val loss: 0.14053, in 0.505s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14007, val loss: 0.13989, in 0.506s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17972, val loss: 0.18043, in 0.364s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14021, val loss: 0.14059, in 0.520s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13567, val loss: 0.13575, in 0.515s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17885, val loss: 0.17976, in 0.373s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17957, val loss: 0.18130, in 0.400s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17838, val loss: 0.17999, in 0.340s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17747, val loss: 0.17843, in 0.330s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17811, val loss: 0.17981, in 0.326s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17815, val loss: 0.17887, in 0.415s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13676, val loss: 0.13706, in 0.536s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13650, val loss: 0.13628, in 0.535s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13665, val loss: 0.13701, in 0.526s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13228, val loss: 0.13232, in 0.532s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17652, val loss: 0.17816, in 0.311s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17618, val loss: 0.17717, in 0.235s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17683, val loss: 0.17758, in 0.215s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17663, val loss: 0.17837, in 0.234s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17516, val loss: 0.17681, in 0.208s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17492, val loss: 0.17594, in 0.185s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17551, val loss: 0.17630, in 0.178s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17529, val loss: 0.17702, in 0.182s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13339, val loss: 0.13362, in 0.331s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13333, val loss: 0.13368, in 0.327s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13304, val loss: 0.13283, in 0.345s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12910, val loss: 0.12914, in 0.331s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17391, val loss: 0.17560, in 0.179s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17376, val loss: 0.17480, in 0.189s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17430, val loss: 0.17512, in 0.181s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17375, val loss: 0.17547, in 0.240s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17275, val loss: 0.17447, in 0.203s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17265, val loss: 0.17371, in 0.180s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13005, val loss: 0.13028, in 0.341s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17312, val loss: 0.17398, in 0.193s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13004, val loss: 0.13042, in 0.325s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12969, val loss: 0.12947, in 0.349s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12598, val loss: 0.12602, in 0.341s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17249, val loss: 0.17421, in 0.174s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17142, val loss: 0.17314, in 0.195s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17142, val loss: 0.17251, in 0.203s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17176, val loss: 0.17266, in 0.190s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17123, val loss: 0.17299, in 0.194s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12693, val loss: 0.12728, in 0.317s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12686, val loss: 0.12710, in 0.352s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17032, val loss: 0.17143, in 0.179s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12665, val loss: 0.12648, in 0.333s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12303, val loss: 0.12308, in 0.349s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16999, val loss: 0.17164, in 0.232s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17009, val loss: 0.17100, in 0.217s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16980, val loss: 0.17159, in 0.212s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16888, val loss: 0.16999, in 0.189s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16893, val loss: 0.17061, in 0.180s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16897, val loss: 0.16988, in 0.184s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16876, val loss: 0.17058, in 0.189s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12381, val loss: 0.12420, in 0.330s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12384, val loss: 0.12410, in 0.343s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12376, val loss: 0.12357, in 0.340s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11992, val loss: 0.11994, in 0.343s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16780, val loss: 0.16946, in 0.178s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16725, val loss: 0.16838, in 0.208s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16758, val loss: 0.16842, in 0.219s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16774, val loss: 0.16958, in 0.166s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16641, val loss: 0.16805, in 0.215s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16627, val loss: 0.16742, in 0.216s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16654, val loss: 0.16739, in 0.204s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16617, val loss: 0.16797, in 0.214s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12073, val loss: 0.12117, in 0.374s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12105, val loss: 0.12133, in 0.351s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12079, val loss: 0.12064, in 0.342s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11689, val loss: 0.11694, in 0.350s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16535, val loss: 0.16695, in 0.183s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16509, val loss: 0.16625, in 0.195s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16541, val loss: 0.16628, in 0.202s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16497, val loss: 0.16676, in 0.201s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16418, val loss: 0.16578, in 0.214s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11799, val loss: 0.11840, in 0.344s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11831, val loss: 0.11858, in 0.338s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11784, val loss: 0.11768, in 0.335s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16415, val loss: 0.16504, in 0.185s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16373, val loss: 0.16489, in 0.237s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11422, val loss: 0.11428, in 0.333s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16391, val loss: 0.16571, in 0.198s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16269, val loss: 0.16429, in 0.207s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16318, val loss: 0.16410, in 0.188s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16278, val loss: 0.16390, in 0.191s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16285, val loss: 0.16466, in 0.337s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11534, val loss: 0.11578, in 0.543s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11575, val loss: 0.11601, in 0.563s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11175, val loss: 0.11178, in 0.559s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11524, val loss: 0.11506, in 0.589s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16170, val loss: 0.16329, in 0.411s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16174, val loss: 0.16263, in 0.429s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16133, val loss: 0.16245, in 0.460s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.16324, in 0.384s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16075, val loss: 0.16236, in 0.302s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16065, val loss: 0.16154, in 0.348s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16011, val loss: 0.16127, in 0.319s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16044, val loss: 0.16221, in 0.297s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11329, val loss: 0.11358, in 0.560s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11278, val loss: 0.11317, in 0.597s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10918, val loss: 0.10924, in 0.552s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11269, val loss: 0.11252, in 0.570s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15950, val loss: 0.16110, in 0.307s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15973, val loss: 0.16064, in 0.302s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15884, val loss: 0.16000, in 0.305s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15951, val loss: 0.16130, in 0.291s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15860, val loss: 0.15955, in 0.351s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15847, val loss: 0.16007, in 0.415s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15791, val loss: 0.15910, in 0.357s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11011, val loss: 0.11053, in 0.579s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11088, val loss: 0.11121, in 0.618s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15835, val loss: 0.16011, in 0.387s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10678, val loss: 0.10684, in 0.635s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11033, val loss: 0.11019, in 0.623s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15772, val loss: 0.15867, in 0.314s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15681, val loss: 0.15802, in 0.315s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15755, val loss: 0.15911, in 0.332s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15696, val loss: 0.15867, in 0.321s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15664, val loss: 0.15759, in 0.351s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15597, val loss: 0.15720, in 0.337s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10751, val loss: 0.10800, in 0.605s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10854, val loss: 0.10888, in 0.587s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15621, val loss: 0.15778, in 0.363s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15595, val loss: 0.15764, in 0.316s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10436, val loss: 0.10446, in 0.600s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10784, val loss: 0.10772, in 0.632s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15535, val loss: 0.15627, in 0.297s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15512, val loss: 0.15637, in 0.315s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15513, val loss: 0.15672, in 0.306s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15507, val loss: 0.15677, in 0.322s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10617, val loss: 0.10655, in 0.535s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10534, val loss: 0.10580, in 0.550s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15440, val loss: 0.15536, in 0.285s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15395, val loss: 0.15521, in 0.271s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10209, val loss: 0.10216, in 0.518s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15427, val loss: 0.15583, in 0.261s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10548, val loss: 0.10541, in 0.492s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15409, val loss: 0.15580, in 0.241s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15347, val loss: 0.15443, in 0.243s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15301, val loss: 0.15426, in 0.243s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15314, val loss: 0.15468, in 0.242s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15335, val loss: 0.15506, in 0.214s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10386, val loss: 0.10420, in 0.526s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10308, val loss: 0.10360, in 0.534s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10005, val loss: 0.10015, in 0.532s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10319, val loss: 0.10314, in 0.526s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15247, val loss: 0.15344, in 0.323s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15227, val loss: 0.15352, in 0.321s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15243, val loss: 0.15398, in 0.314s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15205, val loss: 0.15382, in 0.378s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15164, val loss: 0.15262, in 0.169s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15129, val loss: 0.15257, in 0.188s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15120, val loss: 0.15277, in 0.199s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15098, val loss: 0.15278, in 0.173s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10139, val loss: 0.10173, in 0.341s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10081, val loss: 0.10135, in 0.344s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09768, val loss: 0.09781, in 0.339s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10106, val loss: 0.10101, in 0.339s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15090, val loss: 0.15190, in 0.180s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15014, val loss: 0.15170, in 0.192s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15003, val loss: 0.15130, in 0.212s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14973, val loss: 0.15149, in 0.205s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15008, val loss: 0.15105, in 0.233s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14918, val loss: 0.15073, in 0.210s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14908, val loss: 0.15040, in 0.213s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09931, val loss: 0.09965, in 0.399s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14872, val loss: 0.15046, in 0.220s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09900, val loss: 0.09896, in 0.363s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09874, val loss: 0.09928, in 0.407s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09573, val loss: 0.09587, in 0.398s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14891, val loss: 0.14986, in 0.187s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14845, val loss: 0.14998, in 0.194s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14813, val loss: 0.14944, in 0.202s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14782, val loss: 0.14957, in 0.189s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14823, val loss: 0.14919, in 0.178s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14747, val loss: 0.14901, in 0.187s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14744, val loss: 0.14876, in 0.194s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09720, val loss: 0.09757, in 0.357s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09671, val loss: 0.09725, in 0.348s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14685, val loss: 0.14860, in 0.188s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09691, val loss: 0.09687, in 0.369s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09374, val loss: 0.09391, in 0.346s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14743, val loss: 0.14839, in 0.190s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14639, val loss: 0.14770, in 0.178s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14670, val loss: 0.14826, in 0.204s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14612, val loss: 0.14783, in 0.181s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14671, val loss: 0.14767, in 0.180s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14602, val loss: 0.14758, in 0.174s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09539, val loss: 0.09576, in 0.352s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14550, val loss: 0.14683, in 0.199s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09486, val loss: 0.09540, in 0.336s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09185, val loss: 0.09201, in 0.341s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14534, val loss: 0.14704, in 0.182s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09513, val loss: 0.09507, in 0.366s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14563, val loss: 0.14658, in 0.194s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14513, val loss: 0.14671, in 0.185s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14620, in 0.177s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14447, val loss: 0.14621, in 0.179s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14495, val loss: 0.14590, in 0.178s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09339, val loss: 0.09376, in 0.327s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14417, val loss: 0.14573, in 0.167s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09313, val loss: 0.09364, in 0.339s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09015, val loss: 0.09028, in 0.331s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09311, val loss: 0.09306, in 0.315s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14400, val loss: 0.14532, in 0.181s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14368, val loss: 0.14543, in 0.165s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14425, val loss: 0.14518, in 0.181s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14466, in 0.185s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14336, val loss: 0.14468, in 0.174s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14265, val loss: 0.14438, in 0.211s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09164, val loss: 0.09200, in 0.307s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14340, val loss: 0.14435, in 0.163s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09121, val loss: 0.09175, in 0.314s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08828, val loss: 0.08845, in 0.308s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09128, val loss: 0.09126, in 0.313s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14239, val loss: 0.14371, in 0.160s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14236, val loss: 0.14392, in 0.184s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14185, val loss: 0.14357, in 0.170s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14373, in 0.314s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14160, val loss: 0.14319, in 0.338s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14164, val loss: 0.14297, in 0.387s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14118, val loss: 0.14289, in 0.363s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08988, val loss: 0.09026, in 0.549s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08973, val loss: 0.08971, in 0.568s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08967, val loss: 0.09021, in 0.594s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08674, val loss: 0.08691, in 0.604s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14195, val loss: 0.14286, in 0.347s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14069, val loss: 0.14228, in 0.289s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14100, val loss: 0.14230, in 0.310s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14006, val loss: 0.14175, in 0.293s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14133, val loss: 0.14221, in 0.276s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13993, val loss: 0.14148, in 0.304s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14023, val loss: 0.14159, in 0.269s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13941, val loss: 0.14112, in 0.260s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08817, val loss: 0.08857, in 0.515s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08809, val loss: 0.08806, in 0.501s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08795, val loss: 0.08855, in 0.492s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08509, val loss: 0.08526, in 0.503s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14069, val loss: 0.14158, in 0.295s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13924, val loss: 0.14079, in 0.274s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13944, val loss: 0.14081, in 0.276s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13874, val loss: 0.14045, in 0.271s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13959, val loss: 0.14047, in 0.299s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08655, val loss: 0.08699, in 0.489s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13862, val loss: 0.14013, in 0.280s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13793, val loss: 0.13964, in 0.256s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13888, val loss: 0.14023, in 0.274s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08640, val loss: 0.08698, in 0.512s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08665, val loss: 0.08659, in 0.519s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08370, val loss: 0.08387, in 0.503s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13860, val loss: 0.13946, in 0.254s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13805, val loss: 0.13955, in 0.264s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13824, val loss: 0.13961, in 0.255s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13719, val loss: 0.13887, in 0.300s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13750, val loss: 0.13900, in 0.252s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08509, val loss: 0.08551, in 0.520s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13780, val loss: 0.13868, in 0.280s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08516, val loss: 0.08511, in 0.482s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08499, val loss: 0.08553, in 0.501s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13734, val loss: 0.13877, in 0.289s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13658, val loss: 0.13825, in 0.253s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08224, val loss: 0.08244, in 0.494s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13673, val loss: 0.13824, in 0.275s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13709, val loss: 0.13800, in 0.279s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13592, val loss: 0.13759, in 0.259s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13659, val loss: 0.13798, in 0.265s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08368, val loss: 0.08411, in 0.450s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08359, val loss: 0.08363, in 0.431s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08337, val loss: 0.08393, in 0.437s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13604, val loss: 0.13755, in 0.216s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08084, val loss: 0.08107, in 0.441s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13654, val loss: 0.13743, in 0.215s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13600, val loss: 0.13737, in 0.193s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13520, val loss: 0.13687, in 0.199s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13544, val loss: 0.13693, in 0.274s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13547, val loss: 0.13685, in 0.277s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13435, val loss: 0.13604, in 0.288s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13553, val loss: 0.13642, in 0.299s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08199, val loss: 0.08242, in 0.433s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08213, val loss: 0.08220, in 0.446s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08200, val loss: 0.08254, in 0.431s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07917, val loss: 0.07942, in 0.432s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13481, val loss: 0.13634, in 0.183s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13482, val loss: 0.13620, in 0.168s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13369, val loss: 0.13539, in 0.161s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13585, in 0.162s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13415, val loss: 0.13566, in 0.165s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13411, val loss: 0.13552, in 0.162s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13444, val loss: 0.13536, in 0.156s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13289, val loss: 0.13455, in 0.170s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08042, val loss: 0.08083, in 0.286s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08077, val loss: 0.08085, in 0.283s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07781, val loss: 0.07805, in 0.273s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08028, val loss: 0.08081, in 0.304s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13507, in 0.152s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13354, val loss: 0.13443, in 0.151s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13231, val loss: 0.13393, in 0.156s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13340, val loss: 0.13481, in 0.179s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13289, val loss: 0.13379, in 0.159s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13157, val loss: 0.13320, in 0.147s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13302, val loss: 0.13452, in 0.179s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13280, val loss: 0.13422, in 0.157s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07901, val loss: 0.07943, in 0.318s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07646, val loss: 0.07670, in 0.302s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07916, val loss: 0.07926, in 0.320s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07875, val loss: 0.07926, in 0.301s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13103, val loss: 0.13264, in 0.148s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13211, val loss: 0.13349, in 0.137s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13219, val loss: 0.13311, in 0.183s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13210, val loss: 0.13362, in 0.195s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13031, val loss: 0.13195, in 0.146s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13157, val loss: 0.13297, in 0.155s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13153, val loss: 0.13247, in 0.151s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07766, val loss: 0.07809, in 0.287s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13162, val loss: 0.13314, in 0.148s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07503, val loss: 0.07527, in 0.298s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07768, val loss: 0.07777, in 0.290s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07721, val loss: 0.07774, in 0.292s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.13252, in 0.141s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.13117, in 0.166s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13078, val loss: 0.13177, in 0.147s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13082, val loss: 0.13234, in 0.154s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13025, val loss: 0.13166, in 0.162s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12892, val loss: 0.13054, in 0.159s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13032, val loss: 0.13129, in 0.147s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07641, val loss: 0.07681, in 0.287s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07373, val loss: 0.07400, in 0.288s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13001, val loss: 0.13156, in 0.156s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07631, val loss: 0.07637, in 0.295s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07584, val loss: 0.07637, in 0.285s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12961, val loss: 0.13100, in 0.140s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12843, val loss: 0.13005, in 0.142s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13048, in 0.160s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13100, in 0.161s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12777, val loss: 0.12940, in 0.139s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12903, val loss: 0.13043, in 0.158s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07503, val loss: 0.07544, in 0.297s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12903, val loss: 0.12999, in 0.155s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07241, val loss: 0.07267, in 0.287s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07443, val loss: 0.07494, in 0.291s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07481, val loss: 0.07487, in 0.295s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12902, val loss: 0.13050, in 0.149s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12719, val loss: 0.12881, in 0.136s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12991, in 0.153s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12831, val loss: 0.12929, in 0.153s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12839, val loss: 0.12988, in 0.177s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12660, val loss: 0.12822, in 0.146s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07374, val loss: 0.07415, in 0.285s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12798, val loss: 0.12936, in 0.160s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07090, val loss: 0.07115, in 0.296s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12772, val loss: 0.12871, in 0.159s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07350, val loss: 0.07358, in 0.291s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07316, val loss: 0.07365, in 0.295s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12771, val loss: 0.12919, in 0.155s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12609, val loss: 0.12774, in 0.149s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12752, val loss: 0.12888, in 0.154s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12730, val loss: 0.12829, in 0.147s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12531, val loss: 0.12692, in 0.147s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12694, val loss: 0.12846, in 0.179s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07257, val loss: 0.07295, in 0.303s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12661, val loss: 0.12757, in 0.143s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06979, val loss: 0.07003, in 0.302s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12690, val loss: 0.12826, in 0.168s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07236, val loss: 0.07247, in 0.300s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07194, val loss: 0.07242, in 0.394s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12474, val loss: 0.12635, in 0.345s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12621, val loss: 0.12773, in 0.354s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12612, val loss: 0.12748, in 0.392s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12692, in 0.432s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12572, val loss: 0.12726, in 0.234s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12405, val loss: 0.12565, in 0.271s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07134, val loss: 0.07172, in 0.594s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06849, val loss: 0.06875, in 0.602s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07089, val loss: 0.07106, in 0.615s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07057, val loss: 0.07107, in 0.529s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12552, val loss: 0.12686, in 0.247s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12515, val loss: 0.12608, in 0.253s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12350, val loss: 0.12510, in 0.229s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12516, val loss: 0.12671, in 0.272s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12488, val loss: 0.12624, in 0.239s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12449, val loss: 0.12546, in 0.250s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12287, val loss: 0.12449, in 0.257s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07003, val loss: 0.07042, in 0.471s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12470, val loss: 0.12623, in 0.253s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06730, val loss: 0.06754, in 0.495s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06968, val loss: 0.06984, in 0.477s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12573, in 0.258s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06943, val loss: 0.06992, in 0.529s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12388, val loss: 0.12486, in 0.261s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12407, val loss: 0.12560, in 0.266s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12223, val loss: 0.12384, in 0.318s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12385, val loss: 0.12522, in 0.268s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12313, val loss: 0.12413, in 0.265s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06893, val loss: 0.06934, in 0.532s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12335, val loss: 0.12485, in 0.259s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12168, val loss: 0.12330, in 0.245s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06619, val loss: 0.06644, in 0.514s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06835, val loss: 0.06857, in 0.522s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12327, val loss: 0.12465, in 0.233s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06805, val loss: 0.06860, in 0.501s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12279, val loss: 0.12378, in 0.228s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12298, val loss: 0.12448, in 0.222s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12119, val loss: 0.12277, in 0.254s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12258, val loss: 0.12400, in 0.240s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12214, val loss: 0.12311, in 0.255s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06761, val loss: 0.06802, in 0.500s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12069, val loss: 0.12228, in 0.264s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12235, val loss: 0.12387, in 0.319s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06494, val loss: 0.06518, in 0.507s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06726, val loss: 0.06748, in 0.507s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12218, val loss: 0.12357, in 0.269s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06696, val loss: 0.06753, in 0.506s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12155, val loss: 0.12255, in 0.265s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11999, val loss: 0.12154, in 0.188s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12162, val loss: 0.12302, in 0.174s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12175, val loss: 0.12329, in 0.213s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12098, val loss: 0.12202, in 0.157s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06652, val loss: 0.06692, in 0.366s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11950, val loss: 0.12106, in 0.154s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06393, val loss: 0.06415, in 0.342s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06609, val loss: 0.06633, in 0.337s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12125, val loss: 0.12264, in 0.143s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12117, val loss: 0.12270, in 0.163s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06581, val loss: 0.06642, in 0.334s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12041, val loss: 0.12144, in 0.263s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11901, val loss: 0.12057, in 0.248s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12072, val loss: 0.12208, in 0.248s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12079, val loss: 0.12231, in 0.242s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11990, val loss: 0.12094, in 0.149s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06533, val loss: 0.06573, in 0.378s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06292, val loss: 0.06317, in 0.386s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06469, val loss: 0.06494, in 0.383s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11810, val loss: 0.11964, in 0.153s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12023, val loss: 0.12160, in 0.149s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06496, val loss: 0.06559, in 0.379s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12013, val loss: 0.12162, in 0.149s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11950, val loss: 0.12055, in 0.153s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11909, in 0.147s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11969, val loss: 0.12106, in 0.164s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11948, val loss: 0.12096, in 0.156s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11899, val loss: 0.12005, in 0.145s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06446, val loss: 0.06486, in 0.301s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06190, val loss: 0.06217, in 0.275s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06371, val loss: 0.06396, in 0.296s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11711, val loss: 0.11861, in 0.159s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06387, val loss: 0.06448, in 0.292s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11913, val loss: 0.12053, in 0.152s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11892, val loss: 0.12039, in 0.141s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11841, val loss: 0.11943, in 0.131s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11859, val loss: 0.12010, in 0.135s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11654, val loss: 0.11804, in 0.177s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11795, val loss: 0.11897, in 0.161s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11853, val loss: 0.11995, in 0.190s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06335, val loss: 0.06377, in 0.280s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06107, val loss: 0.06134, in 0.289s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06283, val loss: 0.06307, in 0.289s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06274, val loss: 0.06338, in 0.278s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11807, val loss: 0.11959, in 0.156s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11610, val loss: 0.11759, in 0.143s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11803, val loss: 0.11943, in 0.140s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11744, val loss: 0.11846, in 0.161s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11919, in 0.156s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11545, val loss: 0.11691, in 0.147s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11774, val loss: 0.11914, in 0.140s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11694, val loss: 0.11798, in 0.155s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06008, val loss: 0.06035, in 0.289s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06247, val loss: 0.06290, in 0.308s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06183, val loss: 0.06205, in 0.302s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06174, val loss: 0.06239, in 0.289s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11718, val loss: 0.11868, in 0.129s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11497, val loss: 0.11644, in 0.143s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11724, val loss: 0.11867, in 0.137s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11657, val loss: 0.11760, in 0.149s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11655, val loss: 0.11804, in 0.155s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11450, val loss: 0.11599, in 0.147s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11667, val loss: 0.11810, in 0.158s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11626, val loss: 0.11732, in 0.142s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06144, val loss: 0.06188, in 0.288s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05852, val loss: 0.05884, in 0.303s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06095, val loss: 0.06120, in 0.294s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06074, val loss: 0.06140, in 0.305s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11587, val loss: 0.11740, in 0.173s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11410, val loss: 0.11560, in 0.168s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11636, val loss: 0.11779, in 0.148s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11574, val loss: 0.11682, in 0.149s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11527, val loss: 0.11677, in 0.148s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11369, val loss: 0.11518, in 0.149s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11581, val loss: 0.11725, in 0.164s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11532, val loss: 0.11639, in 0.155s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05987, val loss: 0.06033, in 0.299s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05761, val loss: 0.05792, in 0.305s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06003, val loss: 0.06032, in 0.294s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05921, val loss: 0.05987, in 0.307s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11484, in 0.136s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11487, val loss: 0.11637, in 0.147s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11539, val loss: 0.11683, in 0.149s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11487, val loss: 0.11594, in 0.167s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11277, val loss: 0.11422, in 0.159s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11492, val loss: 0.11637, in 0.133s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11431, val loss: 0.11580, in 0.157s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05860, val loss: 0.05909, in 0.301s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05677, val loss: 0.05711, in 0.294s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05880, val loss: 0.05909, in 0.282s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05796, val loss: 0.05862, in 0.285s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11232, val loss: 0.11377, in 0.133s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11444, val loss: 0.11550, in 0.344s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11461, val loss: 0.11609, in 0.323s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11386, val loss: 0.11533, in 0.364s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11181, val loss: 0.11324, in 0.382s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11397, val loss: 0.11500, in 0.267s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11416, val loss: 0.11561, in 0.235s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05770, val loss: 0.05820, in 0.596s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11489, in 0.284s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05537, val loss: 0.05577, in 0.585s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05799, val loss: 0.05831, in 0.591s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05678, val loss: 0.05745, in 0.617s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11445, in 0.223s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11136, val loss: 0.11280, in 0.281s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11369, val loss: 0.11514, in 0.280s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11307, val loss: 0.11452, in 0.235s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11302, val loss: 0.11405, in 0.263s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11089, val loss: 0.11234, in 0.274s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11342, val loss: 0.11487, in 0.231s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05692, val loss: 0.05727, in 0.458s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11276, val loss: 0.11421, in 0.231s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05691, val loss: 0.05740, in 0.479s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05456, val loss: 0.05500, in 0.498s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05594, val loss: 0.05662, in 0.482s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11263, val loss: 0.11366, in 0.289s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11303, val loss: 0.11445, in 0.246s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11044, val loss: 0.11189, in 0.294s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11235, val loss: 0.11381, in 0.272s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11229, val loss: 0.11333, in 0.253s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11253, val loss: 0.11397, in 0.260s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05593, val loss: 0.05630, in 0.467s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11014, val loss: 0.11161, in 0.238s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11190, val loss: 0.11335, in 0.237s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05548, val loss: 0.05598, in 0.505s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05423, in 0.508s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05486, val loss: 0.05557, in 0.492s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11184, val loss: 0.11289, in 0.248s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11211, val loss: 0.11356, in 0.256s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10959, val loss: 0.11104, in 0.259s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11135, val loss: 0.11278, in 0.260s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05511, val loss: 0.05548, in 0.491s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11129, val loss: 0.11233, in 0.287s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10918, val loss: 0.11061, in 0.231s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11174, val loss: 0.11319, in 0.288s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05479, val loss: 0.05523, in 0.497s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05265, val loss: 0.05315, in 0.481s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11089, val loss: 0.11233, in 0.261s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05422, val loss: 0.05493, in 0.488s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11146, val loss: 0.11294, in 0.241s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11086, val loss: 0.11189, in 0.297s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.11007, in 0.302s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11049, val loss: 0.11192, in 0.270s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05436, val loss: 0.05475, in 0.395s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11105, val loss: 0.11250, in 0.132s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11045, val loss: 0.11148, in 0.138s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05347, val loss: 0.05393, in 0.387s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05249, in 0.392s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05297, val loss: 0.05368, in 0.365s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10812, val loss: 0.10957, in 0.183s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10990, val loss: 0.11131, in 0.169s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11006, val loss: 0.11114, in 0.158s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11071, val loss: 0.11217, in 0.252s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10769, val loss: 0.10915, in 0.257s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10963, val loss: 0.11106, in 0.253s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05333, val loss: 0.05372, in 0.371s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05243, val loss: 0.05291, in 0.381s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11036, val loss: 0.11182, in 0.163s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05204, val loss: 0.05275, in 0.372s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05126, val loss: 0.05180, in 0.393s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10920, val loss: 0.11025, in 0.275s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10734, val loss: 0.10879, in 0.172s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10921, val loss: 0.11066, in 0.185s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10997, val loss: 0.11146, in 0.216s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10893, val loss: 0.10999, in 0.205s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05242, val loss: 0.05285, in 0.357s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.11033, in 0.173s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10839, in 0.202s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05145, val loss: 0.05193, in 0.338s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05100, val loss: 0.05171, in 0.354s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05005, val loss: 0.05060, in 0.356s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10924, val loss: 0.11074, in 0.169s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10949, in 0.149s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10856, val loss: 0.10999, in 0.155s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10646, val loss: 0.10786, in 0.162s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10814, val loss: 0.10917, in 0.155s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.11038, in 0.166s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05178, val loss: 0.05223, in 0.286s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10805, val loss: 0.10946, in 0.152s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10586, val loss: 0.10727, in 0.161s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05024, val loss: 0.05071, in 0.297s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05014, val loss: 0.05085, in 0.281s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04938, val loss: 0.04994, in 0.302s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.11018, in 0.149s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10776, val loss: 0.10879, in 0.197s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10764, val loss: 0.10905, in 0.168s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10698, in 0.167s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10800, val loss: 0.10949, in 0.201s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05083, val loss: 0.05128, in 0.334s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10746, val loss: 0.10849, in 0.187s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10728, val loss: 0.10871, in 0.191s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04913, val loss: 0.04960, in 0.344s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10486, val loss: 0.10625, in 0.195s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.05026, in 0.335s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04826, val loss: 0.04884, in 0.344s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10767, val loss: 0.10916, in 0.191s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10810, in 0.188s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10460, val loss: 0.10602, in 0.152s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10691, val loss: 0.10832, in 0.202s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.04998, in 0.310s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10880, in 0.169s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10685, val loss: 0.10787, in 0.158s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04845, val loss: 0.04892, in 0.312s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04894, val loss: 0.04968, in 0.318s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10412, val loss: 0.10552, in 0.175s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10658, val loss: 0.10798, in 0.157s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04737, val loss: 0.04798, in 0.311s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10700, val loss: 0.10852, in 0.164s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10624, val loss: 0.10731, in 0.178s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10363, val loss: 0.10504, in 0.170s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10610, val loss: 0.10746, in 0.169s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04835, val loss: 0.04876, in 0.306s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04750, val loss: 0.04797, in 0.310s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04784, val loss: 0.04858, in 0.306s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10655, val loss: 0.10807, in 0.188s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04634, val loss: 0.04695, in 0.308s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10322, val loss: 0.10463, in 0.169s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10546, val loss: 0.10651, in 0.196s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10553, val loss: 0.10692, in 0.180s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10593, val loss: 0.10744, in 0.162s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10504, val loss: 0.10606, in 0.157s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10286, val loss: 0.10428, in 0.172s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04751, val loss: 0.04792, in 0.299s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10492, val loss: 0.10632, in 0.200s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04652, val loss: 0.04698, in 0.295s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04707, val loss: 0.04781, in 0.288s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10558, val loss: 0.10712, in 0.154s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04572, val loss: 0.04636, in 0.295s\n",
      "[97/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10262, val loss: 0.10403, in 0.141s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10482, val loss: 0.10585, in 0.151s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10470, val loss: 0.10611, in 0.131s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10521, val loss: 0.10674, in 0.146s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04642, val loss: 0.04681, in 0.278s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10417, val loss: 0.10518, in 0.140s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10232, val loss: 0.10375, in 0.163s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10576, in 0.150s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04610, val loss: 0.04685, in 0.271s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04572, val loss: 0.04618, in 0.286s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04475, val loss: 0.04538, in 0.265s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10456, val loss: 0.10609, in 0.164s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10385, val loss: 0.10485, in 0.158s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10194, val loss: 0.10339, in 0.308s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10400, val loss: 0.10542, in 0.358s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10423, val loss: 0.10577, in 0.371s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10348, val loss: 0.10452, in 0.357s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04540, val loss: 0.04577, in 0.518s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10155, val loss: 0.10302, in 0.239s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04544, val loss: 0.04621, in 0.515s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04515, val loss: 0.04563, in 0.537s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04394, val loss: 0.04460, in 0.564s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10346, val loss: 0.10487, in 0.260s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10400, val loss: 0.10555, in 0.251s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10313, val loss: 0.10420, in 0.294s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10122, val loss: 0.10266, in 0.270s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10448, in 0.257s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10380, val loss: 0.10534, in 0.235s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04483, val loss: 0.04522, in 0.513s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04484, val loss: 0.04560, in 0.463s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04427, val loss: 0.04473, in 0.465s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10053, val loss: 0.10195, in 0.251s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10249, val loss: 0.10357, in 0.291s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04306, val loss: 0.04371, in 0.456s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10274, val loss: 0.10414, in 0.220s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10359, val loss: 0.10515, in 0.220s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10021, val loss: 0.10165, in 0.260s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10214, val loss: 0.10319, in 0.300s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10236, val loss: 0.10377, in 0.263s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04388, val loss: 0.04425, in 0.451s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10465, in 0.274s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04356, val loss: 0.04403, in 0.463s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04406, val loss: 0.04485, in 0.516s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09979, val loss: 0.10120, in 0.257s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04250, val loss: 0.04314, in 0.520s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10175, val loss: 0.10277, in 0.259s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10203, val loss: 0.10342, in 0.323s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10271, val loss: 0.10427, in 0.268s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09946, val loss: 0.10086, in 0.283s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04316, val loss: 0.04354, in 0.475s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10120, val loss: 0.10224, in 0.311s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10320, in 0.261s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10231, val loss: 0.10387, in 0.282s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04282, val loss: 0.04329, in 0.511s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04315, val loss: 0.04393, in 0.515s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04166, val loss: 0.04230, in 0.502s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09882, val loss: 0.10019, in 0.259s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10096, val loss: 0.10201, in 0.247s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10134, val loss: 0.10273, in 0.261s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10189, val loss: 0.10346, in 0.261s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09853, val loss: 0.09989, in 0.255s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04267, in 0.496s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10100, val loss: 0.10239, in 0.206s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10063, val loss: 0.10166, in 0.238s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04252, val loss: 0.04331, in 0.418s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04278, in 0.450s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10155, val loss: 0.10312, in 0.230s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04094, val loss: 0.04161, in 0.403s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09816, val loss: 0.09953, in 0.200s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10064, val loss: 0.10201, in 0.158s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10025, val loss: 0.10130, in 0.193s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10047, val loss: 0.10205, in 0.310s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10045, val loss: 0.10183, in 0.254s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04169, val loss: 0.04250, in 0.390s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04160, val loss: 0.04196, in 0.434s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09757, val loss: 0.09893, in 0.300s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04151, val loss: 0.04201, in 0.408s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09994, val loss: 0.10100, in 0.256s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04018, val loss: 0.04083, in 0.404s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10014, val loss: 0.10169, in 0.153s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09974, val loss: 0.10110, in 0.179s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09722, val loss: 0.09859, in 0.167s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.10071, in 0.187s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09997, val loss: 0.10152, in 0.159s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04104, val loss: 0.04153, in 0.291s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04118, val loss: 0.04198, in 0.337s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04103, val loss: 0.04135, in 0.331s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09938, val loss: 0.10075, in 0.176s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09686, val loss: 0.09824, in 0.157s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03970, val loss: 0.04038, in 0.296s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09931, val loss: 0.10037, in 0.184s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.10118, in 0.174s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09659, val loss: 0.09797, in 0.149s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09889, val loss: 0.10027, in 0.168s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04032, val loss: 0.04077, in 0.290s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09877, val loss: 0.09985, in 0.213s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04048, val loss: 0.04128, in 0.288s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04049, val loss: 0.04083, in 0.293s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09923, val loss: 0.10080, in 0.201s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03920, val loss: 0.03988, in 0.312s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09574, val loss: 0.09711, in 0.204s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09837, val loss: 0.09977, in 0.213s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09820, val loss: 0.09928, in 0.179s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09863, val loss: 0.10020, in 0.190s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09528, val loss: 0.09667, in 0.176s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09775, val loss: 0.09916, in 0.175s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03989, val loss: 0.04034, in 0.301s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03970, val loss: 0.04003, in 0.297s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09794, val loss: 0.09902, in 0.146s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03996, val loss: 0.04077, in 0.340s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03845, val loss: 0.03913, in 0.302s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09833, val loss: 0.09991, in 0.148s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09507, val loss: 0.09648, in 0.143s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09745, val loss: 0.09888, in 0.176s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09695, val loss: 0.09804, in 0.208s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09804, val loss: 0.09961, in 0.165s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09440, val loss: 0.09580, in 0.181s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.03963, in 0.300s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03911, val loss: 0.03942, in 0.304s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09720, val loss: 0.09862, in 0.174s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03919, val loss: 0.03999, in 0.297s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03790, val loss: 0.03858, in 0.319s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09631, val loss: 0.09741, in 0.153s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09743, val loss: 0.09900, in 0.178s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09405, val loss: 0.09545, in 0.162s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09701, val loss: 0.09844, in 0.153s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09575, val loss: 0.09685, in 0.200s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09712, val loss: 0.09871, in 0.171s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03864, val loss: 0.03946, in 0.278s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03863, val loss: 0.03897, in 0.307s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03893, in 0.333s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09670, val loss: 0.09815, in 0.158s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09341, val loss: 0.09480, in 0.204s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03706, val loss: 0.03777, in 0.304s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09676, val loss: 0.09836, in 0.165s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09659, in 0.172s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09640, val loss: 0.09785, in 0.142s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09323, val loss: 0.09463, in 0.157s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09627, in 0.155s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09649, val loss: 0.09811, in 0.162s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03792, val loss: 0.03825, in 0.292s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03801, val loss: 0.03846, in 0.310s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09768, in 0.152s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03797, val loss: 0.03877, in 0.326s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09295, val loss: 0.09434, in 0.151s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03666, val loss: 0.03736, in 0.302s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09485, val loss: 0.09597, in 0.154s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09783, in 0.162s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09258, val loss: 0.09393, in 0.156s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09577, val loss: 0.09723, in 0.212s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03738, val loss: 0.03771, in 0.284s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03753, val loss: 0.03797, in 0.480s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09570, in 0.359s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03742, val loss: 0.03822, in 0.493s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03614, val loss: 0.03683, in 0.466s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09587, val loss: 0.09745, in 0.383s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09227, val loss: 0.09364, in 0.344s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09521, val loss: 0.09668, in 0.369s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09545, in 0.309s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09536, val loss: 0.09695, in 0.343s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09498, val loss: 0.09644, in 0.312s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09178, val loss: 0.09314, in 0.374s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03676, val loss: 0.03707, in 0.685s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03679, val loss: 0.03724, in 0.537s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03678, val loss: 0.03758, in 0.541s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09416, val loss: 0.09528, in 0.256s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03611, in 0.537s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09451, val loss: 0.09596, in 0.274s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09483, val loss: 0.09641, in 0.319s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09155, val loss: 0.09292, in 0.298s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09381, val loss: 0.09492, in 0.280s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03620, val loss: 0.03651, in 0.498s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09138, val loss: 0.09277, in 0.256s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09415, val loss: 0.09560, in 0.290s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09455, val loss: 0.09614, in 0.292s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03678, in 0.537s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03483, val loss: 0.03553, in 0.529s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03623, val loss: 0.03703, in 0.539s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09356, val loss: 0.09467, in 0.295s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09115, val loss: 0.09254, in 0.263s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09393, val loss: 0.09538, in 0.267s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09434, val loss: 0.09593, in 0.253s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09339, val loss: 0.09449, in 0.262s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03555, val loss: 0.03587, in 0.500s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09388, val loss: 0.09547, in 0.311s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09091, val loss: 0.09234, in 0.326s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09306, val loss: 0.09453, in 0.352s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03566, val loss: 0.03608, in 0.547s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03562, val loss: 0.03640, in 0.520s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03440, val loss: 0.03510, in 0.548s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09298, val loss: 0.09407, in 0.292s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09350, val loss: 0.09510, in 0.290s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09065, val loss: 0.09208, in 0.316s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09268, val loss: 0.09413, in 0.289s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09262, val loss: 0.09371, in 0.317s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03494, val loss: 0.03524, in 0.587s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09316, val loss: 0.09476, in 0.322s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09240, val loss: 0.09385, in 0.291s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09004, val loss: 0.09146, in 0.336s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03384, val loss: 0.03454, in 0.575s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03493, val loss: 0.03572, in 0.604s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03500, val loss: 0.03542, in 0.614s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09336, in 0.276s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09218, val loss: 0.09364, in 0.210s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09284, val loss: 0.09444, in 0.235s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08974, val loss: 0.09117, in 0.229s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09310, in 0.201s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03476, in 0.446s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03326, val loss: 0.03395, in 0.357s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09254, val loss: 0.09412, in 0.182s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03447, val loss: 0.03526, in 0.356s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08955, val loss: 0.09099, in 0.284s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09191, val loss: 0.09335, in 0.348s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03435, val loss: 0.03477, in 0.549s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09180, val loss: 0.09291, in 0.320s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08934, val loss: 0.09080, in 0.219s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.09297, in 0.222s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03394, val loss: 0.03425, in 0.460s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09160, val loss: 0.09318, in 0.387s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09275, in 0.173s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03408, val loss: 0.03485, in 0.468s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03273, val loss: 0.03345, in 0.477s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08912, val loss: 0.09059, in 0.144s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03391, val loss: 0.03433, in 0.331s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09113, val loss: 0.09220, in 0.168s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09073, val loss: 0.09219, in 0.204s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03325, val loss: 0.03356, in 0.324s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09055, val loss: 0.09163, in 0.185s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09022, val loss: 0.09171, in 0.214s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03215, val loss: 0.03285, in 0.317s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03346, val loss: 0.03423, in 0.326s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03338, val loss: 0.03379, in 0.310s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03267, val loss: 0.03298, in 0.317s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03159, val loss: 0.03230, in 0.321s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03299, val loss: 0.03374, in 0.327s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03279, val loss: 0.03318, in 0.340s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03260, in 0.334s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03259, val loss: 0.03334, in 0.299s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03115, val loss: 0.03186, in 0.338s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03222, val loss: 0.03260, in 0.328s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03166, val loss: 0.03198, in 0.345s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03199, val loss: 0.03275, in 0.351s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03062, val loss: 0.03132, in 0.342s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03174, val loss: 0.03211, in 0.325s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03168, in 0.300s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03169, val loss: 0.03244, in 0.283s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03078, in 0.332s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03122, val loss: 0.03157, in 0.326s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03086, val loss: 0.03118, in 0.312s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03125, val loss: 0.03199, in 0.347s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.03028, in 0.344s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03078, val loss: 0.03113, in 0.331s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03086, in 0.540s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03072, val loss: 0.03147, in 0.627s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03036, val loss: 0.03071, in 0.640s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02976, in 0.669s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03039, in 0.545s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03040, val loss: 0.03115, in 0.552s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02868, val loss: 0.02939, in 0.553s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03004, val loss: 0.03039, in 0.590s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02961, val loss: 0.02993, in 0.503s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02988, val loss: 0.03064, in 0.626s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02832, val loss: 0.02901, in 0.557s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02959, val loss: 0.02993, in 0.601s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02928, val loss: 0.02960, in 0.619s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03019, in 0.566s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02803, val loss: 0.02872, in 0.627s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02911, val loss: 0.02946, in 0.602s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02901, val loss: 0.02933, in 0.567s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02898, val loss: 0.02971, in 0.578s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02884, val loss: 0.02920, in 0.504s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02769, val loss: 0.02836, in 0.553s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02846, val loss: 0.02876, in 0.468s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09136, val loss: 0.09294, in 0.153s\n",
      "Fit 200 trees in 52.773 s, (1595 total leaves)\n",
      "Time spent computing histograms: 30.636s\n",
      "Time spent finding best splits:  0.197s\n",
      "Time spent applying splits:      4.487s\n",
      "Time spent predicting:           0.382s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02865, val loss: 0.02937, in 0.485s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02739, val loss: 0.02806, in 0.498s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02840, val loss: 0.02875, in 0.519s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08884, val loss: 0.09032, in 0.178s\n",
      "Fit 200 trees in 52.531 s, (1595 total leaves)\n",
      "Time spent computing histograms: 30.673s\n",
      "Time spent finding best splits:  0.180s\n",
      "Time spent applying splits:      4.455s\n",
      "Time spent predicting:           0.445s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02809, val loss: 0.02840, in 0.515s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02827, val loss: 0.02898, in 0.380s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08959, val loss: 0.09108, in 0.167s\n",
      "Fit 200 trees in 53.004 s, (1593 total leaves)\n",
      "Time spent computing histograms: 31.297s\n",
      "Time spent finding best splits:  0.152s\n",
      "Time spent applying splits:      4.393s\n",
      "Time spent predicting:           0.401s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02689, val loss: 0.02758, in 0.386s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02797, val loss: 0.02833, in 0.373s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08962, val loss: 0.09071, in 0.212s\n",
      "Fit 200 trees in 53.018 s, (1593 total leaves)\n",
      "Time spent computing histograms: 30.789s\n",
      "Time spent finding best splits:  0.199s\n",
      "Time spent applying splits:      4.357s\n",
      "Time spent predicting:           0.392s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02758, val loss: 0.02788, in 0.378s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02793, val loss: 0.02863, in 0.375s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02643, val loss: 0.02713, in 0.395s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02765, val loss: 0.02802, in 0.413s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02758, in 0.345s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02760, val loss: 0.02829, in 0.410s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02615, val loss: 0.02683, in 0.385s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02723, val loss: 0.02760, in 0.380s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02695, val loss: 0.02724, in 0.357s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02731, val loss: 0.02801, in 0.376s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02576, val loss: 0.02646, in 0.350s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02683, val loss: 0.02719, in 0.370s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02665, val loss: 0.02695, in 0.397s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02698, val loss: 0.02766, in 0.356s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02553, val loss: 0.02624, in 0.342s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02646, val loss: 0.02682, in 0.319s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02616, val loss: 0.02645, in 0.354s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02652, val loss: 0.02720, in 0.341s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02515, val loss: 0.02587, in 0.364s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02621, val loss: 0.02657, in 0.357s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02586, val loss: 0.02614, in 0.343s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02627, val loss: 0.02695, in 0.618s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02552, in 0.605s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02619, in 0.644s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02555, val loss: 0.02580, in 0.663s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02589, val loss: 0.02655, in 0.515s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02461, val loss: 0.02533, in 0.505s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02588, in 0.511s\n",
      "[136/200] 3.554 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02510, val loss: 0.02534, in 0.552s\n",
      "[137/200] 3.628 s\n",
      "Binning 0.013 GB of validation data: 0.236 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02553, val loss: 0.02618, in 0.561s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02428, val loss: 0.02500, in 0.522s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02550, in 0.520s\n",
      "[137/200] 0.231 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02482, val loss: 0.02506, in 0.538s\n",
      "[138/200] 3.704 s\n",
      "Binning 0.013 GB of validation data: 3.742 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65049, in 0.486s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02409, val loss: 0.02482, in 0.513s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02524, val loss: 0.02590, in 0.551s\n",
      "[138/200] 0.234 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.241 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02479, val loss: 0.02515, in 0.585s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65045, val loss: 0.65048, in 0.502s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02444, val loss: 0.02466, in 0.535s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61188, val loss: 0.61180, in 0.530s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02467, in 0.474s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65053, val loss: 0.65053, in 0.464s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65055, val loss: 0.65058, in 0.444s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02500, val loss: 0.02567, in 0.526s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02478, in 0.473s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61178, val loss: 0.61185, in 0.467s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02409, val loss: 0.02431, in 0.443s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57682, val loss: 0.57671, in 0.341s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02362, val loss: 0.02437, in 0.418s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61200, val loss: 0.61206, in 0.446s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61200, val loss: 0.61202, in 0.439s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02468, val loss: 0.02536, in 0.450s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57672, val loss: 0.57685, in 0.414s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02404, val loss: 0.02440, in 0.455s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02369, val loss: 0.02389, in 0.452s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54474, val loss: 0.54459, in 0.402s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02318, val loss: 0.02394, in 0.321s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57687, val loss: 0.57696, in 0.289s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57694, val loss: 0.57696, in 0.281s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02446, val loss: 0.02514, in 0.288s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54424, val loss: 0.54442, in 0.289s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02383, val loss: 0.02419, in 0.296s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51515, val loss: 0.51498, in 0.281s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02358, in 0.301s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54454, val loss: 0.54464, in 0.284s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02371, in 0.319s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54467, val loss: 0.54468, in 0.285s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51462, val loss: 0.51484, in 0.283s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02421, val loss: 0.02487, in 0.317s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02354, val loss: 0.02391, in 0.291s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02335, in 0.273s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48814, val loss: 0.48794, in 0.280s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51489, val loss: 0.51498, in 0.290s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51505, val loss: 0.51504, in 0.298s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02260, val loss: 0.02337, in 0.324s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48744, val loss: 0.48769, in 0.285s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02388, val loss: 0.02455, in 0.296s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02364, in 0.270s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46311, val loss: 0.46290, in 0.282s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02290, val loss: 0.02311, in 0.351s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48770, val loss: 0.48784, in 0.299s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48785, val loss: 0.48786, in 0.287s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46254, val loss: 0.46285, in 0.284s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02229, val loss: 0.02305, in 0.314s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02299, val loss: 0.02337, in 0.295s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02365, val loss: 0.02432, in 0.309s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44002, val loss: 0.43979, in 0.278s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02257, val loss: 0.02278, in 0.294s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46263, val loss: 0.46279, in 0.296s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46282, val loss: 0.46282, in 0.306s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43943, val loss: 0.43978, in 0.296s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02195, val loss: 0.02270, in 0.296s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02272, val loss: 0.02311, in 0.288s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02338, val loss: 0.02404, in 0.318s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41848, val loss: 0.41822, in 0.290s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02236, val loss: 0.02256, in 0.273s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43967, val loss: 0.43978, in 0.280s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43955, val loss: 0.43955, in 0.280s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41787, val loss: 0.41827, in 0.285s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02174, val loss: 0.02250, in 0.313s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02248, val loss: 0.02287, in 0.297s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39879, val loss: 0.39852, in 0.291s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02303, val loss: 0.02370, in 0.325s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02213, val loss: 0.02235, in 0.324s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41819, val loss: 0.41833, in 0.285s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41807, val loss: 0.41809, in 0.291s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39766, val loss: 0.39809, in 0.295s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02143, val loss: 0.02219, in 0.295s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02217, val loss: 0.02257, in 0.304s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37996, val loss: 0.37967, in 0.292s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02275, val loss: 0.02342, in 0.283s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02189, val loss: 0.02210, in 0.491s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39842, val loss: 0.39861, in 0.473s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39823, val loss: 0.39825, in 0.512s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37888, val loss: 0.37938, in 0.509s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02110, val loss: 0.02186, in 0.567s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02193, val loss: 0.02236, in 0.611s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36249, val loss: 0.36220, in 0.587s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02243, val loss: 0.02309, in 0.588s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37960, val loss: 0.37984, in 0.479s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02175, in 0.535s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37943, val loss: 0.37946, in 0.481s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36157, val loss: 0.36210, in 0.479s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02153, in 0.515s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02210, in 0.500s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34657, val loss: 0.34622, in 0.494s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02222, val loss: 0.02291, in 0.524s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36215, val loss: 0.36239, in 0.526s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36202, val loss: 0.36205, in 0.520s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02132, val loss: 0.02155, in 0.557s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34534, val loss: 0.34588, in 0.520s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02041, val loss: 0.02116, in 0.497s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33137, val loss: 0.33103, in 0.471s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02142, val loss: 0.02185, in 0.518s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02190, val loss: 0.02259, in 0.523s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34585, val loss: 0.34615, in 0.460s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34569, val loss: 0.34574, in 0.469s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33012, val loss: 0.33068, in 0.461s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02123, in 0.493s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.02092, in 0.418s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31718, val loss: 0.31684, in 0.482s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02112, val loss: 0.02154, in 0.468s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02227, in 0.481s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33088, val loss: 0.33117, in 0.455s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33065, val loss: 0.33072, in 0.453s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31607, val loss: 0.31668, in 0.463s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02081, val loss: 0.02104, in 0.507s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01988, val loss: 0.02061, in 0.474s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30396, val loss: 0.30362, in 0.452s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02126, val loss: 0.02192, in 0.415s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02086, val loss: 0.02128, in 0.486s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31669, val loss: 0.31704, in 0.371s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31651, val loss: 0.31661, in 0.346s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30284, val loss: 0.30347, in 0.336s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02065, val loss: 0.02087, in 0.308s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01963, val loss: 0.02035, in 0.403s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29151, val loss: 0.29118, in 0.382s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02102, in 0.393s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02105, val loss: 0.02173, in 0.446s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30347, val loss: 0.30386, in 0.409s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30338, val loss: 0.30347, in 0.390s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29037, val loss: 0.29100, in 0.402s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02039, val loss: 0.02061, in 0.374s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01940, val loss: 0.02011, in 0.280s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28000, val loss: 0.27969, in 0.270s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02032, val loss: 0.02076, in 0.275s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02146, in 0.274s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29107, val loss: 0.29155, in 0.303s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29093, val loss: 0.29106, in 0.286s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27867, val loss: 0.27930, in 0.308s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.02040, in 0.316s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01983, in 0.299s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26910, val loss: 0.26876, in 0.302s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02011, val loss: 0.02055, in 0.315s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02063, val loss: 0.02130, in 0.295s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01902, val loss: 0.01973, in 0.218s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27944, val loss: 0.27994, in 0.303s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27927, val loss: 0.27941, in 0.295s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26770, val loss: 0.26838, in 0.272s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02000, val loss: 0.02023, in 0.266s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25870, val loss: 0.25834, in 0.269s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02037, val loss: 0.02105, in 0.285s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01986, val loss: 0.02029, in 0.323s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26853, val loss: 0.26909, in 0.263s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01868, val loss: 0.01939, in 0.301s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26827, val loss: 0.26847, in 0.294s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01976, val loss: 0.01999, in 0.277s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25737, val loss: 0.25805, in 0.290s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24891, val loss: 0.24855, in 0.295s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02021, val loss: 0.02089, in 0.275s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.02008, in 0.283s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25816, val loss: 0.25878, in 0.281s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01845, val loss: 0.01915, in 0.273s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25797, val loss: 0.25825, in 0.274s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01954, val loss: 0.01978, in 0.292s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24771, val loss: 0.24840, in 0.288s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23979, val loss: 0.23940, in 0.270s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.02072, in 0.277s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01937, val loss: 0.01981, in 0.275s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24851, val loss: 0.24918, in 0.263s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01829, val loss: 0.01901, in 0.288s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24829, val loss: 0.24860, in 0.281s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23852, val loss: 0.23920, in 0.295s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01924, val loss: 0.01948, in 0.311s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23122, val loss: 0.23080, in 0.290s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02053, in 0.258s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01916, val loss: 0.01961, in 0.260s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23937, val loss: 0.24003, in 0.293s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01877, in 0.258s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23909, val loss: 0.23945, in 0.268s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22993, val loss: 0.23062, in 0.281s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01901, val loss: 0.01923, in 0.274s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22309, val loss: 0.22268, in 0.284s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01941, in 0.253s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01957, val loss: 0.02028, in 0.302s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23067, val loss: 0.23137, in 0.469s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01774, val loss: 0.01844, in 0.460s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23054, val loss: 0.23093, in 0.455s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22178, val loss: 0.22249, in 0.515s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.01905, in 0.563s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21531, val loss: 0.21488, in 0.567s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01873, val loss: 0.01920, in 0.563s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01938, val loss: 0.02009, in 0.563s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22242, val loss: 0.22321, in 0.475s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22216, val loss: 0.22258, in 0.501s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01755, val loss: 0.01826, in 0.531s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21416, val loss: 0.21489, in 0.507s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01867, val loss: 0.01889, in 0.467s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20805, val loss: 0.20760, in 0.493s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01896, in 0.501s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01983, in 0.540s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01736, val loss: 0.01808, in 0.497s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21474, val loss: 0.21552, in 0.585s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21443, val loss: 0.21488, in 0.559s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.01861, in 0.522s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20686, val loss: 0.20762, in 0.570s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20120, val loss: 0.20076, in 0.582s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01830, val loss: 0.01878, in 0.550s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01887, val loss: 0.01956, in 0.550s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20743, val loss: 0.20825, in 0.550s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01790, in 0.585s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20719, val loss: 0.20764, in 0.556s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01838, in 0.518s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19987, val loss: 0.20063, in 0.574s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19464, val loss: 0.19418, in 0.551s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01862, val loss: 0.01930, in 0.537s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01811, val loss: 0.01860, in 0.609s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01778, in 0.402s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20061, val loss: 0.20149, in 0.513s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01800, val loss: 0.01821, in 0.454s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20029, val loss: 0.20080, in 0.518s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19334, val loss: 0.19406, in 0.486s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18851, val loss: 0.18808, in 0.440s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01792, val loss: 0.01840, in 0.363s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01843, val loss: 0.01911, in 0.426s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01681, val loss: 0.01753, in 0.419s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19413, val loss: 0.19504, in 0.350s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19378, val loss: 0.19439, in 0.340s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01796, in 0.355s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18712, val loss: 0.18788, in 0.299s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18267, val loss: 0.18225, in 0.416s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01769, val loss: 0.01817, in 0.392s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01820, val loss: 0.01887, in 0.407s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01652, val loss: 0.01724, in 0.413s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18789, val loss: 0.18885, in 0.433s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18767, val loss: 0.18834, in 0.422s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01773, in 0.430s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18129, val loss: 0.18204, in 0.441s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01798, in 0.338s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17704, val loss: 0.17660, in 0.344s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01790, val loss: 0.01855, in 0.341s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01634, val loss: 0.01706, in 0.322s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18211, val loss: 0.18314, in 0.313s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01746, in 0.307s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18171, val loss: 0.18241, in 0.331s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17567, val loss: 0.17641, in 0.327s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01729, val loss: 0.01776, in 0.302s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17170, val loss: 0.17127, in 0.319s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01624, val loss: 0.01695, in 0.263s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01771, val loss: 0.01836, in 0.357s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01727, in 0.293s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17648, val loss: 0.17755, in 0.321s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17595, val loss: 0.17672, in 0.325s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17038, val loss: 0.17113, in 0.315s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16644, val loss: 0.16606, in 0.313s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01711, val loss: 0.01758, in 0.352s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01607, val loss: 0.01677, in 0.330s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01754, val loss: 0.01818, in 0.305s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01695, val loss: 0.01714, in 0.308s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17121, val loss: 0.17234, in 0.350s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17065, val loss: 0.17144, in 0.352s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16503, val loss: 0.16582, in 0.330s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01693, val loss: 0.01741, in 0.308s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16155, val loss: 0.16112, in 0.370s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01652, in 0.354s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01734, val loss: 0.01796, in 0.353s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01693, in 0.332s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16619, val loss: 0.16736, in 0.354s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16560, val loss: 0.16644, in 0.353s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16034, val loss: 0.16118, in 0.344s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01676, val loss: 0.01723, in 0.345s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15701, val loss: 0.15663, in 0.333s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01633, in 0.331s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01712, val loss: 0.01775, in 0.326s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01645, val loss: 0.01665, in 0.315s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16120, val loss: 0.16242, in 0.305s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16087, val loss: 0.16180, in 0.286s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01660, val loss: 0.01709, in 0.300s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15568, val loss: 0.15653, in 0.340s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15266, val loss: 0.15231, in 0.319s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01688, val loss: 0.01751, in 0.301s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01612, in 0.355s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01624, val loss: 0.01644, in 0.350s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15672, val loss: 0.15797, in 0.337s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15609, val loss: 0.15712, in 0.333s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01645, val loss: 0.01693, in 0.317s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15131, val loss: 0.15217, in 0.314s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14838, val loss: 0.14807, in 0.324s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01738, in 0.338s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01595, in 0.339s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15241, val loss: 0.15374, in 0.321s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01601, val loss: 0.01622, in 0.371s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15179, val loss: 0.15288, in 0.470s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01674, in 0.499s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14730, val loss: 0.14820, in 0.506s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14446, val loss: 0.14414, in 0.552s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01656, val loss: 0.01721, in 0.623s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01571, in 0.600s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14817, val loss: 0.14959, in 0.636s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01581, val loss: 0.01601, in 0.644s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14764, val loss: 0.14876, in 0.526s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01655, in 0.506s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14321, val loss: 0.14410, in 0.542s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14077, val loss: 0.14049, in 0.520s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01639, val loss: 0.01703, in 0.527s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01485, val loss: 0.01555, in 0.519s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14419, val loss: 0.14566, in 0.533s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01594, val loss: 0.01643, in 0.475s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14360, val loss: 0.14478, in 0.575s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01581, in 0.617s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.13948, val loss: 0.14038, in 0.507s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13696, val loss: 0.13666, in 0.512s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01617, val loss: 0.01682, in 0.501s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01532, in 0.543s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14045, val loss: 0.14198, in 0.513s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01563, in 0.480s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13974, val loss: 0.14095, in 0.512s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01625, in 0.542s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13573, val loss: 0.13667, in 0.523s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13363, val loss: 0.13333, in 0.497s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01449, val loss: 0.01518, in 0.444s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01600, val loss: 0.01665, in 0.528s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13682, val loss: 0.13837, in 0.497s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01548, in 0.452s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13593, val loss: 0.13714, in 0.485s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01609, in 0.504s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13209, val loss: 0.13307, in 0.484s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13040, val loss: 0.13012, in 0.524s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01647, in 0.448s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01502, in 0.485s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13318, val loss: 0.13476, in 0.414s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13219, val loss: 0.13349, in 0.387s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01508, val loss: 0.01529, in 0.451s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01543, val loss: 0.01592, in 0.378s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12884, val loss: 0.12981, in 0.364s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12724, val loss: 0.12698, in 0.315s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01493, in 0.357s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01568, val loss: 0.01632, in 0.418s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12989, val loss: 0.13155, in 0.418s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01493, val loss: 0.01515, in 0.403s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01574, in 0.400s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12893, val loss: 0.13022, in 0.434s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12569, val loss: 0.12667, in 0.428s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12398, val loss: 0.12371, in 0.424s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01410, val loss: 0.01478, in 0.313s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01616, in 0.287s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12681, val loss: 0.12851, in 0.302s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01560, in 0.283s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01476, val loss: 0.01497, in 0.313s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12581, val loss: 0.12713, in 0.286s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12272, val loss: 0.12375, in 0.282s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12091, val loss: 0.12072, in 0.289s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01465, in 0.277s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01591, in 0.297s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12366, val loss: 0.12534, in 0.309s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01544, in 0.328s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12278, val loss: 0.12417, in 0.325s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01461, val loss: 0.01482, in 0.348s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11987, val loss: 0.12092, in 0.313s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11802, val loss: 0.11786, in 0.314s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01452, in 0.305s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01507, val loss: 0.01570, in 0.332s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12072, val loss: 0.12242, in 0.337s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01478, val loss: 0.01527, in 0.308s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11991, val loss: 0.12134, in 0.330s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11702, val loss: 0.11805, in 0.320s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01465, in 0.346s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01440, in 0.295s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11543, val loss: 0.11527, in 0.332s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01489, val loss: 0.01552, in 0.301s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11794, val loss: 0.11968, in 0.304s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01510, in 0.327s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11722, val loss: 0.11864, in 0.321s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01444, in 0.285s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01429, in 0.295s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11435, val loss: 0.11546, in 0.327s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11290, val loss: 0.11277, in 0.326s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01471, val loss: 0.01535, in 0.317s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11514, val loss: 0.11692, in 0.321s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01445, val loss: 0.01493, in 0.315s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11461, val loss: 0.11606, in 0.320s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11189, val loss: 0.11297, in 0.371s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01402, val loss: 0.01423, in 0.424s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01342, val loss: 0.01411, in 0.409s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11050, val loss: 0.11035, in 0.388s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01457, val loss: 0.01521, in 0.363s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11267, val loss: 0.11448, in 0.369s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01478, in 0.365s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11198, val loss: 0.11351, in 0.356s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10946, val loss: 0.11056, in 0.320s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01405, in 0.325s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01327, val loss: 0.01395, in 0.320s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10816, val loss: 0.10802, in 0.322s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01442, val loss: 0.01505, in 0.325s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11015, val loss: 0.11197, in 0.552s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10966, val loss: 0.11123, in 0.598s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01416, val loss: 0.01464, in 0.620s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01310, val loss: 0.01378, in 0.588s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10712, val loss: 0.10826, in 0.642s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01393, in 0.698s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01488, in 0.681s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10598, val loss: 0.10577, in 0.714s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10772, val loss: 0.10955, in 0.658s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01449, in 0.675s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10735, val loss: 0.10900, in 0.701s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01370, in 0.635s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10489, val loss: 0.10604, in 0.667s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01380, in 0.608s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01473, in 0.631s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10368, val loss: 0.10347, in 0.642s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01444, in 0.443s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10528, val loss: 0.10720, in 0.624s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10515, val loss: 0.10689, in 0.605s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10244, val loss: 0.10362, in 0.583s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01282, val loss: 0.01349, in 0.643s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01340, val loss: 0.01360, in 0.593s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10160, val loss: 0.10136, in 0.602s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01389, val loss: 0.01452, in 0.675s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10316, val loss: 0.10517, in 0.560s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01381, val loss: 0.01431, in 0.683s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01341, in 0.476s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10291, val loss: 0.10468, in 0.606s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10050, val loss: 0.10166, in 0.596s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01349, in 0.575s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09944, val loss: 0.09919, in 0.580s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01436, in 0.561s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10101, val loss: 0.10304, in 0.590s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01261, val loss: 0.01329, in 0.505s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01368, val loss: 0.01420, in 0.535s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10055, val loss: 0.10236, in 0.519s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09833, val loss: 0.09948, in 0.506s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01336, in 0.528s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09760, val loss: 0.09731, in 0.465s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01423, in 0.443s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01249, val loss: 0.01317, in 0.416s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09885, val loss: 0.10091, in 0.483s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01355, val loss: 0.01407, in 0.488s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09869, val loss: 0.10049, in 0.473s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09620, val loss: 0.09735, in 0.469s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01324, in 0.458s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01412, in 0.438s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09563, val loss: 0.09534, in 0.474s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01235, val loss: 0.01302, in 0.394s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09681, val loss: 0.09889, in 0.345s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01341, val loss: 0.01393, in 0.371s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09433, val loss: 0.09550, in 0.319s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09664, val loss: 0.09846, in 0.341s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01290, val loss: 0.01313, in 0.325s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01402, in 0.301s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09386, val loss: 0.09354, in 0.341s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01225, val loss: 0.01291, in 0.355s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09486, val loss: 0.09695, in 0.361s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09260, val loss: 0.09374, in 0.353s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01390, in 0.316s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01378, in 0.397s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01297, in 0.334s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09467, val loss: 0.09648, in 0.370s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09204, val loss: 0.09172, in 0.326s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01276, in 0.291s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09292, val loss: 0.09506, in 0.320s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01313, val loss: 0.01366, in 0.305s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09077, val loss: 0.09191, in 0.338s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01260, val loss: 0.01282, in 0.334s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09275, val loss: 0.09463, in 0.322s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01380, in 0.366s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09043, val loss: 0.09013, in 0.324s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01264, in 0.330s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09127, val loss: 0.09339, in 0.345s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01301, val loss: 0.01356, in 0.312s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01308, val loss: 0.01372, in 0.300s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08922, val loss: 0.09040, in 0.340s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01248, val loss: 0.01272, in 0.341s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09098, val loss: 0.09291, in 0.338s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08873, val loss: 0.08844, in 0.325s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01178, val loss: 0.01244, in 0.317s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08950, val loss: 0.09167, in 0.355s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01344, in 0.357s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01297, val loss: 0.01360, in 0.317s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01263, in 0.327s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08748, val loss: 0.08864, in 0.345s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08925, val loss: 0.09122, in 0.347s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08711, val loss: 0.08688, in 0.356s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01233, in 0.361s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08780, val loss: 0.08990, in 0.343s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01334, in 0.310s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01346, in 0.342s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01226, val loss: 0.01250, in 0.321s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08605, val loss: 0.08722, in 0.352s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08761, val loss: 0.08962, in 0.339s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08578, val loss: 0.08554, in 0.343s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08615, val loss: 0.08831, in 0.367s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01237, in 0.356s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01267, val loss: 0.01322, in 0.397s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01334, in 0.385s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08441, val loss: 0.08565, in 0.506s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08601, val loss: 0.08808, in 0.541s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08430, val loss: 0.08407, in 0.520s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01310, in 0.697s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08465, val loss: 0.08684, in 0.740s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01260, val loss: 0.01322, in 0.768s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01199, val loss: 0.01222, in 0.800s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08288, val loss: 0.08415, in 0.645s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08451, val loss: 0.08656, in 0.642s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08273, val loss: 0.08255, in 0.628s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08311, val loss: 0.08530, in 0.599s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08134, val loss: 0.08265, in 0.627s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08309, val loss: 0.08513, in 0.597s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08147, val loss: 0.08129, in 0.628s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08180, val loss: 0.08400, in 0.668s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07984, val loss: 0.08116, in 0.611s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08176, val loss: 0.08384, in 0.622s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07976, val loss: 0.07962, in 0.626s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08016, val loss: 0.08235, in 0.605s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08020, val loss: 0.08230, in 0.598s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07857, val loss: 0.07995, in 0.628s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07834, val loss: 0.07821, in 0.606s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07879, val loss: 0.08100, in 0.489s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07711, val loss: 0.07849, in 0.430s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07873, val loss: 0.08087, in 0.510s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07693, val loss: 0.07680, in 0.517s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07733, val loss: 0.07955, in 0.497s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07737, val loss: 0.07951, in 0.439s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07579, val loss: 0.07717, in 0.503s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07546, val loss: 0.07533, in 0.394s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07604, val loss: 0.07828, in 0.340s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07455, val loss: 0.07593, in 0.341s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07576, val loss: 0.07785, in 0.346s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07411, val loss: 0.07400, in 0.358s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07466, val loss: 0.07691, in 0.346s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07315, val loss: 0.07456, in 0.338s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07452, val loss: 0.07661, in 0.337s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07289, val loss: 0.07277, in 0.341s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07332, val loss: 0.07556, in 0.324s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07169, val loss: 0.07310, in 0.329s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07292, val loss: 0.07501, in 0.333s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07149, val loss: 0.07138, in 0.340s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07212, val loss: 0.07435, in 0.326s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07176, val loss: 0.07387, in 0.342s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07036, val loss: 0.07183, in 0.354s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07021, val loss: 0.07015, in 0.324s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07070, val loss: 0.07292, in 0.350s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06928, val loss: 0.07075, in 0.332s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07055, val loss: 0.07270, in 0.341s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06907, val loss: 0.06902, in 0.339s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06954, val loss: 0.07179, in 0.534s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06935, val loss: 0.07151, in 0.571s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06790, val loss: 0.06937, in 0.582s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06793, val loss: 0.06792, in 0.566s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06843, val loss: 0.07069, in 0.602s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06679, val loss: 0.06824, in 0.578s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06792, val loss: 0.07007, in 0.590s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06692, val loss: 0.06694, in 0.574s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06747, val loss: 0.06973, in 0.581s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06664, val loss: 0.06878, in 0.554s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06560, val loss: 0.06704, in 0.583s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06585, val loss: 0.06589, in 0.574s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06627, val loss: 0.06857, in 0.560s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01153, val loss: 0.01217, in 0.319s\n",
      "Fit 200 trees in 86.344 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.240s\n",
      "Time spent finding best splits:  1.461s\n",
      "Time spent applying splits:      10.500s\n",
      "Time spent predicting:           0.744s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06552, val loss: 0.06769, in 0.575s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06482, val loss: 0.06486, in 0.564s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06429, val loss: 0.06570, in 0.583s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06531, val loss: 0.06767, in 0.560s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06436, val loss: 0.06648, in 0.526s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06300, val loss: 0.06439, in 0.516s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06385, val loss: 0.06391, in 0.527s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06429, val loss: 0.06665, in 0.319s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01300, in 0.530s\n",
      "Fit 200 trees in 87.489 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.079s\n",
      "Time spent finding best splits:  1.457s\n",
      "Time spent applying splits:      11.036s\n",
      "Time spent predicting:           0.655s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06322, val loss: 0.06532, in 0.446s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01247, val loss: 0.01310, in 0.556s\n",
      "Fit 200 trees in 87.575 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.467s\n",
      "Time spent finding best splits:  1.384s\n",
      "Time spent applying splits:      10.761s\n",
      "Time spent predicting:           0.640s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06203, val loss: 0.06342, in 0.453s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06286, val loss: 0.06293, in 0.468s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01187, val loss: 0.01210, in 0.653s\n",
      "Fit 200 trees in 87.662 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.473s\n",
      "Time spent finding best splits:  1.569s\n",
      "Time spent applying splits:      10.648s\n",
      "Time spent predicting:           0.543s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06334, val loss: 0.06572, in 0.468s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06233, val loss: 0.06448, in 0.341s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06092, val loss: 0.06228, in 0.338s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06193, val loss: 0.06202, in 0.324s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06253, val loss: 0.06493, in 0.328s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06139, val loss: 0.06347, in 0.321s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06058, val loss: 0.06070, in 0.332s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05978, val loss: 0.06117, in 0.344s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06143, val loss: 0.06382, in 0.344s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06052, val loss: 0.06257, in 0.321s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05900, val loss: 0.06038, in 0.330s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05965, val loss: 0.05981, in 0.344s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06033, val loss: 0.06273, in 0.322s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05932, val loss: 0.06137, in 0.316s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05881, val loss: 0.05899, in 0.315s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05821, val loss: 0.05959, in 0.327s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05945, val loss: 0.06188, in 0.339s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05824, val loss: 0.06030, in 0.352s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05705, val loss: 0.05841, in 0.348s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05753, val loss: 0.05772, in 0.374s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05813, val loss: 0.06055, in 0.367s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05738, val loss: 0.05945, in 0.351s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05624, val loss: 0.05763, in 0.316s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05634, val loss: 0.05652, in 0.311s\n",
      "[87/200] 3.078 s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.013 GB of validation data: 0.129 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05657, val loss: 0.05865, in 0.312s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05733, val loss: 0.05978, in 0.346s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05533, val loss: 0.05674, in 0.310s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05528, val loss: 0.05547, in 0.300s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65053, in 0.492s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05562, val loss: 0.05769, in 0.592s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05430, val loss: 0.05568, in 0.578s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05606, val loss: 0.05849, in 0.614s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05457, val loss: 0.05479, in 0.609s\n",
      "[89/200] 3.136 s\n",
      "Binning 0.013 GB of validation data: 3.135 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.61194, val loss: 0.61200, in 0.501s\n",
      "[3/200] 3.194 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05498, val loss: 0.05702, in 0.492s\n",
      "[88/200] 0.202 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05350, val loss: 0.05487, in 0.505s\n",
      "[89/200] 0.223 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05383, val loss: 0.05402, in 0.520s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05523, val loss: 0.05761, in 0.526s\n",
      "[88/200] 0.211 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57689, val loss: 0.57694, in 0.479s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65016, val loss: 0.65014, in 0.472s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05424, val loss: 0.05630, in 0.499s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05282, val loss: 0.05419, in 0.508s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65048, val loss: 0.65047, in 0.477s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05448, val loss: 0.05689, in 0.512s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05260, val loss: 0.05278, in 0.519s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65052, in 0.466s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54454, val loss: 0.54457, in 0.466s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61118, val loss: 0.61120, in 0.490s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05295, val loss: 0.05500, in 0.490s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05188, val loss: 0.05325, in 0.459s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61187, val loss: 0.61185, in 0.490s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05167, val loss: 0.05187, in 0.482s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05622, in 0.507s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61192, val loss: 0.61194, in 0.482s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51494, val loss: 0.51498, in 0.464s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57580, val loss: 0.57581, in 0.430s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05402, in 0.429s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57679, val loss: 0.57679, in 0.410s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05123, val loss: 0.05261, in 0.449s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05056, val loss: 0.05073, in 0.398s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05281, val loss: 0.05521, in 0.396s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57672, val loss: 0.57674, in 0.345s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48797, val loss: 0.48803, in 0.303s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54338, val loss: 0.54342, in 0.382s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05104, val loss: 0.05309, in 0.382s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54442, in 0.387s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05050, val loss: 0.05190, in 0.394s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04970, val loss: 0.04988, in 0.393s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05154, val loss: 0.05395, in 0.389s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54446, in 0.397s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46307, val loss: 0.46315, in 0.371s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51385, val loss: 0.51387, in 0.271s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04985, val loss: 0.05188, in 0.268s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51470, val loss: 0.51479, in 0.266s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04925, val loss: 0.05061, in 0.281s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04866, val loss: 0.04884, in 0.272s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51475, val loss: 0.51479, in 0.251s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05091, val loss: 0.05334, in 0.278s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43985, val loss: 0.43993, in 0.246s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48648, val loss: 0.48655, in 0.272s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48744, val loss: 0.48748, in 0.256s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04914, val loss: 0.05118, in 0.276s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04805, val loss: 0.04825, in 0.247s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04809, val loss: 0.04938, in 0.273s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48758, val loss: 0.48765, in 0.277s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04970, val loss: 0.05215, in 0.295s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41836, val loss: 0.41847, in 0.284s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46245, val loss: 0.46251, in 0.282s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.05009, in 0.281s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46110, val loss: 0.46122, in 0.293s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04728, val loss: 0.04858, in 0.287s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04711, val loss: 0.04730, in 0.306s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46251, val loss: 0.46257, in 0.273s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04882, val loss: 0.05123, in 0.285s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39840, val loss: 0.39853, in 0.282s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43945, val loss: 0.43952, in 0.261s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43781, val loss: 0.43798, in 0.265s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04725, val loss: 0.04927, in 0.280s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04622, val loss: 0.04747, in 0.273s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43956, val loss: 0.43961, in 0.261s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04636, val loss: 0.04655, in 0.265s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04772, val loss: 0.05013, in 0.273s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37962, val loss: 0.37977, in 0.267s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41793, val loss: 0.41802, in 0.288s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41638, val loss: 0.41656, in 0.282s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41821, val loss: 0.41828, in 0.230s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04644, val loss: 0.04847, in 0.294s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04563, val loss: 0.04691, in 0.292s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04561, val loss: 0.04582, in 0.291s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36223, val loss: 0.36238, in 0.267s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04708, val loss: 0.04951, in 0.295s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39771, val loss: 0.39781, in 0.257s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39605, val loss: 0.39624, in 0.271s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39797, val loss: 0.39804, in 0.315s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04564, val loss: 0.04764, in 0.314s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04490, val loss: 0.04511, in 0.305s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04464, val loss: 0.04588, in 0.334s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34600, val loss: 0.34618, in 0.328s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04605, val loss: 0.04848, in 0.345s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37911, val loss: 0.37928, in 0.335s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37717, val loss: 0.37740, in 0.339s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37954, val loss: 0.37960, in 0.320s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04476, val loss: 0.04674, in 0.327s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04372, val loss: 0.04492, in 0.300s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04423, val loss: 0.04444, in 0.330s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33087, val loss: 0.33107, in 0.287s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04509, val loss: 0.04750, in 0.274s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36185, val loss: 0.36199, in 0.452s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36013, val loss: 0.36037, in 0.453s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36206, val loss: 0.36222, in 0.501s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04422, val loss: 0.04622, in 0.522s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04342, val loss: 0.04363, in 0.539s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04302, val loss: 0.04422, in 0.549s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31678, val loss: 0.31703, in 0.546s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04420, val loss: 0.04659, in 0.564s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34549, val loss: 0.34564, in 0.488s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34370, val loss: 0.34397, in 0.470s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34574, val loss: 0.34589, in 0.488s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04329, val loss: 0.04528, in 0.503s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04249, val loss: 0.04371, in 0.507s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30368, val loss: 0.30399, in 0.498s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04289, val loss: 0.04314, in 0.526s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04350, val loss: 0.04587, in 0.511s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33035, val loss: 0.33052, in 0.495s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32841, val loss: 0.32875, in 0.508s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33044, val loss: 0.33058, in 0.491s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29125, val loss: 0.29157, in 0.503s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04257, val loss: 0.04458, in 0.581s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04257, in 0.501s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04164, val loss: 0.04283, in 0.527s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04280, val loss: 0.04517, in 0.518s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31622, val loss: 0.31646, in 0.488s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31399, val loss: 0.31434, in 0.480s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31626, val loss: 0.31650, in 0.480s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04189, val loss: 0.04388, in 0.475s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27956, val loss: 0.27991, in 0.511s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04103, val loss: 0.04221, in 0.527s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04180, val loss: 0.04206, in 0.580s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04216, val loss: 0.04451, in 0.534s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30299, val loss: 0.30324, in 0.458s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30052, val loss: 0.30090, in 0.487s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30291, val loss: 0.30316, in 0.505s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26859, val loss: 0.26900, in 0.459s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04043, val loss: 0.04159, in 0.451s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04125, val loss: 0.04324, in 0.523s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04149, val loss: 0.04383, in 0.422s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04109, val loss: 0.04132, in 0.456s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29054, val loss: 0.29078, in 0.408s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28813, val loss: 0.28855, in 0.387s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29058, val loss: 0.29085, in 0.368s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25833, val loss: 0.25878, in 0.471s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03966, val loss: 0.04078, in 0.455s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04041, val loss: 0.04238, in 0.449s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04088, val loss: 0.04322, in 0.458s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04051, val loss: 0.04075, in 0.482s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27655, val loss: 0.27700, in 0.415s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27892, val loss: 0.27909, in 0.463s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27898, val loss: 0.27924, in 0.419s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24845, val loss: 0.24895, in 0.314s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.04029, in 0.326s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03983, val loss: 0.04180, in 0.328s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04037, val loss: 0.04273, in 0.317s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26543, val loss: 0.26593, in 0.320s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03986, val loss: 0.04011, in 0.352s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26786, val loss: 0.26800, in 0.324s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26799, val loss: 0.26824, in 0.311s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23931, val loss: 0.23988, in 0.313s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03917, val loss: 0.04112, in 0.329s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03983, val loss: 0.04221, in 0.305s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03853, val loss: 0.03966, in 0.350s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03917, val loss: 0.03944, in 0.313s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25500, val loss: 0.25553, in 0.330s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25746, val loss: 0.25762, in 0.330s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25780, val loss: 0.25805, in 0.328s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23070, val loss: 0.23131, in 0.311s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03859, val loss: 0.04052, in 0.300s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03913, val loss: 0.04145, in 0.337s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03895, in 0.341s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24540, val loss: 0.24598, in 0.309s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03872, val loss: 0.03902, in 0.344s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24773, val loss: 0.24792, in 0.311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24807, val loss: 0.24836, in 0.333s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22258, val loss: 0.22322, in 0.315s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03788, val loss: 0.03978, in 0.315s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03857, val loss: 0.04087, in 0.291s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03733, val loss: 0.03841, in 0.331s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23612, val loss: 0.23672, in 0.324s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03810, val loss: 0.03838, in 0.314s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23857, val loss: 0.23882, in 0.320s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23908, val loss: 0.23938, in 0.322s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21472, val loss: 0.21540, in 0.368s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03735, val loss: 0.03922, in 0.350s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03806, val loss: 0.04033, in 0.362s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03658, val loss: 0.03767, in 0.364s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22735, val loss: 0.22800, in 0.373s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03762, val loss: 0.03790, in 0.381s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23001, val loss: 0.23029, in 0.369s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23044, val loss: 0.23073, in 0.347s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20745, val loss: 0.20822, in 0.311s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03681, val loss: 0.03867, in 0.307s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03747, val loss: 0.03974, in 0.320s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03606, val loss: 0.03716, in 0.333s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21919, val loss: 0.21988, in 0.354s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03703, val loss: 0.03731, in 0.332s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22168, val loss: 0.22194, in 0.351s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22228, val loss: 0.22265, in 0.343s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03630, val loss: 0.03815, in 0.332s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20055, val loss: 0.20132, in 0.347s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03692, val loss: 0.03920, in 0.345s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03543, val loss: 0.03652, in 0.312s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21148, val loss: 0.21223, in 0.451s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03662, in 0.461s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21407, val loss: 0.21431, in 0.466s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21451, val loss: 0.21489, in 0.469s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03587, val loss: 0.03774, in 0.506s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19406, val loss: 0.19486, in 0.533s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03622, val loss: 0.03850, in 0.561s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03477, val loss: 0.03584, in 0.583s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20420, val loss: 0.20501, in 0.467s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03592, val loss: 0.03620, in 0.492s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20677, val loss: 0.20707, in 0.476s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20723, val loss: 0.20766, in 0.508s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03534, val loss: 0.03718, in 0.478s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18789, val loss: 0.18878, in 0.494s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03554, val loss: 0.03778, in 0.489s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03416, val loss: 0.03525, in 0.446s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19720, val loss: 0.19797, in 0.491s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03542, val loss: 0.03569, in 0.489s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19990, val loss: 0.20021, in 0.507s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20042, val loss: 0.20086, in 0.478s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03496, val loss: 0.03679, in 0.490s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18194, val loss: 0.18286, in 0.494s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03496, val loss: 0.03722, in 0.465s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03359, val loss: 0.03469, in 0.483s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19058, val loss: 0.19146, in 0.477s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03494, val loss: 0.03519, in 0.480s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19339, val loss: 0.19373, in 0.467s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19395, val loss: 0.19442, in 0.467s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03630, in 0.485s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17628, val loss: 0.17728, in 0.488s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03445, val loss: 0.03669, in 0.503s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03409, in 0.484s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18432, val loss: 0.18517, in 0.481s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03472, in 0.440s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18719, val loss: 0.18753, in 0.463s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18772, val loss: 0.18817, in 0.494s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03578, in 0.499s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17104, val loss: 0.17209, in 0.454s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03387, val loss: 0.03612, in 0.412s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03266, val loss: 0.03375, in 0.401s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03394, val loss: 0.03420, in 0.348s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17842, val loss: 0.17934, in 0.354s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18119, val loss: 0.18154, in 0.353s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18194, val loss: 0.18237, in 0.315s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03337, val loss: 0.03516, in 0.389s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16604, val loss: 0.16716, in 0.397s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03339, val loss: 0.03560, in 0.389s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03337, in 0.411s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03345, val loss: 0.03372, in 0.370s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17275, val loss: 0.17370, in 0.394s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17568, val loss: 0.17605, in 0.392s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17624, val loss: 0.17662, in 0.411s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03468, in 0.272s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16125, val loss: 0.16247, in 0.266s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03288, val loss: 0.03509, in 0.264s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03181, val loss: 0.03292, in 0.263s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03326, in 0.259s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16739, val loss: 0.16834, in 0.281s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17029, val loss: 0.17062, in 0.258s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.17091, val loss: 0.17130, in 0.282s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03258, val loss: 0.03480, in 0.247s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03245, val loss: 0.03421, in 0.263s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15658, val loss: 0.15783, in 0.293s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03129, val loss: 0.03242, in 0.280s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03263, val loss: 0.03291, in 0.290s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16224, val loss: 0.16324, in 0.287s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16494, val loss: 0.16526, in 0.278s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16583, val loss: 0.16622, in 0.303s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03192, val loss: 0.03368, in 0.276s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03202, val loss: 0.03422, in 0.283s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03086, val loss: 0.03196, in 0.268s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15216, val loss: 0.15341, in 0.292s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03217, val loss: 0.03246, in 0.289s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16017, val loss: 0.16043, in 0.288s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15735, val loss: 0.15839, in 0.308s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16088, val loss: 0.16127, in 0.278s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03149, val loss: 0.03366, in 0.306s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03132, val loss: 0.03307, in 0.315s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03049, val loss: 0.03160, in 0.280s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14792, val loss: 0.14927, in 0.281s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03172, val loss: 0.03202, in 0.289s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15283, val loss: 0.15392, in 0.275s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15552, val loss: 0.15576, in 0.308s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15632, val loss: 0.15670, in 0.296s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03096, val loss: 0.03312, in 0.282s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03098, val loss: 0.03270, in 0.284s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03005, val loss: 0.03114, in 0.282s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14396, val loss: 0.14541, in 0.273s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03140, val loss: 0.03171, in 0.279s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15125, val loss: 0.15147, in 0.272s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14849, val loss: 0.14959, in 0.288s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15203, val loss: 0.15245, in 0.270s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03062, val loss: 0.03277, in 0.264s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03059, val loss: 0.03229, in 0.274s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02953, val loss: 0.03060, in 0.274s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14007, val loss: 0.14153, in 0.284s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.03125, in 0.273s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14713, val loss: 0.14736, in 0.271s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14436, val loss: 0.14553, in 0.284s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14789, val loss: 0.14827, in 0.295s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03019, val loss: 0.03232, in 0.260s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03004, val loss: 0.03173, in 0.282s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13642, val loss: 0.13789, in 0.273s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02924, val loss: 0.03032, in 0.410s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03041, val loss: 0.03075, in 0.461s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14313, val loss: 0.14333, in 0.508s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14047, val loss: 0.14169, in 0.507s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14396, val loss: 0.14433, in 0.616s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02970, val loss: 0.03137, in 0.627s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.03203, in 0.665s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13289, val loss: 0.13444, in 0.699s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02886, val loss: 0.02993, in 0.602s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02990, val loss: 0.03024, in 0.568s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13925, val loss: 0.13936, in 0.577s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13649, val loss: 0.13780, in 0.615s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14022, val loss: 0.14053, in 0.561s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02948, val loss: 0.03163, in 0.549s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02938, val loss: 0.03104, in 0.588s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12959, val loss: 0.13119, in 0.576s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02838, val loss: 0.02943, in 0.554s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.02988, in 0.500s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13567, val loss: 0.13575, in 0.566s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13298, val loss: 0.13435, in 0.541s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13676, val loss: 0.13706, in 0.553s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02907, val loss: 0.03119, in 0.514s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02885, val loss: 0.03049, in 0.551s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12644, val loss: 0.12802, in 0.539s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02914, val loss: 0.02949, in 0.516s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02790, val loss: 0.02893, in 0.560s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13228, val loss: 0.13232, in 0.545s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12955, val loss: 0.13097, in 0.520s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13339, val loss: 0.13362, in 0.523s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02865, val loss: 0.03077, in 0.522s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02849, val loss: 0.03012, in 0.487s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12318, val loss: 0.12479, in 0.520s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02889, val loss: 0.02925, in 0.512s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02751, val loss: 0.02854, in 0.584s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12910, val loss: 0.12914, in 0.497s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12616, val loss: 0.12759, in 0.514s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13005, val loss: 0.13028, in 0.473s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02818, val loss: 0.03027, in 0.473s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02799, val loss: 0.02959, in 0.460s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12033, val loss: 0.12196, in 0.412s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02708, val loss: 0.02810, in 0.386s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02888, in 0.483s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12301, val loss: 0.12452, in 0.366s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12598, val loss: 0.12602, in 0.391s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02779, val loss: 0.02986, in 0.508s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12686, val loss: 0.12710, in 0.522s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02766, val loss: 0.02925, in 0.570s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11739, val loss: 0.11906, in 0.602s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02823, val loss: 0.02862, in 0.623s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02665, val loss: 0.02766, in 0.630s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11984, val loss: 0.12138, in 0.587s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12303, val loss: 0.12308, in 0.585s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02759, val loss: 0.02966, in 0.366s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12384, val loss: 0.12410, in 0.437s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02885, in 0.399s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11461, val loss: 0.11633, in 0.398s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02779, val loss: 0.02818, in 0.389s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02627, val loss: 0.02725, in 0.393s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11689, val loss: 0.11844, in 0.375s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11992, val loss: 0.11994, in 0.374s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02728, val loss: 0.02934, in 0.389s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12105, val loss: 0.12133, in 0.337s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02700, val loss: 0.02856, in 0.356s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11217, val loss: 0.11390, in 0.303s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02752, val loss: 0.02791, in 0.302s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11414, val loss: 0.11579, in 0.274s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02596, val loss: 0.02695, in 0.313s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11689, val loss: 0.11694, in 0.296s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02703, val loss: 0.02909, in 0.313s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11831, val loss: 0.11858, in 0.287s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02655, val loss: 0.02811, in 0.301s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10970, val loss: 0.11147, in 0.285s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02715, val loss: 0.02754, in 0.287s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02563, val loss: 0.02662, in 0.276s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11158, val loss: 0.11330, in 0.294s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11422, val loss: 0.11428, in 0.273s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11575, val loss: 0.11601, in 0.337s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02668, val loss: 0.02872, in 0.417s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02606, val loss: 0.02760, in 0.384s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10744, val loss: 0.10928, in 0.395s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10887, val loss: 0.11062, in 0.363s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02528, val loss: 0.02627, in 0.389s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02677, val loss: 0.02714, in 0.407s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11175, val loss: 0.11178, in 0.386s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11329, val loss: 0.11358, in 0.346s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02634, val loss: 0.02835, in 0.288s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02565, val loss: 0.02719, in 0.290s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10518, val loss: 0.10706, in 0.273s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10639, val loss: 0.10817, in 0.302s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10918, val loss: 0.10924, in 0.290s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02503, val loss: 0.02604, in 0.307s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02651, val loss: 0.02690, in 0.313s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11088, val loss: 0.11121, in 0.284s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02597, val loss: 0.02798, in 0.293s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02672, in 0.291s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10306, val loss: 0.10490, in 0.304s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10397, val loss: 0.10575, in 0.295s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02657, in 0.270s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10678, val loss: 0.10684, in 0.288s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02473, val loss: 0.02574, in 0.306s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10854, val loss: 0.10888, in 0.282s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02556, val loss: 0.02754, in 0.291s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02479, val loss: 0.02628, in 0.303s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10089, val loss: 0.10283, in 0.291s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02585, val loss: 0.02623, in 0.449s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02437, val loss: 0.02536, in 0.448s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10179, val loss: 0.10359, in 0.480s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10436, val loss: 0.10446, in 0.476s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10617, val loss: 0.10655, in 0.505s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02529, val loss: 0.02727, in 0.559s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02441, val loss: 0.02592, in 0.563s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09900, val loss: 0.10091, in 0.586s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02559, val loss: 0.02599, in 0.468s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09967, val loss: 0.10151, in 0.495s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02417, val loss: 0.02516, in 0.516s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10209, val loss: 0.10216, in 0.509s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10386, val loss: 0.10420, in 0.513s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02504, val loss: 0.02703, in 0.563s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02415, val loss: 0.02563, in 0.569s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09717, val loss: 0.09908, in 0.544s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02523, val loss: 0.02562, in 0.546s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09772, val loss: 0.09951, in 0.531s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10005, val loss: 0.10015, in 0.533s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02383, val loss: 0.02480, in 0.595s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10139, val loss: 0.10173, in 0.521s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02459, val loss: 0.02656, in 0.519s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02388, val loss: 0.02535, in 0.506s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09517, val loss: 0.09709, in 0.523s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02498, val loss: 0.02537, in 0.538s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09554, val loss: 0.09737, in 0.518s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09768, val loss: 0.09781, in 0.526s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09931, val loss: 0.09965, in 0.548s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02355, val loss: 0.02451, in 0.596s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02363, val loss: 0.02509, in 0.480s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02632, in 0.566s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09322, val loss: 0.09516, in 0.532s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02467, val loss: 0.02508, in 0.541s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09349, val loss: 0.09536, in 0.529s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09573, val loss: 0.09587, in 0.550s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02422, in 0.510s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09720, val loss: 0.09757, in 0.528s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02328, val loss: 0.02474, in 0.477s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02412, val loss: 0.02607, in 0.491s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09145, val loss: 0.09339, in 0.456s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09142, val loss: 0.09332, in 0.386s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02437, val loss: 0.02476, in 0.397s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09374, val loss: 0.09391, in 0.346s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02286, val loss: 0.02381, in 0.292s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09539, val loss: 0.09576, in 0.309s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02306, val loss: 0.02450, in 0.417s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02380, val loss: 0.02573, in 0.389s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08959, val loss: 0.09156, in 0.400s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08939, val loss: 0.09135, in 0.413s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09185, val loss: 0.09201, in 0.405s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02404, val loss: 0.02442, in 0.413s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02256, val loss: 0.02350, in 0.387s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09339, val loss: 0.09376, in 0.413s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02289, val loss: 0.02434, in 0.233s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02350, val loss: 0.02542, in 0.302s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08794, val loss: 0.08986, in 0.305s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02376, val loss: 0.02415, in 0.266s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08765, val loss: 0.08967, in 0.295s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09015, val loss: 0.09028, in 0.293s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02222, val loss: 0.02317, in 0.304s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09164, val loss: 0.09200, in 0.285s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02259, val loss: 0.02401, in 0.288s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08636, val loss: 0.08829, in 0.283s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02328, val loss: 0.02520, in 0.311s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08828, val loss: 0.08845, in 0.305s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02344, val loss: 0.02383, in 0.331s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08589, val loss: 0.08796, in 0.311s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02244, val loss: 0.02387, in 0.243s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02188, val loss: 0.02283, in 0.311s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08988, val loss: 0.09026, in 0.298s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08475, val loss: 0.08673, in 0.297s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02485, in 0.304s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02316, val loss: 0.02355, in 0.284s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08437, val loss: 0.08643, in 0.312s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08674, val loss: 0.08691, in 0.324s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02162, val loss: 0.02257, in 0.298s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02220, val loss: 0.02363, in 0.337s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08817, val loss: 0.08857, in 0.302s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02280, val loss: 0.02470, in 0.233s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08343, val loss: 0.08548, in 0.321s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08278, val loss: 0.08491, in 0.320s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08509, val loss: 0.08526, in 0.322s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02285, val loss: 0.02325, in 0.363s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02136, val loss: 0.02230, in 0.319s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02266, val loss: 0.02456, in 0.253s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02198, val loss: 0.02340, in 0.332s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08655, val loss: 0.08699, in 0.317s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08210, val loss: 0.08416, in 0.300s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02265, val loss: 0.02304, in 0.316s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08141, val loss: 0.08356, in 0.329s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08370, val loss: 0.08387, in 0.323s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02194, in 0.319s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02243, val loss: 0.02433, in 0.335s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02165, val loss: 0.02308, in 0.332s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08509, val loss: 0.08551, in 0.335s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08053, val loss: 0.08260, in 0.311s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02075, val loss: 0.02167, in 0.295s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02235, val loss: 0.02274, in 0.309s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08224, val loss: 0.08244, in 0.326s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07945, val loss: 0.08157, in 0.332s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02219, val loss: 0.02407, in 0.300s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08368, val loss: 0.08411, in 0.421s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02140, val loss: 0.02280, in 0.497s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07881, val loss: 0.08086, in 0.532s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02047, val loss: 0.02140, in 0.613s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02208, val loss: 0.02247, in 0.634s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02187, val loss: 0.02374, in 0.607s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08084, val loss: 0.08107, in 0.629s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07766, val loss: 0.07975, in 0.627s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02114, val loss: 0.02253, in 0.460s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08199, val loss: 0.08242, in 0.568s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07737, val loss: 0.07949, in 0.529s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.02129, in 0.447s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02192, val loss: 0.02231, in 0.500s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02146, val loss: 0.02330, in 0.510s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07917, val loss: 0.07942, in 0.517s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02096, val loss: 0.02233, in 0.474s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07582, val loss: 0.07787, in 0.546s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08042, val loss: 0.08083, in 0.513s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07564, val loss: 0.07775, in 0.538s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02317, in 0.396s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02083, val loss: 0.02221, in 0.401s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02005, val loss: 0.02097, in 0.535s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02165, val loss: 0.02204, in 0.499s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07781, val loss: 0.07805, in 0.525s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07445, val loss: 0.07651, in 0.531s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07901, val loss: 0.07943, in 0.553s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07431, val loss: 0.07643, in 0.525s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02110, val loss: 0.02291, in 0.531s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02065, val loss: 0.02202, in 0.541s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01984, val loss: 0.02076, in 0.548s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02125, val loss: 0.02165, in 0.544s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07646, val loss: 0.07670, in 0.542s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07288, val loss: 0.07489, in 0.549s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07766, val loss: 0.07809, in 0.528s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07309, val loss: 0.07528, in 0.505s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02072, val loss: 0.02250, in 0.435s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01953, val loss: 0.02044, in 0.404s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02044, val loss: 0.02180, in 0.484s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02097, val loss: 0.02138, in 0.422s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07503, val loss: 0.07527, in 0.402s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07158, val loss: 0.07357, in 0.373s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07641, val loss: 0.07681, in 0.354s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02238, in 0.383s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07198, val loss: 0.07419, in 0.445s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.02023, in 0.420s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02021, val loss: 0.02157, in 0.437s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02076, val loss: 0.02119, in 0.468s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07373, val loss: 0.07400, in 0.442s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07011, val loss: 0.07208, in 0.451s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07503, val loss: 0.07544, in 0.457s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02033, val loss: 0.02210, in 0.307s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07088, val loss: 0.07310, in 0.312s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01923, val loss: 0.02014, in 0.262s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02130, in 0.283s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02051, val loss: 0.02094, in 0.308s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07241, val loss: 0.07267, in 0.331s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06892, val loss: 0.07090, in 0.316s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07374, val loss: 0.07415, in 0.331s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01899, val loss: 0.01991, in 0.294s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02015, val loss: 0.02192, in 0.317s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06966, val loss: 0.07189, in 0.338s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01968, val loss: 0.02101, in 0.326s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.02073, in 0.319s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07090, val loss: 0.07115, in 0.339s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06768, val loss: 0.06970, in 0.336s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07257, val loss: 0.07295, in 0.336s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01871, val loss: 0.01962, in 0.319s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01989, val loss: 0.02167, in 0.338s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06858, val loss: 0.07083, in 0.326s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01952, val loss: 0.02084, in 0.327s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02013, val loss: 0.02056, in 0.324s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06979, val loss: 0.07003, in 0.324s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01859, val loss: 0.01950, in 0.249s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06626, val loss: 0.06827, in 0.329s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07134, val loss: 0.07172, in 0.335s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01961, val loss: 0.02137, in 0.307s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06741, val loss: 0.06965, in 0.358s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01926, val loss: 0.02058, in 0.347s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01990, val loss: 0.02032, in 0.368s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01829, val loss: 0.01920, in 0.331s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06849, val loss: 0.06875, in 0.354s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06512, val loss: 0.06719, in 0.356s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07003, val loss: 0.07042, in 0.338s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01929, val loss: 0.02101, in 0.326s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06614, val loss: 0.06834, in 0.338s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01902, val loss: 0.02034, in 0.301s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02009, in 0.310s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01903, in 0.310s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01918, val loss: 0.02090, in 0.265s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06730, val loss: 0.06754, in 0.329s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06393, val loss: 0.06605, in 0.334s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06893, val loss: 0.06934, in 0.333s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06507, val loss: 0.06729, in 0.330s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.02014, in 0.346s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01788, val loss: 0.01879, in 0.278s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01974, in 0.319s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06282, val loss: 0.06491, in 0.325s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06619, val loss: 0.06644, in 0.343s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.02067, in 0.367s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06761, val loss: 0.06802, in 0.346s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06410, val loss: 0.06632, in 0.479s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01868, val loss: 0.01999, in 0.450s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01768, val loss: 0.01859, in 0.509s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01957, in 0.579s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06177, val loss: 0.06390, in 0.611s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01874, val loss: 0.02043, in 0.588s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06494, val loss: 0.06518, in 0.627s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06652, val loss: 0.06692, in 0.668s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01845, val loss: 0.01975, in 0.530s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06306, val loss: 0.06527, in 0.566s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01741, val loss: 0.01831, in 0.514s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01891, val loss: 0.01937, in 0.555s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01856, val loss: 0.02024, in 0.471s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06078, val loss: 0.06292, in 0.534s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06393, val loss: 0.06415, in 0.551s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06533, val loss: 0.06573, in 0.527s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01946, in 0.501s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01821, in 0.427s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06192, val loss: 0.06409, in 0.536s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01874, val loss: 0.01919, in 0.528s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05985, val loss: 0.06196, in 0.520s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.02008, in 0.589s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06292, val loss: 0.06317, in 0.532s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01935, in 0.415s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06446, val loss: 0.06486, in 0.550s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01798, in 0.513s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06093, val loss: 0.06312, in 0.552s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01890, in 0.490s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01819, val loss: 0.01987, in 0.558s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05886, val loss: 0.06097, in 0.570s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06190, val loss: 0.06217, in 0.558s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01780, val loss: 0.01908, in 0.551s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01685, val loss: 0.01775, in 0.462s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06335, val loss: 0.06377, in 0.542s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05981, val loss: 0.06202, in 0.529s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01826, val loss: 0.01870, in 0.543s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05801, val loss: 0.06017, in 0.444s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06107, val loss: 0.06134, in 0.427s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01793, val loss: 0.01959, in 0.486s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01752, in 0.391s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01764, val loss: 0.01892, in 0.420s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06247, val loss: 0.06290, in 0.413s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05888, val loss: 0.06110, in 0.484s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01852, in 0.474s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01652, val loss: 0.01742, in 0.391s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05703, val loss: 0.05915, in 0.453s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01772, val loss: 0.01937, in 0.433s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06008, val loss: 0.06035, in 0.465s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01870, in 0.449s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06144, val loss: 0.06188, in 0.464s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05807, val loss: 0.06034, in 0.331s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01787, val loss: 0.01832, in 0.313s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01638, val loss: 0.01729, in 0.340s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01916, in 0.312s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05589, val loss: 0.05800, in 0.342s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05852, val loss: 0.05884, in 0.341s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01722, val loss: 0.01848, in 0.344s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05987, val loss: 0.06033, in 0.336s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05712, val loss: 0.05937, in 0.326s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01620, val loss: 0.01711, in 0.292s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01732, val loss: 0.01895, in 0.294s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01771, val loss: 0.01815, in 0.365s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05491, val loss: 0.05704, in 0.336s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01827, in 0.314s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05761, val loss: 0.05792, in 0.347s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05860, val loss: 0.05909, in 0.331s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05613, val loss: 0.05836, in 0.368s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01612, val loss: 0.01703, in 0.322s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01714, val loss: 0.01876, in 0.373s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01795, in 0.399s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05407, val loss: 0.05619, in 0.394s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05677, val loss: 0.05711, in 0.393s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01687, val loss: 0.01814, in 0.425s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05770, val loss: 0.05820, in 0.410s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05491, val loss: 0.05714, in 0.358s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01686, in 0.294s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01860, in 0.277s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01776, in 0.318s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05326, val loss: 0.05540, in 0.326s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01672, val loss: 0.01798, in 0.300s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05537, val loss: 0.05577, in 0.325s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05691, val loss: 0.05740, in 0.326s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05423, val loss: 0.05650, in 0.314s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01671, in 0.349s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01838, in 0.322s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01714, val loss: 0.01759, in 0.309s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05257, val loss: 0.05474, in 0.317s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01646, val loss: 0.01770, in 0.353s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05456, val loss: 0.05500, in 0.352s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05548, val loss: 0.05598, in 0.340s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05338, val loss: 0.05563, in 0.322s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01823, in 0.351s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01556, val loss: 0.01647, in 0.374s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01686, val loss: 0.01732, in 0.343s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05176, val loss: 0.05390, in 0.333s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01749, in 0.336s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05423, in 0.340s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05227, val loss: 0.05451, in 0.499s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05479, val loss: 0.05523, in 0.525s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01641, val loss: 0.01799, in 0.540s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01537, val loss: 0.01628, in 0.560s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01671, val loss: 0.01716, in 0.634s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05083, val loss: 0.05297, in 0.653s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01732, in 0.660s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05265, val loss: 0.05315, in 0.744s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05108, val loss: 0.05331, in 0.558s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05347, val loss: 0.05393, in 0.547s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01780, in 0.659s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01614, in 0.710s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01647, val loss: 0.01692, in 0.631s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05004, val loss: 0.05218, in 0.658s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01591, val loss: 0.01715, in 0.680s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05249, in 0.676s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05243, val loss: 0.05291, in 0.659s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05027, val loss: 0.05251, in 0.679s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01504, val loss: 0.01596, in 0.546s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01764, in 0.627s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01628, val loss: 0.01673, in 0.640s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04940, val loss: 0.05157, in 0.630s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01684, in 0.647s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05145, val loss: 0.05193, in 0.655s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05126, val loss: 0.05180, in 0.677s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04961, val loss: 0.05183, in 0.677s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01592, val loss: 0.01749, in 0.562s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01485, val loss: 0.01575, in 0.695s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01614, val loss: 0.01659, in 0.600s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04868, val loss: 0.05086, in 0.591s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05024, val loss: 0.05071, in 0.568s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01541, val loss: 0.01663, in 0.685s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05005, val loss: 0.05060, in 0.576s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04895, val loss: 0.05119, in 0.629s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01730, in 0.571s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01644, in 0.494s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01469, val loss: 0.01559, in 0.567s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04755, val loss: 0.04967, in 0.479s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04913, val loss: 0.04960, in 0.384s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04938, val loss: 0.04994, in 0.386s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04787, val loss: 0.05009, in 0.336s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01647, in 0.449s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01588, val loss: 0.01633, in 0.241s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01718, in 0.491s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01545, in 0.444s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04634, val loss: 0.04846, in 0.443s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04845, val loss: 0.04892, in 0.414s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01638, in 0.359s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04826, val loss: 0.04884, in 0.433s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04729, val loss: 0.04951, in 0.415s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01620, in 0.415s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01706, in 0.312s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01438, val loss: 0.01528, in 0.304s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04520, val loss: 0.04730, in 0.307s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01498, val loss: 0.01618, in 0.284s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04737, val loss: 0.04798, in 0.274s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04750, val loss: 0.04797, in 0.315s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04644, val loss: 0.04866, in 0.299s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01595, in 0.294s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01537, val loss: 0.01692, in 0.308s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04463, val loss: 0.04674, in 0.299s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01515, in 0.345s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01584, in 0.285s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04652, val loss: 0.04698, in 0.336s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04634, val loss: 0.04695, in 0.351s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01483, val loss: 0.01602, in 0.366s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04577, val loss: 0.04798, in 0.360s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01671, in 0.348s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04404, val loss: 0.04618, in 0.351s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01499, in 0.354s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04572, val loss: 0.04636, in 0.294s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04572, val loss: 0.04618, in 0.306s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01584, in 0.298s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01525, val loss: 0.01570, in 0.319s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04494, val loss: 0.04713, in 0.313s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01503, val loss: 0.01655, in 0.297s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04333, val loss: 0.04547, in 0.311s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01393, val loss: 0.01485, in 0.308s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01515, val loss: 0.01560, in 0.297s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04475, val loss: 0.04538, in 0.312s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04515, val loss: 0.04563, in 0.319s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01565, in 0.334s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04388, val loss: 0.04605, in 0.333s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01637, in 0.318s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01478, in 0.255s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04232, val loss: 0.04444, in 0.347s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04394, val loss: 0.04460, in 0.307s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01490, val loss: 0.01536, in 0.322s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04427, val loss: 0.04473, in 0.310s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01550, in 0.306s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04504, in 0.337s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01623, in 0.340s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01465, in 0.339s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04173, val loss: 0.04386, in 0.301s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04306, val loss: 0.04371, in 0.316s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04356, val loss: 0.04403, in 0.312s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01474, val loss: 0.01520, in 0.328s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01415, val loss: 0.01531, in 0.332s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04213, val loss: 0.04426, in 0.312s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01606, in 0.291s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01452, in 0.299s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04117, val loss: 0.04332, in 0.324s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04282, val loss: 0.04329, in 0.465s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04250, val loss: 0.04314, in 0.503s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01506, in 0.509s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01512, in 0.493s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04120, val loss: 0.04334, in 0.578s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01595, in 0.647s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01340, val loss: 0.01432, in 0.630s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04044, val loss: 0.04258, in 0.711s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04278, in 0.518s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04166, val loss: 0.04230, in 0.503s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01382, val loss: 0.01496, in 0.547s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01491, in 0.570s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04060, val loss: 0.04272, in 0.526s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01429, val loss: 0.01581, in 0.472s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01325, val loss: 0.01415, in 0.496s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04151, val loss: 0.04201, in 0.499s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04094, val loss: 0.04161, in 0.489s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03992, val loss: 0.04206, in 0.556s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01477, in 0.467s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01362, val loss: 0.01475, in 0.563s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04014, val loss: 0.04226, in 0.478s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01419, val loss: 0.01571, in 0.470s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01313, val loss: 0.01404, in 0.544s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04018, val loss: 0.04083, in 0.485s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04104, val loss: 0.04153, in 0.504s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03932, val loss: 0.04147, in 0.509s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01467, in 0.494s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01461, in 0.609s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03968, val loss: 0.04178, in 0.482s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01402, val loss: 0.01554, in 0.471s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01303, val loss: 0.01393, in 0.474s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04032, val loss: 0.04077, in 0.484s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03970, val loss: 0.04038, in 0.505s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.04052, in 0.524s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01447, in 0.524s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01538, in 0.472s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03884, val loss: 0.04094, in 0.491s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01399, val loss: 0.01446, in 0.508s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01380, in 0.403s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03989, val loss: 0.04034, in 0.348s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03920, val loss: 0.03988, in 0.371s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03793, val loss: 0.04003, in 0.323s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01439, in 0.240s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01425, in 0.268s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01524, in 0.415s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03835, val loss: 0.04045, in 0.467s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01278, val loss: 0.01369, in 0.456s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.03963, in 0.441s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03746, val loss: 0.03957, in 0.404s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03845, val loss: 0.03913, in 0.444s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01314, val loss: 0.01426, in 0.467s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01503, in 0.305s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01366, val loss: 0.01414, in 0.460s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03794, val loss: 0.04003, in 0.302s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01262, val loss: 0.01351, in 0.307s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03893, in 0.328s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03675, val loss: 0.03882, in 0.304s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03790, val loss: 0.03858, in 0.312s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01496, in 0.246s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01408, in 0.284s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01395, in 0.284s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03724, val loss: 0.03931, in 0.280s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01251, val loss: 0.01339, in 0.300s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03634, val loss: 0.03842, in 0.272s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03801, val loss: 0.03846, in 0.311s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03706, val loss: 0.03777, in 0.317s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01332, val loss: 0.01478, in 0.332s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01284, val loss: 0.01395, in 0.343s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01381, in 0.323s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03653, val loss: 0.03859, in 0.338s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01239, val loss: 0.01328, in 0.277s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03565, val loss: 0.03770, in 0.285s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03753, val loss: 0.03797, in 0.315s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03666, val loss: 0.03736, in 0.303s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01321, val loss: 0.01466, in 0.290s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01382, in 0.311s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01366, in 0.289s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03591, val loss: 0.03796, in 0.298s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01227, val loss: 0.01317, in 0.307s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03527, val loss: 0.03733, in 0.275s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03614, val loss: 0.03683, in 0.286s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03679, val loss: 0.03724, in 0.327s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01304, val loss: 0.01447, in 0.298s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01258, val loss: 0.01369, in 0.296s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01307, val loss: 0.01354, in 0.335s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03742, in 0.294s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03476, val loss: 0.03682, in 0.341s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03611, in 0.322s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03678, in 0.303s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01352, in 0.312s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03482, val loss: 0.03683, in 0.283s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03442, val loss: 0.03647, in 0.247s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03483, val loss: 0.03553, in 0.299s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03566, val loss: 0.03608, in 0.291s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03443, val loss: 0.03645, in 0.515s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03410, val loss: 0.03614, in 0.479s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03440, val loss: 0.03510, in 0.643s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03500, val loss: 0.03542, in 0.649s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03393, val loss: 0.03596, in 0.462s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03368, val loss: 0.03572, in 0.472s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03384, val loss: 0.03454, in 0.482s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03435, val loss: 0.03477, in 0.557s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03326, val loss: 0.03527, in 0.518s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03292, val loss: 0.03493, in 0.511s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03326, val loss: 0.03395, in 0.523s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03391, val loss: 0.03433, in 0.550s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03275, val loss: 0.03476, in 0.524s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03242, val loss: 0.03443, in 0.588s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03273, val loss: 0.03345, in 0.496s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03338, val loss: 0.03379, in 0.521s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03222, val loss: 0.03421, in 0.539s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03206, val loss: 0.03409, in 0.555s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03215, val loss: 0.03285, in 0.443s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03279, val loss: 0.03318, in 0.385s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03189, val loss: 0.03387, in 0.340s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03136, val loss: 0.03337, in 0.293s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03159, val loss: 0.03230, in 0.412s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03222, val loss: 0.03260, in 0.452s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03142, val loss: 0.03338, in 0.437s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03301, in 0.463s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03115, val loss: 0.03186, in 0.349s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03174, val loss: 0.03211, in 0.296s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03094, val loss: 0.03289, in 0.291s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03073, val loss: 0.03274, in 0.274s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03062, val loss: 0.03132, in 0.338s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03122, val loss: 0.03157, in 0.349s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03050, val loss: 0.03243, in 0.356s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03016, val loss: 0.03216, in 0.370s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03078, in 0.386s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03078, val loss: 0.03113, in 0.330s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02994, val loss: 0.03185, in 0.356s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02967, val loss: 0.03166, in 0.340s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.03028, in 0.344s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03036, val loss: 0.03071, in 0.323s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.03143, in 0.352s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02931, val loss: 0.03128, in 0.354s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02976, in 0.342s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03004, val loss: 0.03039, in 0.354s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02905, val loss: 0.03094, in 0.316s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02872, val loss: 0.03067, in 0.319s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02959, val loss: 0.02993, in 0.300s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02868, val loss: 0.02939, in 0.318s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02861, val loss: 0.03049, in 0.306s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02833, val loss: 0.03027, in 0.306s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02832, val loss: 0.02901, in 0.271s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02911, val loss: 0.02946, in 0.461s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02832, val loss: 0.03020, in 0.471s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02778, val loss: 0.02970, in 0.504s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02803, val loss: 0.02872, in 0.632s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02884, val loss: 0.02920, in 0.463s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02799, val loss: 0.02987, in 0.498s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01302, in 0.295s\n",
      "Fit 200 trees in 87.188 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.195s\n",
      "Time spent finding best splits:  1.363s\n",
      "Time spent applying splits:      10.082s\n",
      "Time spent predicting:           0.680s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02915, in 0.501s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01290, val loss: 0.01433, in 0.324s\n",
      "Fit 200 trees in 86.938 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.209s\n",
      "Time spent finding best splits:  1.640s\n",
      "Time spent applying splits:      10.444s\n",
      "Time spent predicting:           0.667s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01343, in 0.274s\n",
      "Fit 200 trees in 87.664 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.795s\n",
      "Time spent finding best splits:  1.596s\n",
      "Time spent applying splits:      10.696s\n",
      "Time spent predicting:           0.676s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02840, val loss: 0.02875, in 0.500s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02769, val loss: 0.02836, in 0.515s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02761, val loss: 0.02946, in 0.496s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02693, val loss: 0.02880, in 0.498s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02739, val loss: 0.02806, in 0.448s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02797, val loss: 0.02833, in 0.477s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02737, val loss: 0.02922, in 0.481s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01227, val loss: 0.01336, in 0.494s\n",
      "Fit 200 trees in 87.411 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.571s\n",
      "Time spent finding best splits:  1.495s\n",
      "Time spent applying splits:      10.365s\n",
      "Time spent predicting:           0.795s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02660, val loss: 0.02846, in 0.489s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02689, val loss: 0.02758, in 0.503s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02704, val loss: 0.02889, in 0.442s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02765, val loss: 0.02802, in 0.560s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02609, val loss: 0.02794, in 0.500s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02643, val loss: 0.02713, in 0.412s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02679, val loss: 0.02864, in 0.371s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02723, val loss: 0.02760, in 0.343s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02579, val loss: 0.02762, in 0.410s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02615, val loss: 0.02683, in 0.415s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02683, val loss: 0.02719, in 0.406s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02632, val loss: 0.02818, in 0.414s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02542, val loss: 0.02723, in 0.283s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02576, val loss: 0.02646, in 0.260s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02646, val loss: 0.02682, in 0.258s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02596, val loss: 0.02781, in 0.287s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02496, val loss: 0.02674, in 0.301s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02578, val loss: 0.02763, in 0.239s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02553, val loss: 0.02624, in 0.326s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02621, val loss: 0.02657, in 0.345s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02627, in 0.320s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02541, val loss: 0.02725, in 0.295s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02515, val loss: 0.02587, in 0.306s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02619, in 0.282s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02420, val loss: 0.02594, in 0.293s\n",
      "[136/200] 3.267 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02510, val loss: 0.02693, in 0.313s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02588, in 0.269s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02552, in 0.279s\n",
      "[136/200] 3.184 s\n",
      "Binning 0.013 GB of validation data: 0.121 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02379, val loss: 0.02551, in 0.287s\n",
      "[137/200] 3.138 s\n",
      "Binning 0.013 GB of validation data: 0.122 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02475, val loss: 0.02657, in 0.284s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02461, val loss: 0.02533, in 0.266s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02550, in 0.296s\n",
      "[137/200] 0.129 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65049, val loss: 0.65049, in 0.268s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02341, val loss: 0.02511, in 0.282s\n",
      "[138/200] 2.867 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65046, in 0.271s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02428, val loss: 0.02500, in 0.261s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02632, in 0.310s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65049, in 0.268s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02479, val loss: 0.02515, in 0.313s\n",
      "[138/200] 0.129 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61192, val loss: 0.61191, in 0.277s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02316, val loss: 0.02484, in 0.299s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61194, val loss: 0.61186, in 0.282s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02409, val loss: 0.02482, in 0.281s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02428, val loss: 0.02608, in 0.473s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61188, val loss: 0.61180, in 0.483s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02478, in 0.498s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65045, val loss: 0.65048, in 0.490s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57677, val loss: 0.57678, in 0.499s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02455, in 0.596s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02467, in 0.579s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57691, val loss: 0.57674, in 0.597s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02398, val loss: 0.02577, in 0.437s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57682, val loss: 0.57671, in 0.460s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02404, val loss: 0.02440, in 0.504s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54440, val loss: 0.54443, in 0.482s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61178, val loss: 0.61185, in 0.501s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02261, val loss: 0.02425, in 0.462s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54484, val loss: 0.54459, in 0.435s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02362, val loss: 0.02437, in 0.470s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02365, val loss: 0.02540, in 0.495s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54474, val loss: 0.54459, in 0.461s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02383, val loss: 0.02419, in 0.481s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51484, val loss: 0.51488, in 0.443s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57672, val loss: 0.57685, in 0.442s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02408, in 0.453s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51515, val loss: 0.51491, in 0.463s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02318, val loss: 0.02394, in 0.477s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51515, val loss: 0.51498, in 0.432s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02345, val loss: 0.02520, in 0.488s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48761, val loss: 0.48762, in 0.456s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54424, val loss: 0.54442, in 0.455s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02354, val loss: 0.02391, in 0.472s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02210, val loss: 0.02370, in 0.513s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48788, val loss: 0.48761, in 0.459s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02371, in 0.494s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48814, val loss: 0.48794, in 0.466s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02501, in 0.467s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02364, in 0.446s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46261, val loss: 0.46263, in 0.446s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51462, val loss: 0.51484, in 0.452s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46282, val loss: 0.46255, in 0.410s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02188, val loss: 0.02347, in 0.426s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02260, val loss: 0.02337, in 0.408s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46311, val loss: 0.46290, in 0.349s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02464, in 0.365s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02299, val loss: 0.02337, in 0.305s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43951, val loss: 0.43956, in 0.306s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48744, val loss: 0.48769, in 0.308s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43978, val loss: 0.43951, in 0.369s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02150, val loss: 0.02307, in 0.405s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44002, val loss: 0.43979, in 0.366s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02229, val loss: 0.02305, in 0.396s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41805, val loss: 0.41810, in 0.367s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02260, val loss: 0.02434, in 0.382s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46254, val loss: 0.46285, in 0.364s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02272, val loss: 0.02311, in 0.374s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41823, val loss: 0.41795, in 0.261s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02116, val loss: 0.02272, in 0.277s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41848, val loss: 0.41822, in 0.270s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02195, val loss: 0.02270, in 0.284s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02248, val loss: 0.02287, in 0.265s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39803, val loss: 0.39814, in 0.273s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02232, val loss: 0.02404, in 0.276s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43943, val loss: 0.43978, in 0.282s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39841, val loss: 0.39806, in 0.257s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02080, val loss: 0.02234, in 0.290s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39879, val loss: 0.39852, in 0.281s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02217, val loss: 0.02390, in 0.233s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02174, val loss: 0.02250, in 0.287s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41787, val loss: 0.41827, in 0.268s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37921, val loss: 0.37931, in 0.283s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02217, val loss: 0.02257, in 0.291s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37966, val loss: 0.37934, in 0.279s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37996, val loss: 0.37967, in 0.286s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02057, val loss: 0.02210, in 0.307s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02184, val loss: 0.02355, in 0.273s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02143, val loss: 0.02219, in 0.328s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36204, val loss: 0.36212, in 0.304s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39766, val loss: 0.39809, in 0.320s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02193, val loss: 0.02236, in 0.332s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36226, val loss: 0.36193, in 0.307s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02039, val loss: 0.02189, in 0.251s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36249, val loss: 0.36220, in 0.295s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02321, in 0.344s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34582, val loss: 0.34594, in 0.282s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37888, val loss: 0.37938, in 0.278s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02110, val loss: 0.02186, in 0.299s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02210, in 0.269s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34609, val loss: 0.34579, in 0.277s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02009, val loss: 0.02158, in 0.305s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34657, val loss: 0.34622, in 0.287s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02121, val loss: 0.02289, in 0.294s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33057, val loss: 0.33075, in 0.284s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36157, val loss: 0.36210, in 0.277s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02153, in 0.301s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02142, val loss: 0.02185, in 0.298s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33087, val loss: 0.33056, in 0.271s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01997, val loss: 0.02144, in 0.249s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33137, val loss: 0.33103, in 0.273s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34534, val loss: 0.34588, in 0.277s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31628, val loss: 0.31644, in 0.285s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02093, val loss: 0.02260, in 0.312s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02041, val loss: 0.02116, in 0.279s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02112, val loss: 0.02154, in 0.295s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31655, val loss: 0.31623, in 0.288s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01975, val loss: 0.02122, in 0.318s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31718, val loss: 0.31684, in 0.290s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30305, val loss: 0.30322, in 0.275s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33012, val loss: 0.33068, in 0.293s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.02092, in 0.276s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02068, val loss: 0.02234, in 0.288s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30346, val loss: 0.30307, in 0.420s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02086, val loss: 0.02128, in 0.527s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01946, val loss: 0.02090, in 0.528s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30396, val loss: 0.30362, in 0.555s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31607, val loss: 0.31668, in 0.578s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29061, val loss: 0.29077, in 0.601s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02047, val loss: 0.02213, in 0.584s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01988, val loss: 0.02061, in 0.599s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29096, val loss: 0.29063, in 0.507s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02102, in 0.498s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01916, val loss: 0.02059, in 0.482s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29151, val loss: 0.29118, in 0.474s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02023, val loss: 0.02186, in 0.476s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27903, val loss: 0.27917, in 0.499s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30284, val loss: 0.30347, in 0.522s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01963, val loss: 0.02035, in 0.502s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27939, val loss: 0.27901, in 0.499s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02032, val loss: 0.02076, in 0.486s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.02029, in 0.498s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28000, val loss: 0.27969, in 0.474s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01940, val loss: 0.02011, in 0.447s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26799, val loss: 0.26815, in 0.503s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29037, val loss: 0.29100, in 0.494s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.02167, in 0.562s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26833, val loss: 0.26796, in 0.514s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02011, val loss: 0.02055, in 0.511s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01861, val loss: 0.01998, in 0.482s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26910, val loss: 0.26876, in 0.500s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01983, in 0.513s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25782, val loss: 0.25800, in 0.500s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27867, val loss: 0.27930, in 0.501s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02145, in 0.498s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25797, val loss: 0.25763, in 0.530s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01986, val loss: 0.02029, in 0.550s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01834, val loss: 0.01970, in 0.457s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25870, val loss: 0.25834, in 0.464s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01902, val loss: 0.01973, in 0.324s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26770, val loss: 0.26838, in 0.369s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24814, val loss: 0.24835, in 0.385s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01956, val loss: 0.02117, in 0.366s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24828, val loss: 0.24804, in 0.297s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.02008, in 0.395s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01941, in 0.380s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24891, val loss: 0.24855, in 0.430s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01868, val loss: 0.01939, in 0.424s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25737, val loss: 0.25805, in 0.409s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23895, val loss: 0.23919, in 0.410s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01934, val loss: 0.02094, in 0.390s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23910, val loss: 0.23883, in 0.419s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01937, val loss: 0.01981, in 0.346s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01916, in 0.356s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01845, val loss: 0.01915, in 0.351s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23979, val loss: 0.23940, in 0.362s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24771, val loss: 0.24840, in 0.368s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01915, val loss: 0.02073, in 0.351s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23030, val loss: 0.23057, in 0.377s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23049, val loss: 0.23022, in 0.364s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01916, val loss: 0.01961, in 0.320s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01897, in 0.364s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23122, val loss: 0.23080, in 0.312s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01829, val loss: 0.01901, in 0.323s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01888, val loss: 0.02044, in 0.277s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23852, val loss: 0.23920, in 0.315s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22203, val loss: 0.22231, in 0.317s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22240, val loss: 0.22220, in 0.294s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01941, in 0.275s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01744, val loss: 0.01875, in 0.289s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01877, in 0.279s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22309, val loss: 0.22268, in 0.325s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.02014, in 0.295s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22993, val loss: 0.23062, in 0.313s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21436, val loss: 0.21465, in 0.310s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21473, val loss: 0.21449, in 0.298s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01873, val loss: 0.01920, in 0.281s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01719, val loss: 0.01847, in 0.346s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01774, val loss: 0.01844, in 0.339s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21531, val loss: 0.21488, in 0.329s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01992, in 0.327s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22178, val loss: 0.22249, in 0.344s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20714, val loss: 0.20741, in 0.350s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01896, in 0.330s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20742, val loss: 0.20718, in 0.342s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01827, in 0.321s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01755, val loss: 0.01826, in 0.363s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01972, in 0.339s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20805, val loss: 0.20760, in 0.361s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21416, val loss: 0.21489, in 0.332s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20028, val loss: 0.20054, in 0.361s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01830, val loss: 0.01878, in 0.352s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20051, val loss: 0.20022, in 0.359s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01802, in 0.344s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01736, val loss: 0.01808, in 0.323s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01794, val loss: 0.01949, in 0.351s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20120, val loss: 0.20076, in 0.365s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20686, val loss: 0.20762, in 0.368s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19381, val loss: 0.19409, in 0.353s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19399, val loss: 0.19374, in 0.359s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01811, val loss: 0.01860, in 0.393s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01655, val loss: 0.01778, in 0.345s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01930, in 0.489s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01790, in 0.539s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19464, val loss: 0.19418, in 0.554s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19987, val loss: 0.20063, in 0.584s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18772, val loss: 0.18807, in 0.609s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01792, val loss: 0.01840, in 0.583s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18774, val loss: 0.18749, in 0.669s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01640, val loss: 0.01762, in 0.606s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01778, in 0.457s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01757, val loss: 0.01911, in 0.604s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18851, val loss: 0.18808, in 0.553s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19334, val loss: 0.19406, in 0.605s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01769, val loss: 0.01817, in 0.533s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18183, val loss: 0.18215, in 0.597s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18193, val loss: 0.18169, in 0.554s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01745, in 0.579s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01681, val loss: 0.01753, in 0.616s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01741, val loss: 0.01895, in 0.560s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18267, val loss: 0.18225, in 0.566s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18712, val loss: 0.18788, in 0.540s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17626, val loss: 0.17658, in 0.535s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01798, in 0.567s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01603, val loss: 0.01721, in 0.485s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17625, val loss: 0.17598, in 0.552s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01652, val loss: 0.01724, in 0.496s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01717, val loss: 0.01869, in 0.497s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17704, val loss: 0.17660, in 0.534s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18129, val loss: 0.18204, in 0.522s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17107, val loss: 0.17138, in 0.495s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01729, val loss: 0.01776, in 0.513s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17095, val loss: 0.17071, in 0.491s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01583, val loss: 0.01701, in 0.542s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01634, val loss: 0.01706, in 0.541s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01694, val loss: 0.01845, in 0.469s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17170, val loss: 0.17127, in 0.532s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17567, val loss: 0.17641, in 0.497s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16615, val loss: 0.16649, in 0.483s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01711, val loss: 0.01758, in 0.489s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16597, val loss: 0.16572, in 0.461s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01679, in 0.432s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01624, val loss: 0.01695, in 0.316s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01672, val loss: 0.01823, in 0.364s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16644, val loss: 0.16606, in 0.436s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16130, val loss: 0.16163, in 0.431s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17038, val loss: 0.17113, in 0.442s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01693, val loss: 0.01741, in 0.424s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01661, in 0.423s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01607, val loss: 0.01677, in 0.430s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16121, val loss: 0.16100, in 0.467s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01649, val loss: 0.01798, in 0.460s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16155, val loss: 0.16112, in 0.353s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16503, val loss: 0.16582, in 0.328s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15664, val loss: 0.15694, in 0.345s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01676, val loss: 0.01723, in 0.325s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01528, val loss: 0.01643, in 0.331s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15657, val loss: 0.15632, in 0.325s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01652, in 0.345s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01631, val loss: 0.01782, in 0.286s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15701, val loss: 0.15663, in 0.320s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16034, val loss: 0.16118, in 0.317s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01660, val loss: 0.01709, in 0.296s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15204, val loss: 0.15235, in 0.319s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15219, val loss: 0.15201, in 0.309s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01633, in 0.311s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01624, in 0.359s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01613, val loss: 0.01763, in 0.322s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15266, val loss: 0.15231, in 0.332s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01645, val loss: 0.01693, in 0.339s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15568, val loss: 0.15653, in 0.350s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14791, val loss: 0.14825, in 0.357s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14786, val loss: 0.14766, in 0.354s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01600, in 0.343s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01612, in 0.376s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01749, in 0.356s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14838, val loss: 0.14807, in 0.318s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01674, in 0.304s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15131, val loss: 0.15217, in 0.309s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14391, val loss: 0.14422, in 0.310s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14392, val loss: 0.14372, in 0.312s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01583, in 0.326s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01595, in 0.317s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01583, val loss: 0.01734, in 0.328s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01655, in 0.296s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14446, val loss: 0.14414, in 0.327s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14730, val loss: 0.14820, in 0.320s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14021, val loss: 0.14059, in 0.312s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14007, val loss: 0.13989, in 0.313s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01571, in 0.306s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01562, in 0.327s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01567, val loss: 0.01717, in 0.291s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01594, val loss: 0.01643, in 0.274s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14077, val loss: 0.14049, in 0.293s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14321, val loss: 0.14410, in 0.303s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13665, val loss: 0.13701, in 0.299s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13650, val loss: 0.13628, in 0.311s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01439, val loss: 0.01550, in 0.303s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01485, val loss: 0.01555, in 0.311s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01548, val loss: 0.01696, in 0.297s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01625, in 0.335s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13696, val loss: 0.13666, in 0.323s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13333, val loss: 0.13368, in 0.438s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.13948, val loss: 0.14038, in 0.457s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01533, val loss: 0.01681, in 0.501s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13304, val loss: 0.13283, in 0.563s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01529, in 0.577s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01532, in 0.575s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13363, val loss: 0.13333, in 0.637s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01609, in 0.670s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13573, val loss: 0.13667, in 0.555s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13004, val loss: 0.13042, in 0.563s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01671, in 0.423s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01404, val loss: 0.01514, in 0.491s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01449, val loss: 0.01518, in 0.505s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12969, val loss: 0.12947, in 0.572s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13040, val loss: 0.13012, in 0.569s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01543, val loss: 0.01592, in 0.562s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12693, val loss: 0.12728, in 0.536s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13209, val loss: 0.13307, in 0.540s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01650, in 0.574s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01390, val loss: 0.01499, in 0.549s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01502, in 0.544s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12665, val loss: 0.12648, in 0.530s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01574, in 0.508s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12724, val loss: 0.12698, in 0.547s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12381, val loss: 0.12420, in 0.542s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12884, val loss: 0.12981, in 0.569s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01632, in 0.528s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01493, in 0.440s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01484, in 0.525s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12376, val loss: 0.12357, in 0.533s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01560, in 0.517s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12398, val loss: 0.12371, in 0.560s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12073, val loss: 0.12117, in 0.557s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12569, val loss: 0.12667, in 0.545s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01475, val loss: 0.01620, in 0.523s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01410, val loss: 0.01478, in 0.560s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01464, in 0.530s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12079, val loss: 0.12064, in 0.523s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01544, in 0.436s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01464, val loss: 0.01609, in 0.326s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12091, val loss: 0.12072, in 0.410s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12272, val loss: 0.12375, in 0.369s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11799, val loss: 0.11840, in 0.397s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01465, in 0.328s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11784, val loss: 0.11768, in 0.432s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01345, val loss: 0.01452, in 0.490s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01478, val loss: 0.01527, in 0.414s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01599, in 0.429s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11802, val loss: 0.11786, in 0.433s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11987, val loss: 0.12092, in 0.441s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11534, val loss: 0.11578, in 0.434s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01452, in 0.415s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11524, val loss: 0.11506, in 0.340s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01435, in 0.306s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01510, in 0.314s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01441, val loss: 0.01585, in 0.307s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11543, val loss: 0.11527, in 0.331s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01440, in 0.291s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11702, val loss: 0.11805, in 0.312s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11278, val loss: 0.11317, in 0.347s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11269, val loss: 0.11252, in 0.339s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01423, in 0.362s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01445, val loss: 0.01493, in 0.325s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01429, in 0.317s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11290, val loss: 0.11277, in 0.350s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01426, val loss: 0.01571, in 0.379s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11435, val loss: 0.11546, in 0.353s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11011, val loss: 0.11053, in 0.328s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11033, val loss: 0.11019, in 0.336s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01305, val loss: 0.01409, in 0.310s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01478, in 0.332s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11050, val loss: 0.11035, in 0.342s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01342, val loss: 0.01411, in 0.374s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01412, val loss: 0.01558, in 0.367s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11189, val loss: 0.11297, in 0.348s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10751, val loss: 0.10800, in 0.339s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01393, in 0.332s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10784, val loss: 0.10772, in 0.342s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01416, val loss: 0.01464, in 0.385s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10816, val loss: 0.10802, in 0.338s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10946, val loss: 0.11056, in 0.330s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01399, val loss: 0.01544, in 0.335s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01327, val loss: 0.01395, in 0.352s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10534, val loss: 0.10580, in 0.358s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01378, in 0.312s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10548, val loss: 0.10541, in 0.331s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01449, in 0.333s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01310, val loss: 0.01378, in 0.302s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01530, in 0.316s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10598, val loss: 0.10577, in 0.342s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10712, val loss: 0.10826, in 0.335s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10308, val loss: 0.10360, in 0.331s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01362, in 0.311s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10319, val loss: 0.10314, in 0.342s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01444, in 0.245s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01517, in 0.419s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01370, in 0.464s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10368, val loss: 0.10347, in 0.511s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10489, val loss: 0.10604, in 0.523s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10081, val loss: 0.10135, in 0.526s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01347, in 0.560s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10106, val loss: 0.10101, in 0.568s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01381, val loss: 0.01431, in 0.699s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01361, val loss: 0.01505, in 0.525s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01282, val loss: 0.01349, in 0.604s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10160, val loss: 0.10136, in 0.576s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10244, val loss: 0.10362, in 0.555s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09874, val loss: 0.09928, in 0.583s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01231, val loss: 0.01335, in 0.557s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09900, val loss: 0.09896, in 0.528s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01368, val loss: 0.01420, in 0.492s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01341, in 0.428s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01350, val loss: 0.01492, in 0.595s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09944, val loss: 0.09919, in 0.556s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10050, val loss: 0.10166, in 0.565s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09671, val loss: 0.09725, in 0.546s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01319, in 0.524s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09691, val loss: 0.09687, in 0.550s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01355, val loss: 0.01407, in 0.568s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01261, val loss: 0.01329, in 0.537s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01480, in 0.533s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09760, val loss: 0.09731, in 0.579s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09833, val loss: 0.09948, in 0.575s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09486, val loss: 0.09540, in 0.540s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01207, val loss: 0.01311, in 0.555s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09513, val loss: 0.09507, in 0.578s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01249, val loss: 0.01317, in 0.453s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01341, val loss: 0.01393, in 0.578s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01328, val loss: 0.01469, in 0.474s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09563, val loss: 0.09534, in 0.557s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09620, val loss: 0.09735, in 0.556s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09313, val loss: 0.09364, in 0.581s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01194, val loss: 0.01299, in 0.580s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09311, val loss: 0.09306, in 0.545s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01235, val loss: 0.01302, in 0.533s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01311, val loss: 0.01452, in 0.492s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01378, in 0.533s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09433, val loss: 0.09550, in 0.462s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09386, val loss: 0.09354, in 0.489s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09121, val loss: 0.09175, in 0.472s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01182, val loss: 0.01285, in 0.441s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09128, val loss: 0.09126, in 0.455s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01225, val loss: 0.01291, in 0.441s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01300, val loss: 0.01440, in 0.422s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01313, val loss: 0.01366, in 0.422s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09260, val loss: 0.09374, in 0.353s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09204, val loss: 0.09172, in 0.339s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01168, val loss: 0.01271, in 0.340s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08967, val loss: 0.09021, in 0.351s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08973, val loss: 0.08971, in 0.334s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01276, in 0.298s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01429, in 0.308s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01301, val loss: 0.01356, in 0.307s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09043, val loss: 0.09013, in 0.385s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09077, val loss: 0.09191, in 0.401s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08795, val loss: 0.08855, in 0.374s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01260, in 0.385s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08809, val loss: 0.08806, in 0.407s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01264, in 0.399s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01344, in 0.400s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01144, val loss: 0.01247, in 0.326s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08873, val loss: 0.08844, in 0.360s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08922, val loss: 0.09040, in 0.360s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08640, val loss: 0.08698, in 0.357s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08665, val loss: 0.08659, in 0.346s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01178, val loss: 0.01244, in 0.317s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01334, in 0.331s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01133, val loss: 0.01234, in 0.321s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08711, val loss: 0.08688, in 0.345s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08748, val loss: 0.08864, in 0.331s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08499, val loss: 0.08553, in 0.329s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08516, val loss: 0.08511, in 0.327s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01233, in 0.353s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01267, val loss: 0.01322, in 0.357s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01125, val loss: 0.01226, in 0.341s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08578, val loss: 0.08554, in 0.314s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08337, val loss: 0.08393, in 0.317s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08605, val loss: 0.08722, in 0.330s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08359, val loss: 0.08363, in 0.309s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01310, in 0.273s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08200, val loss: 0.08254, in 0.297s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08430, val loss: 0.08407, in 0.312s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08441, val loss: 0.08565, in 0.306s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08213, val loss: 0.08220, in 0.312s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08273, val loss: 0.08255, in 0.303s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08028, val loss: 0.08081, in 0.460s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08288, val loss: 0.08415, in 0.448s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08077, val loss: 0.08085, in 0.491s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08147, val loss: 0.08129, in 0.647s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07875, val loss: 0.07926, in 0.529s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08134, val loss: 0.08265, in 0.530s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07916, val loss: 0.07926, in 0.506s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07984, val loss: 0.08116, in 0.470s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07976, val loss: 0.07962, in 0.510s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07721, val loss: 0.07774, in 0.495s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07768, val loss: 0.07777, in 0.496s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07834, val loss: 0.07821, in 0.484s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07584, val loss: 0.07637, in 0.487s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07857, val loss: 0.07995, in 0.513s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07631, val loss: 0.07637, in 0.501s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07693, val loss: 0.07680, in 0.471s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07711, val loss: 0.07849, in 0.479s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07443, val loss: 0.07494, in 0.491s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07481, val loss: 0.07487, in 0.468s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07579, val loss: 0.07717, in 0.318s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07316, val loss: 0.07365, in 0.317s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07546, val loss: 0.07533, in 0.357s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07350, val loss: 0.07358, in 0.394s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07455, val loss: 0.07593, in 0.398s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07194, val loss: 0.07242, in 0.412s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07411, val loss: 0.07400, in 0.429s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07236, val loss: 0.07247, in 0.294s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07315, val loss: 0.07456, in 0.274s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07057, val loss: 0.07107, in 0.283s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07289, val loss: 0.07277, in 0.280s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07089, val loss: 0.07106, in 0.288s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07169, val loss: 0.07310, in 0.307s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06943, val loss: 0.06992, in 0.309s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07149, val loss: 0.07138, in 0.305s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06968, val loss: 0.06984, in 0.311s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07036, val loss: 0.07183, in 0.307s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06805, val loss: 0.06860, in 0.296s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07021, val loss: 0.07015, in 0.292s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06835, val loss: 0.06857, in 0.298s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06928, val loss: 0.07075, in 0.285s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06907, val loss: 0.06902, in 0.293s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06696, val loss: 0.06753, in 0.310s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06726, val loss: 0.06748, in 0.300s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06790, val loss: 0.06937, in 0.310s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06793, val loss: 0.06792, in 0.298s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06581, val loss: 0.06642, in 0.307s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01277, val loss: 0.01417, in 0.448s\n",
      "Fit 200 trees in 85.944 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.038s\n",
      "Time spent finding best splits:  1.471s\n",
      "Time spent applying splits:      10.855s\n",
      "Time spent predicting:           0.661s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06609, val loss: 0.06633, in 0.298s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06679, val loss: 0.06824, in 0.289s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06692, val loss: 0.06694, in 0.297s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06496, val loss: 0.06559, in 0.304s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06469, val loss: 0.06494, in 0.371s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06560, val loss: 0.06704, in 0.586s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06585, val loss: 0.06589, in 0.581s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06387, val loss: 0.06448, in 0.611s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06371, val loss: 0.06396, in 0.572s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01153, val loss: 0.01217, in 0.274s\n",
      "Fit 200 trees in 85.594 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.201s\n",
      "Time spent finding best splits:  1.498s\n",
      "Time spent applying splits:      10.120s\n",
      "Time spent predicting:           0.718s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06429, val loss: 0.06570, in 0.518s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06482, val loss: 0.06486, in 0.497s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06274, val loss: 0.06338, in 0.485s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06283, val loss: 0.06307, in 0.477s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01214, in 0.299s\n",
      "Fit 200 trees in 85.861 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.302s\n",
      "Time spent finding best splits:  1.582s\n",
      "Time spent applying splits:      10.482s\n",
      "Time spent predicting:           0.715s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01300, in 0.272s\n",
      "Fit 200 trees in 85.757 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.553s\n",
      "Time spent finding best splits:  1.502s\n",
      "Time spent applying splits:      10.145s\n",
      "Time spent predicting:           0.849s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06300, val loss: 0.06439, in 0.491s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06385, val loss: 0.06391, in 0.509s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06174, val loss: 0.06239, in 0.506s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06183, val loss: 0.06205, in 0.516s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06203, val loss: 0.06342, in 0.504s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06286, val loss: 0.06293, in 0.520s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06074, val loss: 0.06140, in 0.537s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06095, val loss: 0.06120, in 0.502s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06092, val loss: 0.06228, in 0.392s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06193, val loss: 0.06202, in 0.368s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05921, val loss: 0.05987, in 0.358s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06003, val loss: 0.06032, in 0.349s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06058, val loss: 0.06070, in 0.393s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05978, val loss: 0.06117, in 0.409s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05880, val loss: 0.05909, in 0.382s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05796, val loss: 0.05862, in 0.403s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05900, val loss: 0.06038, in 0.284s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05965, val loss: 0.05981, in 0.294s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05799, val loss: 0.05831, in 0.272s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05678, val loss: 0.05745, in 0.268s\n",
      "[85/200] 3.510 s\n",
      "Binning 0.013 GB of validation data: 0.124 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05881, val loss: 0.05899, in 0.294s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05821, val loss: 0.05959, in 0.304s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05692, val loss: 0.05727, in 0.292s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05594, val loss: 0.05662, in 0.300s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65053, val loss: 0.65053, in 0.272s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05705, val loss: 0.05841, in 0.283s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05753, val loss: 0.05772, in 0.300s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05593, val loss: 0.05630, in 0.287s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05486, val loss: 0.05557, in 0.308s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61200, val loss: 0.61206, in 0.315s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05624, val loss: 0.05763, in 0.311s\n",
      "[86/200] 3.125 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05634, val loss: 0.05652, in 0.310s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05511, val loss: 0.05548, in 0.332s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05422, val loss: 0.05493, in 0.314s\n",
      "[88/200] 0.105 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57687, val loss: 0.57696, in 0.252s\n",
      "[4/200] 2.983 s\n",
      "Binning 0.013 GB of validation data: 2.969 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05528, val loss: 0.05547, in 0.278s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05533, val loss: 0.05674, in 0.297s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05436, val loss: 0.05475, in 0.279s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05297, val loss: 0.05368, in 0.287s\n",
      "[89/200] 0.109 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65055, val loss: 0.65058, in 0.255s\n",
      "[2/200] 0.119 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54454, val loss: 0.54464, in 0.270s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05430, val loss: 0.05568, in 0.255s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05457, val loss: 0.05479, in 0.269s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05333, val loss: 0.05372, in 0.260s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05204, val loss: 0.05275, in 0.262s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.65051, val loss: 0.65053, in 0.243s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61200, val loss: 0.61202, in 0.268s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65016, val loss: 0.65014, in 0.254s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51489, val loss: 0.51498, in 0.260s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05350, val loss: 0.05487, in 0.438s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05383, val loss: 0.05402, in 0.454s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05242, val loss: 0.05285, in 0.461s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05100, val loss: 0.05171, in 0.477s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61194, val loss: 0.61200, in 0.496s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57694, val loss: 0.57696, in 0.495s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61118, val loss: 0.61120, in 0.520s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48770, val loss: 0.48784, in 0.525s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05282, val loss: 0.05419, in 0.447s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05260, val loss: 0.05278, in 0.458s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05178, val loss: 0.05223, in 0.451s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05014, val loss: 0.05085, in 0.469s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57689, val loss: 0.57694, in 0.438s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54467, val loss: 0.54468, in 0.426s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57580, val loss: 0.57581, in 0.410s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46263, val loss: 0.46279, in 0.435s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05188, val loss: 0.05325, in 0.447s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05167, val loss: 0.05187, in 0.438s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05083, val loss: 0.05128, in 0.452s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.05026, in 0.469s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54454, val loss: 0.54457, in 0.445s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51505, val loss: 0.51504, in 0.441s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54338, val loss: 0.54342, in 0.435s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43967, val loss: 0.43978, in 0.423s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05123, val loss: 0.05261, in 0.474s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05056, val loss: 0.05073, in 0.459s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.04998, in 0.459s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04894, val loss: 0.04968, in 0.441s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51494, val loss: 0.51498, in 0.443s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51385, val loss: 0.51387, in 0.441s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48785, val loss: 0.48786, in 0.452s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41819, val loss: 0.41833, in 0.445s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04970, val loss: 0.04988, in 0.443s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05050, val loss: 0.05190, in 0.455s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04835, val loss: 0.04876, in 0.452s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48797, val loss: 0.48803, in 0.429s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04784, val loss: 0.04858, in 0.450s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46282, val loss: 0.46282, in 0.421s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48648, val loss: 0.48655, in 0.431s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39842, val loss: 0.39861, in 0.392s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04866, val loss: 0.04884, in 0.303s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04925, val loss: 0.05061, in 0.314s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04751, val loss: 0.04792, in 0.293s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46307, val loss: 0.46315, in 0.260s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43955, val loss: 0.43955, in 0.253s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04707, val loss: 0.04781, in 0.276s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46110, val loss: 0.46122, in 0.261s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37960, val loss: 0.37984, in 0.373s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04809, val loss: 0.04938, in 0.425s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04805, val loss: 0.04825, in 0.458s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43985, val loss: 0.43993, in 0.437s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04642, val loss: 0.04681, in 0.450s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41807, val loss: 0.41809, in 0.428s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04610, val loss: 0.04685, in 0.433s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43781, val loss: 0.43798, in 0.437s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36215, val loss: 0.36239, in 0.319s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04728, val loss: 0.04858, in 0.278s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04711, val loss: 0.04730, in 0.270s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41836, val loss: 0.41847, in 0.263s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39823, val loss: 0.39825, in 0.270s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04540, val loss: 0.04577, in 0.275s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04544, val loss: 0.04621, in 0.259s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41638, val loss: 0.41656, in 0.275s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34585, val loss: 0.34615, in 0.272s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04636, val loss: 0.04655, in 0.282s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04622, val loss: 0.04747, in 0.300s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39840, val loss: 0.39853, in 0.294s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37943, val loss: 0.37946, in 0.292s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04484, val loss: 0.04560, in 0.286s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39605, val loss: 0.39624, in 0.277s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04483, val loss: 0.04522, in 0.320s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33088, val loss: 0.33117, in 0.284s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04561, val loss: 0.04582, in 0.331s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37962, val loss: 0.37977, in 0.305s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04563, val loss: 0.04691, in 0.328s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36202, val loss: 0.36205, in 0.323s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37717, val loss: 0.37740, in 0.324s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04406, val loss: 0.04485, in 0.342s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31669, val loss: 0.31704, in 0.311s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04388, val loss: 0.04425, in 0.318s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36223, val loss: 0.36238, in 0.309s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04490, val loss: 0.04511, in 0.316s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04464, val loss: 0.04588, in 0.316s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34569, val loss: 0.34574, in 0.297s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36013, val loss: 0.36037, in 0.302s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04316, val loss: 0.04354, in 0.306s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04315, val loss: 0.04393, in 0.318s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30347, val loss: 0.30386, in 0.319s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34600, val loss: 0.34618, in 0.293s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04372, val loss: 0.04492, in 0.296s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33065, val loss: 0.33072, in 0.297s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04423, val loss: 0.04444, in 0.323s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34370, val loss: 0.34397, in 0.303s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04267, in 0.310s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04252, val loss: 0.04331, in 0.306s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29107, val loss: 0.29155, in 0.307s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33087, val loss: 0.33107, in 0.284s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31651, val loss: 0.31661, in 0.278s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04302, val loss: 0.04422, in 0.295s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04342, val loss: 0.04363, in 0.279s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32841, val loss: 0.32875, in 0.283s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04169, val loss: 0.04250, in 0.285s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27944, val loss: 0.27994, in 0.284s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04160, val loss: 0.04196, in 0.317s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31678, val loss: 0.31703, in 0.443s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30338, val loss: 0.30347, in 0.475s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04249, val loss: 0.04371, in 0.504s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04289, val loss: 0.04314, in 0.510s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31399, val loss: 0.31434, in 0.501s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26853, val loss: 0.26909, in 0.517s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04118, val loss: 0.04198, in 0.547s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04103, val loss: 0.04135, in 0.551s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30368, val loss: 0.30399, in 0.459s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29093, val loss: 0.29106, in 0.472s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04231, val loss: 0.04257, in 0.449s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04164, val loss: 0.04283, in 0.470s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30052, val loss: 0.30090, in 0.453s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25816, val loss: 0.25878, in 0.458s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04048, val loss: 0.04128, in 0.441s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04049, val loss: 0.04083, in 0.434s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29125, val loss: 0.29157, in 0.453s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27927, val loss: 0.27941, in 0.470s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28813, val loss: 0.28855, in 0.450s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04103, val loss: 0.04221, in 0.489s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24851, val loss: 0.24918, in 0.455s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04180, val loss: 0.04206, in 0.538s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03970, val loss: 0.04003, in 0.481s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03996, val loss: 0.04077, in 0.522s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27956, val loss: 0.27991, in 0.480s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26827, val loss: 0.26847, in 0.477s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27655, val loss: 0.27700, in 0.466s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04043, val loss: 0.04159, in 0.481s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23937, val loss: 0.24003, in 0.497s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04109, val loss: 0.04132, in 0.517s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03911, val loss: 0.03942, in 0.500s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03919, val loss: 0.03999, in 0.498s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26859, val loss: 0.26900, in 0.535s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25797, val loss: 0.25825, in 0.539s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26543, val loss: 0.26593, in 0.544s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03966, val loss: 0.04078, in 0.518s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23067, val loss: 0.23137, in 0.501s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03864, val loss: 0.03946, in 0.443s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03863, val loss: 0.03897, in 0.465s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04051, val loss: 0.04075, in 0.495s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25833, val loss: 0.25878, in 0.324s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24829, val loss: 0.24860, in 0.276s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25500, val loss: 0.25553, in 0.293s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.04029, in 0.353s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22242, val loss: 0.22321, in 0.392s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03792, val loss: 0.03825, in 0.384s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03797, val loss: 0.03877, in 0.411s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03986, val loss: 0.04011, in 0.418s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24845, val loss: 0.24895, in 0.402s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23909, val loss: 0.23945, in 0.381s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24540, val loss: 0.24598, in 0.365s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03738, val loss: 0.03771, in 0.260s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21474, val loss: 0.21552, in 0.287s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03853, val loss: 0.03966, in 0.352s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03742, val loss: 0.03822, in 0.283s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03917, val loss: 0.03944, in 0.268s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23931, val loss: 0.23988, in 0.289s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23054, val loss: 0.23093, in 0.278s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23612, val loss: 0.23672, in 0.298s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20743, val loss: 0.20825, in 0.292s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03676, val loss: 0.03707, in 0.304s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03895, in 0.299s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03678, val loss: 0.03758, in 0.313s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03872, val loss: 0.03902, in 0.319s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23070, val loss: 0.23131, in 0.259s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22216, val loss: 0.22258, in 0.284s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22735, val loss: 0.22800, in 0.288s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03620, val loss: 0.03651, in 0.254s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03733, val loss: 0.03841, in 0.277s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20061, val loss: 0.20149, in 0.299s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03810, val loss: 0.03838, in 0.254s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03623, val loss: 0.03703, in 0.269s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22258, val loss: 0.22322, in 0.267s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21443, val loss: 0.21488, in 0.277s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21919, val loss: 0.21988, in 0.273s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03555, val loss: 0.03587, in 0.267s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03658, val loss: 0.03767, in 0.288s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19413, val loss: 0.19504, in 0.279s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03562, val loss: 0.03640, in 0.267s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03762, val loss: 0.03790, in 0.292s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21472, val loss: 0.21540, in 0.278s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20719, val loss: 0.20764, in 0.281s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21148, val loss: 0.21223, in 0.278s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03494, val loss: 0.03524, in 0.288s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03606, val loss: 0.03716, in 0.259s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18789, val loss: 0.18885, in 0.282s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03493, val loss: 0.03572, in 0.287s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03703, val loss: 0.03731, in 0.266s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20745, val loss: 0.20822, in 0.264s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20029, val loss: 0.20080, in 0.279s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20420, val loss: 0.20501, in 0.273s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03476, in 0.292s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03543, val loss: 0.03652, in 0.282s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03447, val loss: 0.03526, in 0.258s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18211, val loss: 0.18314, in 0.281s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03662, in 0.295s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20055, val loss: 0.20132, in 0.321s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19378, val loss: 0.19439, in 0.307s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19720, val loss: 0.19797, in 0.322s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03394, val loss: 0.03425, in 0.290s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03477, val loss: 0.03584, in 0.498s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03408, val loss: 0.03485, in 0.481s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17648, val loss: 0.17755, in 0.510s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03592, val loss: 0.03620, in 0.525s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19406, val loss: 0.19486, in 0.581s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18767, val loss: 0.18834, in 0.594s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19058, val loss: 0.19146, in 0.613s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03325, val loss: 0.03356, in 0.683s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03416, val loss: 0.03525, in 0.494s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17121, val loss: 0.17234, in 0.488s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03346, val loss: 0.03423, in 0.546s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03542, val loss: 0.03569, in 0.519s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18789, val loss: 0.18878, in 0.503s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18171, val loss: 0.18241, in 0.521s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18432, val loss: 0.18517, in 0.516s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03267, val loss: 0.03298, in 0.488s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03359, val loss: 0.03469, in 0.472s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03299, val loss: 0.03374, in 0.465s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16619, val loss: 0.16736, in 0.489s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03494, val loss: 0.03519, in 0.482s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18194, val loss: 0.18286, in 0.502s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17595, val loss: 0.17672, in 0.488s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17842, val loss: 0.17934, in 0.459s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03260, in 0.467s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03409, in 0.498s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03259, val loss: 0.03334, in 0.458s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16120, val loss: 0.16242, in 0.483s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03472, in 0.448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17628, val loss: 0.17728, in 0.502s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17065, val loss: 0.17144, in 0.463s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17275, val loss: 0.17370, in 0.501s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03266, val loss: 0.03375, in 0.454s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03166, val loss: 0.03198, in 0.506s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03199, val loss: 0.03275, in 0.499s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15672, val loss: 0.15797, in 0.491s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03394, val loss: 0.03420, in 0.471s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17104, val loss: 0.17209, in 0.418s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16560, val loss: 0.16644, in 0.405s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16739, val loss: 0.16834, in 0.390s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03168, in 0.343s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03169, val loss: 0.03244, in 0.305s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03345, val loss: 0.03372, in 0.325s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03337, in 0.418s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15241, val loss: 0.15374, in 0.408s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16087, val loss: 0.16180, in 0.407s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16604, val loss: 0.16716, in 0.424s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16224, val loss: 0.16324, in 0.431s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03086, val loss: 0.03118, in 0.409s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03326, in 0.377s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03181, val loss: 0.03292, in 0.372s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03125, val loss: 0.03199, in 0.440s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14817, val loss: 0.14959, in 0.324s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16125, val loss: 0.16247, in 0.287s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15609, val loss: 0.15712, in 0.312s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03086, in 0.311s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15735, val loss: 0.15839, in 0.322s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03129, val loss: 0.03242, in 0.286s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03263, val loss: 0.03291, in 0.311s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03072, val loss: 0.03147, in 0.306s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14419, val loss: 0.14566, in 0.301s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15179, val loss: 0.15288, in 0.276s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15658, val loss: 0.15783, in 0.298s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03086, val loss: 0.03196, in 0.269s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03039, in 0.287s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14045, val loss: 0.14198, in 0.294s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03217, val loss: 0.03246, in 0.315s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03040, val loss: 0.03115, in 0.312s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15283, val loss: 0.15392, in 0.374s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14764, val loss: 0.14876, in 0.295s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15216, val loss: 0.15341, in 0.319s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03049, val loss: 0.03160, in 0.297s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02961, val loss: 0.02993, in 0.290s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03172, val loss: 0.03202, in 0.279s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13682, val loss: 0.13837, in 0.303s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02988, val loss: 0.03064, in 0.309s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14849, val loss: 0.14959, in 0.276s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14360, val loss: 0.14478, in 0.321s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14792, val loss: 0.14927, in 0.287s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02928, val loss: 0.02960, in 0.286s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03005, val loss: 0.03114, in 0.304s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03140, val loss: 0.03171, in 0.298s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13318, val loss: 0.13476, in 0.305s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03019, in 0.295s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14436, val loss: 0.14553, in 0.311s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13974, val loss: 0.14095, in 0.290s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14396, val loss: 0.14541, in 0.290s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02953, val loss: 0.03060, in 0.300s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02901, val loss: 0.02933, in 0.312s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.03125, in 0.289s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12989, val loss: 0.13155, in 0.285s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02898, val loss: 0.02971, in 0.314s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14047, val loss: 0.14169, in 0.304s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13593, val loss: 0.13714, in 0.293s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14007, val loss: 0.14153, in 0.303s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02846, val loss: 0.02876, in 0.312s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02924, val loss: 0.03032, in 0.324s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03041, val loss: 0.03075, in 0.307s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02865, val loss: 0.02937, in 0.271s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12681, val loss: 0.12851, in 0.315s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13649, val loss: 0.13780, in 0.339s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13219, val loss: 0.13349, in 0.524s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13642, val loss: 0.13789, in 0.539s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02809, val loss: 0.02840, in 0.601s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02886, val loss: 0.02993, in 0.598s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02990, val loss: 0.03024, in 0.630s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02827, val loss: 0.02898, in 0.634s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12366, val loss: 0.12534, in 0.636s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13298, val loss: 0.13435, in 0.621s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13289, val loss: 0.13444, in 0.484s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12893, val loss: 0.13022, in 0.520s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02838, val loss: 0.02943, in 0.499s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02758, val loss: 0.02788, in 0.514s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.02988, in 0.461s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02793, val loss: 0.02863, in 0.498s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12072, val loss: 0.12242, in 0.519s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12955, val loss: 0.13097, in 0.500s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12581, val loss: 0.12713, in 0.487s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12959, val loss: 0.13119, in 0.511s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02758, in 0.472s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02914, val loss: 0.02949, in 0.481s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02790, val loss: 0.02893, in 0.524s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11794, val loss: 0.11968, in 0.486s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02760, val loss: 0.02829, in 0.528s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12616, val loss: 0.12759, in 0.503s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12278, val loss: 0.12417, in 0.527s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12644, val loss: 0.12802, in 0.521s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02695, val loss: 0.02724, in 0.470s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02889, val loss: 0.02925, in 0.487s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11514, val loss: 0.11692, in 0.489s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02751, val loss: 0.02854, in 0.587s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02731, val loss: 0.02801, in 0.526s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12301, val loss: 0.12452, in 0.504s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11991, val loss: 0.12134, in 0.460s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12318, val loss: 0.12479, in 0.454s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02665, val loss: 0.02695, in 0.480s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02888, in 0.493s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11267, val loss: 0.11448, in 0.421s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02708, val loss: 0.02810, in 0.393s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11984, val loss: 0.12138, in 0.371s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02698, val loss: 0.02766, in 0.389s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12033, val loss: 0.12196, in 0.466s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11722, val loss: 0.11864, in 0.480s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02616, val loss: 0.02645, in 0.500s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02823, val loss: 0.02862, in 0.495s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02652, val loss: 0.02720, in 0.493s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11015, val loss: 0.11197, in 0.519s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11689, val loss: 0.11844, in 0.511s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02665, val loss: 0.02766, in 0.519s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11739, val loss: 0.11906, in 0.353s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11461, val loss: 0.11606, in 0.348s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02586, val loss: 0.02614, in 0.347s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02779, val loss: 0.02818, in 0.357s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11414, val loss: 0.11579, in 0.337s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10772, val loss: 0.10955, in 0.364s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02627, val loss: 0.02725, in 0.362s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02627, val loss: 0.02695, in 0.394s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11198, val loss: 0.11351, in 0.371s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11461, val loss: 0.11633, in 0.389s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02555, val loss: 0.02580, in 0.343s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02752, val loss: 0.02791, in 0.385s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11158, val loss: 0.11330, in 0.383s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02589, val loss: 0.02655, in 0.352s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10528, val loss: 0.10720, in 0.384s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02596, val loss: 0.02695, in 0.397s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10966, val loss: 0.11123, in 0.360s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11217, val loss: 0.11390, in 0.358s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02510, val loss: 0.02534, in 0.361s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02715, val loss: 0.02754, in 0.340s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02563, val loss: 0.02662, in 0.298s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10887, val loss: 0.11062, in 0.340s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10316, val loss: 0.10517, in 0.327s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02553, val loss: 0.02618, in 0.346s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10970, val loss: 0.11147, in 0.318s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10735, val loss: 0.10900, in 0.334s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02482, val loss: 0.02506, in 0.325s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02677, val loss: 0.02714, in 0.357s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10101, val loss: 0.10304, in 0.331s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10639, val loss: 0.10817, in 0.353s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02524, val loss: 0.02590, in 0.343s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02528, val loss: 0.02627, in 0.380s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10515, val loss: 0.10689, in 0.339s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10744, val loss: 0.10928, in 0.362s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02444, val loss: 0.02466, in 0.331s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09885, val loss: 0.10091, in 0.350s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02651, val loss: 0.02690, in 0.371s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10397, val loss: 0.10575, in 0.355s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02503, val loss: 0.02604, in 0.347s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02500, val loss: 0.02567, in 0.368s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10291, val loss: 0.10468, in 0.348s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10518, val loss: 0.10706, in 0.339s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02409, val loss: 0.02431, in 0.354s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02657, in 0.354s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02468, val loss: 0.02536, in 0.378s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09681, val loss: 0.09889, in 0.424s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10179, val loss: 0.10359, in 0.411s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02473, val loss: 0.02574, in 0.445s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10055, val loss: 0.10236, in 0.442s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10306, val loss: 0.10490, in 0.458s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02369, val loss: 0.02389, in 0.431s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02585, val loss: 0.02623, in 0.560s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09486, val loss: 0.09695, in 0.592s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09967, val loss: 0.10151, in 0.616s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02446, val loss: 0.02514, in 0.630s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02437, val loss: 0.02536, in 0.570s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09869, val loss: 0.10049, in 0.633s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10089, val loss: 0.10283, in 0.635s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02358, in 0.699s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02559, val loss: 0.02599, in 0.547s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09292, val loss: 0.09506, in 0.569s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02421, val loss: 0.02487, in 0.557s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09772, val loss: 0.09951, in 0.575s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02417, val loss: 0.02516, in 0.581s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09664, val loss: 0.09846, in 0.571s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09900, val loss: 0.10091, in 0.615s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02335, in 0.553s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02523, val loss: 0.02562, in 0.606s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02388, val loss: 0.02455, in 0.572s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09127, val loss: 0.09339, in 0.604s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09554, val loss: 0.09737, in 0.570s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02383, val loss: 0.02480, in 0.668s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09467, val loss: 0.09648, in 0.585s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09717, val loss: 0.09908, in 0.568s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02290, val loss: 0.02311, in 0.602s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02498, val loss: 0.02537, in 0.581s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02365, val loss: 0.02432, in 0.544s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08950, val loss: 0.09167, in 0.555s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09349, val loss: 0.09536, in 0.566s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09275, val loss: 0.09463, in 0.538s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02355, val loss: 0.02451, in 0.609s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09517, val loss: 0.09709, in 0.542s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02257, val loss: 0.02278, in 0.512s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02467, val loss: 0.02508, in 0.551s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02338, val loss: 0.02404, in 0.546s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09142, val loss: 0.09332, in 0.525s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08780, val loss: 0.08990, in 0.546s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02422, in 0.453s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09098, val loss: 0.09291, in 0.479s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02236, val loss: 0.02256, in 0.383s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09322, val loss: 0.09516, in 0.455s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02437, val loss: 0.02476, in 0.508s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08615, val loss: 0.08831, in 0.450s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02303, val loss: 0.02370, in 0.472s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08939, val loss: 0.09135, in 0.461s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02286, val loss: 0.02381, in 0.443s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08925, val loss: 0.09122, in 0.438s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09145, val loss: 0.09339, in 0.445s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02213, val loss: 0.02235, in 0.462s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02275, val loss: 0.02342, in 0.324s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02404, val loss: 0.02442, in 0.354s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08465, val loss: 0.08684, in 0.338s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08765, val loss: 0.08967, in 0.341s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02256, val loss: 0.02350, in 0.305s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08761, val loss: 0.08962, in 0.333s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08959, val loss: 0.09156, in 0.332s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02189, val loss: 0.02210, in 0.334s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02376, val loss: 0.02415, in 0.303s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02243, val loss: 0.02309, in 0.330s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08311, val loss: 0.08530, in 0.334s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08589, val loss: 0.08796, in 0.344s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02222, val loss: 0.02317, in 0.352s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08601, val loss: 0.08808, in 0.344s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08794, val loss: 0.08986, in 0.356s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02175, in 0.364s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02222, val loss: 0.02291, in 0.328s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02344, val loss: 0.02383, in 0.358s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08180, val loss: 0.08400, in 0.341s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08437, val loss: 0.08643, in 0.337s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02188, val loss: 0.02283, in 0.334s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08451, val loss: 0.08656, in 0.322s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08636, val loss: 0.08829, in 0.317s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02132, val loss: 0.02155, in 0.333s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02316, val loss: 0.02355, in 0.312s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02190, val loss: 0.02259, in 0.344s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08016, val loss: 0.08235, in 0.334s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08278, val loss: 0.08491, in 0.321s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02162, val loss: 0.02257, in 0.313s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08309, val loss: 0.08513, in 0.317s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08475, val loss: 0.08673, in 0.312s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02123, in 0.321s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02227, in 0.322s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02285, val loss: 0.02325, in 0.358s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07879, val loss: 0.08100, in 0.327s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08141, val loss: 0.08356, in 0.339s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08176, val loss: 0.08384, in 0.310s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02136, val loss: 0.02230, in 0.338s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08343, val loss: 0.08548, in 0.330s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02081, val loss: 0.02104, in 0.340s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02126, val loss: 0.02192, in 0.322s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02265, val loss: 0.02304, in 0.321s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07733, val loss: 0.07955, in 0.324s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07945, val loss: 0.08157, in 0.339s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02194, in 0.317s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08020, val loss: 0.08230, in 0.333s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08210, val loss: 0.08416, in 0.323s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02065, val loss: 0.02087, in 0.299s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02235, val loss: 0.02274, in 0.530s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02075, val loss: 0.02167, in 0.545s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07604, val loss: 0.07828, in 0.578s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02105, val loss: 0.02173, in 0.611s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07766, val loss: 0.07975, in 0.596s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07873, val loss: 0.08087, in 0.612s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08053, val loss: 0.08260, in 0.609s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02039, val loss: 0.02061, in 0.597s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02208, val loss: 0.02247, in 0.554s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02146, in 0.510s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02047, val loss: 0.02140, in 0.541s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07466, val loss: 0.07691, in 0.550s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07737, val loss: 0.07951, in 0.538s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07582, val loss: 0.07787, in 0.567s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.02040, in 0.542s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07881, val loss: 0.08086, in 0.569s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.02129, in 0.470s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02192, val loss: 0.02231, in 0.520s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07332, val loss: 0.07556, in 0.515s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02063, val loss: 0.02130, in 0.548s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07445, val loss: 0.07651, in 0.532s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07576, val loss: 0.07785, in 0.565s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02000, val loss: 0.02023, in 0.511s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07737, val loss: 0.07949, in 0.521s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02165, val loss: 0.02204, in 0.506s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02005, val loss: 0.02097, in 0.549s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07212, val loss: 0.07435, in 0.508s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02037, val loss: 0.02105, in 0.511s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07288, val loss: 0.07489, in 0.531s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01976, val loss: 0.01999, in 0.506s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07452, val loss: 0.07661, in 0.534s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07564, val loss: 0.07775, in 0.529s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02125, val loss: 0.02165, in 0.532s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01984, val loss: 0.02076, in 0.497s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02021, val loss: 0.02089, in 0.482s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07070, val loss: 0.07292, in 0.507s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07158, val loss: 0.07357, in 0.449s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01954, val loss: 0.01978, in 0.455s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07292, val loss: 0.07501, in 0.442s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07431, val loss: 0.07643, in 0.439s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01953, val loss: 0.02044, in 0.415s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02097, val loss: 0.02138, in 0.432s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.02072, in 0.427s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06954, val loss: 0.07179, in 0.449s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07011, val loss: 0.07208, in 0.442s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07176, val loss: 0.07387, in 0.430s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07309, val loss: 0.07528, in 0.421s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01924, val loss: 0.01948, in 0.457s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.02023, in 0.281s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02053, in 0.286s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02076, val loss: 0.02119, in 0.306s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06843, val loss: 0.07069, in 0.314s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06892, val loss: 0.07090, in 0.292s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07055, val loss: 0.07270, in 0.296s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01901, val loss: 0.01923, in 0.288s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07198, val loss: 0.07419, in 0.311s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01923, val loss: 0.02014, in 0.249s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01957, val loss: 0.02028, in 0.297s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02051, val loss: 0.02094, in 0.303s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06747, val loss: 0.06973, in 0.296s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06768, val loss: 0.06970, in 0.312s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06935, val loss: 0.07151, in 0.302s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07088, val loss: 0.07310, in 0.289s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.01905, in 0.316s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01899, val loss: 0.01991, in 0.275s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01938, val loss: 0.02009, in 0.262s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.02073, in 0.276s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06627, val loss: 0.06857, in 0.300s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06792, val loss: 0.07007, in 0.298s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06626, val loss: 0.06827, in 0.317s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01867, val loss: 0.01889, in 0.300s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06966, val loss: 0.07189, in 0.327s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01871, val loss: 0.01962, in 0.277s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01983, in 0.303s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02013, val loss: 0.02056, in 0.306s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06531, val loss: 0.06767, in 0.319s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06664, val loss: 0.06878, in 0.303s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.01861, in 0.275s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06512, val loss: 0.06719, in 0.305s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01859, val loss: 0.01950, in 0.250s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06858, val loss: 0.07083, in 0.301s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01887, val loss: 0.01956, in 0.317s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01990, val loss: 0.02032, in 0.312s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06429, val loss: 0.06665, in 0.308s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01838, in 0.288s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01829, val loss: 0.01920, in 0.286s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06552, val loss: 0.06769, in 0.328s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06393, val loss: 0.06605, in 0.316s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06741, val loss: 0.06965, in 0.308s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01862, val loss: 0.01930, in 0.286s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02009, in 0.307s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01800, val loss: 0.01821, in 0.294s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06334, val loss: 0.06572, in 0.343s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01903, in 0.332s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06282, val loss: 0.06491, in 0.317s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06436, val loss: 0.06648, in 0.342s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06614, val loss: 0.06834, in 0.345s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01843, val loss: 0.01911, in 0.357s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01974, in 0.308s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01788, val loss: 0.01879, in 0.269s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01796, in 0.331s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06253, val loss: 0.06493, in 0.303s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06177, val loss: 0.06390, in 0.314s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06322, val loss: 0.06532, in 0.453s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06507, val loss: 0.06729, in 0.461s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01820, val loss: 0.01887, in 0.528s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01957, in 0.560s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01768, val loss: 0.01859, in 0.535s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01773, in 0.597s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06143, val loss: 0.06382, in 0.628s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06078, val loss: 0.06292, in 0.611s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06233, val loss: 0.06448, in 0.519s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06410, val loss: 0.06632, in 0.513s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01790, val loss: 0.01855, in 0.496s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01891, val loss: 0.01937, in 0.500s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01741, val loss: 0.01831, in 0.457s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01746, in 0.462s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05985, val loss: 0.06196, in 0.464s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06033, val loss: 0.06273, in 0.477s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06139, val loss: 0.06347, in 0.461s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06306, val loss: 0.06527, in 0.495s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01821, in 0.389s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01874, val loss: 0.01919, in 0.472s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01771, val loss: 0.01836, in 0.530s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01727, in 0.444s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05945, val loss: 0.06188, in 0.475s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05886, val loss: 0.06097, in 0.528s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06052, val loss: 0.06257, in 0.492s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06192, val loss: 0.06409, in 0.496s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01798, in 0.441s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01890, in 0.425s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01754, val loss: 0.01818, in 0.427s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01695, val loss: 0.01714, in 0.444s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05813, val loss: 0.06055, in 0.514s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05801, val loss: 0.06017, in 0.484s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05932, val loss: 0.06137, in 0.469s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06093, val loss: 0.06312, in 0.486s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01685, val loss: 0.01775, in 0.428s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01734, val loss: 0.01796, in 0.465s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01826, val loss: 0.01870, in 0.503s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01693, in 0.420s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05824, val loss: 0.06030, in 0.354s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05733, val loss: 0.05978, in 0.411s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05703, val loss: 0.05915, in 0.389s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05981, val loss: 0.06202, in 0.330s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01752, in 0.326s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01712, val loss: 0.01775, in 0.339s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01645, val loss: 0.01665, in 0.329s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01852, in 0.474s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01652, val loss: 0.01742, in 0.385s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05589, val loss: 0.05800, in 0.438s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05738, val loss: 0.05945, in 0.471s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05606, val loss: 0.05849, in 0.460s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05888, val loss: 0.06110, in 0.482s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01688, val loss: 0.01751, in 0.399s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01624, val loss: 0.01644, in 0.427s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01787, val loss: 0.01832, in 0.292s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01638, val loss: 0.01729, in 0.298s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05657, val loss: 0.05865, in 0.289s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05523, val loss: 0.05761, in 0.292s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05491, val loss: 0.05704, in 0.324s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05807, val loss: 0.06034, in 0.284s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01738, in 0.296s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01771, val loss: 0.01815, in 0.336s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01601, val loss: 0.01622, in 0.364s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01620, val loss: 0.01711, in 0.295s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05562, val loss: 0.05769, in 0.337s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05407, val loss: 0.05619, in 0.323s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05448, val loss: 0.05689, in 0.336s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05712, val loss: 0.05937, in 0.345s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01656, val loss: 0.01721, in 0.390s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01612, val loss: 0.01703, in 0.263s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01581, val loss: 0.01601, in 0.329s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01795, in 0.358s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05498, val loss: 0.05702, in 0.308s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05326, val loss: 0.05540, in 0.332s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05622, in 0.332s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05613, val loss: 0.05836, in 0.336s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01639, val loss: 0.01703, in 0.326s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01686, in 0.316s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01776, in 0.336s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01581, in 0.374s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05424, val loss: 0.05630, in 0.311s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05281, val loss: 0.05521, in 0.307s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05257, val loss: 0.05474, in 0.316s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05491, val loss: 0.05714, in 0.323s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01617, val loss: 0.01682, in 0.288s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01671, in 0.333s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01714, val loss: 0.01759, in 0.315s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01563, in 0.293s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05295, val loss: 0.05500, in 0.317s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05154, val loss: 0.05395, in 0.316s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05176, val loss: 0.05390, in 0.323s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05423, val loss: 0.05650, in 0.313s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01600, val loss: 0.01665, in 0.330s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01548, in 0.273s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01686, val loss: 0.01732, in 0.295s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01556, val loss: 0.01647, in 0.326s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05402, in 0.269s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05091, val loss: 0.05334, in 0.282s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05083, val loss: 0.05297, in 0.289s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05338, val loss: 0.05563, in 0.286s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01647, in 0.277s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01671, val loss: 0.01716, in 0.453s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05104, val loss: 0.05309, in 0.423s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01537, val loss: 0.01628, in 0.454s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01508, val loss: 0.01529, in 0.479s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04970, val loss: 0.05215, in 0.488s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05004, val loss: 0.05218, in 0.518s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05227, val loss: 0.05451, in 0.527s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01568, val loss: 0.01632, in 0.580s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01647, val loss: 0.01692, in 0.458s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01493, val loss: 0.01515, in 0.467s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04985, val loss: 0.05188, in 0.499s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01614, in 0.523s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04882, val loss: 0.05123, in 0.462s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04940, val loss: 0.05157, in 0.448s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05108, val loss: 0.05331, in 0.478s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01616, in 0.477s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01628, val loss: 0.01673, in 0.499s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01476, val loss: 0.01497, in 0.495s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04914, val loss: 0.05118, in 0.480s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01504, val loss: 0.01596, in 0.449s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04772, val loss: 0.05013, in 0.470s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04868, val loss: 0.05086, in 0.495s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05027, val loss: 0.05251, in 0.484s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01591, in 0.463s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01614, val loss: 0.01659, in 0.449s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.05009, in 0.451s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01461, val loss: 0.01482, in 0.510s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01485, val loss: 0.01575, in 0.527s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04708, val loss: 0.04951, in 0.487s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04755, val loss: 0.04967, in 0.438s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04961, val loss: 0.05183, in 0.485s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01507, val loss: 0.01570, in 0.490s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01644, in 0.437s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04725, val loss: 0.04927, in 0.451s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01465, in 0.494s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04605, val loss: 0.04848, in 0.478s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01469, val loss: 0.01559, in 0.505s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04634, val loss: 0.04846, in 0.492s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04895, val loss: 0.05119, in 0.480s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01588, val loss: 0.01633, in 0.324s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01489, val loss: 0.01552, in 0.402s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04644, val loss: 0.04847, in 0.381s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01444, in 0.295s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04509, val loss: 0.04750, in 0.306s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01545, in 0.326s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04520, val loss: 0.04730, in 0.333s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04787, val loss: 0.05009, in 0.381s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01620, in 0.386s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01471, val loss: 0.01535, in 0.394s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04564, val loss: 0.04764, in 0.413s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04420, val loss: 0.04659, in 0.393s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01402, val loss: 0.01423, in 0.442s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01438, val loss: 0.01528, in 0.396s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04463, val loss: 0.04674, in 0.393s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04729, val loss: 0.04951, in 0.282s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01595, in 0.286s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01457, val loss: 0.01521, in 0.308s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04476, val loss: 0.04674, in 0.292s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04350, val loss: 0.04587, in 0.286s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01405, in 0.280s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01515, in 0.313s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01584, in 0.216s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04404, val loss: 0.04618, in 0.302s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04644, val loss: 0.04866, in 0.287s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01442, val loss: 0.01505, in 0.287s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04422, val loss: 0.04622, in 0.278s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04280, val loss: 0.04517, in 0.291s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01393, in 0.316s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04333, val loss: 0.04547, in 0.277s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01525, val loss: 0.01570, in 0.288s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01499, in 0.293s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04577, val loss: 0.04798, in 0.286s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01488, in 0.266s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04329, val loss: 0.04528, in 0.279s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04216, val loss: 0.04451, in 0.281s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01380, in 0.268s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01515, val loss: 0.01560, in 0.256s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01393, val loss: 0.01485, in 0.290s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04232, val loss: 0.04444, in 0.315s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04494, val loss: 0.04713, in 0.274s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01473, in 0.248s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04149, val loss: 0.04383, in 0.279s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04257, val loss: 0.04458, in 0.328s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01478, in 0.222s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01340, val loss: 0.01360, in 0.284s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01490, val loss: 0.01536, in 0.282s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04173, val loss: 0.04386, in 0.271s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04388, val loss: 0.04605, in 0.289s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01389, val loss: 0.01452, in 0.314s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04189, val loss: 0.04388, in 0.269s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04088, val loss: 0.04322, in 0.291s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01349, in 0.291s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01465, in 0.312s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01474, val loss: 0.01520, in 0.292s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04117, val loss: 0.04332, in 0.307s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04504, in 0.294s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01436, in 0.286s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04037, val loss: 0.04273, in 0.286s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01452, in 0.270s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04125, val loss: 0.04324, in 0.326s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01336, in 0.299s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01506, in 0.293s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04044, val loss: 0.04258, in 0.309s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04213, val loss: 0.04426, in 0.302s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01423, in 0.303s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03983, val loss: 0.04221, in 0.520s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04041, val loss: 0.04238, in 0.557s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01324, in 0.552s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01340, val loss: 0.01432, in 0.575s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01491, in 0.596s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01412, in 0.578s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03992, val loss: 0.04206, in 0.642s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04120, val loss: 0.04334, in 0.647s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03913, val loss: 0.04145, in 0.461s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01325, val loss: 0.01415, in 0.446s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01290, val loss: 0.01313, in 0.464s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03983, val loss: 0.04180, in 0.479s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01477, in 0.466s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01402, in 0.403s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03932, val loss: 0.04147, in 0.463s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04060, val loss: 0.04272, in 0.498s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03857, val loss: 0.04087, in 0.453s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01297, in 0.462s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03917, val loss: 0.04112, in 0.502s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01313, val loss: 0.01404, in 0.540s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01390, in 0.447s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01461, in 0.565s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.04052, in 0.502s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04014, val loss: 0.04226, in 0.457s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03806, val loss: 0.04033, in 0.512s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01260, val loss: 0.01282, in 0.463s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01303, val loss: 0.01393, in 0.468s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03859, val loss: 0.04052, in 0.483s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01380, in 0.532s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01399, val loss: 0.01446, in 0.513s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03968, val loss: 0.04178, in 0.475s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03793, val loss: 0.04003, in 0.497s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03747, val loss: 0.03974, in 0.471s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01248, val loss: 0.01272, in 0.514s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03788, val loss: 0.03978, in 0.453s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01380, in 0.459s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01308, val loss: 0.01372, in 0.431s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01425, in 0.399s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03746, val loss: 0.03957, in 0.359s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03884, val loss: 0.04094, in 0.434s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03692, val loss: 0.03920, in 0.463s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01263, in 0.397s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03735, val loss: 0.03922, in 0.432s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01297, val loss: 0.01360, in 0.386s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01278, val loss: 0.01369, in 0.437s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03675, val loss: 0.03882, in 0.427s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01366, val loss: 0.01414, in 0.434s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03835, val loss: 0.04045, in 0.444s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01226, val loss: 0.01250, in 0.297s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03622, val loss: 0.03850, in 0.321s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03681, val loss: 0.03867, in 0.285s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01262, val loss: 0.01351, in 0.289s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01346, in 0.301s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03634, val loss: 0.03842, in 0.254s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01395, in 0.263s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03794, val loss: 0.04003, in 0.264s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01237, in 0.294s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03554, val loss: 0.03778, in 0.307s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03630, val loss: 0.03815, in 0.301s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01251, val loss: 0.01339, in 0.323s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01334, in 0.316s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03565, val loss: 0.03770, in 0.305s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01381, in 0.333s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03724, val loss: 0.03931, in 0.302s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01199, val loss: 0.01222, in 0.313s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03496, val loss: 0.03722, in 0.301s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03587, val loss: 0.03774, in 0.311s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01239, val loss: 0.01328, in 0.280s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03527, val loss: 0.03733, in 0.281s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01260, val loss: 0.01322, in 0.302s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01366, in 0.342s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03653, val loss: 0.03859, in 0.454s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03445, val loss: 0.03669, in 0.458s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03534, val loss: 0.03718, in 0.454s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01227, val loss: 0.01317, in 0.459s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03476, val loss: 0.03682, in 0.508s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01307, val loss: 0.01354, in 0.453s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03591, val loss: 0.03796, in 0.389s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03387, val loss: 0.03612, in 0.370s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03442, val loss: 0.03647, in 0.301s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03496, val loss: 0.03679, in 0.375s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03742, in 0.328s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03410, val loss: 0.03614, in 0.332s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03339, val loss: 0.03560, in 0.391s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03630, in 0.391s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03482, val loss: 0.03683, in 0.352s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03368, val loss: 0.03572, in 0.351s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03288, val loss: 0.03509, in 0.334s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03578, in 0.398s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03443, val loss: 0.03645, in 0.535s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03258, val loss: 0.03480, in 0.571s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03292, val loss: 0.03493, in 0.649s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03337, val loss: 0.03516, in 0.671s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03393, val loss: 0.03596, in 0.589s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03202, val loss: 0.03422, in 0.740s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03242, val loss: 0.03443, in 0.761s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03468, in 0.743s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03326, val loss: 0.03527, in 0.730s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03149, val loss: 0.03366, in 0.597s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03245, val loss: 0.03421, in 0.553s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03206, val loss: 0.03409, in 0.669s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03275, val loss: 0.03476, in 0.539s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03096, val loss: 0.03312, in 0.571s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03136, val loss: 0.03337, in 0.606s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03192, val loss: 0.03368, in 0.630s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03222, val loss: 0.03421, in 0.609s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03062, val loss: 0.03277, in 0.570s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03301, in 0.494s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03132, val loss: 0.03307, in 0.477s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03189, val loss: 0.03387, in 0.429s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03019, val loss: 0.03232, in 0.461s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03073, val loss: 0.03274, in 0.513s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03098, val loss: 0.03270, in 0.547s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03142, val loss: 0.03338, in 0.515s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.03203, in 0.439s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03016, val loss: 0.03216, in 0.389s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03059, val loss: 0.03229, in 0.377s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03094, val loss: 0.03289, in 0.372s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02948, val loss: 0.03163, in 0.343s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03004, val loss: 0.03173, in 0.346s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02967, val loss: 0.03166, in 0.374s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03050, val loss: 0.03243, in 0.354s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02907, val loss: 0.03119, in 0.361s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02970, val loss: 0.03137, in 0.353s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02931, val loss: 0.03128, in 0.379s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02994, val loss: 0.03185, in 0.376s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02865, val loss: 0.03077, in 0.376s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02938, val loss: 0.03104, in 0.368s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02872, val loss: 0.03067, in 0.369s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.03143, in 0.385s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02818, val loss: 0.03027, in 0.327s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02885, val loss: 0.03049, in 0.325s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02833, val loss: 0.03027, in 0.300s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02905, val loss: 0.03094, in 0.312s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02779, val loss: 0.02986, in 0.316s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02849, val loss: 0.03012, in 0.305s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02778, val loss: 0.02970, in 0.359s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02861, val loss: 0.03049, in 0.336s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02759, val loss: 0.02966, in 0.275s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01187, val loss: 0.01210, in 0.474s\n",
      "Fit 200 trees in 84.314 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.446s\n",
      "Time spent finding best splits:  1.344s\n",
      "Time spent applying splits:      10.033s\n",
      "Time spent predicting:           0.821s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01247, val loss: 0.01310, in 0.453s\n",
      "Fit 200 trees in 84.487 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.802s\n",
      "Time spent finding best splits:  1.378s\n",
      "Time spent applying splits:      10.254s\n",
      "Time spent predicting:           0.613s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02799, val loss: 0.02959, in 0.499s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02915, in 0.521s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02832, val loss: 0.03020, in 0.560s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02728, val loss: 0.02934, in 0.650s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01302, in 0.346s\n",
      "Fit 200 trees in 84.043 s, (6200 total leaves)\n",
      "Time spent computing histograms: 49.941s\n",
      "Time spent finding best splits:  1.432s\n",
      "Time spent applying splits:      10.150s\n",
      "Time spent predicting:           0.798s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01343, in 0.333s\n",
      "Fit 200 trees in 84.712 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.492s\n",
      "Time spent finding best splits:  1.562s\n",
      "Time spent applying splits:      10.010s\n",
      "Time spent predicting:           0.752s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02766, val loss: 0.02925, in 0.579s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02693, val loss: 0.02880, in 0.559s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02799, val loss: 0.02987, in 0.589s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02703, val loss: 0.02909, in 0.599s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02727, val loss: 0.02885, in 0.572s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02660, val loss: 0.02846, in 0.557s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02761, val loss: 0.02946, in 0.555s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02668, val loss: 0.02872, in 0.647s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02700, val loss: 0.02856, in 0.591s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02609, val loss: 0.02794, in 0.573s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02737, val loss: 0.02922, in 0.556s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02634, val loss: 0.02835, in 0.524s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02655, val loss: 0.02811, in 0.566s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02579, val loss: 0.02762, in 0.571s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02704, val loss: 0.02889, in 0.503s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02597, val loss: 0.02798, in 0.453s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02542, val loss: 0.02723, in 0.411s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02606, val loss: 0.02760, in 0.471s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02679, val loss: 0.02864, in 0.444s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02556, val loss: 0.02754, in 0.445s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02565, val loss: 0.02719, in 0.314s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02496, val loss: 0.02674, in 0.347s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02632, val loss: 0.02818, in 0.313s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02529, val loss: 0.02727, in 0.316s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02627, in 0.324s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02672, in 0.334s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02596, val loss: 0.02781, in 0.321s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02504, val loss: 0.02703, in 0.335s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02578, val loss: 0.02763, in 0.247s\n",
      "[137/200] 4.019 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02420, val loss: 0.02594, in 0.321s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02479, val loss: 0.02628, in 0.322s\n",
      "[138/200] 3.991 s\n",
      "Binning 0.013 GB of validation data: 0.148 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.147 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02459, val loss: 0.02656, in 0.342s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02541, val loss: 0.02725, in 0.325s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02441, val loss: 0.02592, in 0.330s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02379, val loss: 0.02551, in 0.338s\n",
      "[137/200] 3.681 s\n",
      "Binning 0.013 GB of validation data: 3.622 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62077, val loss: 0.62048, in 0.222s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62079, val loss: 0.62055, in 0.224s\n",
      "[2/200] 0.132 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.129 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02632, in 0.340s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02510, val loss: 0.02693, in 0.348s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56158, val loss: 0.56104, in 0.227s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02341, val loss: 0.02511, in 0.309s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56161, val loss: 0.56117, in 0.218s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02415, val loss: 0.02563, in 0.335s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62082, val loss: 0.62049, in 0.220s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62080, val loss: 0.62052, in 0.222s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51229, val loss: 0.51149, in 0.217s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51233, val loss: 0.51169, in 0.221s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02412, val loss: 0.02607, in 0.351s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02475, val loss: 0.02657, in 0.301s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56167, val loss: 0.56105, in 0.222s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02316, val loss: 0.02484, in 0.329s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56164, val loss: 0.56111, in 0.213s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02388, val loss: 0.02535, in 0.326s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47084, val loss: 0.46985, in 0.222s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47089, val loss: 0.47010, in 0.217s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51235, val loss: 0.51155, in 0.223s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51245, val loss: 0.51156, in 0.232s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02380, val loss: 0.02573, in 0.314s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02632, in 0.338s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02363, val loss: 0.02509, in 0.460s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02455, in 0.491s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43542, val loss: 0.43422, in 0.392s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43542, val loss: 0.43447, in 0.396s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47092, val loss: 0.46994, in 0.461s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47103, val loss: 0.46993, in 0.463s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40496, val loss: 0.40365, in 0.383s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40500, val loss: 0.40393, in 0.378s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02350, val loss: 0.02542, in 0.663s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02428, val loss: 0.02608, in 0.667s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02261, val loss: 0.02425, in 0.493s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02328, val loss: 0.02474, in 0.521s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43539, val loss: 0.43434, in 0.374s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43553, val loss: 0.43434, in 0.370s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37855, val loss: 0.37707, in 0.352s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37861, val loss: 0.37739, in 0.385s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40488, val loss: 0.40374, in 0.378s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40506, val loss: 0.40377, in 0.385s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02398, val loss: 0.02577, in 0.494s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02408, in 0.494s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02328, val loss: 0.02520, in 0.567s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02306, val loss: 0.02450, in 0.587s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35563, val loss: 0.35412, in 0.370s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35571, val loss: 0.35444, in 0.368s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37851, val loss: 0.37739, in 0.356s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37872, val loss: 0.37739, in 0.362s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02365, val loss: 0.02540, in 0.527s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33550, val loss: 0.33388, in 0.383s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33561, val loss: 0.33428, in 0.350s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02210, val loss: 0.02370, in 0.533s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02289, val loss: 0.02434, in 0.434s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02485, in 0.544s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35547, val loss: 0.35431, in 0.391s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35570, val loss: 0.35428, in 0.376s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31788, val loss: 0.31610, in 0.375s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31802, val loss: 0.31660, in 0.399s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02280, val loss: 0.02470, in 0.440s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02345, val loss: 0.02520, in 0.542s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33568, val loss: 0.33432, in 0.374s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33544, val loss: 0.33429, in 0.379s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02188, val loss: 0.02347, in 0.563s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02259, val loss: 0.02401, in 0.560s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30226, val loss: 0.30035, in 0.366s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30254, val loss: 0.30111, in 0.359s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02266, val loss: 0.02456, in 0.351s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31810, val loss: 0.31673, in 0.286s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31785, val loss: 0.31674, in 0.292s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02244, val loss: 0.02387, in 0.312s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02325, val loss: 0.02501, in 0.392s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28849, val loss: 0.28664, in 0.231s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02150, val loss: 0.02307, in 0.401s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28859, val loss: 0.28707, in 0.232s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30234, val loss: 0.30091, in 0.281s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30213, val loss: 0.30099, in 0.343s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02243, val loss: 0.02433, in 0.448s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27622, val loss: 0.27428, in 0.343s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27634, val loss: 0.27481, in 0.340s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02220, val loss: 0.02363, in 0.471s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02464, in 0.458s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28848, val loss: 0.28699, in 0.286s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02116, val loss: 0.02272, in 0.440s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28826, val loss: 0.28711, in 0.228s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26531, val loss: 0.26332, in 0.233s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26535, val loss: 0.26371, in 0.242s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02219, val loss: 0.02407, in 0.295s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27627, val loss: 0.27490, in 0.229s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27610, val loss: 0.27497, in 0.229s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02260, val loss: 0.02434, in 0.306s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02198, val loss: 0.02340, in 0.358s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25542, val loss: 0.25329, in 0.221s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02080, val loss: 0.02234, in 0.345s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25566, val loss: 0.25402, in 0.213s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26549, val loss: 0.26409, in 0.220s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26517, val loss: 0.26401, in 0.214s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02187, val loss: 0.02374, in 0.304s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24617, val loss: 0.24408, in 0.230s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02232, val loss: 0.02404, in 0.309s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24680, val loss: 0.24502, in 0.233s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02165, val loss: 0.02308, in 0.321s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02057, val loss: 0.02210, in 0.320s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25556, val loss: 0.25400, in 0.233s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25524, val loss: 0.25400, in 0.232s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02146, val loss: 0.02330, in 0.338s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23817, val loss: 0.23595, in 0.258s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23846, val loss: 0.23672, in 0.253s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02217, val loss: 0.02390, in 0.294s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24678, val loss: 0.24510, in 0.259s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24607, val loss: 0.24484, in 0.268s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02039, val loss: 0.02189, in 0.305s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02140, val loss: 0.02280, in 0.384s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23074, val loss: 0.22859, in 0.226s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02317, in 0.265s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23127, val loss: 0.22950, in 0.223s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02184, val loss: 0.02355, in 0.273s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23844, val loss: 0.23686, in 0.231s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23807, val loss: 0.23681, in 0.215s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22461, val loss: 0.22288, in 0.216s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02114, val loss: 0.02253, in 0.281s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22429, val loss: 0.22206, in 0.242s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02009, val loss: 0.02158, in 0.332s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02110, val loss: 0.02291, in 0.321s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23128, val loss: 0.22962, in 0.220s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23067, val loss: 0.22948, in 0.220s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02321, in 0.355s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21736, val loss: 0.21531, in 0.206s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21768, val loss: 0.21611, in 0.219s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01997, val loss: 0.02144, in 0.290s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02096, val loss: 0.02233, in 0.304s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22500, val loss: 0.22331, in 0.222s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22418, val loss: 0.22289, in 0.223s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02072, val loss: 0.02250, in 0.299s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21210, val loss: 0.21044, in 0.227s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21181, val loss: 0.20988, in 0.235s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02121, val loss: 0.02289, in 0.323s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21729, val loss: 0.21612, in 0.210s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21791, val loss: 0.21636, in 0.217s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02083, val loss: 0.02221, in 0.253s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01975, val loss: 0.02122, in 0.321s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02238, in 0.243s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20672, val loss: 0.20466, in 0.198s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20698, val loss: 0.20522, in 0.211s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21235, val loss: 0.21085, in 0.215s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21182, val loss: 0.21058, in 0.222s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02093, val loss: 0.02260, in 0.506s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20117, val loss: 0.19911, in 0.406s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02065, val loss: 0.02202, in 0.495s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20145, val loss: 0.19978, in 0.411s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01946, val loss: 0.02090, in 0.547s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02033, val loss: 0.02210, in 0.542s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20674, val loss: 0.20555, in 0.463s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20728, val loss: 0.20575, in 0.464s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19710, val loss: 0.19520, in 0.295s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19750, val loss: 0.19600, in 0.307s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02068, val loss: 0.02234, in 0.492s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20127, val loss: 0.20006, in 0.338s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20180, val loss: 0.20039, in 0.338s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02044, val loss: 0.02180, in 0.578s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19349, val loss: 0.19170, in 0.315s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01916, val loss: 0.02059, in 0.509s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02015, val loss: 0.02192, in 0.528s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19342, val loss: 0.19202, in 0.366s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19726, val loss: 0.19615, in 0.336s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19786, val loss: 0.19655, in 0.340s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02047, val loss: 0.02213, in 0.535s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18954, val loss: 0.18787, in 0.427s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18981, val loss: 0.18841, in 0.353s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02021, val loss: 0.02157, in 0.581s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19372, val loss: 0.19268, in 0.344s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.02029, in 0.577s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19380, val loss: 0.19254, in 0.374s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01989, val loss: 0.02167, in 0.585s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18618, val loss: 0.18451, in 0.301s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18603, val loss: 0.18456, in 0.383s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02023, val loss: 0.02186, in 0.499s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19021, val loss: 0.18890, in 0.305s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18980, val loss: 0.18869, in 0.359s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02130, in 0.461s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18261, val loss: 0.18088, in 0.361s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01861, val loss: 0.01998, in 0.509s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18291, val loss: 0.18160, in 0.294s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01961, val loss: 0.02137, in 0.491s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18649, val loss: 0.18535, in 0.297s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18639, val loss: 0.18496, in 0.354s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17869, val loss: 0.17710, in 0.329s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18005, val loss: 0.17880, in 0.317s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.02167, in 0.598s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01968, val loss: 0.02101, in 0.548s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18323, val loss: 0.18192, in 0.356s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01929, val loss: 0.02101, in 0.516s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01834, val loss: 0.01970, in 0.537s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18287, val loss: 0.18165, in 0.415s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17724, val loss: 0.17611, in 0.268s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17611, val loss: 0.17451, in 0.279s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18037, val loss: 0.17910, in 0.205s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17897, val loss: 0.17792, in 0.213s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17472, val loss: 0.17362, in 0.195s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17340, val loss: 0.17179, in 0.195s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02145, in 0.403s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01918, val loss: 0.02090, in 0.283s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01952, val loss: 0.02084, in 0.368s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01941, in 0.329s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17764, val loss: 0.17646, in 0.288s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17623, val loss: 0.17519, in 0.283s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17035, val loss: 0.16878, in 0.323s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17169, val loss: 0.17057, in 0.340s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17512, val loss: 0.17390, in 0.186s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17374, val loss: 0.17273, in 0.189s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01956, val loss: 0.02117, in 0.436s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01926, val loss: 0.02058, in 0.420s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16947, val loss: 0.16839, in 0.164s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16812, val loss: 0.16654, in 0.180s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.02067, in 0.476s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01916, in 0.430s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17205, val loss: 0.17085, in 0.228s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17073, val loss: 0.16969, in 0.218s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16581, val loss: 0.16419, in 0.173s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16712, val loss: 0.16604, in 0.191s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01934, val loss: 0.02094, in 0.312s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01902, val loss: 0.02034, in 0.300s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16985, val loss: 0.16872, in 0.172s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01874, val loss: 0.02043, in 0.311s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16855, val loss: 0.16745, in 0.165s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16337, val loss: 0.16180, in 0.191s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16496, val loss: 0.16387, in 0.178s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01897, in 0.361s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16765, val loss: 0.16647, in 0.154s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16604, val loss: 0.16502, in 0.184s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16150, val loss: 0.15989, in 0.167s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16204, val loss: 0.16103, in 0.170s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01915, val loss: 0.02073, in 0.288s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01856, val loss: 0.02024, in 0.264s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.02014, in 0.336s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16492, val loss: 0.16375, in 0.178s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01744, val loss: 0.01875, in 0.278s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16314, val loss: 0.16222, in 0.181s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15875, val loss: 0.15713, in 0.158s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15983, val loss: 0.15889, in 0.175s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01888, val loss: 0.02044, in 0.262s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16189, val loss: 0.16084, in 0.171s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16079, val loss: 0.15981, in 0.155s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01868, val loss: 0.01999, in 0.266s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15652, val loss: 0.15503, in 0.173s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15756, val loss: 0.15672, in 0.154s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.02008, in 0.320s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01719, val loss: 0.01847, in 0.307s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15992, val loss: 0.15887, in 0.162s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15847, val loss: 0.15753, in 0.164s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15503, val loss: 0.15348, in 0.143s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15576, val loss: 0.15489, in 0.163s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.02014, in 0.281s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15819, val loss: 0.15715, in 0.173s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01845, val loss: 0.01975, in 0.289s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15671, val loss: 0.15576, in 0.166s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15323, val loss: 0.15173, in 0.172s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15304, val loss: 0.15220, in 0.156s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01819, val loss: 0.01987, in 0.312s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01827, in 0.291s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15582, val loss: 0.15478, in 0.176s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15416, val loss: 0.15322, in 0.171s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15134, val loss: 0.15052, in 0.175s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15143, val loss: 0.14996, in 0.193s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01992, in 0.287s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01946, in 0.299s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15237, val loss: 0.15139, in 0.170s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15388, val loss: 0.15278, in 0.187s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14979, val loss: 0.14902, in 0.166s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01793, val loss: 0.01959, in 0.336s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01802, in 0.305s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14919, val loss: 0.14774, in 0.195s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01935, in 0.212s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15079, val loss: 0.14981, in 0.164s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01817, val loss: 0.01972, in 0.302s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14841, val loss: 0.14757, in 0.155s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15242, val loss: 0.15129, in 0.175s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14722, val loss: 0.14579, in 0.153s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01772, val loss: 0.01937, in 0.271s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01655, val loss: 0.01778, in 0.267s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14610, val loss: 0.14529, in 0.154s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14994, val loss: 0.14891, in 0.151s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14542, val loss: 0.14397, in 0.137s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14894, val loss: 0.14798, in 0.376s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01780, val loss: 0.01908, in 0.504s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01794, val loss: 0.01949, in 0.498s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14794, val loss: 0.14697, in 0.392s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14404, in 0.393s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14308, val loss: 0.14180, in 0.432s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14728, val loss: 0.14638, in 0.290s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01640, val loss: 0.01762, in 0.529s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01916, in 0.606s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14595, val loss: 0.14499, in 0.278s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14326, val loss: 0.14252, in 0.308s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14181, val loss: 0.14050, in 0.257s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14591, val loss: 0.14499, in 0.260s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01930, in 0.446s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01764, val loss: 0.01892, in 0.508s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14214, val loss: 0.14136, in 0.241s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14420, val loss: 0.14333, in 0.319s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13964, val loss: 0.13835, in 0.282s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01745, in 0.522s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01732, val loss: 0.01895, in 0.454s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14429, val loss: 0.14333, in 0.288s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14051, val loss: 0.13978, in 0.278s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14274, val loss: 0.14185, in 0.270s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13807, val loss: 0.13681, in 0.281s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01757, val loss: 0.01911, in 0.525s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01870, in 0.496s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14214, val loss: 0.14126, in 0.289s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01603, val loss: 0.01721, in 0.465s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14148, val loss: 0.14057, in 0.249s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13847, val loss: 0.13785, in 0.289s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13704, val loss: 0.13583, in 0.272s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01714, val loss: 0.01876, in 0.521s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14003, val loss: 0.13914, in 0.290s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13706, val loss: 0.13647, in 0.295s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13544, val loss: 0.13425, in 0.272s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01741, val loss: 0.01895, in 0.534s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13890, val loss: 0.13809, in 0.338s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13804, in 0.233s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01722, val loss: 0.01848, in 0.542s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01860, in 0.453s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01583, val loss: 0.01701, in 0.551s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13558, val loss: 0.13500, in 0.270s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13446, val loss: 0.13324, in 0.286s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13736, val loss: 0.13657, in 0.292s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13747, val loss: 0.13655, in 0.301s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01717, val loss: 0.01869, in 0.561s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13405, val loss: 0.13347, in 0.330s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13134, in 0.304s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01827, in 0.537s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13610, val loss: 0.13531, in 0.314s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13588, val loss: 0.13495, in 0.291s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01838, in 0.505s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01679, in 0.494s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13300, val loss: 0.13238, in 0.174s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13117, val loss: 0.12994, in 0.208s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13472, val loss: 0.13374, in 0.171s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13422, val loss: 0.13343, in 0.231s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01694, val loss: 0.01845, in 0.297s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13116, val loss: 0.13059, in 0.277s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01687, val loss: 0.01814, in 0.475s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13366, val loss: 0.13264, in 0.278s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12929, val loss: 0.12821, in 0.296s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01661, in 0.396s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13180, in 0.274s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01823, in 0.439s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12973, val loss: 0.12910, in 0.158s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13190, val loss: 0.13092, in 0.161s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12766, val loss: 0.12658, in 0.172s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01672, val loss: 0.01823, in 0.399s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13155, val loss: 0.13077, in 0.151s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01672, val loss: 0.01798, in 0.258s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12791, in 0.156s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01641, val loss: 0.01799, in 0.256s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12638, val loss: 0.12530, in 0.138s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01528, val loss: 0.01643, in 0.290s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13025, val loss: 0.12936, in 0.163s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12942, in 0.154s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12721, val loss: 0.12656, in 0.170s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12538, val loss: 0.12429, in 0.141s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01649, val loss: 0.01798, in 0.273s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12925, val loss: 0.12835, in 0.177s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12891, val loss: 0.12815, in 0.161s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01646, val loss: 0.01770, in 0.320s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12641, val loss: 0.12574, in 0.155s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01780, in 0.301s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12448, val loss: 0.12334, in 0.158s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12848, val loss: 0.12759, in 0.145s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01624, in 0.346s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12774, val loss: 0.12697, in 0.166s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01631, val loss: 0.01782, in 0.282s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12498, val loss: 0.12431, in 0.164s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12336, val loss: 0.12222, in 0.186s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12697, val loss: 0.12610, in 0.161s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12653, val loss: 0.12581, in 0.204s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01749, in 0.336s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12346, val loss: 0.12286, in 0.203s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01764, in 0.352s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12244, val loss: 0.12129, in 0.186s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01600, in 0.334s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12569, val loss: 0.12478, in 0.221s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12540, val loss: 0.12465, in 0.182s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01613, val loss: 0.01763, in 0.344s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12261, val loss: 0.12197, in 0.156s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12136, val loss: 0.12022, in 0.155s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12483, val loss: 0.12384, in 0.155s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01732, in 0.297s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12417, val loss: 0.12340, in 0.143s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01592, val loss: 0.01749, in 0.258s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12160, val loss: 0.12096, in 0.145s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01583, in 0.294s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12042, val loss: 0.11925, in 0.171s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12330, val loss: 0.12235, in 0.160s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12345, val loss: 0.12266, in 0.146s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01749, in 0.312s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12066, val loss: 0.12001, in 0.174s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11914, val loss: 0.11799, in 0.154s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01591, val loss: 0.01715, in 0.283s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01730, in 0.285s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12237, val loss: 0.12161, in 0.157s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.12059, in 0.188s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01562, in 0.315s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11819, val loss: 0.11703, in 0.152s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11902, in 0.194s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12125, val loss: 0.12055, in 0.146s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12021, val loss: 0.11942, in 0.145s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01583, val loss: 0.01734, in 0.315s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01684, in 0.288s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11721, val loss: 0.11615, in 0.159s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11886, val loss: 0.11823, in 0.159s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11902, val loss: 0.11822, in 0.165s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12011, val loss: 0.11942, in 0.190s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01718, in 0.342s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01439, val loss: 0.01550, in 0.289s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11763, val loss: 0.11702, in 0.154s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11614, val loss: 0.11505, in 0.178s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11839, val loss: 0.11761, in 0.148s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01567, val loss: 0.01717, in 0.271s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11894, val loss: 0.11828, in 0.156s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01541, val loss: 0.01663, in 0.339s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11656, val loss: 0.11592, in 0.183s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11536, val loss: 0.11434, in 0.168s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11763, val loss: 0.11688, in 0.166s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11764, val loss: 0.11694, in 0.159s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01706, in 0.326s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01529, in 0.312s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11599, val loss: 0.11535, in 0.299s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01548, val loss: 0.01696, in 0.491s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11653, val loss: 0.11582, in 0.347s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11660, val loss: 0.11590, in 0.347s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11446, val loss: 0.11344, in 0.390s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11492, val loss: 0.11432, in 0.279s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11586, val loss: 0.11515, in 0.257s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01647, in 0.663s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11338, val loss: 0.11235, in 0.265s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01404, val loss: 0.01514, in 0.585s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01537, val loss: 0.01692, in 0.628s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11572, val loss: 0.11505, in 0.292s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01533, val loss: 0.01681, in 0.432s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11348, in 0.283s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11507, val loss: 0.11441, in 0.271s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11468, val loss: 0.11389, in 0.322s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11215, val loss: 0.11112, in 0.333s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01638, in 0.386s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11328, val loss: 0.11261, in 0.264s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01671, in 0.506s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11441, val loss: 0.11377, in 0.244s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01390, val loss: 0.01499, in 0.526s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01671, in 0.416s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11365, val loss: 0.11287, in 0.256s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11107, val loss: 0.11002, in 0.253s\n",
      "[72/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11253, val loss: 0.11186, in 0.276s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11173, in 0.276s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11029, val loss: 0.10922, in 0.251s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11272, in 0.303s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01498, val loss: 0.01618, in 0.476s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01503, val loss: 0.01655, in 0.465s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01484, in 0.470s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11186, val loss: 0.11127, in 0.267s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01650, in 0.515s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11200, val loss: 0.11120, in 0.257s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11246, val loss: 0.11177, in 0.253s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10935, val loss: 0.10824, in 0.273s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11045, val loss: 0.10992, in 0.255s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11105, val loss: 0.11028, in 0.252s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11165, val loss: 0.11095, in 0.256s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01483, val loss: 0.01602, in 0.518s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10678, in 0.289s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01637, in 0.487s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01464, in 0.476s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10944, val loss: 0.10890, in 0.238s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01632, in 0.458s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11026, val loss: 0.10951, in 0.273s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10734, val loss: 0.10623, in 0.265s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11082, val loss: 0.11014, in 0.324s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10792, in 0.289s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01584, in 0.447s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10938, val loss: 0.10867, in 0.226s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10995, val loss: 0.10927, in 0.194s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10620, val loss: 0.10511, in 0.210s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01623, in 0.426s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01475, val loss: 0.01620, in 0.390s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10796, val loss: 0.10741, in 0.146s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01345, val loss: 0.01452, in 0.474s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10867, val loss: 0.10791, in 0.163s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10909, val loss: 0.10839, in 0.146s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10573, val loss: 0.10463, in 0.150s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10726, val loss: 0.10668, in 0.261s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01565, in 0.419s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10745, val loss: 0.10673, in 0.280s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10825, val loss: 0.10757, in 0.269s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10529, val loss: 0.10418, in 0.268s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01464, val loss: 0.01609, in 0.380s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01606, in 0.405s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01435, in 0.399s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10649, val loss: 0.10596, in 0.169s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10672, val loss: 0.10597, in 0.156s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10758, val loss: 0.10694, in 0.160s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10410, val loss: 0.10300, in 0.160s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01550, in 0.271s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10570, val loss: 0.10520, in 0.156s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01599, in 0.270s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10684, val loss: 0.10614, in 0.148s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10518, val loss: 0.10442, in 0.168s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10344, val loss: 0.10234, in 0.166s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01444, val loss: 0.01595, in 0.319s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10473, in 0.140s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01423, in 0.314s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10441, val loss: 0.10366, in 0.149s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10563, val loss: 0.10497, in 0.163s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10257, val loss: 0.10149, in 0.151s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01415, val loss: 0.01531, in 0.304s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10465, val loss: 0.10415, in 0.169s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01441, val loss: 0.01585, in 0.291s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10490, val loss: 0.10424, in 0.142s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01429, val loss: 0.01581, in 0.271s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10134, val loss: 0.10037, in 0.167s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10367, val loss: 0.10290, in 0.179s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01305, val loss: 0.01409, in 0.268s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10347, val loss: 0.10299, in 0.162s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10415, val loss: 0.10353, in 0.158s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10078, val loss: 0.09978, in 0.153s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10285, val loss: 0.10208, in 0.157s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01512, in 0.298s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10260, val loss: 0.10212, in 0.154s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01419, val loss: 0.01571, in 0.266s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01426, val loss: 0.01571, in 0.334s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10367, val loss: 0.10306, in 0.144s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10230, val loss: 0.10155, in 0.140s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01393, in 0.297s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.09867, in 0.176s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10131, in 0.161s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10283, val loss: 0.10218, in 0.154s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10161, val loss: 0.10087, in 0.147s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01382, val loss: 0.01496, in 0.301s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01402, val loss: 0.01554, in 0.277s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09765, val loss: 0.09674, in 0.201s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10109, val loss: 0.10062, in 0.166s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01412, val loss: 0.01558, in 0.326s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01378, in 0.285s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10202, val loss: 0.10135, in 0.181s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10105, val loss: 0.10030, in 0.160s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09724, val loss: 0.09633, in 0.145s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10044, val loss: 0.10000, in 0.161s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09989, val loss: 0.09915, in 0.179s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10071, val loss: 0.10001, in 0.184s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01362, val loss: 0.01475, in 0.336s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01538, in 0.293s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09661, val loss: 0.09570, in 0.196s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01362, in 0.283s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01399, val loss: 0.01544, in 0.299s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09960, val loss: 0.09914, in 0.202s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10010, val loss: 0.09941, in 0.159s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09861, in 0.182s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09465, in 0.210s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09945, val loss: 0.09875, in 0.157s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09824, val loss: 0.09782, in 0.195s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01467, in 0.298s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09874, val loss: 0.09804, in 0.149s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01524, in 0.321s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01530, in 0.280s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01347, in 0.310s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09508, val loss: 0.09416, in 0.182s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09889, val loss: 0.09818, in 0.184s\n",
      "[89/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09759, val loss: 0.09716, in 0.188s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09814, val loss: 0.09742, in 0.188s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01503, in 0.481s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09424, val loss: 0.09335, in 0.375s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09836, val loss: 0.09767, in 0.365s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01447, in 0.555s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01517, in 0.531s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09745, val loss: 0.09671, in 0.390s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09697, val loss: 0.09655, in 0.416s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01231, val loss: 0.01335, in 0.564s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09359, val loss: 0.09269, in 0.265s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09698, in 0.300s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09694, val loss: 0.09623, in 0.261s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09525, in 0.305s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01349, val loss: 0.01496, in 0.408s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01439, in 0.385s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01361, val loss: 0.01505, in 0.469s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09726, val loss: 0.09658, in 0.254s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09265, val loss: 0.09178, in 0.315s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09636, val loss: 0.09567, in 0.290s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01319, in 0.508s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09494, val loss: 0.09456, in 0.278s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09605, val loss: 0.09542, in 0.346s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09563, val loss: 0.09498, in 0.331s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09395, val loss: 0.09358, in 0.346s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09098, val loss: 0.09018, in 0.418s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01332, val loss: 0.01478, in 0.626s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01314, val loss: 0.01426, in 0.605s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01350, val loss: 0.01492, in 0.634s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01207, val loss: 0.01311, in 0.563s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09540, val loss: 0.09481, in 0.332s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09328, val loss: 0.09290, in 0.264s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09406, in 0.333s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08967, val loss: 0.08893, in 0.296s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09270, val loss: 0.09230, in 0.254s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01408, in 0.505s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01321, val loss: 0.01466, in 0.520s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09395, val loss: 0.09330, in 0.268s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08918, val loss: 0.08841, in 0.252s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09408, in 0.310s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01480, in 0.476s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01194, val loss: 0.01299, in 0.558s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09353, val loss: 0.09287, in 0.281s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08858, val loss: 0.08777, in 0.282s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09208, val loss: 0.09170, in 0.339s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09370, val loss: 0.09307, in 0.379s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01304, val loss: 0.01447, in 0.491s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08825, val loss: 0.08746, in 0.308s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09290, val loss: 0.09225, in 0.329s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01284, val loss: 0.01395, in 0.649s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.09113, in 0.315s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01328, val loss: 0.01469, in 0.590s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09319, val loss: 0.09255, in 0.357s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01182, val loss: 0.01285, in 0.592s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08786, val loss: 0.08707, in 0.309s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09120, val loss: 0.09081, in 0.287s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09231, val loss: 0.09164, in 0.319s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09265, val loss: 0.09199, in 0.237s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08728, val loss: 0.08648, in 0.186s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01382, in 0.486s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09071, val loss: 0.09035, in 0.204s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01311, val loss: 0.01452, in 0.455s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09128, val loss: 0.09064, in 0.219s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01168, val loss: 0.01271, in 0.482s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09202, val loss: 0.09137, in 0.292s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09076, val loss: 0.09014, in 0.309s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08973, val loss: 0.08937, in 0.349s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08640, val loss: 0.08561, in 0.391s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09136, val loss: 0.09074, in 0.220s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01258, val loss: 0.01369, in 0.455s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01300, val loss: 0.01440, in 0.454s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08615, val loss: 0.08538, in 0.166s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08888, in 0.182s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01260, in 0.393s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09037, val loss: 0.08973, in 0.203s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08985, val loss: 0.08921, in 0.256s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08471, in 0.200s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08871, val loss: 0.08832, in 0.206s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08922, val loss: 0.08854, in 0.199s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08975, val loss: 0.08911, in 0.209s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01429, in 0.340s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01352, in 0.365s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01144, val loss: 0.01247, in 0.342s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08843, val loss: 0.08804, in 0.178s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08894, val loss: 0.08828, in 0.170s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08928, val loss: 0.08864, in 0.177s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08370, val loss: 0.08300, in 0.251s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08776, val loss: 0.08738, in 0.206s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08898, val loss: 0.08834, in 0.197s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08310, val loss: 0.08239, in 0.195s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08822, val loss: 0.08755, in 0.217s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01133, val loss: 0.01234, in 0.344s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08713, val loss: 0.08677, in 0.188s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08863, val loss: 0.08801, in 0.158s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08193, val loss: 0.08124, in 0.219s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08738, val loss: 0.08668, in 0.230s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08755, val loss: 0.08697, in 0.201s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08628, val loss: 0.08586, in 0.234s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01125, val loss: 0.01226, in 0.346s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08692, val loss: 0.08624, in 0.172s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08060, val loss: 0.07995, in 0.222s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08709, val loss: 0.08651, in 0.169s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08562, val loss: 0.08524, in 0.201s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08572, val loss: 0.08504, in 0.201s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07944, val loss: 0.07884, in 0.182s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08593, in 0.171s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08519, val loss: 0.08477, in 0.157s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08510, val loss: 0.08445, in 0.176s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07857, val loss: 0.07798, in 0.226s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08623, val loss: 0.08563, in 0.166s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08439, val loss: 0.08399, in 0.173s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08446, val loss: 0.08378, in 0.189s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07821, val loss: 0.07763, in 0.152s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08559, val loss: 0.08498, in 0.199s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08322, val loss: 0.08290, in 0.227s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08363, val loss: 0.08299, in 0.182s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07765, val loss: 0.07705, in 0.179s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08521, val loss: 0.08463, in 0.179s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08338, val loss: 0.08274, in 0.156s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08131, in 0.211s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08487, val loss: 0.08429, in 0.161s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07642, val loss: 0.07588, in 0.216s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08313, val loss: 0.08249, in 0.163s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08448, val loss: 0.08388, in 0.332s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08023, val loss: 0.07995, in 0.397s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07555, val loss: 0.07504, in 0.375s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08273, val loss: 0.08209, in 0.380s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08396, val loss: 0.08337, in 0.312s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07911, val loss: 0.07886, in 0.341s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07519, val loss: 0.07470, in 0.313s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08225, val loss: 0.08161, in 0.311s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08366, val loss: 0.08309, in 0.257s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07840, val loss: 0.07816, in 0.272s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07498, val loss: 0.07451, in 0.272s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08098, in 0.326s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08316, val loss: 0.08260, in 0.284s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07797, val loss: 0.07771, in 0.289s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07443, val loss: 0.07396, in 0.305s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08091, val loss: 0.08022, in 0.388s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07748, val loss: 0.07719, in 0.290s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08172, val loss: 0.08120, in 0.361s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07405, val loss: 0.07356, in 0.298s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08068, val loss: 0.08000, in 0.268s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07719, val loss: 0.07689, in 0.280s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08119, val loss: 0.08067, in 0.300s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07367, val loss: 0.07318, in 0.317s\n",
      "[118/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07994, val loss: 0.07928, in 0.311s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07665, val loss: 0.07633, in 0.298s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08047, val loss: 0.07997, in 0.342s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07282, val loss: 0.07237, in 0.313s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07934, val loss: 0.07871, in 0.277s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07251, val loss: 0.07205, in 0.251s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07552, val loss: 0.07522, in 0.348s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07972, val loss: 0.07925, in 0.289s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07774, val loss: 0.07705, in 0.282s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07443, in 0.201s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07913, val loss: 0.07865, in 0.209s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07201, val loss: 0.07156, in 0.258s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07747, val loss: 0.07679, in 0.162s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07425, val loss: 0.07405, in 0.300s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07884, val loss: 0.07836, in 0.280s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07178, val loss: 0.07134, in 0.275s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07694, val loss: 0.07626, in 0.297s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07861, val loss: 0.07813, in 0.163s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07383, val loss: 0.07364, in 0.190s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07147, val loss: 0.07103, in 0.209s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07557, val loss: 0.07484, in 0.217s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07818, val loss: 0.07771, in 0.190s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07348, val loss: 0.07330, in 0.186s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07102, val loss: 0.07056, in 0.184s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07800, val loss: 0.07753, in 0.155s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07449, val loss: 0.07380, in 0.184s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07268, val loss: 0.07250, in 0.188s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07001, val loss: 0.06959, in 0.208s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07411, val loss: 0.07343, in 0.153s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07711, val loss: 0.07664, in 0.178s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07185, val loss: 0.07171, in 0.160s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06905, val loss: 0.06866, in 0.203s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07630, val loss: 0.07584, in 0.176s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07300, val loss: 0.07227, in 0.222s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01290, val loss: 0.01433, in 0.585s\n",
      "Fit 200 trees in 85.412 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.027s\n",
      "Time spent finding best splits:  1.481s\n",
      "Time spent applying splits:      10.529s\n",
      "Time spent predicting:           0.657s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.07152, val loss: 0.07135, in 0.204s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06843, val loss: 0.06807, in 0.217s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07521, val loss: 0.07475, in 0.205s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07211, val loss: 0.07143, in 0.180s\n",
      "[127/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07116, val loss: 0.07101, in 0.194s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06779, val loss: 0.06746, in 0.184s\n",
      "[128/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07484, val loss: 0.07437, in 0.158s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07123, val loss: 0.07055, in 0.184s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07063, in 0.164s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06752, val loss: 0.06718, in 0.156s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07438, val loss: 0.07389, in 0.173s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07011, in 0.198s\n",
      "[129/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07033, val loss: 0.07019, in 0.184s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06660, val loss: 0.06627, in 0.201s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07042, val loss: 0.06974, in 0.157s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07312, val loss: 0.07264, in 0.212s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07008, val loss: 0.06992, in 0.158s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07273, val loss: 0.07227, in 0.166s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06600, val loss: 0.06569, in 0.212s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06967, val loss: 0.06899, in 0.185s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06933, val loss: 0.06920, in 0.202s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01277, val loss: 0.01417, in 0.406s\n",
      "Fit 200 trees in 85.707 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.365s\n",
      "Time spent finding best splits:  1.346s\n",
      "Time spent applying splits:      10.328s\n",
      "Time spent predicting:           0.732s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01227, val loss: 0.01336, in 0.397s\n",
      "Fit 200 trees in 85.911 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.780s\n",
      "Time spent finding best splits:  1.366s\n",
      "Time spent applying splits:      10.737s\n",
      "Time spent predicting:           0.620s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.07167, val loss: 0.07124, in 0.194s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06543, val loss: 0.06511, in 0.196s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06935, val loss: 0.06865, in 0.189s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06905, val loss: 0.06891, in 0.158s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06509, val loss: 0.06476, in 0.169s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06858, val loss: 0.06847, in 0.166s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07058, val loss: 0.07015, in 0.366s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06863, val loss: 0.06798, in 0.393s\n",
      "[133/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06494, val loss: 0.06463, in 0.399s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06840, val loss: 0.06830, in 0.411s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07014, val loss: 0.06971, in 0.335s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06792, val loss: 0.06732, in 0.299s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06471, val loss: 0.06438, in 0.258s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06798, val loss: 0.06786, in 0.299s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06757, val loss: 0.06697, in 0.270s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06972, val loss: 0.06929, in 0.341s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01214, in 0.326s\n",
      "Fit 200 trees in 86.345 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.224s\n",
      "Time spent finding best splits:  1.312s\n",
      "Time spent applying splits:      9.977s\n",
      "Time spent predicting:           0.708s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06413, val loss: 0.06378, in 0.318s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06770, val loss: 0.06755, in 0.277s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06730, val loss: 0.06670, in 0.283s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06940, val loss: 0.06897, in 0.336s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06720, val loss: 0.06708, in 0.329s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06368, val loss: 0.06334, in 0.382s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06667, val loss: 0.06608, in 0.394s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06850, val loss: 0.06808, in 0.346s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06336, val loss: 0.06302, in 0.260s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06665, val loss: 0.06652, in 0.351s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06642, val loss: 0.06586, in 0.325s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06303, val loss: 0.06270, in 0.278s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06796, val loss: 0.06750, in 0.361s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06629, val loss: 0.06616, in 0.297s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06594, val loss: 0.06535, in 0.354s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06275, val loss: 0.06244, in 0.319s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06768, val loss: 0.06721, in 0.309s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06610, val loss: 0.06596, in 0.279s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06527, val loss: 0.06471, in 0.316s\n",
      "[140/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06749, val loss: 0.06704, in 0.263s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06245, val loss: 0.06213, in 0.281s\n",
      "[141/200] 3.768 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06522, val loss: 0.06511, in 0.300s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06724, val loss: 0.06680, in 0.163s\n",
      "[142/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06229, val loss: 0.06197, in 0.156s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06452, val loss: 0.06393, in 0.194s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06488, val loss: 0.06481, in 0.265s\n",
      "[144/200] 0.131 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06206, val loss: 0.06174, in 0.327s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06421, val loss: 0.06362, in 0.328s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06652, val loss: 0.06610, in 0.387s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06462, val loss: 0.06453, in 0.300s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62080, val loss: 0.62051, in 0.362s\n",
      "[2/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06406, val loss: 0.06347, in 0.265s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06615, val loss: 0.06574, in 0.283s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06155, val loss: 0.06124, in 0.344s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06449, val loss: 0.06443, in 0.259s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56164, val loss: 0.56110, in 0.328s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06365, val loss: 0.06308, in 0.278s\n",
      "[144/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06593, val loss: 0.06553, in 0.227s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06097, val loss: 0.06069, in 0.265s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06417, val loss: 0.06408, in 0.235s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06578, val loss: 0.06539, in 0.171s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06350, val loss: 0.06293, in 0.185s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51238, val loss: 0.51158, in 0.246s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06036, val loss: 0.06015, in 0.205s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06384, val loss: 0.06375, in 0.214s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06333, val loss: 0.06277, in 0.152s\n",
      "[146/200] 4.158 s\n",
      "Binning 0.013 GB of validation data: 4.158 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06488, val loss: 0.06450, in 0.222s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47095, val loss: 0.46996, in 0.213s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06347, val loss: 0.06339, in 0.179s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05975, val loss: 0.05955, in 0.212s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06298, val loss: 0.06242, in 0.176s\n",
      "[147/200] 0.128 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.128 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06453, val loss: 0.06414, in 0.191s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05962, val loss: 0.05942, in 0.158s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43543, val loss: 0.43442, in 0.207s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06305, val loss: 0.06300, in 0.192s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06212, val loss: 0.06158, in 0.218s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62074, val loss: 0.62068, in 0.221s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06379, val loss: 0.06345, in 0.198s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62083, val loss: 0.62079, in 0.224s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05918, val loss: 0.05899, in 0.181s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06268, val loss: 0.06260, in 0.159s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40493, val loss: 0.40385, in 0.228s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06165, val loss: 0.06111, in 0.188s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05884, val loss: 0.05870, in 0.176s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56153, val loss: 0.56143, in 0.238s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06209, val loss: 0.06200, in 0.206s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06300, val loss: 0.06266, in 0.231s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56168, val loss: 0.56162, in 0.234s\n",
      "[3/200] 3.726 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.37857, val loss: 0.37750, in 0.224s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06079, val loss: 0.06026, in 0.223s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05873, val loss: 0.05859, in 0.158s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06160, val loss: 0.06153, in 0.180s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51221, val loss: 0.51201, in 0.214s\n",
      "[4/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06255, val loss: 0.06223, in 0.191s\n",
      "[151/200] 0.135 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51243, val loss: 0.51228, in 0.216s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35555, val loss: 0.35445, in 0.224s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05838, val loss: 0.05826, in 0.200s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06026, val loss: 0.05972, in 0.222s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06113, val loss: 0.06108, in 0.195s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47075, val loss: 0.47052, in 0.237s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06208, val loss: 0.06180, in 0.246s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47100, val loss: 0.47082, in 0.232s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62081, val loss: 0.62072, in 0.241s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33555, val loss: 0.33452, in 0.244s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06078, val loss: 0.06070, in 0.180s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05798, val loss: 0.05788, in 0.243s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05972, val loss: 0.05917, in 0.236s\n",
      "[152/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06196, val loss: 0.06169, in 0.162s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43517, val loss: 0.43510, in 0.229s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43550, val loss: 0.43536, in 0.221s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56165, val loss: 0.56149, in 0.224s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06037, val loss: 0.06031, in 0.199s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06167, val loss: 0.06140, in 0.169s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31793, val loss: 0.31688, in 0.228s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05938, val loss: 0.05882, in 0.203s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05754, val loss: 0.05745, in 0.218s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40465, val loss: 0.40460, in 0.275s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40501, val loss: 0.40493, in 0.275s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51238, val loss: 0.51213, in 0.277s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05994, val loss: 0.05987, in 0.290s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05707, val loss: 0.05701, in 0.261s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06076, val loss: 0.06047, in 0.280s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05874, val loss: 0.05821, in 0.281s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30232, val loss: 0.30138, in 0.295s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37824, val loss: 0.37845, in 0.252s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37864, val loss: 0.37866, in 0.241s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05686, val loss: 0.05681, in 0.158s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47095, val loss: 0.47064, in 0.237s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05962, val loss: 0.05955, in 0.174s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05853, val loss: 0.05800, in 0.157s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06047, val loss: 0.06018, in 0.212s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28859, val loss: 0.28761, in 0.218s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05658, val loss: 0.05651, in 0.171s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05950, val loss: 0.05946, in 0.162s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35532, val loss: 0.35554, in 0.221s\n",
      "[9/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05831, val loss: 0.05778, in 0.187s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43543, val loss: 0.43521, in 0.228s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35578, val loss: 0.35583, in 0.236s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06015, val loss: 0.05989, in 0.185s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27630, val loss: 0.27542, in 0.227s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05915, val loss: 0.05915, in 0.185s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05607, val loss: 0.05598, in 0.196s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06002, val loss: 0.05977, in 0.154s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05763, val loss: 0.05709, in 0.202s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33516, val loss: 0.33554, in 0.226s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33566, val loss: 0.33579, in 0.213s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40498, val loss: 0.40480, in 0.225s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05904, val loss: 0.05904, in 0.169s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05565, val loss: 0.05556, in 0.173s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26544, val loss: 0.26452, in 0.228s\n",
      "[15/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05984, val loss: 0.05958, in 0.173s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05716, val loss: 0.05661, in 0.193s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31743, val loss: 0.31800, in 0.233s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31816, val loss: 0.31825, in 0.233s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37859, val loss: 0.37854, in 0.225s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05885, val loss: 0.05886, in 0.172s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05534, val loss: 0.05525, in 0.208s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25560, val loss: 0.25459, in 0.240s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05656, val loss: 0.05599, in 0.203s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05942, val loss: 0.05917, in 0.238s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30192, val loss: 0.30251, in 0.249s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05839, val loss: 0.05838, in 0.210s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35570, val loss: 0.35561, in 0.255s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30236, val loss: 0.30260, in 0.261s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05495, in 0.191s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05913, val loss: 0.05889, in 0.210s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24641, val loss: 0.24548, in 0.241s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05589, val loss: 0.05535, in 0.228s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05821, val loss: 0.05820, in 0.156s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05480, val loss: 0.05472, in 0.186s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28802, val loss: 0.28867, in 0.228s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33557, val loss: 0.33553, in 0.223s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28849, val loss: 0.28878, in 0.224s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05876, val loss: 0.05851, in 0.176s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05755, val loss: 0.05758, in 0.192s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23840, val loss: 0.23737, in 0.237s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05545, val loss: 0.05489, in 0.234s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05414, val loss: 0.05414, in 0.204s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27574, val loss: 0.27657, in 0.235s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05850, val loss: 0.05825, in 0.193s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27623, val loss: 0.27662, in 0.230s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31781, val loss: 0.31783, in 0.235s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05514, val loss: 0.05456, in 0.183s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05688, val loss: 0.05692, in 0.233s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23097, val loss: 0.22996, in 0.238s\n",
      "[19/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05404, val loss: 0.05404, in 0.172s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05827, val loss: 0.05801, in 0.185s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26496, val loss: 0.26579, in 0.247s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30231, val loss: 0.30243, in 0.239s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26542, val loss: 0.26585, in 0.247s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05460, val loss: 0.05408, in 0.200s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05374, val loss: 0.05373, in 0.193s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05642, val loss: 0.05648, in 0.237s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22450, val loss: 0.22346, in 0.247s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05770, val loss: 0.05742, in 0.221s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05442, val loss: 0.05390, in 0.205s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25504, val loss: 0.25583, in 0.240s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25549, val loss: 0.25591, in 0.235s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05351, val loss: 0.05348, in 0.184s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28843, val loss: 0.28859, in 0.248s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05606, val loss: 0.05612, in 0.210s\n",
      "[168/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05756, val loss: 0.05728, in 0.163s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21753, val loss: 0.21658, in 0.237s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05424, val loss: 0.05372, in 0.173s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05325, val loss: 0.05324, in 0.177s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24631, val loss: 0.24701, in 0.228s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24673, val loss: 0.24705, in 0.236s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05568, val loss: 0.05570, in 0.183s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27619, val loss: 0.27638, in 0.240s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05729, val loss: 0.05703, in 0.177s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05408, val loss: 0.05358, in 0.162s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21211, val loss: 0.21104, in 0.225s\n",
      "[22/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05314, val loss: 0.05314, in 0.165s\n",
      "[168/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05695, val loss: 0.05670, in 0.190s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23794, val loss: 0.23879, in 0.243s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26540, val loss: 0.26558, in 0.234s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05501, val loss: 0.05504, in 0.247s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23839, val loss: 0.23881, in 0.260s\n",
      "[18/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05398, val loss: 0.05348, in 0.187s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05295, val loss: 0.05296, in 0.189s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20644, val loss: 0.20539, in 0.234s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05686, val loss: 0.05661, in 0.181s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23088, val loss: 0.23170, in 0.248s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05346, val loss: 0.05300, in 0.201s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05470, val loss: 0.05475, in 0.207s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25548, val loss: 0.25553, in 0.238s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23123, val loss: 0.23143, in 0.241s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05259, val loss: 0.05256, in 0.239s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05656, val loss: 0.05632, in 0.177s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20172, val loss: 0.20061, in 0.247s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05430, val loss: 0.05437, in 0.191s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22439, val loss: 0.22532, in 0.213s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05308, val loss: 0.05265, in 0.216s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24661, val loss: 0.24669, in 0.226s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05231, val loss: 0.05227, in 0.182s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22458, val loss: 0.22484, in 0.223s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05609, val loss: 0.05586, in 0.192s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19770, val loss: 0.19669, in 0.182s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05392, val loss: 0.05399, in 0.211s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21731, val loss: 0.21834, in 0.215s\n",
      "[21/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05272, val loss: 0.05232, in 0.221s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05183, in 0.184s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23829, val loss: 0.23845, in 0.209s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21773, val loss: 0.21806, in 0.205s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19368, val loss: 0.19270, in 0.215s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05571, val loss: 0.05550, in 0.222s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05382, val loss: 0.05390, in 0.165s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05148, val loss: 0.05153, in 0.195s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05246, val loss: 0.05205, in 0.203s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21170, val loss: 0.21265, in 0.223s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23113, val loss: 0.23118, in 0.229s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21214, val loss: 0.21257, in 0.229s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19029, val loss: 0.18939, in 0.190s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05373, val loss: 0.05380, in 0.143s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05542, val loss: 0.05522, in 0.201s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05205, val loss: 0.05166, in 0.167s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05089, val loss: 0.05095, in 0.211s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20605, val loss: 0.20703, in 0.208s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05335, val loss: 0.05342, in 0.161s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05484, in 0.162s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22448, val loss: 0.22462, in 0.212s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20711, val loss: 0.20756, in 0.210s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18675, val loss: 0.18585, in 0.222s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05179, val loss: 0.05140, in 0.162s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05053, val loss: 0.05058, in 0.215s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05289, val loss: 0.05298, in 0.193s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20137, val loss: 0.20239, in 0.210s\n",
      "[24/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05475, val loss: 0.05459, in 0.195s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18358, val loss: 0.18261, in 0.179s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21760, val loss: 0.21771, in 0.208s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20164, val loss: 0.20210, in 0.212s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05160, val loss: 0.05122, in 0.171s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05255, val loss: 0.05265, in 0.183s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19741, val loss: 0.19852, in 0.183s\n",
      "[25/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05025, val loss: 0.05031, in 0.213s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19765, val loss: 0.19827, in 0.165s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05440, val loss: 0.05421, in 0.209s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05141, val loss: 0.05105, in 0.147s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18073, val loss: 0.17983, in 0.188s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21202, val loss: 0.21219, in 0.203s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05224, val loss: 0.05235, in 0.171s\n",
      "[179/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05017, val loss: 0.05023, in 0.142s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05133, val loss: 0.05096, in 0.147s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17812, val loss: 0.17724, in 0.154s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19341, val loss: 0.19449, in 0.196s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05422, val loss: 0.05402, in 0.162s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19354, val loss: 0.19425, in 0.218s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20691, val loss: 0.20702, in 0.200s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04996, val loss: 0.05004, in 0.154s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05112, val loss: 0.05075, in 0.142s\n",
      "[177/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05412, val loss: 0.05392, in 0.144s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17545, val loss: 0.17455, in 0.169s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18978, val loss: 0.19080, in 0.169s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05203, val loss: 0.05213, in 0.199s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18997, val loss: 0.19078, in 0.165s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20140, val loss: 0.20165, in 0.208s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05095, val loss: 0.05059, in 0.155s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04967, val loss: 0.04974, in 0.182s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05393, val loss: 0.05372, in 0.173s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17232, val loss: 0.17137, in 0.207s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05165, val loss: 0.05173, in 0.214s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18691, val loss: 0.18781, in 0.168s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18593, val loss: 0.18694, in 0.222s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19739, val loss: 0.19781, in 0.183s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05072, val loss: 0.05035, in 0.181s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05382, val loss: 0.05362, in 0.153s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04920, val loss: 0.04925, in 0.185s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05146, val loss: 0.05154, in 0.153s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16987, val loss: 0.16897, in 0.185s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18274, val loss: 0.18381, in 0.182s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18331, val loss: 0.18407, in 0.215s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05048, val loss: 0.05010, in 0.174s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05353, val loss: 0.05337, in 0.182s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19331, val loss: 0.19388, in 0.223s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04876, val loss: 0.04880, in 0.200s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05138, val loss: 0.05148, in 0.170s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16768, val loss: 0.16673, in 0.172s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18005, val loss: 0.18108, in 0.187s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17941, val loss: 0.18018, in 0.187s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05345, val loss: 0.05330, in 0.141s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05033, val loss: 0.04995, in 0.163s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18965, val loss: 0.19025, in 0.166s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04843, val loss: 0.04850, in 0.169s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05115, val loss: 0.05123, in 0.162s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16501, val loss: 0.16417, in 0.165s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17733, val loss: 0.17839, in 0.157s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17664, val loss: 0.17751, in 0.158s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05314, val loss: 0.05299, in 0.163s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05017, val loss: 0.04979, in 0.164s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04808, val loss: 0.04817, in 0.169s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18588, val loss: 0.18644, in 0.208s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05088, val loss: 0.05096, in 0.182s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16181, in 0.177s\n",
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05010, val loss: 0.04971, in 0.142s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05287, val loss: 0.05275, in 0.155s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17410, val loss: 0.17507, in 0.174s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17418, val loss: 0.17528, in 0.210s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05053, val loss: 0.05062, in 0.173s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04767, val loss: 0.04774, in 0.199s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16033, val loss: 0.15944, in 0.173s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18272, val loss: 0.18335, in 0.205s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17162, val loss: 0.17269, in 0.181s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04961, val loss: 0.04926, in 0.204s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05258, val loss: 0.05245, in 0.203s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17120, val loss: 0.17221, in 0.226s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04752, val loss: 0.04759, in 0.149s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15842, val loss: 0.15759, in 0.161s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05021, val loss: 0.05031, in 0.181s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18002, val loss: 0.18071, in 0.157s\n",
      "[30/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05233, val loss: 0.05221, in 0.160s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16892, val loss: 0.17005, in 0.175s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16895, val loss: 0.17004, in 0.152s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04928, val loss: 0.04892, in 0.190s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05014, val loss: 0.05025, in 0.139s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04715, val loss: 0.04721, in 0.173s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15666, val loss: 0.15579, in 0.158s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17741, val loss: 0.17818, in 0.160s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05215, val loss: 0.05203, in 0.150s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16672, val loss: 0.16782, in 0.155s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16666, val loss: 0.16780, in 0.156s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04907, val loss: 0.04872, in 0.175s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04694, val loss: 0.04697, in 0.156s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15479, val loss: 0.15389, in 0.160s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04972, val loss: 0.04984, in 0.183s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17495, val loss: 0.17572, in 0.171s\n",
      "[32/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05190, val loss: 0.05179, in 0.179s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16539, in 0.172s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04888, val loss: 0.04856, in 0.142s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16464, val loss: 0.16586, in 0.172s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15254, val loss: 0.15170, in 0.178s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04665, val loss: 0.04668, in 0.196s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04934, val loss: 0.04947, in 0.181s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05177, val loss: 0.05167, in 0.147s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17188, val loss: 0.17261, in 0.210s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16259, val loss: 0.16362, in 0.169s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16192, val loss: 0.16315, in 0.165s\n",
      "[37/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04870, val loss: 0.04838, in 0.190s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04919, val loss: 0.04932, in 0.143s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15074, val loss: 0.14992, in 0.167s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04641, val loss: 0.04645, in 0.186s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05169, val loss: 0.05159, in 0.167s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16970, val loss: 0.17051, in 0.176s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16081, val loss: 0.16182, in 0.162s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04855, val loss: 0.04823, in 0.159s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15967, val loss: 0.16091, in 0.181s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14903, val loss: 0.14825, in 0.172s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04912, in 0.189s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04624, val loss: 0.04627, in 0.158s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16739, val loss: 0.16825, in 0.151s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05141, val loss: 0.05130, in 0.171s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15796, val loss: 0.15923, in 0.154s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15822, val loss: 0.15926, in 0.197s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04830, val loss: 0.04801, in 0.176s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14771, val loss: 0.14690, in 0.153s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04870, val loss: 0.04884, in 0.172s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04588, val loss: 0.04594, in 0.181s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16450, val loss: 0.16531, in 0.163s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05104, val loss: 0.05093, in 0.194s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04823, val loss: 0.04794, in 0.144s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15579, val loss: 0.15703, in 0.169s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15568, val loss: 0.15670, in 0.171s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14605, val loss: 0.14522, in 0.152s\n",
      "[46/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04582, val loss: 0.04588, in 0.143s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04821, val loss: 0.04835, in 0.189s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16148, val loss: 0.16236, in 0.170s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04782, val loss: 0.04756, in 0.162s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05049, val loss: 0.05041, in 0.186s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15385, val loss: 0.15490, in 0.175s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15331, val loss: 0.15440, in 0.198s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14423, val loss: 0.14341, in 0.158s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04574, val loss: 0.04579, in 0.135s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15945, val loss: 0.16035, in 0.160s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04796, val loss: 0.04811, in 0.174s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04760, val loss: 0.04732, in 0.150s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15241, val loss: 0.15335, in 0.150s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15180, val loss: 0.15292, in 0.157s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14264, val loss: 0.14183, in 0.149s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04993, val loss: 0.04986, in 0.188s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04533, val loss: 0.04540, in 0.165s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04790, val loss: 0.04805, in 0.140s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15764, val loss: 0.15848, in 0.162s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04746, val loss: 0.04719, in 0.162s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15064, val loss: 0.15151, in 0.145s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14139, val loss: 0.14056, in 0.153s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14959, val loss: 0.15072, in 0.168s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04954, val loss: 0.04944, in 0.188s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04776, val loss: 0.04792, in 0.145s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04493, val loss: 0.04500, in 0.205s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15571, val loss: 0.15658, in 0.168s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14866, val loss: 0.14952, in 0.164s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04716, val loss: 0.04686, in 0.200s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14024, val loss: 0.13938, in 0.165s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14805, val loss: 0.14912, in 0.159s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04762, val loss: 0.04775, in 0.161s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04933, val loss: 0.04921, in 0.180s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04456, val loss: 0.04463, in 0.155s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15327, val loss: 0.15407, in 0.162s\n",
      "[41/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04710, val loss: 0.04680, in 0.139s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14694, val loss: 0.14785, in 0.159s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14646, val loss: 0.14757, in 0.159s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13869, val loss: 0.13778, in 0.168s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04917, val loss: 0.04906, in 0.162s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04723, val loss: 0.04735, in 0.201s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04427, val loss: 0.04434, in 0.199s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15166, val loss: 0.15247, in 0.190s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04698, val loss: 0.04668, in 0.164s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14552, val loss: 0.14634, in 0.173s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13720, val loss: 0.13629, in 0.170s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14496, val loss: 0.14613, in 0.177s\n",
      "[46/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04904, val loss: 0.04893, in 0.137s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04687, val loss: 0.04703, in 0.176s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15026, val loss: 0.15110, in 0.148s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04415, val loss: 0.04423, in 0.171s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04674, val loss: 0.04646, in 0.153s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14390, val loss: 0.14478, in 0.157s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13538, in 0.158s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14343, val loss: 0.14461, in 0.156s\n",
      "[47/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04888, val loss: 0.04877, in 0.193s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14826, val loss: 0.14914, in 0.152s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04668, val loss: 0.04639, in 0.150s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13406, in 0.135s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04384, val loss: 0.04390, in 0.196s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14231, val loss: 0.14318, in 0.184s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14167, val loss: 0.14289, in 0.150s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04850, val loss: 0.04840, in 0.162s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04649, val loss: 0.04620, in 0.168s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14657, val loss: 0.14752, in 0.187s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04377, val loss: 0.04385, in 0.159s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14026, val loss: 0.14111, in 0.170s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13350, val loss: 0.13256, in 0.197s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13977, val loss: 0.14100, in 0.186s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14520, val loss: 0.14608, in 0.167s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13818, val loss: 0.13933, in 0.134s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13979, in 0.167s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13235, val loss: 0.13137, in 0.171s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13713, val loss: 0.13831, in 0.147s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13756, val loss: 0.13834, in 0.142s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14296, val loss: 0.14381, in 0.193s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13085, val loss: 0.12985, in 0.153s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13618, val loss: 0.13706, in 0.162s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14184, val loss: 0.14265, in 0.160s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13601, val loss: 0.13715, in 0.178s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12981, val loss: 0.12877, in 0.170s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13465, val loss: 0.13555, in 0.147s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14037, val loss: 0.14120, in 0.144s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12871, val loss: 0.12765, in 0.139s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13414, val loss: 0.13539, in 0.199s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13873, val loss: 0.13960, in 0.154s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12749, val loss: 0.12645, in 0.190s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13324, val loss: 0.13411, in 0.218s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13283, val loss: 0.13408, in 0.207s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13676, val loss: 0.13759, in 0.189s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13229, val loss: 0.13311, in 0.144s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12585, val loss: 0.12486, in 0.154s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13108, val loss: 0.13242, in 0.220s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13541, val loss: 0.13624, in 0.151s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.13188, in 0.149s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12498, val loss: 0.12399, in 0.163s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.13087, in 0.178s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13428, val loss: 0.13509, in 0.175s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12998, val loss: 0.13081, in 0.166s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12391, val loss: 0.12293, in 0.197s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12866, val loss: 0.12999, in 0.164s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13323, val loss: 0.13403, in 0.169s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12897, val loss: 0.12976, in 0.177s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12282, val loss: 0.12185, in 0.157s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12776, val loss: 0.12906, in 0.194s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13173, val loss: 0.13254, in 0.211s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12769, val loss: 0.12850, in 0.207s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12181, val loss: 0.12075, in 0.193s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12688, val loss: 0.12819, in 0.149s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12599, val loss: 0.12685, in 0.144s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13061, val loss: 0.13143, in 0.165s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12089, val loss: 0.11983, in 0.172s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12564, val loss: 0.12689, in 0.161s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12506, val loss: 0.12591, in 0.168s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12909, val loss: 0.12998, in 0.163s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11982, val loss: 0.11871, in 0.168s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12457, val loss: 0.12584, in 0.153s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12788, val loss: 0.12877, in 0.139s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12317, val loss: 0.12404, in 0.184s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11873, val loss: 0.11767, in 0.157s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12357, val loss: 0.12488, in 0.141s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12687, val loss: 0.12779, in 0.144s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12214, val loss: 0.12302, in 0.152s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11775, val loss: 0.11674, in 0.133s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12235, val loss: 0.12367, in 0.150s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12586, val loss: 0.12678, in 0.155s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11711, val loss: 0.11612, in 0.158s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12118, val loss: 0.12205, in 0.162s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12148, val loss: 0.12281, in 0.167s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12476, val loss: 0.12568, in 0.183s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11628, val loss: 0.11528, in 0.151s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12028, val loss: 0.12120, in 0.159s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12043, val loss: 0.12180, in 0.158s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12342, val loss: 0.12427, in 0.143s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11906, val loss: 0.11997, in 0.148s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11533, val loss: 0.11435, in 0.165s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11938, val loss: 0.12069, in 0.135s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12233, val loss: 0.12317, in 0.169s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11778, val loss: 0.11866, in 0.146s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11462, val loss: 0.11369, in 0.158s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11825, val loss: 0.11960, in 0.139s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12074, val loss: 0.12154, in 0.149s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11674, val loss: 0.11759, in 0.141s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11331, val loss: 0.11243, in 0.157s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11679, val loss: 0.11814, in 0.154s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11577, val loss: 0.11660, in 0.146s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11942, val loss: 0.12022, in 0.174s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11241, val loss: 0.11156, in 0.150s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11580, val loss: 0.11717, in 0.125s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11503, val loss: 0.11586, in 0.149s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11830, val loss: 0.11914, in 0.139s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11157, val loss: 0.11074, in 0.147s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11439, val loss: 0.11578, in 0.165s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04630, val loss: 0.04647, in 0.181s\n",
      "Fit 200 trees in 50.616 s, (1567 total leaves)\n",
      "Time spent computing histograms: 29.033s\n",
      "Time spent finding best splits:  0.201s\n",
      "Time spent applying splits:      4.319s\n",
      "Time spent predicting:           0.397s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11415, val loss: 0.11496, in 0.148s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11770, val loss: 0.11854, in 0.140s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11077, val loss: 0.10995, in 0.137s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11365, val loss: 0.11500, in 0.159s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11332, val loss: 0.11408, in 0.154s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11656, val loss: 0.11740, in 0.153s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10999, val loss: 0.10912, in 0.159s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04805, val loss: 0.04802, in 0.190s\n",
      "Fit 200 trees in 50.621 s, (1550 total leaves)\n",
      "Time spent computing histograms: 28.868s\n",
      "Time spent finding best splits:  0.283s\n",
      "Time spent applying splits:      3.949s\n",
      "Time spent predicting:           0.495s\n",
      "Binning 0.119 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.04634, val loss: 0.04607, in 0.162s\n",
      "Fit 200 trees in 50.619 s, (1567 total leaves)\n",
      "Time spent computing histograms: 29.279s\n",
      "Time spent finding best splits:  0.215s\n",
      "Time spent applying splits:      3.895s\n",
      "Time spent predicting:           0.410s\n",
      "Binning 0.119 GB of training data: 1 tree, 5 leaves, max depth = 3, train loss: 0.04372, val loss: 0.04379, in 0.154s\n",
      "Fit 200 trees in 50.992 s, (1557 total leaves)\n",
      "Time spent computing histograms: 29.245s\n",
      "Time spent finding best splits:  0.208s\n",
      "Time spent applying splits:      4.454s\n",
      "Time spent predicting:           0.472s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11294, val loss: 0.11433, in 0.166s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11270, val loss: 0.11345, in 0.146s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11561, val loss: 0.11653, in 0.168s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10936, val loss: 0.10851, in 0.155s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11216, val loss: 0.11354, in 0.152s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11177, val loss: 0.11249, in 0.156s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11449, val loss: 0.11536, in 0.138s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.10776, in 0.152s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11129, val loss: 0.11261, in 0.159s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11093, val loss: 0.11167, in 0.164s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11399, in 0.186s\n",
      "[71/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10785, val loss: 0.10700, in 0.187s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11027, val loss: 0.11161, in 0.173s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.11106, in 0.139s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11223, val loss: 0.11320, in 0.140s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10718, val loss: 0.10635, in 0.165s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10950, val loss: 0.11085, in 0.168s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10955, val loss: 0.11026, in 0.162s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11132, val loss: 0.11233, in 0.155s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10618, val loss: 0.10533, in 0.174s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10843, val loss: 0.10976, in 0.168s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.10940, in 0.147s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11080, val loss: 0.11182, in 0.148s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10569, val loss: 0.10486, in 0.138s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11028, val loss: 0.11129, in 0.141s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10761, val loss: 0.10893, in 0.187s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10773, val loss: 0.10848, in 0.181s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10493, val loss: 0.10408, in 0.146s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10964, val loss: 0.11068, in 0.149s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10831, in 0.159s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10636, val loss: 0.10712, in 0.165s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10365, val loss: 0.10287, in 0.168s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10892, val loss: 0.11000, in 0.166s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10582, val loss: 0.10662, in 0.138s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10609, val loss: 0.10750, in 0.155s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10303, val loss: 0.10227, in 0.144s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10800, val loss: 0.10902, in 0.146s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10517, val loss: 0.10601, in 0.150s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10530, val loss: 0.10673, in 0.162s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10172, val loss: 0.10097, in 0.163s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10469, val loss: 0.10552, in 0.138s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10720, val loss: 0.10823, in 0.148s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10454, val loss: 0.10592, in 0.137s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10063, val loss: 0.09983, in 0.195s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10404, val loss: 0.10487, in 0.140s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10632, val loss: 0.10738, in 0.160s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10532, in 0.147s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10026, val loss: 0.09946, in 0.137s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10336, val loss: 0.10420, in 0.162s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10302, val loss: 0.10444, in 0.153s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10540, val loss: 0.10646, in 0.166s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09982, val loss: 0.09905, in 0.134s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10355, in 0.142s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10235, val loss: 0.10377, in 0.138s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10478, val loss: 0.10580, in 0.160s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09908, val loss: 0.09830, in 0.170s\n",
      "[92/200] 2.483 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10189, val loss: 0.10335, in 0.161s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10176, val loss: 0.10259, in 0.204s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10438, val loss: 0.10539, in 0.165s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09860, val loss: 0.09778, in 0.162s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10097, val loss: 0.10248, in 0.159s\n",
      "[87/200] 0.134 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10312, val loss: 0.10410, in 0.153s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10120, val loss: 0.10206, in 0.163s\n",
      "[88/200] 2.508 s\n",
      "Binning 0.013 GB of validation data: 2.537 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.09756, val loss: 0.09677, in 0.148s\n",
      "[94/200] 2.542 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.10026, val loss: 0.10173, in 0.170s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10244, val loss: 0.10349, in 0.140s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10040, val loss: 0.10122, in 0.146s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62076, val loss: 0.62081, in 0.179s\n",
      "[2/200] 0.108 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09681, val loss: 0.09599, in 0.137s\n",
      "[95/200] 0.111 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.110 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10164, val loss: 0.10274, in 0.150s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09973, val loss: 0.10116, in 0.152s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09952, val loss: 0.10036, in 0.151s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56156, val loss: 0.56164, in 0.189s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09640, val loss: 0.09559, in 0.138s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62114, val loss: 0.62121, in 0.221s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62077, val loss: 0.62048, in 0.229s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09913, val loss: 0.09996, in 0.168s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09918, val loss: 0.10060, in 0.189s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62079, val loss: 0.62055, in 0.236s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10017, val loss: 0.10123, in 0.225s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09582, val loss: 0.09503, in 0.233s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51226, val loss: 0.51238, in 0.255s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56226, val loss: 0.56239, in 0.236s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09797, val loss: 0.09884, in 0.198s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09862, val loss: 0.10004, in 0.205s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56158, val loss: 0.56104, in 0.251s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56161, val loss: 0.56117, in 0.230s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09911, val loss: 0.10020, in 0.221s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09487, val loss: 0.09415, in 0.197s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47080, val loss: 0.47092, in 0.203s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09734, val loss: 0.09822, in 0.159s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09801, val loss: 0.09949, in 0.169s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51320, val loss: 0.51344, in 0.205s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09821, val loss: 0.09927, in 0.153s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51229, val loss: 0.51149, in 0.191s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51233, val loss: 0.51169, in 0.192s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09443, val loss: 0.09372, in 0.147s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09654, val loss: 0.09744, in 0.155s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43527, val loss: 0.43552, in 0.189s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09697, val loss: 0.09846, in 0.167s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09780, val loss: 0.09883, in 0.150s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47176, val loss: 0.47217, in 0.188s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09382, val loss: 0.09310, in 0.146s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47084, val loss: 0.46985, in 0.188s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47089, val loss: 0.47010, in 0.200s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09556, val loss: 0.09642, in 0.197s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09579, val loss: 0.09729, in 0.162s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09705, val loss: 0.09804, in 0.148s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40481, val loss: 0.40517, in 0.207s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09266, in 0.156s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43645, val loss: 0.43694, in 0.191s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43542, val loss: 0.43422, in 0.193s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43542, val loss: 0.43447, in 0.189s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09506, val loss: 0.09592, in 0.158s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09472, val loss: 0.09620, in 0.160s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09652, val loss: 0.09755, in 0.163s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09212, in 0.147s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37840, val loss: 0.37895, in 0.192s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40609, val loss: 0.40676, in 0.198s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40496, val loss: 0.40365, in 0.204s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09399, val loss: 0.09549, in 0.153s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40500, val loss: 0.40393, in 0.197s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09607, val loss: 0.09709, in 0.150s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09447, val loss: 0.09533, in 0.167s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09231, val loss: 0.09153, in 0.145s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35548, val loss: 0.35610, in 0.193s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37972, val loss: 0.38051, in 0.194s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09340, val loss: 0.09492, in 0.152s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09339, val loss: 0.09422, in 0.147s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09500, val loss: 0.09602, in 0.167s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09161, val loss: 0.09084, in 0.156s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37855, val loss: 0.37707, in 0.195s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37861, val loss: 0.37739, in 0.197s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33535, val loss: 0.33610, in 0.197s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09293, val loss: 0.09445, in 0.150s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09243, val loss: 0.09330, in 0.172s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09445, val loss: 0.09547, in 0.164s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09096, val loss: 0.09022, in 0.152s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35689, val loss: 0.35775, in 0.198s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35563, val loss: 0.35412, in 0.193s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35571, val loss: 0.35444, in 0.190s\n",
      "[9/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09257, val loss: 0.09407, in 0.145s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09387, val loss: 0.09491, in 0.145s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09191, val loss: 0.09274, in 0.156s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31765, val loss: 0.31857, in 0.199s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09038, val loss: 0.08963, in 0.162s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33683, val loss: 0.33787, in 0.198s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33550, val loss: 0.33388, in 0.208s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33561, val loss: 0.33428, in 0.204s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09198, val loss: 0.09344, in 0.156s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09009, val loss: 0.08936, in 0.147s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09073, val loss: 0.09156, in 0.166s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09272, val loss: 0.09382, in 0.183s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30213, val loss: 0.30311, in 0.199s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31925, val loss: 0.32033, in 0.189s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09109, val loss: 0.09256, in 0.174s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31788, val loss: 0.31610, in 0.190s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08969, val loss: 0.08895, in 0.137s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31802, val loss: 0.31660, in 0.198s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09018, val loss: 0.09102, in 0.150s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09217, val loss: 0.09324, in 0.150s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28825, val loss: 0.28934, in 0.187s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09075, val loss: 0.09224, in 0.138s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30379, val loss: 0.30493, in 0.197s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08960, val loss: 0.09042, in 0.146s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30226, val loss: 0.30035, in 0.191s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08809, val loss: 0.08736, in 0.192s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09155, val loss: 0.09264, in 0.167s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30254, val loss: 0.30111, in 0.197s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27601, val loss: 0.27716, in 0.206s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28990, val loss: 0.29116, in 0.195s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08986, val loss: 0.09137, in 0.205s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09126, val loss: 0.09233, in 0.143s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08708, val loss: 0.08641, in 0.163s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08901, val loss: 0.08983, in 0.197s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28849, val loss: 0.28664, in 0.212s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28859, val loss: 0.28707, in 0.219s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26520, val loss: 0.26640, in 0.222s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09065, val loss: 0.09173, in 0.186s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.09024, in 0.193s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08625, val loss: 0.08561, in 0.181s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08861, val loss: 0.08943, in 0.178s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27765, val loss: 0.27898, in 0.234s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27622, val loss: 0.27428, in 0.221s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27634, val loss: 0.27481, in 0.225s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08946, val loss: 0.09057, in 0.177s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08769, val loss: 0.08853, in 0.170s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08771, val loss: 0.08925, in 0.201s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25527, val loss: 0.25650, in 0.225s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08553, val loss: 0.08485, in 0.218s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26687, val loss: 0.26831, in 0.219s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26531, val loss: 0.26332, in 0.223s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26535, val loss: 0.26371, in 0.219s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08727, val loss: 0.08811, in 0.173s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08878, in 0.156s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08769, val loss: 0.08881, in 0.220s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08504, val loss: 0.08440, in 0.175s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24646, val loss: 0.24758, in 0.229s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25694, val loss: 0.25841, in 0.231s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08680, val loss: 0.08765, in 0.160s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25542, val loss: 0.25329, in 0.223s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08739, val loss: 0.08854, in 0.159s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08659, val loss: 0.08818, in 0.202s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25566, val loss: 0.25402, in 0.225s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08469, val loss: 0.08404, in 0.183s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23809, val loss: 0.23932, in 0.216s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08622, val loss: 0.08705, in 0.167s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24808, val loss: 0.24966, in 0.217s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08673, val loss: 0.08787, in 0.159s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08576, val loss: 0.08733, in 0.168s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08412, val loss: 0.08350, in 0.168s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24617, val loss: 0.24408, in 0.221s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24680, val loss: 0.24502, in 0.224s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08574, val loss: 0.08659, in 0.160s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23091, val loss: 0.23212, in 0.221s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08613, val loss: 0.08729, in 0.172s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08531, val loss: 0.08689, in 0.185s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23957, val loss: 0.24115, in 0.215s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08344, val loss: 0.08279, in 0.214s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23817, val loss: 0.23595, in 0.210s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23846, val loss: 0.23672, in 0.204s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08525, val loss: 0.08608, in 0.155s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08559, val loss: 0.08675, in 0.150s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08508, val loss: 0.08666, in 0.135s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22425, val loss: 0.22557, in 0.200s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23167, val loss: 0.23320, in 0.195s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08287, val loss: 0.08224, in 0.172s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08493, val loss: 0.08577, in 0.157s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23074, val loss: 0.22859, in 0.214s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23127, val loss: 0.22950, in 0.216s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08521, val loss: 0.08636, in 0.179s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08472, val loss: 0.08632, in 0.170s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21740, val loss: 0.21866, in 0.217s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08242, val loss: 0.08181, in 0.168s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08431, val loss: 0.08514, in 0.180s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22502, val loss: 0.22660, in 0.231s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08571, in 0.157s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08376, val loss: 0.08537, in 0.165s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22429, val loss: 0.22206, in 0.212s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22461, val loss: 0.22288, in 0.207s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08206, val loss: 0.08144, in 0.139s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21180, val loss: 0.21309, in 0.203s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08302, val loss: 0.08378, in 0.187s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21866, val loss: 0.22018, in 0.195s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08310, val loss: 0.08420, in 0.186s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08223, val loss: 0.08384, in 0.186s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21736, val loss: 0.21531, in 0.181s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08099, in 0.150s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21768, val loss: 0.21611, in 0.195s\n",
      "[21/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08279, val loss: 0.08354, in 0.136s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20667, val loss: 0.20802, in 0.190s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08224, val loss: 0.08328, in 0.157s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21240, val loss: 0.21405, in 0.184s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08124, val loss: 0.08286, in 0.167s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21181, val loss: 0.20988, in 0.192s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08019, val loss: 0.07962, in 0.196s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21210, val loss: 0.21044, in 0.198s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08226, val loss: 0.08300, in 0.169s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08148, val loss: 0.08254, in 0.157s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20120, val loss: 0.20267, in 0.197s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08082, val loss: 0.08243, in 0.151s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20725, val loss: 0.20890, in 0.201s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07981, val loss: 0.07921, in 0.159s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20672, val loss: 0.20466, in 0.191s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20698, val loss: 0.20522, in 0.199s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08159, val loss: 0.08229, in 0.186s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08047, val loss: 0.08208, in 0.149s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08085, val loss: 0.08191, in 0.163s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19883, in 0.169s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20261, val loss: 0.20423, in 0.194s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07860, val loss: 0.07801, in 0.190s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20117, val loss: 0.19911, in 0.207s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08045, val loss: 0.08151, in 0.142s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08031, val loss: 0.08101, in 0.176s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20145, val loss: 0.19978, in 0.195s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07999, val loss: 0.08163, in 0.173s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19309, val loss: 0.19466, in 0.199s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07812, val loss: 0.07752, in 0.140s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19727, val loss: 0.19896, in 0.168s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08017, val loss: 0.08127, in 0.137s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19710, val loss: 0.19520, in 0.175s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07981, val loss: 0.08051, in 0.174s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19750, val loss: 0.19600, in 0.166s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07950, val loss: 0.08109, in 0.159s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18941, val loss: 0.19093, in 0.164s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07737, val loss: 0.07677, in 0.166s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07963, val loss: 0.08069, in 0.165s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19269, val loss: 0.19435, in 0.205s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07937, val loss: 0.08003, in 0.140s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19349, val loss: 0.19170, in 0.170s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07832, val loss: 0.07985, in 0.194s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19342, val loss: 0.19202, in 0.217s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07692, val loss: 0.07634, in 0.151s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18564, val loss: 0.18709, in 0.206s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07827, val loss: 0.07935, in 0.192s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18815, val loss: 0.18983, in 0.183s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07795, val loss: 0.07854, in 0.209s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18954, val loss: 0.18787, in 0.213s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07700, val loss: 0.07852, in 0.178s\n",
      "[120/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07670, val loss: 0.07612, in 0.149s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18981, val loss: 0.18841, in 0.172s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18153, val loss: 0.18304, in 0.185s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07735, val loss: 0.07844, in 0.170s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18478, val loss: 0.18654, in 0.175s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18618, val loss: 0.18451, in 0.168s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07685, val loss: 0.07742, in 0.187s\n",
      "[122/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07650, val loss: 0.07803, in 0.184s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07539, val loss: 0.07478, in 0.200s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18603, val loss: 0.18456, in 0.208s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17883, val loss: 0.18046, in 0.166s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07623, val loss: 0.07733, in 0.195s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07654, val loss: 0.07711, in 0.145s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18119, val loss: 0.18287, in 0.202s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18261, val loss: 0.18088, in 0.206s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07488, val loss: 0.07425, in 0.160s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07532, val loss: 0.07685, in 0.187s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17635, val loss: 0.17802, in 0.153s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18291, val loss: 0.18160, in 0.175s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07576, val loss: 0.07688, in 0.154s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07605, val loss: 0.07660, in 0.154s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17807, val loss: 0.17971, in 0.168s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07407, in 0.140s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07491, val loss: 0.07641, in 0.165s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17869, val loss: 0.17710, in 0.183s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17369, val loss: 0.17541, in 0.163s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18005, val loss: 0.17880, in 0.172s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07483, val loss: 0.07591, in 0.161s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17466, val loss: 0.17635, in 0.179s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07485, val loss: 0.07534, in 0.211s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07359, val loss: 0.07295, in 0.227s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17611, val loss: 0.17451, in 0.193s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07444, val loss: 0.07593, in 0.216s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17724, val loss: 0.17611, in 0.196s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17070, val loss: 0.17237, in 0.234s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07444, val loss: 0.07493, in 0.178s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17209, val loss: 0.17373, in 0.182s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07403, val loss: 0.07509, in 0.241s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07323, val loss: 0.07261, in 0.162s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17340, val loss: 0.17179, in 0.166s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07381, val loss: 0.07530, in 0.166s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17472, val loss: 0.17362, in 0.159s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16826, val loss: 0.16997, in 0.181s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16979, val loss: 0.17149, in 0.149s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07391, val loss: 0.07439, in 0.168s\n",
      "[127/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07352, val loss: 0.07455, in 0.186s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07274, val loss: 0.07212, in 0.177s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07349, val loss: 0.07497, in 0.163s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16621, val loss: 0.16792, in 0.149s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17035, val loss: 0.16878, in 0.214s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17169, val loss: 0.17057, in 0.211s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07374, val loss: 0.07422, in 0.143s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16733, val loss: 0.16910, in 0.175s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07259, val loss: 0.07197, in 0.138s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07292, val loss: 0.07396, in 0.195s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16812, val loss: 0.16654, in 0.155s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07288, val loss: 0.07438, in 0.212s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16382, val loss: 0.16550, in 0.183s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16947, val loss: 0.16839, in 0.162s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07290, val loss: 0.07334, in 0.175s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16434, val loss: 0.16607, in 0.202s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07257, val loss: 0.07359, in 0.165s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07193, val loss: 0.07128, in 0.198s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16581, val loss: 0.16419, in 0.159s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07256, val loss: 0.07402, in 0.147s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16153, val loss: 0.16321, in 0.155s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16712, val loss: 0.16604, in 0.176s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07251, val loss: 0.07297, in 0.162s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07230, val loss: 0.07332, in 0.140s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16212, val loss: 0.16388, in 0.173s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07161, val loss: 0.07096, in 0.147s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07228, val loss: 0.07375, in 0.165s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15997, val loss: 0.16167, in 0.160s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16337, val loss: 0.16180, in 0.192s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16496, val loss: 0.16387, in 0.168s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07214, val loss: 0.07261, in 0.184s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07183, val loss: 0.07281, in 0.172s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15912, val loss: 0.16078, in 0.169s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07054, val loss: 0.06986, in 0.204s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07184, val loss: 0.07334, in 0.160s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15737, val loss: 0.15904, in 0.160s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16150, val loss: 0.15989, in 0.151s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16204, val loss: 0.16103, in 0.174s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07187, val loss: 0.07234, in 0.168s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15715, val loss: 0.15879, in 0.163s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07146, val loss: 0.07245, in 0.180s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07027, val loss: 0.06958, in 0.163s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07158, val loss: 0.07306, in 0.158s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15552, val loss: 0.15728, in 0.178s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15875, val loss: 0.15713, in 0.179s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15983, val loss: 0.15889, in 0.179s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07155, val loss: 0.07201, in 0.154s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15486, val loss: 0.15645, in 0.191s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07081, val loss: 0.07180, in 0.177s\n",
      "[129/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07000, val loss: 0.06930, in 0.150s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07131, val loss: 0.07283, in 0.158s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15340, val loss: 0.15520, in 0.167s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15652, val loss: 0.15503, in 0.171s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15756, val loss: 0.15672, in 0.178s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07052, val loss: 0.07100, in 0.222s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07039, val loss: 0.07138, in 0.159s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06967, val loss: 0.06898, in 0.162s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15281, val loss: 0.15449, in 0.174s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15199, val loss: 0.15379, in 0.161s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07083, val loss: 0.07236, in 0.205s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15503, val loss: 0.15348, in 0.159s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15576, val loss: 0.15489, in 0.166s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06994, val loss: 0.07041, in 0.164s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06943, val loss: 0.07041, in 0.200s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15104, val loss: 0.15274, in 0.188s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06935, val loss: 0.06867, in 0.200s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14980, val loss: 0.15157, in 0.168s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15323, val loss: 0.15173, in 0.179s\n",
      "[41/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07053, val loss: 0.07209, in 0.187s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15304, val loss: 0.15220, in 0.167s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06881, val loss: 0.06932, in 0.208s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06903, val loss: 0.07000, in 0.166s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14918, val loss: 0.15084, in 0.168s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06896, val loss: 0.06826, in 0.165s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14812, val loss: 0.14995, in 0.168s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15143, val loss: 0.14996, in 0.185s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06951, val loss: 0.07106, in 0.197s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15134, val loss: 0.15052, in 0.168s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14671, val loss: 0.14829, in 0.165s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14663, val loss: 0.14846, in 0.163s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06838, val loss: 0.06887, in 0.185s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06796, val loss: 0.06731, in 0.200s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06798, val loss: 0.06896, in 0.209s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14919, val loss: 0.14774, in 0.197s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14979, val loss: 0.14902, in 0.174s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06883, val loss: 0.07039, in 0.185s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06801, val loss: 0.06852, in 0.138s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14488, val loss: 0.14664, in 0.180s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14484, val loss: 0.14650, in 0.202s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06709, val loss: 0.06804, in 0.202s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06708, val loss: 0.06640, in 0.218s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14841, val loss: 0.14757, in 0.173s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14722, val loss: 0.14579, in 0.181s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06840, val loss: 0.06995, in 0.183s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06773, val loss: 0.06825, in 0.183s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14469, in 0.187s\n",
      "[45/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06695, val loss: 0.06790, in 0.158s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14273, val loss: 0.14446, in 0.210s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06674, val loss: 0.06606, in 0.162s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14610, val loss: 0.14529, in 0.160s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14542, val loss: 0.14397, in 0.159s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06819, val loss: 0.06973, in 0.155s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06732, val loss: 0.06783, in 0.161s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14157, val loss: 0.14331, in 0.147s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14110, val loss: 0.14276, in 0.181s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14404, in 0.149s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06633, val loss: 0.06731, in 0.179s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06602, val loss: 0.06531, in 0.184s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14308, val loss: 0.14180, in 0.186s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06775, val loss: 0.06932, in 0.183s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06692, val loss: 0.06742, in 0.182s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13983, val loss: 0.14151, in 0.167s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13972, val loss: 0.14136, in 0.153s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06569, val loss: 0.06500, in 0.153s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14326, val loss: 0.14252, in 0.193s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14181, val loss: 0.14050, in 0.157s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06575, val loss: 0.06672, in 0.199s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06711, val loss: 0.06865, in 0.210s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06649, val loss: 0.06699, in 0.190s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13795, val loss: 0.13960, in 0.156s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13773, val loss: 0.13943, in 0.188s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06548, val loss: 0.06476, in 0.160s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14214, val loss: 0.14136, in 0.157s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13964, val loss: 0.13835, in 0.171s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06684, val loss: 0.06838, in 0.142s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06485, val loss: 0.06583, in 0.205s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06610, val loss: 0.06660, in 0.163s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13622, val loss: 0.13795, in 0.155s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13631, val loss: 0.13795, in 0.196s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14051, val loss: 0.13978, in 0.158s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06512, val loss: 0.06443, in 0.192s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13807, val loss: 0.13681, in 0.173s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06607, val loss: 0.06759, in 0.192s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06416, val loss: 0.06516, in 0.202s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13460, val loss: 0.13633, in 0.154s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06516, val loss: 0.06568, in 0.197s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13503, val loss: 0.13672, in 0.166s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13847, val loss: 0.13785, in 0.187s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13704, val loss: 0.13583, in 0.161s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06428, val loss: 0.06360, in 0.190s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06391, val loss: 0.06490, in 0.147s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06559, val loss: 0.06714, in 0.214s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13467, in 0.184s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13350, val loss: 0.13520, in 0.182s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06425, val loss: 0.06480, in 0.197s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13706, val loss: 0.13647, in 0.172s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13544, val loss: 0.13425, in 0.173s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06366, val loss: 0.06295, in 0.187s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06358, val loss: 0.06459, in 0.170s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06523, val loss: 0.06679, in 0.173s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13208, val loss: 0.13371, in 0.164s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13234, val loss: 0.13402, in 0.168s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13446, val loss: 0.13324, in 0.154s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13558, val loss: 0.13500, in 0.164s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06351, val loss: 0.06400, in 0.205s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06322, val loss: 0.06418, in 0.161s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06293, val loss: 0.06225, in 0.214s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06492, val loss: 0.06645, in 0.168s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13096, val loss: 0.13250, in 0.182s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13088, val loss: 0.13250, in 0.172s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13405, val loss: 0.13347, in 0.172s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13134, in 0.185s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06285, val loss: 0.06330, in 0.192s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06305, val loss: 0.06406, in 0.168s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06266, val loss: 0.06199, in 0.157s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12946, val loss: 0.13111, in 0.161s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06431, val loss: 0.06586, in 0.222s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13300, val loss: 0.13238, in 0.164s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13099, in 0.192s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13117, val loss: 0.12994, in 0.193s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06240, val loss: 0.06173, in 0.164s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06236, val loss: 0.06285, in 0.207s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06252, val loss: 0.06352, in 0.215s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12825, val loss: 0.12990, in 0.182s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06404, val loss: 0.06557, in 0.173s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13116, val loss: 0.13059, in 0.179s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12778, val loss: 0.12936, in 0.201s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12929, val loss: 0.12821, in 0.187s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06189, val loss: 0.06120, in 0.199s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06161, val loss: 0.06205, in 0.217s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06198, val loss: 0.06297, in 0.208s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12726, val loss: 0.12885, in 0.187s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12973, val loss: 0.12910, in 0.185s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06324, val loss: 0.06473, in 0.222s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12657, val loss: 0.12813, in 0.190s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12766, val loss: 0.12658, in 0.188s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06118, val loss: 0.06051, in 0.216s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06163, val loss: 0.06260, in 0.185s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06087, val loss: 0.06131, in 0.222s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12852, val loss: 0.12791, in 0.173s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12553, val loss: 0.12712, in 0.194s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12529, val loss: 0.12687, in 0.159s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12638, val loss: 0.12530, in 0.170s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06244, val loss: 0.06392, in 0.220s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06101, val loss: 0.06195, in 0.186s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06066, val loss: 0.06109, in 0.157s\n",
      "[151/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06092, val loss: 0.06025, in 0.211s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12457, val loss: 0.12615, in 0.169s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12538, val loss: 0.12429, in 0.148s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12395, val loss: 0.12557, in 0.178s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12721, val loss: 0.12656, in 0.212s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06223, val loss: 0.06372, in 0.188s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06064, val loss: 0.06160, in 0.190s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06035, val loss: 0.06079, in 0.187s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12308, val loss: 0.12469, in 0.180s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06050, val loss: 0.05984, in 0.211s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12641, val loss: 0.12574, in 0.173s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12448, val loss: 0.12334, in 0.193s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12285, val loss: 0.12444, in 0.223s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06211, val loss: 0.06360, in 0.159s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06046, val loss: 0.06141, in 0.163s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12498, val loss: 0.12431, in 0.157s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12156, val loss: 0.12310, in 0.166s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05970, val loss: 0.06015, in 0.222s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12336, val loss: 0.12222, in 0.185s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12166, val loss: 0.12319, in 0.174s\n",
      "[62/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06192, val loss: 0.06342, in 0.158s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06010, val loss: 0.05940, in 0.224s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06013, val loss: 0.06105, in 0.198s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12051, val loss: 0.12203, in 0.167s\n",
      "[61/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05952, val loss: 0.05996, in 0.153s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12346, val loss: 0.12286, in 0.193s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06178, val loss: 0.06332, in 0.162s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12244, val loss: 0.12129, in 0.175s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12075, val loss: 0.12230, in 0.187s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05986, val loss: 0.05916, in 0.177s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06001, val loss: 0.06093, in 0.165s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05939, val loss: 0.05984, in 0.157s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11958, val loss: 0.12114, in 0.191s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12261, val loss: 0.12197, in 0.172s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12136, val loss: 0.12022, in 0.161s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06153, val loss: 0.06304, in 0.169s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11982, val loss: 0.12132, in 0.183s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05956, val loss: 0.05885, in 0.182s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05963, val loss: 0.06055, in 0.193s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05900, val loss: 0.05945, in 0.186s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11882, val loss: 0.12043, in 0.160s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12160, val loss: 0.12096, in 0.154s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06138, val loss: 0.06288, in 0.159s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12042, val loss: 0.11925, in 0.184s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11912, val loss: 0.12060, in 0.170s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05920, val loss: 0.05853, in 0.178s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11931, in 0.188s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12066, val loss: 0.12001, in 0.188s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11914, val loss: 0.11799, in 0.158s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05870, val loss: 0.05914, in 0.194s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06086, val loss: 0.06235, in 0.196s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05921, val loss: 0.06012, in 0.226s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11792, val loss: 0.11940, in 0.182s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05879, val loss: 0.05812, in 0.173s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11819, val loss: 0.11703, in 0.165s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11640, val loss: 0.11796, in 0.170s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05817, val loss: 0.05860, in 0.184s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11842, in 0.145s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05886, val loss: 0.05976, in 0.174s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11902, in 0.211s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06051, val loss: 0.06205, in 0.206s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05852, val loss: 0.05786, in 0.180s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11534, val loss: 0.11689, in 0.172s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11741, in 0.161s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11721, val loss: 0.11615, in 0.197s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05859, val loss: 0.05950, in 0.163s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11886, val loss: 0.11823, in 0.167s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05780, val loss: 0.05826, in 0.191s\n",
      "[159/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05842, val loss: 0.05775, in 0.156s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05999, val loss: 0.06153, in 0.210s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11445, val loss: 0.11598, in 0.167s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11489, val loss: 0.11638, in 0.175s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11763, val loss: 0.11702, in 0.171s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11614, val loss: 0.11505, in 0.193s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05758, val loss: 0.05808, in 0.180s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05788, val loss: 0.05881, in 0.197s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05821, val loss: 0.05754, in 0.168s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05954, val loss: 0.06107, in 0.168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11359, val loss: 0.11510, in 0.164s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11401, val loss: 0.11553, in 0.178s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11656, val loss: 0.11592, in 0.180s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11536, val loss: 0.11434, in 0.193s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05794, val loss: 0.05727, in 0.181s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05763, val loss: 0.05860, in 0.184s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05726, val loss: 0.05775, in 0.223s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05933, val loss: 0.06088, in 0.187s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11237, val loss: 0.11386, in 0.214s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11599, val loss: 0.11535, in 0.159s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11312, val loss: 0.11464, in 0.189s\n",
      "[71/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05753, val loss: 0.05850, in 0.168s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11446, val loss: 0.11344, in 0.204s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05895, val loss: 0.06047, in 0.173s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05740, val loss: 0.05676, in 0.217s\n",
      "[168/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05705, val loss: 0.05757, in 0.189s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11409, in 0.155s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11492, val loss: 0.11432, in 0.173s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11161, val loss: 0.11307, in 0.177s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11338, val loss: 0.11235, in 0.168s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05861, val loss: 0.06014, in 0.175s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05713, val loss: 0.05812, in 0.222s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05681, val loss: 0.05732, in 0.173s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05627, in 0.201s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11169, val loss: 0.11332, in 0.176s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11068, val loss: 0.11217, in 0.180s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11348, in 0.185s\n",
      "[71/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05851, val loss: 0.06003, in 0.155s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05692, val loss: 0.05793, in 0.170s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11215, val loss: 0.11112, in 0.199s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05628, val loss: 0.05678, in 0.204s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05659, val loss: 0.05596, in 0.196s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11081, val loss: 0.11240, in 0.168s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11020, val loss: 0.11169, in 0.153s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11328, val loss: 0.11261, in 0.162s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05662, val loss: 0.05765, in 0.166s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11107, val loss: 0.11002, in 0.171s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05815, val loss: 0.05967, in 0.226s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05595, val loss: 0.05645, in 0.182s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05631, val loss: 0.05568, in 0.178s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10957, val loss: 0.11108, in 0.161s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10951, val loss: 0.11110, in 0.178s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11253, val loss: 0.11186, in 0.195s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11029, val loss: 0.10922, in 0.158s\n",
      "[73/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05633, val loss: 0.05734, in 0.183s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05802, val loss: 0.05956, in 0.161s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05577, val loss: 0.05627, in 0.149s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05571, val loss: 0.05508, in 0.182s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10864, val loss: 0.11016, in 0.172s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.11025, in 0.163s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11186, val loss: 0.11127, in 0.179s\n",
      "[74/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05614, val loss: 0.05713, in 0.169s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10935, val loss: 0.10824, in 0.186s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05558, val loss: 0.05607, in 0.168s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05754, val loss: 0.05910, in 0.194s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10698, val loss: 0.10847, in 0.181s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05531, val loss: 0.05465, in 0.205s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10782, val loss: 0.10939, in 0.201s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11045, val loss: 0.10992, in 0.175s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05554, val loss: 0.05652, in 0.204s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10678, in 0.201s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05724, val loss: 0.05877, in 0.168s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05531, val loss: 0.05582, in 0.192s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10620, val loss: 0.10769, in 0.173s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10729, val loss: 0.10887, in 0.171s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05520, val loss: 0.05455, in 0.182s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10944, val loss: 0.10890, in 0.197s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05521, val loss: 0.05573, in 0.204s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10734, val loss: 0.10623, in 0.215s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05680, val loss: 0.05837, in 0.254s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10515, val loss: 0.10658, in 0.221s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05501, val loss: 0.05602, in 0.283s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05497, val loss: 0.05432, in 0.217s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10639, val loss: 0.10797, in 0.255s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10792, in 0.221s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10620, val loss: 0.10511, in 0.183s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05488, val loss: 0.05541, in 0.210s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05473, val loss: 0.05576, in 0.153s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10391, val loss: 0.10539, in 0.193s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05612, val loss: 0.05768, in 0.217s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05472, val loss: 0.05406, in 0.186s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10796, val loss: 0.10741, in 0.168s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10562, val loss: 0.10723, in 0.183s\n",
      "[80/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10573, val loss: 0.10463, in 0.164s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10326, val loss: 0.10474, in 0.164s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05593, val loss: 0.05749, in 0.159s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05463, val loss: 0.05397, in 0.164s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05450, val loss: 0.05500, in 0.233s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05433, val loss: 0.05534, in 0.221s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10726, val loss: 0.10668, in 0.157s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10457, val loss: 0.10616, in 0.176s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10529, val loss: 0.10418, in 0.159s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10254, val loss: 0.10403, in 0.163s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05583, val loss: 0.05740, in 0.170s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05450, val loss: 0.05383, in 0.167s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05421, val loss: 0.05471, in 0.168s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05402, val loss: 0.05502, in 0.168s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10649, val loss: 0.10596, in 0.194s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10412, val loss: 0.10569, in 0.178s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10410, val loss: 0.10300, in 0.192s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10186, val loss: 0.10333, in 0.168s\n",
      "[81/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05550, val loss: 0.05706, in 0.196s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05401, val loss: 0.05452, in 0.186s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05403, val loss: 0.05336, in 0.212s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10570, val loss: 0.10520, in 0.176s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10269, val loss: 0.10427, in 0.170s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05364, val loss: 0.05462, in 0.220s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10344, val loss: 0.10234, in 0.187s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10096, val loss: 0.10237, in 0.173s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05526, val loss: 0.05680, in 0.154s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05372, val loss: 0.05423, in 0.187s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10523, val loss: 0.10473, in 0.161s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05355, val loss: 0.05291, in 0.188s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10198, val loss: 0.10353, in 0.203s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05336, val loss: 0.05433, in 0.194s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10257, val loss: 0.10149, in 0.163s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10018, val loss: 0.10164, in 0.188s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05495, val loss: 0.05649, in 0.186s\n",
      "[174/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05354, val loss: 0.05403, in 0.179s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10465, val loss: 0.10415, in 0.188s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05326, val loss: 0.05263, in 0.177s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05328, val loss: 0.05426, in 0.160s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10110, val loss: 0.10269, in 0.165s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10134, val loss: 0.10037, in 0.180s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09942, val loss: 0.10088, in 0.176s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05464, val loss: 0.05617, in 0.167s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05343, val loss: 0.05394, in 0.158s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05302, val loss: 0.05239, in 0.159s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10347, val loss: 0.10299, in 0.182s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10043, val loss: 0.10202, in 0.176s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05281, val loss: 0.05380, in 0.202s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10078, val loss: 0.09978, in 0.175s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09905, val loss: 0.10052, in 0.154s\n",
      "[85/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05438, val loss: 0.05591, in 0.177s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05329, val loss: 0.05381, in 0.165s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10260, val loss: 0.10212, in 0.170s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05269, val loss: 0.05208, in 0.188s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09936, val loss: 0.10097, in 0.173s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05246, val loss: 0.05344, in 0.188s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09963, val loss: 0.09867, in 0.187s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09856, val loss: 0.10001, in 0.184s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05409, val loss: 0.05563, in 0.203s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05294, val loss: 0.05342, in 0.198s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10179, val loss: 0.10131, in 0.164s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05238, val loss: 0.05177, in 0.181s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09853, val loss: 0.10013, in 0.178s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05234, val loss: 0.05331, in 0.160s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09722, val loss: 0.09864, in 0.179s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09765, val loss: 0.09674, in 0.210s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05373, val loss: 0.05529, in 0.177s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10109, val loss: 0.10062, in 0.183s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05198, val loss: 0.05138, in 0.187s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05229, val loss: 0.05281, in 0.214s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09762, val loss: 0.09923, in 0.185s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05278, in 0.207s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09651, val loss: 0.09794, in 0.162s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09724, val loss: 0.09633, in 0.160s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05358, val loss: 0.05512, in 0.170s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10044, val loss: 0.10000, in 0.180s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05214, val loss: 0.05267, in 0.159s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05183, val loss: 0.05124, in 0.162s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09568, val loss: 0.09732, in 0.213s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09524, val loss: 0.09667, in 0.198s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05147, val loss: 0.05241, in 0.212s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09661, val loss: 0.09570, in 0.203s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05331, val loss: 0.05486, in 0.188s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05138, val loss: 0.05083, in 0.194s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05176, val loss: 0.05228, in 0.205s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09960, val loss: 0.09914, in 0.214s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09682, in 0.174s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09612, in 0.167s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05116, val loss: 0.05208, in 0.174s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05315, val loss: 0.05469, in 0.164s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09465, in 0.226s\n",
      "[89/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05093, val loss: 0.05042, in 0.186s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09824, val loss: 0.09782, in 0.186s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09447, val loss: 0.09613, in 0.169s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05125, val loss: 0.05178, in 0.203s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09403, val loss: 0.09550, in 0.170s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05069, val loss: 0.05165, in 0.206s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05277, val loss: 0.05432, in 0.193s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09508, val loss: 0.09416, in 0.177s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05050, val loss: 0.05001, in 0.202s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09759, val loss: 0.09716, in 0.210s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09388, val loss: 0.09555, in 0.206s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05082, val loss: 0.05135, in 0.213s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09273, val loss: 0.09417, in 0.191s\n",
      "[92/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05046, val loss: 0.05142, in 0.186s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05267, val loss: 0.05421, in 0.160s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09424, val loss: 0.09335, in 0.189s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05036, val loss: 0.04988, in 0.174s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09485, in 0.173s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09226, val loss: 0.09369, in 0.158s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09697, val loss: 0.09655, in 0.210s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05032, val loss: 0.05081, in 0.223s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04989, val loss: 0.05087, in 0.186s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09359, val loss: 0.09269, in 0.159s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05239, val loss: 0.05393, in 0.207s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05019, val loss: 0.04969, in 0.161s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09172, val loss: 0.09314, in 0.180s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09525, in 0.174s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09392, in 0.216s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04964, val loss: 0.05064, in 0.180s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05227, val loss: 0.05381, in 0.157s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04995, val loss: 0.05045, in 0.214s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09265, val loss: 0.09178, in 0.197s\n",
      "[93/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04989, val loss: 0.04941, in 0.189s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09494, val loss: 0.09456, in 0.163s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09180, val loss: 0.09339, in 0.187s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09079, val loss: 0.09220, in 0.222s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04939, val loss: 0.05041, in 0.180s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05202, val loss: 0.05358, in 0.204s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04971, val loss: 0.04925, in 0.163s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09098, val loss: 0.09018, in 0.210s\n",
      "[94/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04964, val loss: 0.05013, in 0.229s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09395, val loss: 0.09358, in 0.177s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09131, val loss: 0.09288, in 0.163s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09011, val loss: 0.09153, in 0.174s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05195, val loss: 0.05350, in 0.151s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.05005, in 0.205s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08967, val loss: 0.08893, in 0.181s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04936, val loss: 0.04985, in 0.170s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09328, val loss: 0.09290, in 0.163s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04933, val loss: 0.04891, in 0.229s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08979, val loss: 0.09121, in 0.159s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09023, val loss: 0.09187, in 0.186s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05170, val loss: 0.05325, in 0.169s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04885, val loss: 0.04991, in 0.162s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08918, val loss: 0.08841, in 0.155s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04927, val loss: 0.04977, in 0.163s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09270, val loss: 0.09230, in 0.160s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08940, val loss: 0.09086, in 0.152s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08966, val loss: 0.09129, in 0.170s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04900, val loss: 0.04859, in 0.222s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05132, val loss: 0.05289, in 0.196s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04914, val loss: 0.04963, in 0.152s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08858, val loss: 0.08777, in 0.172s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04856, val loss: 0.04962, in 0.201s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09208, val loss: 0.09170, in 0.198s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04884, val loss: 0.04844, in 0.151s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08992, in 0.203s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08922, val loss: 0.09088, in 0.196s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08825, val loss: 0.08746, in 0.161s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04826, val loss: 0.04932, in 0.180s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04881, val loss: 0.04929, in 0.195s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05069, val loss: 0.05226, in 0.218s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.09113, in 0.174s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08780, val loss: 0.08933, in 0.172s\n",
      "[100/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04860, val loss: 0.04822, in 0.181s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08860, val loss: 0.09030, in 0.206s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08786, val loss: 0.08707, in 0.168s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04869, val loss: 0.04917, in 0.161s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05050, val loss: 0.05205, in 0.168s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09120, val loss: 0.09081, in 0.147s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04790, val loss: 0.04894, in 0.220s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08706, val loss: 0.08854, in 0.167s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08808, val loss: 0.08978, in 0.166s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08728, val loss: 0.08648, in 0.164s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04827, val loss: 0.04791, in 0.221s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04848, val loss: 0.04897, in 0.186s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05026, val loss: 0.05183, in 0.196s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04772, val loss: 0.04877, in 0.157s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09071, val loss: 0.09035, in 0.176s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08516, val loss: 0.08664, in 0.213s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08783, val loss: 0.08954, in 0.163s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04813, val loss: 0.04777, in 0.196s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04825, val loss: 0.04876, in 0.181s\n",
      "[193/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04765, val loss: 0.04871, in 0.155s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08640, val loss: 0.08561, in 0.231s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04996, val loss: 0.05154, in 0.187s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08973, val loss: 0.08937, in 0.198s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08564, in 0.157s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08738, val loss: 0.08906, in 0.161s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04744, val loss: 0.04850, in 0.152s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08615, val loss: 0.08538, in 0.153s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04847, in 0.188s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04787, val loss: 0.04748, in 0.215s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08888, in 0.160s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04958, val loss: 0.05115, in 0.207s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08385, val loss: 0.08537, in 0.155s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08666, val loss: 0.08833, in 0.209s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08471, in 0.172s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04708, val loss: 0.04815, in 0.209s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04777, val loss: 0.04826, in 0.196s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08871, val loss: 0.08832, in 0.188s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04929, val loss: 0.05087, in 0.194s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08314, val loss: 0.08463, in 0.204s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08593, val loss: 0.08761, in 0.206s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08370, val loss: 0.08300, in 0.214s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04764, val loss: 0.04814, in 0.163s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08843, val loss: 0.08804, in 0.151s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04666, val loss: 0.04774, in 0.205s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08251, val loss: 0.08397, in 0.159s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04896, val loss: 0.05055, in 0.214s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08511, val loss: 0.08676, in 0.179s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04749, val loss: 0.04801, in 0.158s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08310, val loss: 0.08239, in 0.166s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08776, val loss: 0.08738, in 0.175s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04741, in 0.167s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04880, val loss: 0.05041, in 0.183s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08092, val loss: 0.08238, in 0.218s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08457, val loss: 0.08621, in 0.164s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08713, val loss: 0.08677, in 0.177s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04724, val loss: 0.04777, in 0.207s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08193, val loss: 0.08124, in 0.217s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04605, val loss: 0.04715, in 0.231s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04868, val loss: 0.05030, in 0.171s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08002, val loss: 0.08143, in 0.194s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08350, val loss: 0.08513, in 0.214s\n",
      "[109/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04711, val loss: 0.04763, in 0.188s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04581, val loss: 0.04692, in 0.188s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08628, val loss: 0.08586, in 0.254s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08060, val loss: 0.07995, in 0.236s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04844, val loss: 0.05003, in 0.185s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07957, val loss: 0.08100, in 0.190s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08308, val loss: 0.08470, in 0.164s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04702, val loss: 0.04754, in 0.171s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04569, val loss: 0.04679, in 0.149s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07944, val loss: 0.07884, in 0.185s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08562, val loss: 0.08524, in 0.202s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07882, val loss: 0.08027, in 0.175s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08264, val loss: 0.08425, in 0.165s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04795, val loss: 0.04954, in 0.221s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04551, val loss: 0.04660, in 0.159s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08519, val loss: 0.08477, in 0.164s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07835, val loss: 0.07980, in 0.171s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07857, val loss: 0.07798, in 0.222s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04539, val loss: 0.04648, in 0.142s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08103, val loss: 0.08265, in 0.209s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08439, val loss: 0.08399, in 0.172s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07802, val loss: 0.07948, in 0.163s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07821, val loss: 0.07763, in 0.166s\n",
      "[110/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04533, val loss: 0.04643, in 0.170s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08051, val loss: 0.08210, in 0.175s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07752, val loss: 0.07899, in 0.180s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08322, val loss: 0.08290, in 0.215s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07765, val loss: 0.07706, in 0.174s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08019, val loss: 0.08178, in 0.155s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04520, val loss: 0.04628, in 0.173s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07726, val loss: 0.07876, in 0.149s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08131, in 0.208s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07642, val loss: 0.07588, in 0.212s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07879, val loss: 0.08039, in 0.215s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07640, val loss: 0.07785, in 0.167s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07555, val loss: 0.07504, in 0.169s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08023, val loss: 0.07995, in 0.209s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07759, val loss: 0.07916, in 0.192s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07511, val loss: 0.07654, in 0.210s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07519, val loss: 0.07470, in 0.172s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07911, val loss: 0.07886, in 0.179s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07704, val loss: 0.07857, in 0.204s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07483, val loss: 0.07630, in 0.161s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07498, val loss: 0.07451, in 0.164s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07840, val loss: 0.07816, in 0.181s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07630, val loss: 0.07788, in 0.185s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07450, val loss: 0.07597, in 0.163s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07420, val loss: 0.07376, in 0.210s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07797, val loss: 0.07771, in 0.156s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07588, val loss: 0.07744, in 0.206s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07419, val loss: 0.07572, in 0.201s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07748, val loss: 0.07719, in 0.171s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07338, val loss: 0.07298, in 0.183s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07551, val loss: 0.07705, in 0.160s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07323, val loss: 0.07471, in 0.172s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07719, val loss: 0.07689, in 0.154s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07233, val loss: 0.07197, in 0.207s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07501, val loss: 0.07656, in 0.169s\n",
      "[121/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07270, val loss: 0.07418, in 0.200s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07665, val loss: 0.07633, in 0.175s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07203, val loss: 0.07166, in 0.151s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07470, val loss: 0.07623, in 0.174s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07230, val loss: 0.07380, in 0.172s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07552, val loss: 0.07522, in 0.205s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07166, val loss: 0.07129, in 0.196s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07436, val loss: 0.07589, in 0.159s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07165, val loss: 0.07312, in 0.204s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07443, in 0.174s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07407, val loss: 0.07559, in 0.150s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07101, val loss: 0.07066, in 0.180s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07126, val loss: 0.07278, in 0.163s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07425, val loss: 0.07405, in 0.171s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07060, val loss: 0.07030, in 0.164s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07351, val loss: 0.07503, in 0.185s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07234, in 0.197s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04764, val loss: 0.04728, in 0.204s\n",
      "Fit 200 trees in 41.260 s, (1558 total leaves)\n",
      "Time spent computing histograms: 23.166s\n",
      "Time spent finding best splits:  0.149s\n",
      "Time spent applying splits:      3.265s\n",
      "Time spent predicting:           0.380s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.07024, val loss: 0.06993, in 0.172s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07383, val loss: 0.07364, in 0.205s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07306, val loss: 0.07457, in 0.177s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07006, val loss: 0.07159, in 0.184s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07000, val loss: 0.06971, in 0.161s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07348, val loss: 0.07330, in 0.183s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07188, val loss: 0.07340, in 0.216s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06939, val loss: 0.07092, in 0.189s\n",
      "[127/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06952, val loss: 0.06923, in 0.180s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07268, val loss: 0.07250, in 0.184s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07139, val loss: 0.07287, in 0.170s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06923, val loss: 0.06892, in 0.167s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07185, val loss: 0.07171, in 0.186s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06836, val loss: 0.06989, in 0.220s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07037, val loss: 0.07185, in 0.211s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06893, val loss: 0.06861, in 0.212s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06801, val loss: 0.06956, in 0.192s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07152, val loss: 0.07135, in 0.198s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06999, val loss: 0.07147, in 0.163s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06756, val loss: 0.06910, in 0.150s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06833, val loss: 0.06804, in 0.211s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06957, val loss: 0.07100, in 0.168s\n",
      "[131/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07116, val loss: 0.07101, in 0.202s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04681, val loss: 0.04734, in 0.151s\n",
      "Fit 200 trees in 41.354 s, (1566 total leaves)\n",
      "Time spent computing histograms: 23.141s\n",
      "Time spent finding best splits:  0.150s\n",
      "Time spent applying splits:      3.268s\n",
      "Time spent predicting:           0.341s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06710, val loss: 0.06867, in 0.181s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06789, val loss: 0.06762, in 0.155s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07063, in 0.161s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06863, val loss: 0.07008, in 0.218s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04772, val loss: 0.04929, in 0.193s\n",
      "Fit 200 trees in 41.480 s, (1561 total leaves)\n",
      "Time spent computing histograms: 23.191s\n",
      "Time spent finding best splits:  0.170s\n",
      "Time spent applying splits:      3.234s\n",
      "Time spent predicting:           0.348s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06751, val loss: 0.06726, in 0.175s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06616, val loss: 0.06773, in 0.222s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07033, val loss: 0.07019, in 0.190s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06826, val loss: 0.06971, in 0.160s\n",
      "[133/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06736, val loss: 0.06713, in 0.184s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07008, val loss: 0.06992, in 0.198s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06596, val loss: 0.06755, in 0.205s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06755, val loss: 0.06902, in 0.242s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06700, val loss: 0.06678, in 0.165s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06561, val loss: 0.06720, in 0.151s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06933, val loss: 0.06920, in 0.195s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06683, val loss: 0.06828, in 0.181s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04510, val loss: 0.04617, in 0.150s\n",
      "Fit 200 trees in 41.323 s, (1558 total leaves)\n",
      "Time spent computing histograms: 23.065s\n",
      "Time spent finding best splits:  0.159s\n",
      "Time spent applying splits:      3.320s\n",
      "Time spent predicting:           0.308s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06617, val loss: 0.06596, in 0.200s\n",
      "[133/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06521, val loss: 0.06680, in 0.204s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06905, val loss: 0.06891, in 0.164s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06662, val loss: 0.06811, in 0.167s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06594, val loss: 0.06571, in 0.154s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06858, val loss: 0.06847, in 0.159s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06468, val loss: 0.06627, in 0.197s\n",
      "[136/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06647, val loss: 0.06794, in 0.141s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06840, val loss: 0.06830, in 0.157s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06545, val loss: 0.06526, in 0.217s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06426, val loss: 0.06582, in 0.161s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06594, val loss: 0.06743, in 0.205s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06505, val loss: 0.06485, in 0.157s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06798, val loss: 0.06786, in 0.167s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06390, val loss: 0.06545, in 0.149s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06561, val loss: 0.06707, in 0.158s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06770, val loss: 0.06755, in 0.155s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06447, val loss: 0.06429, in 0.178s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06302, val loss: 0.06458, in 0.206s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06513, val loss: 0.06659, in 0.166s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140/200] 2.687 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06419, val loss: 0.06403, in 0.168s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06721, val loss: 0.06708, in 0.189s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06399, in 0.203s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06428, val loss: 0.06574, in 0.223s\n",
      "[141/200] 0.135 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06369, val loss: 0.06355, in 0.187s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06665, val loss: 0.06652, in 0.207s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06227, val loss: 0.06384, in 0.167s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06406, val loss: 0.06552, in 0.157s\n",
      "[142/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06355, val loss: 0.06343, in 0.150s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06629, val loss: 0.06616, in 0.162s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62082, val loss: 0.62049, in 0.212s\n",
      "[2/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06362, val loss: 0.06506, in 0.153s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06169, val loss: 0.06325, in 0.202s\n",
      "[142/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06342, val loss: 0.06329, in 0.149s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06611, val loss: 0.06596, in 0.151s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06342, val loss: 0.06483, in 0.159s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56167, val loss: 0.56105, in 0.213s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06124, val loss: 0.06281, in 0.176s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06295, val loss: 0.06281, in 0.200s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06522, val loss: 0.06511, in 0.195s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06313, val loss: 0.06454, in 0.172s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06097, val loss: 0.06254, in 0.156s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51245, val loss: 0.51156, in 0.194s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06244, val loss: 0.06236, in 0.198s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06488, val loss: 0.06481, in 0.165s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06289, val loss: 0.06429, in 0.153s\n",
      "[146/200] 2.667 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06020, val loss: 0.06175, in 0.196s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47103, val loss: 0.46993, in 0.205s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06200, val loss: 0.06193, in 0.168s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06276, val loss: 0.06416, in 0.136s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06462, val loss: 0.06453, in 0.183s\n",
      "[145/200] 0.132 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05984, val loss: 0.06135, in 0.196s\n",
      "[146/200] 2.692 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06449, val loss: 0.06443, in 0.147s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43553, val loss: 0.43434, in 0.214s\n",
      "[6/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06247, val loss: 0.06386, in 0.221s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06122, val loss: 0.06118, in 0.250s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05948, val loss: 0.06095, in 0.202s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06418, val loss: 0.06408, in 0.194s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62080, val loss: 0.62052, in 0.262s\n",
      "[2/200] 0.165 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06217, val loss: 0.06355, in 0.205s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40506, val loss: 0.40377, in 0.266s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06085, val loss: 0.06083, in 0.229s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05894, val loss: 0.06044, in 0.246s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06384, val loss: 0.06375, in 0.242s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56164, val loss: 0.56111, in 0.260s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62080, val loss: 0.62051, in 0.260s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06066, val loss: 0.06062, in 0.163s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06171, val loss: 0.06310, in 0.243s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37872, val loss: 0.37739, in 0.247s\n",
      "[8/200] 2.706 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06348, val loss: 0.06339, in 0.204s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05835, val loss: 0.05980, in 0.228s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06029, val loss: 0.06024, in 0.193s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51235, val loss: 0.51155, in 0.206s\n",
      "[4/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06141, val loss: 0.06277, in 0.164s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56164, val loss: 0.56110, in 0.217s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35570, val loss: 0.35428, in 0.221s\n",
      "[9/200] 0.131 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06305, val loss: 0.06300, in 0.169s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06105, val loss: 0.06241, in 0.176s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05997, val loss: 0.05992, in 0.182s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05760, val loss: 0.05904, in 0.209s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51238, val loss: 0.51158, in 0.208s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47092, val loss: 0.46994, in 0.222s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33568, val loss: 0.33432, in 0.206s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06268, val loss: 0.06260, in 0.157s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62074, val loss: 0.62068, in 0.203s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06045, val loss: 0.06179, in 0.193s\n",
      "[153/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05733, val loss: 0.05877, in 0.190s\n",
      "[151/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05969, val loss: 0.05964, in 0.219s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43539, val loss: 0.43434, in 0.220s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47095, val loss: 0.46996, in 0.222s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06210, val loss: 0.06200, in 0.191s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31810, val loss: 0.31673, in 0.215s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06033, val loss: 0.06166, in 0.158s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05706, val loss: 0.05848, in 0.155s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05944, val loss: 0.05939, in 0.139s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56153, val loss: 0.56143, in 0.220s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43543, val loss: 0.43442, in 0.206s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40488, val loss: 0.40374, in 0.213s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06160, val loss: 0.06153, in 0.178s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05830, in 0.162s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05915, val loss: 0.05909, in 0.158s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30234, val loss: 0.30091, in 0.210s\n",
      "[12/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05984, val loss: 0.06122, in 0.173s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51221, val loss: 0.51201, in 0.211s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06113, val loss: 0.06108, in 0.162s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40493, val loss: 0.40385, in 0.209s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37851, val loss: 0.37739, in 0.210s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05628, val loss: 0.05772, in 0.184s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05838, val loss: 0.05832, in 0.188s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05960, val loss: 0.06097, in 0.188s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28848, val loss: 0.28699, in 0.209s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47075, val loss: 0.47052, in 0.190s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06078, val loss: 0.06070, in 0.169s\n",
      "[155/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05944, val loss: 0.06081, in 0.146s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05579, val loss: 0.05720, in 0.173s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37857, val loss: 0.37750, in 0.203s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35547, val loss: 0.35431, in 0.212s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05782, val loss: 0.05774, in 0.203s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27627, val loss: 0.27490, in 0.205s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43517, val loss: 0.43510, in 0.208s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06037, val loss: 0.06031, in 0.174s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05934, val loss: 0.06071, in 0.151s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05522, val loss: 0.05663, in 0.190s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35555, val loss: 0.35445, in 0.219s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33544, val loss: 0.33429, in 0.213s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05734, val loss: 0.05726, in 0.215s\n",
      "[155/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05914, val loss: 0.06052, in 0.146s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26549, val loss: 0.26409, in 0.219s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40465, val loss: 0.40460, in 0.212s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05994, val loss: 0.05987, in 0.208s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05482, val loss: 0.05618, in 0.195s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33555, val loss: 0.33452, in 0.199s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05699, val loss: 0.05693, in 0.179s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05889, val loss: 0.06026, in 0.157s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31785, val loss: 0.31674, in 0.221s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05962, val loss: 0.05955, in 0.162s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25556, val loss: 0.25400, in 0.211s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37824, val loss: 0.37845, in 0.211s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05455, val loss: 0.05587, in 0.184s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05676, val loss: 0.05668, in 0.158s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05858, val loss: 0.05995, in 0.162s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05950, val loss: 0.05946, in 0.146s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31793, val loss: 0.31688, in 0.214s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30213, val loss: 0.30099, in 0.211s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24678, val loss: 0.24510, in 0.225s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35532, val loss: 0.35554, in 0.207s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05404, val loss: 0.05532, in 0.173s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05806, val loss: 0.05940, in 0.183s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05622, val loss: 0.05615, in 0.196s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05915, val loss: 0.05915, in 0.171s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30232, val loss: 0.30138, in 0.215s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28826, val loss: 0.28711, in 0.221s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23844, val loss: 0.23686, in 0.203s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05374, val loss: 0.05503, in 0.182s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33516, val loss: 0.33554, in 0.205s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05904, val loss: 0.05904, in 0.148s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05758, val loss: 0.05892, in 0.182s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05582, val loss: 0.05574, in 0.194s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28859, val loss: 0.28761, in 0.210s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05346, val loss: 0.05476, in 0.151s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27610, val loss: 0.27497, in 0.216s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05885, val loss: 0.05886, in 0.172s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23128, val loss: 0.22962, in 0.242s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05548, val loss: 0.05543, in 0.191s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31743, val loss: 0.31800, in 0.235s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05737, val loss: 0.05870, in 0.226s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27630, val loss: 0.27542, in 0.245s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05300, val loss: 0.05429, in 0.249s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05839, val loss: 0.05838, in 0.212s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05517, val loss: 0.05512, in 0.177s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26517, val loss: 0.26401, in 0.255s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30192, val loss: 0.30251, in 0.225s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22500, val loss: 0.22331, in 0.235s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05700, val loss: 0.05832, in 0.237s\n",
      "[165/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05290, val loss: 0.05421, in 0.153s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05821, val loss: 0.05820, in 0.163s\n",
      "[164/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05507, val loss: 0.05502, in 0.171s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26544, val loss: 0.26452, in 0.222s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25524, val loss: 0.25400, in 0.222s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05673, val loss: 0.05804, in 0.181s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21791, val loss: 0.21636, in 0.227s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28802, val loss: 0.28867, in 0.231s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05279, val loss: 0.05410, in 0.169s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05755, val loss: 0.05758, in 0.265s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05473, val loss: 0.05472, in 0.336s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25560, val loss: 0.25459, in 0.408s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05644, val loss: 0.05775, in 0.390s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05269, val loss: 0.05402, in 0.358s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24607, val loss: 0.24484, in 0.422s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21235, val loss: 0.21085, in 0.442s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27574, val loss: 0.27657, in 0.443s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05456, val loss: 0.05456, in 0.251s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05688, val loss: 0.05692, in 0.359s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05624, val loss: 0.05756, in 0.186s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24641, val loss: 0.24548, in 0.257s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05233, val loss: 0.05368, in 0.217s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23807, val loss: 0.23681, in 0.236s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05446, val loss: 0.05448, in 0.151s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26496, val loss: 0.26579, in 0.217s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20728, val loss: 0.20575, in 0.223s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05643, val loss: 0.05648, in 0.200s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05614, val loss: 0.05746, in 0.143s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05213, val loss: 0.05347, in 0.153s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23840, val loss: 0.23737, in 0.212s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05404, val loss: 0.05407, in 0.176s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23067, val loss: 0.22948, in 0.216s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05592, val loss: 0.05721, in 0.154s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20180, val loss: 0.20039, in 0.206s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25504, val loss: 0.25583, in 0.218s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05607, val loss: 0.05612, in 0.189s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05317, in 0.162s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05385, val loss: 0.05387, in 0.159s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23097, val loss: 0.22996, in 0.215s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05540, val loss: 0.05667, in 0.180s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22418, val loss: 0.22289, in 0.217s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19786, val loss: 0.19655, in 0.185s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05569, val loss: 0.05571, in 0.176s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05144, val loss: 0.05277, in 0.173s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24631, val loss: 0.24701, in 0.202s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05334, val loss: 0.05335, in 0.179s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05519, val loss: 0.05650, in 0.161s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22450, val loss: 0.22346, in 0.219s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19380, val loss: 0.19254, in 0.208s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05501, val loss: 0.05504, in 0.204s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21729, val loss: 0.21612, in 0.219s\n",
      "[21/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05124, val loss: 0.05258, in 0.200s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23794, val loss: 0.23879, in 0.209s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05297, val loss: 0.05300, in 0.183s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05456, val loss: 0.05589, in 0.200s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21753, val loss: 0.21658, in 0.209s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19021, val loss: 0.18890, in 0.167s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05102, val loss: 0.05235, in 0.167s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05471, val loss: 0.05476, in 0.192s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21182, val loss: 0.21058, in 0.207s\n",
      "[22/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05270, val loss: 0.05273, in 0.174s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23088, val loss: 0.23170, in 0.219s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05429, val loss: 0.05561, in 0.195s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05069, val loss: 0.05204, in 0.181s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05430, val loss: 0.05437, in 0.180s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21211, val loss: 0.21104, in 0.214s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05244, val loss: 0.05247, in 0.164s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18639, val loss: 0.18496, in 0.236s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20674, val loss: 0.20555, in 0.214s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22439, val loss: 0.22532, in 0.204s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05404, val loss: 0.05536, in 0.182s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05392, val loss: 0.05399, in 0.203s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05036, val loss: 0.05168, in 0.219s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20644, val loss: 0.20539, in 0.211s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18323, val loss: 0.18192, in 0.193s\n",
      "[29/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05223, val loss: 0.05226, in 0.207s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20127, val loss: 0.20006, in 0.220s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21731, val loss: 0.21834, in 0.212s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05381, val loss: 0.05512, in 0.185s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05383, val loss: 0.05390, in 0.168s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05011, val loss: 0.05142, in 0.174s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18037, val loss: 0.17910, in 0.192s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20172, val loss: 0.20061, in 0.228s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05192, val loss: 0.05200, in 0.215s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19726, val loss: 0.19615, in 0.185s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21170, val loss: 0.21265, in 0.230s\n",
      "[22/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05373, val loss: 0.05380, in 0.154s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05345, val loss: 0.05482, in 0.208s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04991, val loss: 0.05119, in 0.171s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17764, val loss: 0.17646, in 0.165s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05184, val loss: 0.05192, in 0.155s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19770, val loss: 0.19669, in 0.181s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19372, val loss: 0.19268, in 0.181s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05335, val loss: 0.05342, in 0.164s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05312, val loss: 0.05449, in 0.171s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04977, val loss: 0.05106, in 0.153s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20605, val loss: 0.20703, in 0.205s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05167, val loss: 0.05176, in 0.146s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17512, val loss: 0.17390, in 0.170s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19368, val loss: 0.19270, in 0.201s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18980, val loss: 0.18869, in 0.206s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05289, val loss: 0.05298, in 0.182s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05280, val loss: 0.05416, in 0.183s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04958, val loss: 0.05087, in 0.196s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05133, val loss: 0.05142, in 0.171s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20137, val loss: 0.20239, in 0.212s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17205, val loss: 0.17085, in 0.221s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19029, val loss: 0.18939, in 0.178s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18649, val loss: 0.18535, in 0.179s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05272, val loss: 0.05409, in 0.146s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05256, val loss: 0.05266, in 0.178s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05123, val loss: 0.05130, in 0.165s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19741, val loss: 0.19852, in 0.177s\n",
      "[25/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04925, val loss: 0.05058, in 0.211s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16985, val loss: 0.16872, in 0.160s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05242, val loss: 0.05376, in 0.168s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18675, val loss: 0.18585, in 0.215s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05225, val loss: 0.05235, in 0.202s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05085, val loss: 0.05090, in 0.179s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18287, val loss: 0.18165, in 0.243s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16765, val loss: 0.16647, in 0.169s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04892, val loss: 0.05024, in 0.186s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19341, val loss: 0.19449, in 0.203s\n",
      "[26/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05227, val loss: 0.05361, in 0.150s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18358, val loss: 0.18261, in 0.180s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05067, val loss: 0.05072, in 0.156s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05203, val loss: 0.05213, in 0.197s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17897, val loss: 0.17792, in 0.188s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04867, val loss: 0.04997, in 0.155s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16492, val loss: 0.16375, in 0.179s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18978, val loss: 0.19080, in 0.178s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05209, val loss: 0.05343, in 0.164s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18073, val loss: 0.17983, in 0.207s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05027, val loss: 0.05034, in 0.203s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04859, val loss: 0.04990, in 0.177s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17623, val loss: 0.17519, in 0.198s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16189, val loss: 0.16084, in 0.205s\n",
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05165, val loss: 0.05173, in 0.238s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05196, val loss: 0.05330, in 0.177s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18593, val loss: 0.18694, in 0.256s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04842, val loss: 0.04971, in 0.167s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17812, val loss: 0.17724, in 0.201s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17374, val loss: 0.17273, in 0.189s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05001, val loss: 0.05006, in 0.235s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05170, val loss: 0.05305, in 0.176s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15992, val loss: 0.15887, in 0.203s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05147, val loss: 0.05154, in 0.209s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04833, val loss: 0.04964, in 0.169s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18274, val loss: 0.18381, in 0.223s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17545, val loss: 0.17455, in 0.194s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05147, val loss: 0.05282, in 0.184s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04974, val loss: 0.04981, in 0.203s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05138, val loss: 0.05148, in 0.167s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15819, val loss: 0.15715, in 0.200s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17073, val loss: 0.16969, in 0.259s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18005, val loss: 0.18108, in 0.189s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04793, val loss: 0.04918, in 0.220s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17232, val loss: 0.17137, in 0.221s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05121, val loss: 0.05260, in 0.195s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04951, val loss: 0.04960, in 0.195s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05115, val loss: 0.05124, in 0.198s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15582, val loss: 0.15478, in 0.178s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16855, val loss: 0.16745, in 0.175s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17733, val loss: 0.17839, in 0.179s\n",
      "[31/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04778, val loss: 0.04903, in 0.198s\n",
      "[185/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04943, val loss: 0.04953, in 0.166s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16987, val loss: 0.16897, in 0.200s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05095, val loss: 0.05231, in 0.185s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05088, val loss: 0.05096, in 0.200s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16604, val loss: 0.16502, in 0.206s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15388, val loss: 0.15278, in 0.231s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17418, val loss: 0.17528, in 0.253s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04716, val loss: 0.04835, in 0.213s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04936, val loss: 0.04947, in 0.187s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16768, val loss: 0.16673, in 0.211s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05078, val loss: 0.05213, in 0.210s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05053, val loss: 0.05062, in 0.219s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15242, val loss: 0.15129, in 0.188s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16314, val loss: 0.16222, in 0.222s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04687, val loss: 0.04805, in 0.208s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17162, val loss: 0.17269, in 0.219s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04912, in 0.219s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16501, val loss: 0.16417, in 0.204s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05050, val loss: 0.05184, in 0.213s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05021, val loss: 0.05031, in 0.199s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16079, val loss: 0.15981, in 0.190s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14994, val loss: 0.14891, in 0.213s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04892, val loss: 0.04906, in 0.142s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04661, val loss: 0.04780, in 0.179s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16892, val loss: 0.17005, in 0.187s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05028, val loss: 0.05161, in 0.161s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16181, in 0.183s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05014, val loss: 0.05025, in 0.150s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14794, val loss: 0.14697, in 0.158s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15847, val loss: 0.15753, in 0.165s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04871, val loss: 0.04883, in 0.154s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16672, val loss: 0.16782, in 0.170s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16033, val loss: 0.15944, in 0.167s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04633, val loss: 0.04752, in 0.203s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04980, val loss: 0.05115, in 0.188s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04972, val loss: 0.04984, in 0.192s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14595, val loss: 0.14499, in 0.175s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15671, val loss: 0.15576, in 0.174s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04855, val loss: 0.04870, in 0.168s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04626, val loss: 0.04745, in 0.140s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15842, val loss: 0.15759, in 0.159s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16539, in 0.179s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04965, val loss: 0.05102, in 0.168s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04934, val loss: 0.04947, in 0.175s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15416, val loss: 0.15322, in 0.163s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14420, val loss: 0.14333, in 0.192s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04841, val loss: 0.04856, in 0.143s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04610, val loss: 0.04729, in 0.160s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16259, val loss: 0.16362, in 0.163s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15666, val loss: 0.15579, in 0.171s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04919, val loss: 0.04933, in 0.152s\n",
      "[191/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04948, val loss: 0.05084, in 0.179s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15237, val loss: 0.15139, in 0.163s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14274, val loss: 0.14185, in 0.170s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04796, val loss: 0.04809, in 0.198s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16081, val loss: 0.16182, in 0.162s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15479, val loss: 0.15389, in 0.166s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04584, val loss: 0.04708, in 0.207s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04916, val loss: 0.05053, in 0.186s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15079, val loss: 0.14981, in 0.182s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04912, in 0.194s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14148, val loss: 0.14057, in 0.168s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04769, val loss: 0.04783, in 0.187s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15254, val loss: 0.15170, in 0.167s\n",
      "[42/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04557, val loss: 0.04680, in 0.174s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04906, val loss: 0.05042, in 0.150s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15822, val loss: 0.15926, in 0.214s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14894, val loss: 0.14798, in 0.169s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04870, val loss: 0.04885, in 0.180s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13890, val loss: 0.13809, in 0.194s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04539, val loss: 0.04661, in 0.151s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04735, val loss: 0.04748, in 0.207s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15074, val loss: 0.14992, in 0.194s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15568, val loss: 0.15670, in 0.162s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14728, val loss: 0.14638, in 0.173s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04877, val loss: 0.05014, in 0.209s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04821, val loss: 0.04835, in 0.195s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13736, val loss: 0.13657, in 0.165s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04697, val loss: 0.04715, in 0.165s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14903, val loss: 0.14825, in 0.174s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04513, val loss: 0.04634, in 0.201s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15385, val loss: 0.15490, in 0.181s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14591, val loss: 0.14499, in 0.164s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04860, val loss: 0.04995, in 0.157s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04811, in 0.177s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13610, val loss: 0.13531, in 0.176s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14771, val loss: 0.14690, in 0.162s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04499, val loss: 0.04620, in 0.174s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15241, val loss: 0.15335, in 0.171s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04650, val loss: 0.04668, in 0.220s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14429, val loss: 0.14333, in 0.188s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04822, val loss: 0.04954, in 0.207s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04790, val loss: 0.04805, in 0.172s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13422, val loss: 0.13343, in 0.231s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14605, val loss: 0.14522, in 0.169s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15064, val loss: 0.15151, in 0.168s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04452, val loss: 0.04572, in 0.211s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14214, val loss: 0.14126, in 0.186s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04605, val loss: 0.04623, in 0.212s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04796, val loss: 0.04926, in 0.164s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04776, val loss: 0.04792, in 0.163s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13255, val loss: 0.13180, in 0.185s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14423, val loss: 0.14341, in 0.184s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14866, val loss: 0.14952, in 0.173s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04762, val loss: 0.04775, in 0.177s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14003, val loss: 0.13914, in 0.186s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04571, val loss: 0.04588, in 0.195s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04421, val loss: 0.04542, in 0.211s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13155, val loss: 0.13077, in 0.167s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14264, val loss: 0.14183, in 0.152s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14694, val loss: 0.14785, in 0.165s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13804, in 0.153s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04406, val loss: 0.04528, in 0.151s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04562, val loss: 0.04579, in 0.157s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04723, val loss: 0.04735, in 0.196s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12942, in 0.157s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14139, val loss: 0.14056, in 0.154s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14552, val loss: 0.14634, in 0.169s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13747, val loss: 0.13655, in 0.160s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04387, val loss: 0.04509, in 0.183s\n",
      "[200/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04547, val loss: 0.04564, in 0.192s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04687, val loss: 0.04703, in 0.185s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12891, val loss: 0.12815, in 0.159s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14024, val loss: 0.13938, in 0.159s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14390, val loss: 0.14478, in 0.185s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13588, val loss: 0.13495, in 0.173s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04521, val loss: 0.04540, in 0.199s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12774, val loss: 0.12697, in 0.184s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13869, val loss: 0.13778, in 0.193s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14231, val loss: 0.14318, in 0.192s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13472, val loss: 0.13374, in 0.167s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13720, val loss: 0.13629, in 0.166s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12653, val loss: 0.12581, in 0.185s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14026, val loss: 0.14111, in 0.171s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13366, val loss: 0.13264, in 0.172s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13538, in 0.175s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12540, val loss: 0.12465, in 0.181s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13190, val loss: 0.13092, in 0.199s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13979, in 0.220s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13406, in 0.203s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12417, val loss: 0.12340, in 0.192s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13025, val loss: 0.12936, in 0.214s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13756, val loss: 0.13834, in 0.204s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12345, val loss: 0.12266, in 0.181s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13350, val loss: 0.13256, in 0.218s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13618, val loss: 0.13706, in 0.166s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12925, val loss: 0.12835, in 0.191s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12237, val loss: 0.12161, in 0.174s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13235, val loss: 0.13137, in 0.176s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13465, val loss: 0.13555, in 0.165s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12848, val loss: 0.12759, in 0.155s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12125, val loss: 0.12055, in 0.157s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13085, val loss: 0.12985, in 0.159s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12697, val loss: 0.12610, in 0.155s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13324, val loss: 0.13411, in 0.173s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12011, val loss: 0.11942, in 0.195s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12981, val loss: 0.12877, in 0.159s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13229, val loss: 0.13311, in 0.150s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12569, val loss: 0.12478, in 0.183s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11894, val loss: 0.11828, in 0.155s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12871, val loss: 0.12765, in 0.166s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.13188, in 0.162s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12483, val loss: 0.12384, in 0.172s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11764, val loss: 0.11694, in 0.170s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12749, val loss: 0.12645, in 0.159s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12998, val loss: 0.13081, in 0.166s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12330, val loss: 0.12235, in 0.163s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11660, val loss: 0.11590, in 0.157s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12585, val loss: 0.12486, in 0.159s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12897, val loss: 0.12976, in 0.161s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.12059, in 0.182s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12498, val loss: 0.12399, in 0.161s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11572, val loss: 0.11505, in 0.169s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12769, val loss: 0.12850, in 0.165s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12021, val loss: 0.11942, in 0.157s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11507, val loss: 0.11441, in 0.143s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12391, val loss: 0.12293, in 0.203s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12599, val loss: 0.12685, in 0.161s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11902, val loss: 0.11822, in 0.149s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11441, val loss: 0.11377, in 0.160s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12282, val loss: 0.12185, in 0.147s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12506, val loss: 0.12591, in 0.164s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11839, val loss: 0.11761, in 0.149s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11337, val loss: 0.11272, in 0.189s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12181, val loss: 0.12075, in 0.166s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11763, val loss: 0.11688, in 0.169s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12317, val loss: 0.12404, in 0.196s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11246, val loss: 0.11177, in 0.156s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12089, val loss: 0.11983, in 0.166s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11653, val loss: 0.11582, in 0.152s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12214, val loss: 0.12302, in 0.155s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11165, val loss: 0.11095, in 0.157s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11982, val loss: 0.11871, in 0.184s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11586, val loss: 0.11515, in 0.151s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12118, val loss: 0.12205, in 0.176s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11082, val loss: 0.11014, in 0.180s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11873, val loss: 0.11767, in 0.139s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11468, val loss: 0.11389, in 0.173s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12028, val loss: 0.12120, in 0.149s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10995, val loss: 0.10927, in 0.153s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11775, val loss: 0.11674, in 0.144s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11365, val loss: 0.11287, in 0.142s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04753, val loss: 0.04885, in 0.207s\n",
      "Fit 200 trees in 40.130 s, (1557 total leaves)\n",
      "Time spent computing histograms: 23.394s\n",
      "Time spent finding best splits:  0.130s\n",
      "Time spent applying splits:      3.256s\n",
      "Time spent predicting:           0.345s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11906, val loss: 0.11997, in 0.139s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10909, val loss: 0.10839, in 0.149s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11711, val loss: 0.11612, in 0.150s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11173, in 0.149s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11778, val loss: 0.11866, in 0.150s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10825, val loss: 0.10757, in 0.152s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11628, val loss: 0.11528, in 0.145s\n",
      "[71/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11200, val loss: 0.11120, in 0.157s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11674, val loss: 0.11759, in 0.147s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10758, val loss: 0.10694, in 0.161s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11533, val loss: 0.11435, in 0.160s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11577, val loss: 0.11660, in 0.145s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11105, val loss: 0.11028, in 0.149s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04350, val loss: 0.04472, in 0.185s\n",
      "Fit 200 trees in 40.436 s, (1554 total leaves)\n",
      "Time spent computing histograms: 23.562s\n",
      "Time spent finding best splits:  0.165s\n",
      "Time spent applying splits:      3.374s\n",
      "Time spent predicting:           0.333s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.04630, val loss: 0.04647, in 0.189s\n",
      "Fit 200 trees in 40.454 s, (1567 total leaves)\n",
      "Time spent computing histograms: 23.505s\n",
      "Time spent finding best splits:  0.141s\n",
      "Time spent applying splits:      3.348s\n",
      "Time spent predicting:           0.347s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10684, val loss: 0.10614, in 0.156s\n",
      "[79/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11462, val loss: 0.11369, in 0.177s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11026, val loss: 0.10951, in 0.157s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11503, val loss: 0.11586, in 0.166s\n",
      "[70/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04501, val loss: 0.04518, in 0.163s\n",
      "Fit 200 trees in 40.617 s, (1553 total leaves)\n",
      "Time spent computing histograms: 23.493s\n",
      "Time spent finding best splits:  0.196s\n",
      "Time spent applying splits:      3.532s\n",
      "Time spent predicting:           0.325s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10563, val loss: 0.10497, in 0.155s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11331, val loss: 0.11243, in 0.154s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10938, val loss: 0.10867, in 0.153s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11415, val loss: 0.11496, in 0.155s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10490, val loss: 0.10424, in 0.148s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11241, val loss: 0.11156, in 0.161s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10867, val loss: 0.10791, in 0.157s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11332, val loss: 0.11408, in 0.151s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10415, val loss: 0.10353, in 0.139s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11157, val loss: 0.11074, in 0.153s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11270, val loss: 0.11345, in 0.158s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10745, val loss: 0.10673, in 0.164s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10367, val loss: 0.10306, in 0.158s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11077, val loss: 0.10995, in 0.148s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11177, val loss: 0.11249, in 0.159s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10672, val loss: 0.10597, in 0.158s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10283, val loss: 0.10218, in 0.160s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10999, val loss: 0.10912, in 0.165s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11093, val loss: 0.11167, in 0.164s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10518, val loss: 0.10442, in 0.177s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10202, val loss: 0.10135, in 0.172s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10936, val loss: 0.10851, in 0.163s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.11106, in 0.141s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10441, val loss: 0.10366, in 0.151s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10071, val loss: 0.10001, in 0.179s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10862, val loss: 0.10776, in 0.150s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10955, val loss: 0.11026, in 0.160s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10367, val loss: 0.10290, in 0.169s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10010, val loss: 0.09941, in 0.154s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10869, val loss: 0.10940, in 0.151s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10785, val loss: 0.10700, in 0.182s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10285, val loss: 0.10208, in 0.149s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09945, val loss: 0.09875, in 0.142s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10773, val loss: 0.10848, in 0.177s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10230, val loss: 0.10155, in 0.147s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10718, val loss: 0.10635, in 0.174s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09889, val loss: 0.09818, in 0.167s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10161, val loss: 0.10087, in 0.139s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10636, val loss: 0.10712, in 0.165s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10618, val loss: 0.10533, in 0.173s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09836, val loss: 0.09767, in 0.146s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10105, val loss: 0.10030, in 0.158s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10582, val loss: 0.10662, in 0.140s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10569, val loss: 0.10486, in 0.151s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09766, val loss: 0.09698, in 0.166s\n",
      "[91/200] 2.476 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10517, val loss: 0.10601, in 0.162s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09989, val loss: 0.09915, in 0.176s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10493, val loss: 0.10408, in 0.146s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09726, val loss: 0.09658, in 0.149s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10469, val loss: 0.10552, in 0.141s\n",
      "[83/200] 0.128 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09861, in 0.171s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10365, val loss: 0.10287, in 0.183s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09605, val loss: 0.09542, in 0.163s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10404, val loss: 0.10487, in 0.146s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09874, val loss: 0.09804, in 0.151s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10303, val loss: 0.10227, in 0.155s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62083, val loss: 0.62079, in 0.197s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09540, val loss: 0.09481, in 0.178s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10336, val loss: 0.10420, in 0.181s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09814, val loss: 0.09742, in 0.162s\n",
      "[89/200] 2.491 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10172, val loss: 0.10097, in 0.168s\n",
      "[88/200] 2.520 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.56168, val loss: 0.56162, in 0.196s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09408, in 0.162s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10355, in 0.146s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09745, val loss: 0.09671, in 0.164s\n",
      "[90/200] 0.126 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.121 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10063, val loss: 0.09983, in 0.191s\n",
      "[89/200] 2.512 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.51243, val loss: 0.51228, in 0.192s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10176, val loss: 0.10259, in 0.174s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09694, val loss: 0.09623, in 0.139s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09370, val loss: 0.09307, in 0.194s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10026, val loss: 0.09946, in 0.148s\n",
      "[90/200] 0.119 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62076, val loss: 0.62081, in 0.209s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62081, val loss: 0.62072, in 0.201s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47100, val loss: 0.47082, in 0.199s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09319, val loss: 0.09255, in 0.160s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09636, val loss: 0.09567, in 0.160s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10120, val loss: 0.10206, in 0.166s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09982, val loss: 0.09905, in 0.153s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62114, val loss: 0.62121, in 0.201s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56165, val loss: 0.56149, in 0.191s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56156, val loss: 0.56164, in 0.198s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10040, val loss: 0.10122, in 0.162s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09265, val loss: 0.09199, in 0.167s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09563, val loss: 0.09498, in 0.175s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43550, val loss: 0.43536, in 0.197s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09908, val loss: 0.09830, in 0.155s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09952, val loss: 0.10036, in 0.150s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09202, val loss: 0.09137, in 0.159s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56226, val loss: 0.56239, in 0.203s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51226, val loss: 0.51238, in 0.193s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51238, val loss: 0.51213, in 0.197s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09406, in 0.173s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09860, val loss: 0.09778, in 0.150s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40501, val loss: 0.40493, in 0.194s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09913, val loss: 0.09996, in 0.149s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09136, val loss: 0.09074, in 0.158s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09395, val loss: 0.09330, in 0.155s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09756, val loss: 0.09677, in 0.164s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51320, val loss: 0.51344, in 0.198s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47095, val loss: 0.47064, in 0.205s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47080, val loss: 0.47092, in 0.212s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37864, val loss: 0.37866, in 0.204s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09797, val loss: 0.09884, in 0.168s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09353, val loss: 0.09287, in 0.144s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09037, val loss: 0.08973, in 0.176s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09681, val loss: 0.09599, in 0.163s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47176, val loss: 0.47217, in 0.200s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43527, val loss: 0.43552, in 0.194s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43543, val loss: 0.43521, in 0.205s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09734, val loss: 0.09822, in 0.141s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35578, val loss: 0.35583, in 0.190s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09290, val loss: 0.09225, in 0.165s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09640, val loss: 0.09559, in 0.137s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08975, val loss: 0.08911, in 0.165s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43645, val loss: 0.43694, in 0.206s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09654, val loss: 0.09744, in 0.185s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40498, val loss: 0.40480, in 0.213s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40481, val loss: 0.40517, in 0.233s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09231, val loss: 0.09164, in 0.183s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08928, val loss: 0.08864, in 0.177s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33566, val loss: 0.33579, in 0.235s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09582, val loss: 0.09503, in 0.223s\n",
      "[97/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08898, val loss: 0.08834, in 0.149s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40609, val loss: 0.40676, in 0.226s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09556, val loss: 0.09642, in 0.212s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09128, val loss: 0.09064, in 0.188s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37840, val loss: 0.37895, in 0.214s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37859, val loss: 0.37854, in 0.231s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31816, val loss: 0.31825, in 0.197s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09487, val loss: 0.09415, in 0.193s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08863, val loss: 0.08801, in 0.152s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09076, val loss: 0.09014, in 0.161s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09506, val loss: 0.09592, in 0.176s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37972, val loss: 0.38051, in 0.214s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35570, val loss: 0.35561, in 0.198s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35548, val loss: 0.35610, in 0.211s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09443, val loss: 0.09372, in 0.161s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30236, val loss: 0.30260, in 0.221s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08755, val loss: 0.08697, in 0.175s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09447, val loss: 0.09533, in 0.170s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08985, val loss: 0.08921, in 0.207s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09382, val loss: 0.09310, in 0.156s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35689, val loss: 0.35775, in 0.200s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33557, val loss: 0.33553, in 0.211s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33535, val loss: 0.33610, in 0.211s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08709, val loss: 0.08651, in 0.146s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28849, val loss: 0.28878, in 0.209s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09339, val loss: 0.09422, in 0.194s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08922, val loss: 0.08854, in 0.204s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09266, in 0.209s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33683, val loss: 0.33787, in 0.264s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08593, in 0.221s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31781, val loss: 0.31783, in 0.270s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31765, val loss: 0.31857, in 0.263s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27623, val loss: 0.27662, in 0.262s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08894, val loss: 0.08828, in 0.154s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09243, val loss: 0.09330, in 0.211s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09212, in 0.162s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08623, val loss: 0.08563, in 0.158s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31925, val loss: 0.32033, in 0.208s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09191, val loss: 0.09274, in 0.149s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30231, val loss: 0.30243, in 0.202s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30213, val loss: 0.30311, in 0.205s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09231, val loss: 0.09153, in 0.153s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08822, val loss: 0.08755, in 0.175s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26542, val loss: 0.26585, in 0.203s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08559, val loss: 0.08498, in 0.173s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09073, val loss: 0.09156, in 0.171s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09161, val loss: 0.09084, in 0.163s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30379, val loss: 0.30493, in 0.198s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28843, val loss: 0.28859, in 0.205s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08738, val loss: 0.08668, in 0.195s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28825, val loss: 0.28934, in 0.209s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25549, val loss: 0.25591, in 0.202s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08521, val loss: 0.08463, in 0.157s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09018, val loss: 0.09102, in 0.153s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09096, val loss: 0.09022, in 0.152s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08692, val loss: 0.08624, in 0.167s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28990, val loss: 0.29116, in 0.209s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27619, val loss: 0.27638, in 0.198s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08487, val loss: 0.08429, in 0.151s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27601, val loss: 0.27716, in 0.205s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24673, val loss: 0.24705, in 0.202s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08960, val loss: 0.09042, in 0.156s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09038, val loss: 0.08963, in 0.173s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08572, val loss: 0.08504, in 0.159s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08448, val loss: 0.08388, in 0.154s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27765, val loss: 0.27898, in 0.203s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26540, val loss: 0.26558, in 0.216s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26520, val loss: 0.26640, in 0.204s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09009, val loss: 0.08936, in 0.143s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23839, val loss: 0.23881, in 0.205s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08901, val loss: 0.08983, in 0.189s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08511, val loss: 0.08445, in 0.171s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08396, val loss: 0.08337, in 0.167s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26687, val loss: 0.26831, in 0.207s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25548, val loss: 0.25553, in 0.196s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08969, val loss: 0.08895, in 0.176s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08861, val loss: 0.08943, in 0.159s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25527, val loss: 0.25650, in 0.211s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23123, val loss: 0.23143, in 0.217s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08446, val loss: 0.08378, in 0.175s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08366, val loss: 0.08309, in 0.149s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25694, val loss: 0.25841, in 0.198s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08809, val loss: 0.08736, in 0.183s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08769, val loss: 0.08853, in 0.168s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24661, val loss: 0.24669, in 0.215s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08316, val loss: 0.08260, in 0.149s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24646, val loss: 0.24758, in 0.208s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08363, val loss: 0.08299, in 0.165s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22458, val loss: 0.22484, in 0.197s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08727, val loss: 0.08811, in 0.154s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08708, val loss: 0.08641, in 0.169s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08338, val loss: 0.08274, in 0.145s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24808, val loss: 0.24966, in 0.209s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08172, val loss: 0.08120, in 0.191s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23829, val loss: 0.23845, in 0.201s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23809, val loss: 0.23932, in 0.202s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21773, val loss: 0.21806, in 0.195s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08680, val loss: 0.08765, in 0.151s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08625, val loss: 0.08561, in 0.166s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08313, val loss: 0.08250, in 0.149s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08119, val loss: 0.08067, in 0.177s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23957, val loss: 0.24115, in 0.218s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23113, val loss: 0.23118, in 0.216s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23091, val loss: 0.23212, in 0.212s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08622, val loss: 0.08705, in 0.170s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21214, val loss: 0.21257, in 0.223s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08273, val loss: 0.08209, in 0.147s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08553, val loss: 0.08485, in 0.199s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08047, val loss: 0.07997, in 0.200s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08574, val loss: 0.08659, in 0.154s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23167, val loss: 0.23320, in 0.217s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08225, val loss: 0.08161, in 0.174s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22448, val loss: 0.22462, in 0.218s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22425, val loss: 0.22557, in 0.216s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20711, val loss: 0.20756, in 0.205s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08504, val loss: 0.08440, in 0.170s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07972, val loss: 0.07925, in 0.156s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08525, val loss: 0.08608, in 0.152s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22502, val loss: 0.22660, in 0.207s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08098, in 0.183s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21760, val loss: 0.21771, in 0.201s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21740, val loss: 0.21866, in 0.205s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08469, val loss: 0.08404, in 0.174s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20164, val loss: 0.20210, in 0.219s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08493, val loss: 0.08577, in 0.157s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07913, val loss: 0.07865, in 0.196s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08412, val loss: 0.08350, in 0.180s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21866, val loss: 0.22018, in 0.225s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08091, val loss: 0.08022, in 0.225s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19765, val loss: 0.19827, in 0.191s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21202, val loss: 0.21219, in 0.247s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08431, val loss: 0.08514, in 0.184s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21180, val loss: 0.21309, in 0.242s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07884, val loss: 0.07836, in 0.168s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08068, val loss: 0.08000, in 0.168s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21240, val loss: 0.21405, in 0.213s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08344, val loss: 0.08279, in 0.245s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07861, val loss: 0.07813, in 0.187s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19354, val loss: 0.19425, in 0.243s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20667, val loss: 0.20802, in 0.230s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20691, val loss: 0.20702, in 0.236s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08302, val loss: 0.08378, in 0.234s\n",
      "[114/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07994, val loss: 0.07928, in 0.196s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08287, val loss: 0.08224, in 0.205s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07818, val loss: 0.07771, in 0.201s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08279, val loss: 0.08354, in 0.160s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20725, val loss: 0.20890, in 0.245s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18997, val loss: 0.19078, in 0.187s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20120, val loss: 0.20267, in 0.226s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20140, val loss: 0.20165, in 0.229s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07934, val loss: 0.07871, in 0.174s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08242, val loss: 0.08181, in 0.152s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07800, val loss: 0.07753, in 0.156s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08226, val loss: 0.08300, in 0.186s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18691, val loss: 0.18781, in 0.185s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20261, val loss: 0.20423, in 0.231s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19739, val loss: 0.19781, in 0.186s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19724, val loss: 0.19883, in 0.205s\n",
      "[25/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08206, val loss: 0.08144, in 0.159s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07774, val loss: 0.07705, in 0.220s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07711, val loss: 0.07664, in 0.192s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08097, val loss: 0.08171, in 0.208s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18331, val loss: 0.18407, in 0.221s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19727, val loss: 0.19896, in 0.203s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07747, val loss: 0.07679, in 0.163s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08161, val loss: 0.08099, in 0.177s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19331, val loss: 0.19388, in 0.235s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19309, val loss: 0.19466, in 0.236s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07630, val loss: 0.07584, in 0.195s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08052, val loss: 0.08123, in 0.186s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17941, val loss: 0.18018, in 0.240s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07694, val loss: 0.07626, in 0.210s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19269, val loss: 0.19435, in 0.259s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18965, val loss: 0.19025, in 0.230s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18941, val loss: 0.19093, in 0.227s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08019, val loss: 0.07962, in 0.258s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07521, val loss: 0.07475, in 0.260s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07907, val loss: 0.07971, in 0.254s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17664, val loss: 0.17751, in 0.206s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18815, val loss: 0.18983, in 0.221s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07557, val loss: 0.07484, in 0.245s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07981, val loss: 0.07921, in 0.211s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18588, val loss: 0.18644, in 0.252s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18564, val loss: 0.18709, in 0.270s\n",
      "[28/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07484, val loss: 0.07437, in 0.211s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17410, val loss: 0.17507, in 0.205s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07818, val loss: 0.07883, in 0.260s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07449, val loss: 0.07380, in 0.231s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18478, val loss: 0.18654, in 0.242s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07438, val loss: 0.07389, in 0.198s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18272, val loss: 0.18335, in 0.244s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07860, val loss: 0.07801, in 0.266s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18153, val loss: 0.18304, in 0.230s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07750, val loss: 0.07812, in 0.236s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17120, val loss: 0.17221, in 0.275s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07411, val loss: 0.07343, in 0.193s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07812, val loss: 0.07752, in 0.179s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18002, val loss: 0.18071, in 0.186s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18119, val loss: 0.18287, in 0.237s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17883, val loss: 0.18046, in 0.197s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07312, val loss: 0.07264, in 0.233s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07713, val loss: 0.07775, in 0.184s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16895, val loss: 0.17004, in 0.174s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17807, val loss: 0.17971, in 0.188s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07300, val loss: 0.07227, in 0.235s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17741, val loss: 0.17818, in 0.197s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07737, val loss: 0.07677, in 0.200s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17635, val loss: 0.17802, in 0.192s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07273, val loss: 0.07227, in 0.188s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16666, val loss: 0.16780, in 0.189s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07669, val loss: 0.07729, in 0.196s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07692, val loss: 0.07634, in 0.192s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07211, val loss: 0.07143, in 0.213s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17495, val loss: 0.17572, in 0.212s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17466, val loss: 0.17635, in 0.243s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17369, val loss: 0.17541, in 0.217s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07167, val loss: 0.07124, in 0.229s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16464, val loss: 0.16586, in 0.210s\n",
      "[36/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07670, val loss: 0.07612, in 0.170s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07561, val loss: 0.07616, in 0.254s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07124, val loss: 0.07055, in 0.229s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17209, val loss: 0.17373, in 0.204s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17188, val loss: 0.17261, in 0.263s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17070, val loss: 0.17237, in 0.261s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07058, val loss: 0.07015, in 0.253s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16192, val loss: 0.16315, in 0.206s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07512, val loss: 0.07565, in 0.189s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07539, val loss: 0.07478, in 0.241s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16979, val loss: 0.17149, in 0.166s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07011, in 0.199s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16970, val loss: 0.17051, in 0.183s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16826, val loss: 0.16997, in 0.207s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07483, val loss: 0.07536, in 0.175s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07014, val loss: 0.06971, in 0.215s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15967, val loss: 0.16091, in 0.213s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16733, val loss: 0.16910, in 0.208s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07488, val loss: 0.07425, in 0.218s\n",
      "[129/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07042, val loss: 0.06974, in 0.197s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16739, val loss: 0.16825, in 0.212s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16621, val loss: 0.16792, in 0.291s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15796, val loss: 0.15923, in 0.325s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06972, val loss: 0.06929, in 0.399s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07362, val loss: 0.07410, in 0.423s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07407, in 0.336s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06968, val loss: 0.06900, in 0.400s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16450, val loss: 0.16531, in 0.394s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16434, val loss: 0.16607, in 0.455s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16382, val loss: 0.16550, in 0.357s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15579, val loss: 0.15703, in 0.370s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07325, val loss: 0.07374, in 0.316s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06940, val loss: 0.06897, in 0.376s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07359, val loss: 0.07295, in 0.378s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06935, val loss: 0.06865, in 0.326s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16148, val loss: 0.16236, in 0.336s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16212, val loss: 0.16388, in 0.333s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16153, val loss: 0.16321, in 0.289s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07275, val loss: 0.07321, in 0.292s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15331, val loss: 0.15440, in 0.347s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07323, val loss: 0.07261, in 0.253s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06850, val loss: 0.06808, in 0.316s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15945, val loss: 0.16035, in 0.272s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15912, val loss: 0.16078, in 0.277s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06863, val loss: 0.06798, in 0.344s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15997, val loss: 0.16167, in 0.273s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07211, val loss: 0.07258, in 0.263s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15180, val loss: 0.15292, in 0.259s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07274, val loss: 0.07212, in 0.317s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06796, val loss: 0.06750, in 0.318s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15764, val loss: 0.15848, in 0.274s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15715, val loss: 0.15879, in 0.268s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06793, val loss: 0.06732, in 0.258s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15737, val loss: 0.15904, in 0.254s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14959, val loss: 0.15072, in 0.282s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07259, val loss: 0.07197, in 0.242s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07112, val loss: 0.07157, in 0.334s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15486, val loss: 0.15645, in 0.261s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06768, val loss: 0.06721, in 0.273s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15571, val loss: 0.15658, in 0.278s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06757, val loss: 0.06697, in 0.279s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15552, val loss: 0.15728, in 0.277s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14805, val loss: 0.14912, in 0.236s\n",
      "[44/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07095, val loss: 0.07139, in 0.214s\n",
      "[132/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06749, val loss: 0.06704, in 0.205s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07193, val loss: 0.07128, in 0.277s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15281, val loss: 0.15449, in 0.229s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06730, val loss: 0.06670, in 0.202s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15327, val loss: 0.15407, in 0.225s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15340, val loss: 0.15520, in 0.216s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14646, val loss: 0.14757, in 0.184s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07033, val loss: 0.07078, in 0.201s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06724, val loss: 0.06680, in 0.180s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07161, val loss: 0.07096, in 0.184s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15199, val loss: 0.15379, in 0.178s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15104, val loss: 0.15274, in 0.209s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15166, val loss: 0.15247, in 0.203s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06667, val loss: 0.06608, in 0.247s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14496, val loss: 0.14613, in 0.203s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06990, val loss: 0.07035, in 0.206s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06652, val loss: 0.06610, in 0.209s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15026, val loss: 0.15110, in 0.177s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14980, val loss: 0.15157, in 0.191s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14918, val loss: 0.15084, in 0.187s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07054, val loss: 0.06986, in 0.235s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06643, val loss: 0.06586, in 0.200s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14343, val loss: 0.14461, in 0.181s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06950, val loss: 0.06993, in 0.184s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06615, val loss: 0.06574, in 0.180s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14812, val loss: 0.14995, in 0.169s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07027, val loss: 0.06958, in 0.166s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14826, val loss: 0.14914, in 0.186s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14671, val loss: 0.14829, in 0.182s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14167, val loss: 0.14289, in 0.171s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06594, val loss: 0.06535, in 0.228s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06935, val loss: 0.06978, in 0.160s\n",
      "[136/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06593, val loss: 0.06553, in 0.158s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07000, val loss: 0.06930, in 0.146s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14663, val loss: 0.14846, in 0.179s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14657, val loss: 0.14752, in 0.186s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14484, val loss: 0.14650, in 0.206s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13977, val loss: 0.14100, in 0.170s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06527, val loss: 0.06471, in 0.181s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06578, val loss: 0.06539, in 0.160s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06884, val loss: 0.06929, in 0.188s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06967, val loss: 0.06898, in 0.178s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14520, val loss: 0.14608, in 0.180s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14488, val loss: 0.14664, in 0.203s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14307, val loss: 0.14469, in 0.204s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13818, val loss: 0.13933, in 0.188s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06839, val loss: 0.06883, in 0.191s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06452, val loss: 0.06393, in 0.219s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06488, val loss: 0.06450, in 0.232s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06935, val loss: 0.06867, in 0.220s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13713, val loss: 0.13831, in 0.168s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14273, val loss: 0.14446, in 0.245s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14296, val loss: 0.14381, in 0.248s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14110, val loss: 0.14276, in 0.229s\n",
      "[46/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06421, val loss: 0.06363, in 0.184s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06453, val loss: 0.06414, in 0.207s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06896, val loss: 0.06826, in 0.197s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06732, val loss: 0.06778, in 0.263s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14184, val loss: 0.14265, in 0.177s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14157, val loss: 0.14331, in 0.181s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13601, val loss: 0.13715, in 0.189s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13972, val loss: 0.14136, in 0.164s\n",
      "[47/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06383, val loss: 0.06326, in 0.206s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06701, val loss: 0.06747, in 0.160s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06379, val loss: 0.06345, in 0.214s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06796, val loss: 0.06731, in 0.210s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13983, val loss: 0.14151, in 0.166s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14037, val loss: 0.14120, in 0.174s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13773, val loss: 0.13943, in 0.199s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13414, val loss: 0.13539, in 0.226s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06359, val loss: 0.06302, in 0.176s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06655, val loss: 0.06701, in 0.220s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13873, val loss: 0.13960, in 0.167s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13795, val loss: 0.13960, in 0.187s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06300, val loss: 0.06266, in 0.222s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06708, val loss: 0.06640, in 0.251s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13622, val loss: 0.13795, in 0.208s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13283, val loss: 0.13408, in 0.271s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06319, val loss: 0.06264, in 0.228s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06629, val loss: 0.06676, in 0.218s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13676, val loss: 0.13759, in 0.233s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06674, val loss: 0.06606, in 0.194s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13631, val loss: 0.13795, in 0.254s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13460, val loss: 0.13633, in 0.194s\n",
      "[50/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06255, val loss: 0.06223, in 0.243s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06305, val loss: 0.06251, in 0.162s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13541, val loss: 0.13624, in 0.180s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13108, val loss: 0.13242, in 0.254s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06534, val loss: 0.06584, in 0.209s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13503, val loss: 0.13672, in 0.173s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13301, val loss: 0.13467, in 0.191s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06602, val loss: 0.06531, in 0.213s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06208, val loss: 0.06180, in 0.237s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06270, val loss: 0.06216, in 0.189s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13428, val loss: 0.13509, in 0.233s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.13087, in 0.234s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13208, val loss: 0.13371, in 0.235s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13350, val loss: 0.13520, in 0.266s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06569, val loss: 0.06500, in 0.239s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06449, val loss: 0.06494, in 0.289s\n",
      "[144/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06196, val loss: 0.06169, in 0.223s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06253, val loss: 0.06199, in 0.220s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12866, val loss: 0.12999, in 0.174s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13323, val loss: 0.13403, in 0.193s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06548, val loss: 0.06476, in 0.170s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13234, val loss: 0.13402, in 0.178s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13096, val loss: 0.13250, in 0.193s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06167, val loss: 0.06140, in 0.175s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06385, val loss: 0.06436, in 0.215s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06201, val loss: 0.06146, in 0.198s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12776, val loss: 0.12906, in 0.193s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13173, val loss: 0.13254, in 0.227s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13088, val loss: 0.13250, in 0.205s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.13099, in 0.223s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06512, val loss: 0.06443, in 0.244s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06325, val loss: 0.06376, in 0.206s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06076, val loss: 0.06047, in 0.237s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06124, val loss: 0.06067, in 0.238s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12688, val loss: 0.12819, in 0.175s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13061, val loss: 0.13143, in 0.172s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12946, val loss: 0.13111, in 0.172s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12778, val loss: 0.12936, in 0.212s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06428, val loss: 0.06360, in 0.212s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06051, val loss: 0.05992, in 0.186s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06276, val loss: 0.06327, in 0.235s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12564, val loss: 0.12689, in 0.181s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06047, val loss: 0.06018, in 0.231s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12909, val loss: 0.12998, in 0.200s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12825, val loss: 0.12990, in 0.207s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12657, val loss: 0.12813, in 0.190s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06366, val loss: 0.06295, in 0.205s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12457, val loss: 0.12584, in 0.185s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06247, val loss: 0.06298, in 0.189s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06015, val loss: 0.05989, in 0.183s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05977, val loss: 0.05919, in 0.238s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12788, val loss: 0.12877, in 0.181s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12726, val loss: 0.12885, in 0.189s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12529, val loss: 0.12687, in 0.184s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06002, val loss: 0.05977, in 0.191s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12357, val loss: 0.12488, in 0.195s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06210, val loss: 0.06259, in 0.202s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06293, val loss: 0.06225, in 0.248s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05940, val loss: 0.05880, in 0.216s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12687, val loss: 0.12779, in 0.197s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12553, val loss: 0.12712, in 0.224s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12395, val loss: 0.12557, in 0.209s\n",
      "[58/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05984, val loss: 0.05958, in 0.181s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06193, val loss: 0.06242, in 0.204s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12235, val loss: 0.12367, in 0.221s\n",
      "[63/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06266, val loss: 0.06199, in 0.204s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05917, val loss: 0.05856, in 0.203s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12586, val loss: 0.12678, in 0.199s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12457, val loss: 0.12615, in 0.181s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12308, val loss: 0.12469, in 0.199s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12148, val loss: 0.12281, in 0.278s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06240, val loss: 0.06173, in 0.262s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06173, val loss: 0.06223, in 0.294s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05942, val loss: 0.05917, in 0.337s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12476, val loss: 0.12568, in 0.296s\n",
      "[61/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05885, val loss: 0.05826, in 0.313s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12156, val loss: 0.12310, in 0.262s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12285, val loss: 0.12444, in 0.368s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06157, val loss: 0.06207, in 0.222s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12043, val loss: 0.12180, in 0.233s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05913, val loss: 0.05889, in 0.246s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06189, val loss: 0.06120, in 0.264s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12342, val loss: 0.12427, in 0.234s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12051, val loss: 0.12203, in 0.218s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05844, val loss: 0.05787, in 0.301s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12166, val loss: 0.12319, in 0.207s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06135, val loss: 0.06185, in 0.201s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11938, val loss: 0.12069, in 0.203s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05876, val loss: 0.05851, in 0.225s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06118, val loss: 0.06051, in 0.261s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12233, val loss: 0.12317, in 0.254s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11958, val loss: 0.12114, in 0.239s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05790, val loss: 0.05736, in 0.256s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06109, val loss: 0.06157, in 0.224s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12075, val loss: 0.12230, in 0.275s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11825, val loss: 0.11960, in 0.236s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05850, val loss: 0.05825, in 0.300s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12074, val loss: 0.12154, in 0.259s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11882, val loss: 0.12043, in 0.242s\n",
      "[63/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06092, val loss: 0.06025, in 0.303s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05758, val loss: 0.05705, in 0.257s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11982, val loss: 0.12132, in 0.259s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11679, val loss: 0.11814, in 0.253s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06075, val loss: 0.06124, in 0.288s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05827, val loss: 0.05801, in 0.230s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06050, val loss: 0.05984, in 0.231s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11942, val loss: 0.12022, in 0.263s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11769, val loss: 0.11931, in 0.276s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05735, val loss: 0.05680, in 0.233s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11912, val loss: 0.12060, in 0.224s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11580, val loss: 0.11717, in 0.220s\n",
      "[69/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06055, val loss: 0.06103, in 0.233s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05770, val loss: 0.05742, in 0.292s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11830, val loss: 0.11914, in 0.246s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11640, val loss: 0.11796, in 0.255s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05718, val loss: 0.05666, in 0.242s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06010, val loss: 0.05940, in 0.319s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11792, val loss: 0.11940, in 0.243s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06018, val loss: 0.06065, in 0.242s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11439, val loss: 0.11578, in 0.277s\n",
      "[70/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05756, val loss: 0.05728, in 0.193s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11770, val loss: 0.11854, in 0.207s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11534, val loss: 0.11689, in 0.216s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11842, in 0.206s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05684, val loss: 0.05636, in 0.238s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05986, val loss: 0.05916, in 0.233s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11365, val loss: 0.11500, in 0.216s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05979, val loss: 0.06025, in 0.291s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05729, val loss: 0.05703, in 0.249s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11656, val loss: 0.11740, in 0.244s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11445, val loss: 0.11599, in 0.212s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11741, in 0.221s\n",
      "[68/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05623, val loss: 0.05573, in 0.245s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05956, val loss: 0.05885, in 0.239s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11294, val loss: 0.11433, in 0.285s\n",
      "[72/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05695, val loss: 0.05670, in 0.268s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11561, val loss: 0.11653, in 0.259s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11359, val loss: 0.11510, in 0.266s\n",
      "[68/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05934, val loss: 0.05981, in 0.333s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11489, val loss: 0.11638, in 0.252s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05614, val loss: 0.05564, in 0.246s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05920, val loss: 0.05853, in 0.284s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11216, val loss: 0.11354, in 0.225s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11449, val loss: 0.11536, in 0.238s\n",
      "[70/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05906, val loss: 0.05955, in 0.251s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05686, val loss: 0.05661, in 0.272s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11401, val loss: 0.11553, in 0.303s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11237, val loss: 0.11386, in 0.333s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05583, val loss: 0.05533, in 0.388s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11129, val loss: 0.11261, in 0.360s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05879, val loss: 0.05812, in 0.378s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05656, val loss: 0.05632, in 0.327s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11399, in 0.358s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05876, val loss: 0.05926, in 0.337s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11312, val loss: 0.11464, in 0.293s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11161, val loss: 0.11307, in 0.295s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05563, val loss: 0.05513, in 0.221s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05852, val loss: 0.05786, in 0.256s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11027, val loss: 0.11161, in 0.286s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11223, val loss: 0.11320, in 0.244s\n",
      "[72/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05853, val loss: 0.05902, in 0.244s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05609, val loss: 0.05586, in 0.265s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11409, in 0.231s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11068, val loss: 0.11217, in 0.250s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05531, val loss: 0.05484, in 0.239s\n",
      "[166/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05842, val loss: 0.05775, in 0.180s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10950, val loss: 0.11085, in 0.204s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11132, val loss: 0.11233, in 0.170s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05841, val loss: 0.05892, in 0.169s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11169, val loss: 0.11332, in 0.194s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11020, val loss: 0.11169, in 0.177s\n",
      "[72/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05571, val loss: 0.05550, in 0.237s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05821, val loss: 0.05754, in 0.188s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05490, val loss: 0.05446, in 0.196s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10843, val loss: 0.10976, in 0.212s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11080, val loss: 0.11182, in 0.177s\n",
      "[74/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05830, val loss: 0.05880, in 0.172s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11081, val loss: 0.11240, in 0.176s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10957, val loss: 0.11108, in 0.167s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05470, val loss: 0.05426, in 0.170s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05794, val loss: 0.05727, in 0.182s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05542, val loss: 0.05522, in 0.205s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11028, val loss: 0.11129, in 0.164s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05800, val loss: 0.05850, in 0.162s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10761, val loss: 0.10893, in 0.216s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10864, val loss: 0.11016, in 0.184s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10951, val loss: 0.11110, in 0.192s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05436, val loss: 0.05392, in 0.209s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05484, in 0.202s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10964, val loss: 0.11068, in 0.180s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05740, val loss: 0.05676, in 0.243s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05736, val loss: 0.05787, in 0.241s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10696, val loss: 0.10831, in 0.195s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.11025, in 0.177s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10698, val loss: 0.10847, in 0.198s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05406, val loss: 0.05360, in 0.208s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05475, val loss: 0.05459, in 0.209s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10892, val loss: 0.11000, in 0.223s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05627, in 0.227s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10620, val loss: 0.10769, in 0.178s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10609, val loss: 0.10750, in 0.209s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05689, val loss: 0.05738, in 0.243s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10782, val loss: 0.10939, in 0.237s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05386, val loss: 0.05337, in 0.225s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10800, val loss: 0.10902, in 0.194s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05440, val loss: 0.05421, in 0.246s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10530, val loss: 0.10673, in 0.176s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10515, val loss: 0.10658, in 0.194s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05659, val loss: 0.05597, in 0.238s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10729, val loss: 0.10887, in 0.181s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05660, val loss: 0.05708, in 0.199s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05367, val loss: 0.05317, in 0.184s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10720, val loss: 0.10823, in 0.174s\n",
      "[79/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05422, val loss: 0.05402, in 0.189s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10454, val loss: 0.10592, in 0.193s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05631, val loss: 0.05568, in 0.204s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10391, val loss: 0.10539, in 0.218s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10639, val loss: 0.10797, in 0.237s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05611, val loss: 0.05663, in 0.244s\n",
      "[169/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05412, val loss: 0.05392, in 0.189s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10632, val loss: 0.10738, in 0.230s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05306, val loss: 0.05260, in 0.255s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10532, in 0.194s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10326, val loss: 0.10474, in 0.211s\n",
      "[79/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05571, val loss: 0.05508, in 0.235s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10562, val loss: 0.10723, in 0.227s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05576, val loss: 0.05627, in 0.235s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05393, val loss: 0.05372, in 0.213s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05256, val loss: 0.05215, in 0.220s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10302, val loss: 0.10444, in 0.217s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10540, val loss: 0.10646, in 0.234s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10254, val loss: 0.10403, in 0.196s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10457, val loss: 0.10616, in 0.196s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05531, val loss: 0.05465, in 0.257s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05536, val loss: 0.05587, in 0.214s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05382, val loss: 0.05362, in 0.198s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10235, val loss: 0.10377, in 0.208s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10478, val loss: 0.10580, in 0.220s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05227, val loss: 0.05184, in 0.239s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10186, val loss: 0.10333, in 0.214s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10412, val loss: 0.10569, in 0.184s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05521, val loss: 0.05455, in 0.175s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05517, val loss: 0.05568, in 0.186s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05353, val loss: 0.05337, in 0.197s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10189, val loss: 0.10335, in 0.166s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10438, val loss: 0.10539, in 0.169s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10096, val loss: 0.10237, in 0.176s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05201, val loss: 0.05159, in 0.191s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05438, in 0.173s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10269, val loss: 0.10427, in 0.218s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05345, val loss: 0.05330, in 0.174s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05451, val loss: 0.05509, in 0.249s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10312, val loss: 0.10410, in 0.204s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10097, val loss: 0.10248, in 0.227s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05480, val loss: 0.05415, in 0.190s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05174, val loss: 0.05135, in 0.221s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10018, val loss: 0.10164, in 0.236s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10198, val loss: 0.10353, in 0.212s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05314, val loss: 0.05299, in 0.210s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10244, val loss: 0.10349, in 0.164s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05403, val loss: 0.05462, in 0.197s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10026, val loss: 0.10173, in 0.217s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09942, val loss: 0.10088, in 0.193s\n",
      "[84/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05152, val loss: 0.05114, in 0.224s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05432, val loss: 0.05367, in 0.239s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10110, val loss: 0.10269, in 0.195s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05287, val loss: 0.05275, in 0.203s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10164, val loss: 0.10274, in 0.218s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05376, val loss: 0.05434, in 0.210s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09973, val loss: 0.10116, in 0.209s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09905, val loss: 0.10052, in 0.179s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05423, val loss: 0.05357, in 0.182s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05124, val loss: 0.05085, in 0.201s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10043, val loss: 0.10202, in 0.193s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05258, val loss: 0.05245, in 0.224s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05343, val loss: 0.05400, in 0.206s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10017, val loss: 0.10123, in 0.223s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09918, val loss: 0.10060, in 0.190s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05386, val loss: 0.05323, in 0.174s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09856, val loss: 0.10001, in 0.216s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05092, val loss: 0.05056, in 0.217s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09936, val loss: 0.10097, in 0.204s\n",
      "[87/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05233, val loss: 0.05221, in 0.210s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05311, val loss: 0.05368, in 0.220s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09722, val loss: 0.09864, in 0.188s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05358, val loss: 0.05295, in 0.188s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09862, val loss: 0.10004, in 0.219s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09911, val loss: 0.10020, in 0.250s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05076, val loss: 0.05041, in 0.182s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09853, val loss: 0.10013, in 0.181s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05215, val loss: 0.05203, in 0.181s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09651, val loss: 0.09794, in 0.175s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05281, val loss: 0.05338, in 0.215s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09821, val loss: 0.09927, in 0.190s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05329, val loss: 0.05264, in 0.211s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09801, val loss: 0.09949, in 0.208s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05061, val loss: 0.05025, in 0.201s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09762, val loss: 0.09923, in 0.191s\n",
      "[89/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05190, val loss: 0.05179, in 0.197s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05272, val loss: 0.05329, in 0.166s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09524, val loss: 0.09667, in 0.211s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09780, val loss: 0.09883, in 0.180s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05310, val loss: 0.05248, in 0.178s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09697, val loss: 0.09846, in 0.190s\n",
      "[93/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05035, val loss: 0.05001, in 0.184s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09568, val loss: 0.09732, in 0.232s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05177, val loss: 0.05167, in 0.176s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09612, in 0.177s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09705, val loss: 0.09804, in 0.187s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05243, val loss: 0.05301, in 0.227s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09579, val loss: 0.09729, in 0.195s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05255, val loss: 0.05195, in 0.217s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05005, val loss: 0.04970, in 0.203s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09682, in 0.171s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05169, val loss: 0.05159, in 0.168s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09403, val loss: 0.09550, in 0.183s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09652, val loss: 0.09755, in 0.198s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09472, val loss: 0.09620, in 0.193s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05226, val loss: 0.05284, in 0.209s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05210, val loss: 0.05153, in 0.219s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09447, val loss: 0.09613, in 0.181s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04958, val loss: 0.04929, in 0.200s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05141, val loss: 0.05130, in 0.206s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09273, val loss: 0.09417, in 0.190s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09607, val loss: 0.09709, in 0.177s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09399, val loss: 0.09549, in 0.183s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04946, val loss: 0.04918, in 0.163s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05201, val loss: 0.05258, in 0.196s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09388, val loss: 0.09555, in 0.212s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05168, val loss: 0.05109, in 0.241s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05104, val loss: 0.05093, in 0.237s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09226, val loss: 0.09369, in 0.183s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09340, val loss: 0.09492, in 0.178s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09500, val loss: 0.09602, in 0.208s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04937, val loss: 0.04910, in 0.168s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05183, val loss: 0.05243, in 0.187s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09485, in 0.184s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05128, val loss: 0.05071, in 0.227s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09172, val loss: 0.09314, in 0.185s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05049, val loss: 0.05041, in 0.218s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09293, val loss: 0.09445, in 0.184s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05174, val loss: 0.05234, in 0.173s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09445, val loss: 0.09547, in 0.199s\n",
      "[95/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04919, val loss: 0.04893, in 0.218s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09228, val loss: 0.09392, in 0.228s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09257, val loss: 0.09407, in 0.172s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05089, val loss: 0.05033, in 0.216s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05165, val loss: 0.05227, in 0.164s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09387, val loss: 0.09491, in 0.167s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09079, val loss: 0.09220, in 0.247s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04993, val loss: 0.04986, in 0.232s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04897, val loss: 0.04873, in 0.201s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09180, val loss: 0.09339, in 0.194s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09198, val loss: 0.09344, in 0.176s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05046, val loss: 0.04993, in 0.200s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05139, val loss: 0.05199, in 0.193s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09272, val loss: 0.09382, in 0.206s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09011, val loss: 0.09153, in 0.187s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04890, val loss: 0.04865, in 0.159s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04954, val loss: 0.04944, in 0.225s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09131, val loss: 0.09288, in 0.181s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09109, val loss: 0.09256, in 0.205s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05113, val loss: 0.05172, in 0.202s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08979, val loss: 0.09121, in 0.179s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05002, val loss: 0.04955, in 0.220s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09217, val loss: 0.09324, in 0.202s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04841, val loss: 0.04815, in 0.214s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04933, val loss: 0.04921, in 0.208s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09023, val loss: 0.09187, in 0.208s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09075, val loss: 0.09224, in 0.184s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08940, val loss: 0.09086, in 0.179s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04984, val loss: 0.04938, in 0.174s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05065, val loss: 0.05128, in 0.208s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09155, val loss: 0.09264, in 0.203s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04814, val loss: 0.04788, in 0.187s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04917, val loss: 0.04906, in 0.178s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08966, val loss: 0.09129, in 0.193s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04967, val loss: 0.04919, in 0.174s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08992, in 0.200s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08986, val loss: 0.09137, in 0.234s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09126, val loss: 0.09233, in 0.174s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05004, val loss: 0.05065, in 0.213s\n",
      "[189/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04904, val loss: 0.04893, in 0.167s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04770, val loss: 0.04745, in 0.209s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08922, val loss: 0.09088, in 0.196s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04953, val loss: 0.04906, in 0.170s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08780, val loss: 0.08933, in 0.201s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09065, val loss: 0.09173, in 0.191s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.09024, in 0.219s\n",
      "[104/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04888, val loss: 0.04877, in 0.249s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04958, val loss: 0.05021, in 0.276s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04729, val loss: 0.04705, in 0.270s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08860, val loss: 0.09030, in 0.264s\n",
      "[101/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04936, val loss: 0.04889, in 0.257s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08706, val loss: 0.08854, in 0.214s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08946, val loss: 0.09057, in 0.220s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08771, val loss: 0.08925, in 0.232s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04850, val loss: 0.04840, in 0.206s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04920, val loss: 0.04983, in 0.201s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04710, val loss: 0.04684, in 0.215s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08808, val loss: 0.08978, in 0.183s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04910, val loss: 0.04863, in 0.198s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08516, val loss: 0.08664, in 0.230s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08769, val loss: 0.08881, in 0.227s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08878, in 0.192s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04905, val loss: 0.04968, in 0.177s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04668, val loss: 0.04640, in 0.199s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08783, val loss: 0.08954, in 0.181s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04873, val loss: 0.04830, in 0.230s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08564, in 0.195s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08739, val loss: 0.08854, in 0.194s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08659, val loss: 0.08818, in 0.214s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04859, val loss: 0.04923, in 0.213s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04650, val loss: 0.04622, in 0.176s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08738, val loss: 0.08906, in 0.189s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08385, val loss: 0.08537, in 0.177s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08673, val loss: 0.08787, in 0.186s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08576, val loss: 0.08733, in 0.183s\n",
      "[108/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04841, val loss: 0.04799, in 0.230s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04808, val loss: 0.04870, in 0.208s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08666, val loss: 0.08833, in 0.211s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04625, val loss: 0.04597, in 0.241s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08314, val loss: 0.08463, in 0.193s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08613, val loss: 0.08729, in 0.183s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04816, val loss: 0.04774, in 0.182s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08531, val loss: 0.08689, in 0.203s\n",
      "[109/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04793, val loss: 0.04855, in 0.205s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04585, val loss: 0.04555, in 0.226s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08593, val loss: 0.08761, in 0.234s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08559, val loss: 0.08675, in 0.193s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08251, val loss: 0.08397, in 0.199s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08508, val loss: 0.08666, in 0.175s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04809, val loss: 0.04767, in 0.187s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04754, val loss: 0.04815, in 0.212s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08511, val loss: 0.08676, in 0.196s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04562, val loss: 0.04531, in 0.209s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08521, val loss: 0.08636, in 0.197s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08472, val loss: 0.08632, in 0.180s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04802, val loss: 0.04759, in 0.183s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08092, val loss: 0.08238, in 0.248s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04737, val loss: 0.04800, in 0.182s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08457, val loss: 0.08621, in 0.187s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08571, in 0.186s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08376, val loss: 0.08537, in 0.202s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04775, val loss: 0.04733, in 0.203s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08002, val loss: 0.08143, in 0.190s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04703, val loss: 0.04766, in 0.242s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08350, val loss: 0.08513, in 0.194s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08310, val loss: 0.08420, in 0.228s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07957, val loss: 0.08100, in 0.183s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08223, val loss: 0.08384, in 0.231s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08308, val loss: 0.08470, in 0.179s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04690, val loss: 0.04755, in 0.207s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08224, val loss: 0.08328, in 0.183s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07882, val loss: 0.08027, in 0.200s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08124, val loss: 0.08286, in 0.195s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08264, val loss: 0.08425, in 0.177s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04664, val loss: 0.04729, in 0.187s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08148, val loss: 0.08254, in 0.194s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07835, val loss: 0.07980, in 0.171s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08083, val loss: 0.08243, in 0.170s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08103, val loss: 0.08265, in 0.232s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07802, val loss: 0.07948, in 0.171s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08085, val loss: 0.08191, in 0.194s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08047, val loss: 0.08208, in 0.183s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08051, val loss: 0.08210, in 0.166s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07752, val loss: 0.07899, in 0.180s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08045, val loss: 0.08151, in 0.175s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08000, val loss: 0.08164, in 0.215s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08019, val loss: 0.08178, in 0.178s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07726, val loss: 0.07876, in 0.177s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08017, val loss: 0.08128, in 0.171s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07950, val loss: 0.08109, in 0.171s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07963, val loss: 0.08070, in 0.174s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07640, val loss: 0.07785, in 0.181s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07879, val loss: 0.08039, in 0.228s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07832, val loss: 0.07985, in 0.213s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07827, val loss: 0.07935, in 0.242s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07759, val loss: 0.07916, in 0.229s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07511, val loss: 0.07655, in 0.254s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07700, val loss: 0.07852, in 0.236s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07483, val loss: 0.07630, in 0.161s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07735, val loss: 0.07844, in 0.197s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07704, val loss: 0.07857, in 0.208s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07650, val loss: 0.07803, in 0.186s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07450, val loss: 0.07597, in 0.178s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07623, val loss: 0.07733, in 0.230s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07630, val loss: 0.07788, in 0.219s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07532, val loss: 0.07686, in 0.241s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07419, val loss: 0.07572, in 0.213s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07576, val loss: 0.07688, in 0.186s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07588, val loss: 0.07744, in 0.225s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07492, val loss: 0.07641, in 0.186s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07323, val loss: 0.07471, in 0.202s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07483, val loss: 0.07591, in 0.191s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07551, val loss: 0.07705, in 0.181s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07444, val loss: 0.07593, in 0.214s\n",
      "[124/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07270, val loss: 0.07418, in 0.217s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07501, val loss: 0.07656, in 0.180s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07403, val loss: 0.07509, in 0.235s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07381, val loss: 0.07530, in 0.177s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07231, val loss: 0.07380, in 0.184s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07470, val loss: 0.07623, in 0.194s\n",
      "[122/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07352, val loss: 0.07455, in 0.229s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07349, val loss: 0.07497, in 0.205s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07436, val loss: 0.07589, in 0.172s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04805, val loss: 0.04802, in 0.211s\n",
      "Fit 200 trees in 43.549 s, (1550 total leaves)\n",
      "Time spent computing histograms: 25.548s\n",
      "Time spent finding best splits:  0.152s\n",
      "Time spent applying splits:      3.612s\n",
      "Time spent predicting:           0.337s\n",
      "Binning 0.119 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.07165, val loss: 0.07312, in 0.239s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07321, val loss: 0.07468, in 0.212s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07292, val loss: 0.07396, in 0.231s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07407, val loss: 0.07559, in 0.166s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07127, val loss: 0.07279, in 0.171s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07257, val loss: 0.07359, in 0.175s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07271, val loss: 0.07417, in 0.181s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07351, val loss: 0.07503, in 0.198s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07080, val loss: 0.07234, in 0.200s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07230, val loss: 0.07332, in 0.173s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07170, val loss: 0.07317, in 0.239s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07306, val loss: 0.07457, in 0.193s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07006, val loss: 0.07159, in 0.202s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07183, val loss: 0.07281, in 0.213s\n",
      "[127/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07136, val loss: 0.07281, in 0.171s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07188, val loss: 0.07340, in 0.250s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06939, val loss: 0.07092, in 0.214s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07146, val loss: 0.07245, in 0.195s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07071, val loss: 0.07216, in 0.230s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07139, val loss: 0.07287, in 0.168s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06836, val loss: 0.06989, in 0.231s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07081, val loss: 0.07180, in 0.193s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04524, val loss: 0.04493, in 0.227s\n",
      "Fit 200 trees in 43.669 s, (1559 total leaves)\n",
      "Time spent computing histograms: 25.595s\n",
      "Time spent finding best splits:  0.159s\n",
      "Time spent applying splits:      3.603s\n",
      "Time spent predicting:           0.352s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06980, val loss: 0.07119, in 0.243s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07037, val loss: 0.07185, in 0.250s\n",
      "[129/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07039, val loss: 0.07138, in 0.167s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06801, val loss: 0.06956, in 0.208s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04760, val loss: 0.04720, in 0.175s\n",
      "Fit 200 trees in 43.660 s, (1560 total leaves)\n",
      "Time spent computing histograms: 25.535s\n",
      "Time spent finding best splits:  0.183s\n",
      "Time spent applying splits:      3.590s\n",
      "Time spent predicting:           0.354s\n",
      "Binning 0.119 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.06999, val loss: 0.07147, in 0.163s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06886, val loss: 0.07028, in 0.232s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06755, val loss: 0.06913, in 0.183s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06943, val loss: 0.07041, in 0.235s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06958, val loss: 0.07100, in 0.175s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06710, val loss: 0.06867, in 0.167s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06842, val loss: 0.06987, in 0.218s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06903, val loss: 0.07000, in 0.175s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06863, val loss: 0.07008, in 0.214s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06816, val loss: 0.06962, in 0.170s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06616, val loss: 0.06773, in 0.228s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04647, val loss: 0.04713, in 0.168s\n",
      "Fit 200 trees in 43.600 s, (1563 total leaves)\n",
      "Time spent computing histograms: 25.594s\n",
      "Time spent finding best splits:  0.209s\n",
      "Time spent applying splits:      3.552s\n",
      "Time spent predicting:           0.325s\n",
      "Binning 0.119 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06799, val loss: 0.06896, in 0.241s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06826, val loss: 0.06971, in 0.174s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06596, val loss: 0.06755, in 0.154s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06771, val loss: 0.06916, in 0.194s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06709, val loss: 0.06804, in 0.211s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06753, val loss: 0.06901, in 0.170s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06561, val loss: 0.06720, in 0.190s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06755, val loss: 0.06902, in 0.226s\n",
      "[134/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06695, val loss: 0.06791, in 0.163s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06700, val loss: 0.06851, in 0.197s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06683, val loss: 0.06828, in 0.183s\n",
      "[135/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06521, val loss: 0.06680, in 0.196s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06633, val loss: 0.06731, in 0.194s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06663, val loss: 0.06811, in 0.161s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06665, val loss: 0.06817, in 0.196s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06468, val loss: 0.06627, in 0.216s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06575, val loss: 0.06672, in 0.210s\n",
      "[137/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06647, val loss: 0.06794, in 0.154s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06650, val loss: 0.06801, in 0.152s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06427, val loss: 0.06582, in 0.159s\n",
      "[137/200] 2.817 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06485, val loss: 0.06583, in 0.204s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06619, val loss: 0.06767, in 0.169s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06594, val loss: 0.06743, in 0.217s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06400, val loss: 0.06554, in 0.164s\n",
      "[138/200] 0.121 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06561, val loss: 0.06707, in 0.157s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06577, val loss: 0.06724, in 0.180s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06416, val loss: 0.06516, in 0.210s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06311, val loss: 0.06465, in 0.198s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06554, val loss: 0.06700, in 0.155s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06391, val loss: 0.06490, in 0.150s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06513, val loss: 0.06659, in 0.181s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61000, val loss: 0.60998, in 0.305s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06254, val loss: 0.06407, in 0.222s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06513, val loss: 0.06662, in 0.181s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06358, val loss: 0.06459, in 0.173s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06428, val loss: 0.06574, in 0.221s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06219, val loss: 0.06372, in 0.156s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06490, val loss: 0.06639, in 0.160s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06322, val loss: 0.06419, in 0.163s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06406, val loss: 0.06552, in 0.146s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54194, val loss: 0.54198, in 0.315s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06201, val loss: 0.06357, in 0.141s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06305, val loss: 0.06406, in 0.145s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06435, val loss: 0.06587, in 0.177s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06362, val loss: 0.06506, in 0.161s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06117, val loss: 0.06271, in 0.183s\n",
      "[143/200] 2.796 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 6 leaves, max depth = 3, train loss: 0.06404, val loss: 0.06557, in 0.161s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48438, val loss: 0.48447, in 0.278s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06345, val loss: 0.06488, in 0.144s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06252, val loss: 0.06352, in 0.201s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06042, val loss: 0.06197, in 0.208s\n",
      "[144/200] 2.748 s\n",
      "Binning 0.013 GB of validation data: 0.138 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06341, val loss: 0.06496, in 0.186s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06198, val loss: 0.06298, in 0.190s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06307, val loss: 0.06448, in 0.196s\n",
      "[145/200] 0.123 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43575, val loss: 0.43595, in 0.296s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05985, val loss: 0.06138, in 0.194s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06328, val loss: 0.06483, in 0.144s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06163, val loss: 0.06260, in 0.165s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06260, val loss: 0.06402, in 0.197s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61005, val loss: 0.61007, in 0.264s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06304, val loss: 0.06460, in 0.160s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05932, val loss: 0.06087, in 0.211s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06101, val loss: 0.06196, in 0.168s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06232, val loss: 0.06373, in 0.151s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39482, in 0.277s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61002, val loss: 0.61001, in 0.283s\n",
      "[2/200] 2.683 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06401, in 0.173s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05871, val loss: 0.06022, in 0.166s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06220, val loss: 0.06362, in 0.158s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06064, val loss: 0.06160, in 0.177s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54194, val loss: 0.54198, in 0.308s\n",
      "[3/200] 0.127 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06226, val loss: 0.06380, in 0.158s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06046, val loss: 0.06141, in 0.145s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06189, val loss: 0.06331, in 0.151s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35839, val loss: 0.35880, in 0.290s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54181, val loss: 0.54183, in 0.291s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05811, val loss: 0.05958, in 0.204s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06207, val loss: 0.06360, in 0.141s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48444, val loss: 0.48446, in 0.266s\n",
      "[4/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06157, val loss: 0.06297, in 0.158s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06013, val loss: 0.06105, in 0.180s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61005, val loss: 0.60996, in 0.268s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05782, val loss: 0.05931, in 0.184s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06161, val loss: 0.06314, in 0.160s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32714, val loss: 0.32747, in 0.269s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48432, val loss: 0.48437, in 0.274s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06119, val loss: 0.06257, in 0.158s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06001, val loss: 0.06093, in 0.147s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05738, val loss: 0.05889, in 0.162s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06143, val loss: 0.06296, in 0.148s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43596, val loss: 0.43605, in 0.289s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06084, val loss: 0.06223, in 0.160s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54184, in 0.285s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05963, val loss: 0.06055, in 0.167s\n",
      "[152/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05725, val loss: 0.05876, in 0.150s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43589, val loss: 0.43599, in 0.269s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29984, val loss: 0.30022, in 0.290s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06060, val loss: 0.06214, in 0.198s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06065, val loss: 0.06202, in 0.149s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05921, val loss: 0.06012, in 0.205s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05678, val loss: 0.05827, in 0.167s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39456, in 0.289s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48455, val loss: 0.48429, in 0.263s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06028, val loss: 0.06179, in 0.167s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06025, val loss: 0.06163, in 0.164s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39460, in 0.287s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05886, val loss: 0.05977, in 0.174s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27570, val loss: 0.27609, in 0.308s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05637, val loss: 0.05780, in 0.197s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06013, val loss: 0.06152, in 0.177s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05978, val loss: 0.06129, in 0.254s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35833, val loss: 0.35832, in 0.324s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05859, val loss: 0.05950, in 0.202s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43634, val loss: 0.43615, in 0.362s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05603, val loss: 0.05742, in 0.250s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05977, val loss: 0.06112, in 0.239s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35851, val loss: 0.35856, in 0.383s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05941, val loss: 0.06091, in 0.202s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25480, val loss: 0.25508, in 0.432s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05788, val loss: 0.05881, in 0.254s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05571, val loss: 0.05710, in 0.269s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05959, val loss: 0.06094, in 0.245s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32725, val loss: 0.32741, in 0.431s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05916, val loss: 0.06067, in 0.289s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05764, val loss: 0.05860, in 0.192s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39477, val loss: 0.39442, in 0.410s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05551, val loss: 0.05693, in 0.164s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32746, in 0.389s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05922, val loss: 0.06056, in 0.170s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23602, val loss: 0.23637, in 0.361s\n",
      "[12/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05753, val loss: 0.05851, in 0.156s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05541, val loss: 0.05684, in 0.135s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05860, val loss: 0.06016, in 0.205s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30010, val loss: 0.30024, in 0.290s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05870, val loss: 0.06005, in 0.172s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35875, val loss: 0.35842, in 0.286s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05528, val loss: 0.05673, in 0.152s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05714, val loss: 0.05812, in 0.211s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29991, val loss: 0.30007, in 0.276s\n",
      "[9/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05818, val loss: 0.05975, in 0.200s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05838, val loss: 0.05974, in 0.143s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21941, val loss: 0.21986, in 0.287s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05692, val loss: 0.05793, in 0.146s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27636, val loss: 0.27654, in 0.284s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05507, val loss: 0.05651, in 0.180s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32688, in 0.275s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05807, val loss: 0.05944, in 0.152s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05778, val loss: 0.05936, in 0.190s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05662, val loss: 0.05765, in 0.142s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27605, val loss: 0.27620, in 0.285s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05785, val loss: 0.05921, in 0.139s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05469, val loss: 0.05616, in 0.189s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20455, val loss: 0.20495, in 0.290s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05761, val loss: 0.05920, in 0.145s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05633, val loss: 0.05735, in 0.155s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25527, val loss: 0.25548, in 0.293s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30012, val loss: 0.29964, in 0.265s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05776, val loss: 0.05912, in 0.135s\n",
      "[163/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05740, val loss: 0.05898, in 0.143s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05433, val loss: 0.05579, in 0.172s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25499, val loss: 0.25518, in 0.282s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05614, val loss: 0.05713, in 0.152s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19122, val loss: 0.19156, in 0.296s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05712, val loss: 0.05848, in 0.192s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05719, val loss: 0.05875, in 0.165s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05385, val loss: 0.05529, in 0.161s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27633, val loss: 0.27593, in 0.270s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23659, val loss: 0.23694, in 0.293s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05554, val loss: 0.05653, in 0.183s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05689, val loss: 0.05846, in 0.160s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05356, val loss: 0.05499, in 0.157s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23648, val loss: 0.23663, in 0.278s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05659, val loss: 0.05794, in 0.191s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17929, val loss: 0.17967, in 0.297s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05501, val loss: 0.05602, in 0.196s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05658, val loss: 0.05813, in 0.152s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21988, val loss: 0.22032, in 0.287s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05616, val loss: 0.05751, in 0.168s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25511, val loss: 0.25475, in 0.309s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05312, val loss: 0.05453, in 0.202s\n",
      "[164/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05473, val loss: 0.05576, in 0.148s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21977, val loss: 0.21998, in 0.306s\n",
      "[13/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05625, val loss: 0.05782, in 0.172s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05291, val loss: 0.05431, in 0.138s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05568, val loss: 0.05703, in 0.195s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16832, val loss: 0.16868, in 0.291s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05615, val loss: 0.05771, in 0.141s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05433, val loss: 0.05535, in 0.187s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20502, val loss: 0.20549, in 0.301s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23651, val loss: 0.23628, in 0.291s\n",
      "[12/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05254, val loss: 0.05397, in 0.210s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05529, val loss: 0.05664, in 0.177s\n",
      "[168/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05600, val loss: 0.05754, in 0.165s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20503, val loss: 0.20532, in 0.319s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05402, val loss: 0.05502, in 0.171s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05230, val loss: 0.05374, in 0.162s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15872, val loss: 0.15904, in 0.327s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05501, val loss: 0.05635, in 0.178s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05573, val loss: 0.05729, in 0.182s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19176, val loss: 0.19215, in 0.341s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22002, val loss: 0.21980, in 0.341s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05364, val loss: 0.05462, in 0.215s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05214, val loss: 0.05360, in 0.162s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05447, val loss: 0.05582, in 0.207s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19166, val loss: 0.19201, in 0.332s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05559, val loss: 0.05716, in 0.161s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14936, val loss: 0.14963, in 0.327s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05337, val loss: 0.05433, in 0.212s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05153, val loss: 0.05297, in 0.206s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05550, val loss: 0.05707, in 0.153s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05406, val loss: 0.05544, in 0.193s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20499, val loss: 0.20470, in 0.328s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17997, val loss: 0.18041, in 0.340s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05328, val loss: 0.05426, in 0.148s\n",
      "[171/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05136, val loss: 0.05277, in 0.187s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17976, val loss: 0.18018, in 0.323s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05387, val loss: 0.05523, in 0.179s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05521, val loss: 0.05676, in 0.216s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14147, val loss: 0.14167, in 0.320s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05113, val loss: 0.05252, in 0.151s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05281, val loss: 0.05380, in 0.206s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19186, val loss: 0.19175, in 0.305s\n",
      "[15/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05378, val loss: 0.05515, in 0.150s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16949, val loss: 0.16996, in 0.318s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05660, in 0.190s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05246, val loss: 0.05344, in 0.170s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05065, val loss: 0.05204, in 0.197s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16901, val loss: 0.16939, in 0.330s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05360, val loss: 0.05497, in 0.162s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13417, val loss: 0.13424, in 0.316s\n",
      "[21/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05466, val loss: 0.05624, in 0.172s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05234, val loss: 0.05332, in 0.140s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05342, val loss: 0.05478, in 0.132s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05017, val loss: 0.05156, in 0.165s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17994, val loss: 0.17973, in 0.319s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16001, val loss: 0.16048, in 0.300s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05405, val loss: 0.05563, in 0.179s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15915, val loss: 0.15956, in 0.269s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05278, in 0.174s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05311, val loss: 0.05448, in 0.172s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12752, val loss: 0.12752, in 0.274s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04976, val loss: 0.05115, in 0.200s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05380, val loss: 0.05536, in 0.138s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15073, val loss: 0.15111, in 0.286s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16914, val loss: 0.16890, in 0.297s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05148, val loss: 0.05242, in 0.192s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05278, val loss: 0.05419, in 0.196s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04927, val loss: 0.05065, in 0.191s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15014, val loss: 0.15061, in 0.288s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05352, val loss: 0.05510, in 0.190s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05116, val loss: 0.05208, in 0.162s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12155, val loss: 0.12154, in 0.309s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05235, val loss: 0.05374, in 0.171s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04903, val loss: 0.05040, in 0.142s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05332, val loss: 0.05487, in 0.168s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14234, val loss: 0.14266, in 0.300s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15952, val loss: 0.15922, in 0.296s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05216, val loss: 0.05356, in 0.143s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05070, val loss: 0.05165, in 0.184s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14218, val loss: 0.14266, in 0.290s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04883, val loss: 0.05021, in 0.182s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05300, val loss: 0.05453, in 0.154s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11596, val loss: 0.11599, in 0.278s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05207, val loss: 0.05347, in 0.136s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05047, val loss: 0.05142, in 0.154s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04858, val loss: 0.04995, in 0.161s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13499, val loss: 0.13528, in 0.284s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15076, val loss: 0.15039, in 0.297s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05251, val loss: 0.05406, in 0.183s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05183, val loss: 0.05324, in 0.160s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13488, val loss: 0.13540, in 0.274s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04989, val loss: 0.05087, in 0.159s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04818, val loss: 0.04956, in 0.169s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11082, val loss: 0.11082, in 0.289s\n",
      "[25/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05225, val loss: 0.05381, in 0.170s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05159, val loss: 0.05297, in 0.153s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04965, val loss: 0.05065, in 0.164s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12858, val loss: 0.12883, in 0.274s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14291, val loss: 0.14262, in 0.294s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04778, val loss: 0.04914, in 0.156s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05207, val loss: 0.05364, in 0.143s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12842, val loss: 0.12898, in 0.285s\n",
      "[22/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05139, val loss: 0.05276, in 0.170s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04939, val loss: 0.05041, in 0.151s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10622, val loss: 0.10620, in 0.275s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04760, val loss: 0.04893, in 0.159s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05200, val loss: 0.05357, in 0.137s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05131, val loss: 0.05268, in 0.152s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12215, val loss: 0.12232, in 0.302s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13547, val loss: 0.13517, in 0.274s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.05005, in 0.186s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12190, val loss: 0.12253, in 0.277s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04720, val loss: 0.04854, in 0.171s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05170, val loss: 0.05332, in 0.178s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05088, val loss: 0.05223, in 0.176s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10210, val loss: 0.10211, in 0.283s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04886, val loss: 0.04991, in 0.153s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05159, val loss: 0.05320, in 0.143s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04690, val loss: 0.04822, in 0.208s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11679, val loss: 0.11690, in 0.292s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12899, val loss: 0.12870, in 0.284s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05057, val loss: 0.05192, in 0.199s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04856, val loss: 0.04962, in 0.176s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11636, val loss: 0.11695, in 0.293s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05123, val loss: 0.05284, in 0.156s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09770, val loss: 0.09769, in 0.290s\n",
      "[28/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04675, val loss: 0.04807, in 0.183s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04826, val loss: 0.04933, in 0.157s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05030, val loss: 0.05166, in 0.178s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05096, val loss: 0.05259, in 0.158s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12268, val loss: 0.12244, in 0.277s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11140, val loss: 0.11151, in 0.291s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04652, val loss: 0.04782, in 0.163s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11133, val loss: 0.11196, in 0.282s\n",
      "[25/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05079, val loss: 0.05240, in 0.143s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04972, val loss: 0.05107, in 0.180s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04791, val loss: 0.04895, in 0.201s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09367, val loss: 0.09375, in 0.270s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04637, val loss: 0.04766, in 0.123s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04772, val loss: 0.04877, in 0.138s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11711, val loss: 0.11687, in 0.287s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05056, val loss: 0.05218, in 0.166s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10688, val loss: 0.10701, in 0.298s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04940, val loss: 0.05078, in 0.178s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04602, val loss: 0.04730, in 0.164s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10670, val loss: 0.10728, in 0.310s\n",
      "[26/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04765, val loss: 0.04871, in 0.134s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09044, val loss: 0.09043, in 0.289s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05041, val loss: 0.05202, in 0.157s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04911, val loss: 0.05045, in 0.158s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04572, val loss: 0.04698, in 0.161s\n",
      "[188/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04744, val loss: 0.04851, in 0.146s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11167, val loss: 0.11160, in 0.284s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10243, val loss: 0.10255, in 0.282s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05004, val loss: 0.05167, in 0.175s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04565, val loss: 0.04692, in 0.137s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04877, val loss: 0.05014, in 0.194s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10232, val loss: 0.10297, in 0.290s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04708, val loss: 0.04815, in 0.175s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08689, val loss: 0.08697, in 0.293s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04954, val loss: 0.05117, in 0.165s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04544, val loss: 0.04672, in 0.157s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04863, val loss: 0.05001, in 0.159s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10691, val loss: 0.10686, in 0.301s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09781, val loss: 0.09794, in 0.288s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04666, val loss: 0.04774, in 0.176s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04536, val loss: 0.04665, in 0.139s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09796, val loss: 0.09865, in 0.292s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04826, val loss: 0.04965, in 0.152s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04904, val loss: 0.05067, in 0.190s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08359, val loss: 0.08370, in 0.291s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04741, in 0.152s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04527, val loss: 0.04656, in 0.137s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04811, val loss: 0.04948, in 0.134s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04892, val loss: 0.05055, in 0.133s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09418, val loss: 0.09437, in 0.275s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10280, val loss: 0.10267, in 0.286s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04799, val loss: 0.04936, in 0.142s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09432, val loss: 0.09499, in 0.296s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04513, val loss: 0.04644, in 0.183s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04605, val loss: 0.04715, in 0.201s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04869, val loss: 0.05034, in 0.172s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08063, val loss: 0.08070, in 0.275s\n",
      "[33/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04506, val loss: 0.04637, in 0.138s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04581, val loss: 0.04692, in 0.145s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04766, val loss: 0.04901, in 0.169s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09072, val loss: 0.09093, in 0.279s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09844, val loss: 0.09827, in 0.284s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04848, val loss: 0.05014, in 0.162s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09068, val loss: 0.09137, in 0.279s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04569, val loss: 0.04679, in 0.142s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04480, val loss: 0.04611, in 0.170s\n",
      "[195/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04754, val loss: 0.04889, in 0.156s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.07778, val loss: 0.07786, in 0.290s\n",
      "[34/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04832, val loss: 0.04996, in 0.184s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04664, in 0.134s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08728, val loss: 0.08760, in 0.283s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09434, val loss: 0.09416, in 0.279s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04744, val loss: 0.04879, in 0.150s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04454, val loss: 0.04583, in 0.193s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08763, val loss: 0.08834, in 0.309s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04517, val loss: 0.04625, in 0.164s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04728, val loss: 0.04866, in 0.148s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07521, val loss: 0.07530, in 0.291s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04430, val loss: 0.04562, in 0.183s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08420, val loss: 0.08440, in 0.292s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09071, val loss: 0.09051, in 0.292s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04712, val loss: 0.04849, in 0.144s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04487, val loss: 0.04597, in 0.179s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04399, val loss: 0.04529, in 0.167s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08464, val loss: 0.08541, in 0.277s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07182, val loss: 0.07189, in 0.289s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04444, val loss: 0.04553, in 0.168s\n",
      "[200/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04375, val loss: 0.04506, in 0.174s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08117, val loss: 0.08135, in 0.291s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08745, val loss: 0.08726, in 0.300s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08183, val loss: 0.08265, in 0.281s\n",
      "[33/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04365, val loss: 0.04496, in 0.165s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06926, val loss: 0.06930, in 0.286s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07845, val loss: 0.07862, in 0.272s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08432, val loss: 0.08409, in 0.280s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07852, val loss: 0.07938, in 0.272s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06696, val loss: 0.06701, in 0.307s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07579, val loss: 0.07598, in 0.291s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08129, val loss: 0.08119, in 0.281s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07618, val loss: 0.07689, in 0.295s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06452, val loss: 0.06456, in 0.278s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07307, val loss: 0.07325, in 0.284s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07792, val loss: 0.07789, in 0.273s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07334, val loss: 0.07404, in 0.281s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06254, val loss: 0.06263, in 0.292s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07508, val loss: 0.07506, in 0.278s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07013, val loss: 0.07031, in 0.280s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07092, val loss: 0.07163, in 0.281s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06058, val loss: 0.06066, in 0.277s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06754, val loss: 0.06773, in 0.270s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07225, val loss: 0.07232, in 0.274s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06864, val loss: 0.06940, in 0.277s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05890, val loss: 0.05899, in 0.298s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06992, val loss: 0.07003, in 0.291s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06546, val loss: 0.06570, in 0.301s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06648, val loss: 0.06722, in 0.265s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05713, val loss: 0.05726, in 0.257s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06765, val loss: 0.06776, in 0.263s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06342, val loss: 0.06364, in 0.267s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06415, val loss: 0.06497, in 0.275s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05421, val loss: 0.05444, in 0.284s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06475, val loss: 0.06499, in 0.294s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06131, val loss: 0.06155, in 0.292s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06232, val loss: 0.06315, in 0.313s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05262, val loss: 0.05286, in 0.319s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06275, val loss: 0.06299, in 0.312s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05864, val loss: 0.05898, in 0.316s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05927, val loss: 0.06004, in 0.295s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05018, val loss: 0.05044, in 0.296s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05711, val loss: 0.05742, in 0.291s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06048, val loss: 0.06069, in 0.311s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05701, val loss: 0.05780, in 0.287s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04825, val loss: 0.04987, in 0.143s\n",
      "Fit 200 trees in 43.180 s, (1555 total leaves)\n",
      "Time spent computing histograms: 25.219s\n",
      "Time spent finding best splits:  0.244s\n",
      "Time spent applying splits:      3.655s\n",
      "Time spent predicting:           0.337s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04804, val loss: 0.04837, in 0.281s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05434, val loss: 0.05470, in 0.298s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05839, val loss: 0.05868, in 0.298s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05453, val loss: 0.05535, in 0.278s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04691, val loss: 0.04829, in 0.143s\n",
      "Fit 200 trees in 43.055 s, (1559 total leaves)\n",
      "Time spent computing histograms: 25.320s\n",
      "Time spent finding best splits:  0.218s\n",
      "Time spent applying splits:      3.456s\n",
      "Time spent predicting:           0.426s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04610, val loss: 0.04651, in 0.276s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05287, val loss: 0.05322, in 0.267s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05539, val loss: 0.05570, in 0.286s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05311, val loss: 0.05395, in 0.296s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04428, val loss: 0.04537, in 0.152s\n",
      "Fit 200 trees in 43.253 s, (1558 total leaves)\n",
      "Time spent computing histograms: 25.633s\n",
      "Time spent finding best splits:  0.167s\n",
      "Time spent applying splits:      3.486s\n",
      "Time spent predicting:           0.301s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04484, val loss: 0.04528, in 0.302s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05090, val loss: 0.05128, in 0.269s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05381, val loss: 0.05418, in 0.304s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04336, val loss: 0.04467, in 0.152s\n",
      "Fit 200 trees in 43.321 s, (1553 total leaves)\n",
      "Time spent computing histograms: 25.333s\n",
      "Time spent finding best splits:  0.200s\n",
      "Time spent applying splits:      3.639s\n",
      "Time spent predicting:           0.400s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05186, val loss: 0.05274, in 0.290s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04356, val loss: 0.04399, in 0.300s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04969, val loss: 0.05006, in 0.278s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05218, val loss: 0.05261, in 0.317s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05050, val loss: 0.05138, in 0.272s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04226, val loss: 0.04255, in 0.320s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04734, val loss: 0.04768, in 0.307s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05079, val loss: 0.05121, in 0.298s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04828, val loss: 0.04917, in 0.291s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04056, val loss: 0.04091, in 0.288s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04532, val loss: 0.04569, in 0.273s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04662, val loss: 0.04751, in 0.274s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04879, val loss: 0.04924, in 0.287s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03961, val loss: 0.03997, in 0.302s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04382, val loss: 0.04422, in 0.280s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04470, val loss: 0.04558, in 0.294s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04665, val loss: 0.04705, in 0.305s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03849, val loss: 0.03886, in 0.263s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04283, val loss: 0.04319, in 0.290s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04301, val loss: 0.04392, in 0.269s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04503, val loss: 0.04544, in 0.268s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03681, val loss: 0.03723, in 0.291s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04141, in 0.275s\n",
      "[52/200] 2.456 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04172, val loss: 0.04263, in 0.272s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04311, val loss: 0.04349, in 0.281s\n",
      "[50/200] 0.112 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03960, val loss: 0.03992, in 0.253s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03541, val loss: 0.03585, in 0.284s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04145, val loss: 0.04185, in 0.274s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04053, val loss: 0.04138, in 0.304s\n",
      "[53/200] 2.485 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.61006, val loss: 0.61001, in 0.253s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.03878, in 0.276s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03421, val loss: 0.03471, in 0.279s\n",
      "[57/200] 0.127 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 2.447 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04012, val loss: 0.04052, in 0.269s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03948, val loss: 0.04034, in 0.293s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54209, val loss: 0.54199, in 0.290s\n",
      "[3/200] 0.128 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03332, val loss: 0.03382, in 0.261s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03725, val loss: 0.03761, in 0.299s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.60994, val loss: 0.61000, in 0.275s\n",
      "[2/200] 2.485 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03820, val loss: 0.03907, in 0.273s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.03959, in 0.302s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48516, val loss: 0.48497, in 0.270s\n",
      "[4/200] 0.123 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61008, val loss: 0.61009, in 0.272s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03219, val loss: 0.03268, in 0.305s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03604, val loss: 0.03640, in 0.289s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54186, val loss: 0.54202, in 0.303s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03728, val loss: 0.03811, in 0.333s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03780, val loss: 0.03819, in 0.342s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43680, val loss: 0.43655, in 0.322s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61012, val loss: 0.61020, in 0.319s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54204, val loss: 0.54216, in 0.323s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03512, val loss: 0.03550, in 0.298s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48429, val loss: 0.48453, in 0.286s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03098, val loss: 0.03149, in 0.331s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39506, val loss: 0.39475, in 0.286s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03588, val loss: 0.03669, in 0.336s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03643, val loss: 0.03681, in 0.338s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48465, val loss: 0.48476, in 0.287s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54199, in 0.306s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43627, val loss: 0.43664, in 0.301s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03008, val loss: 0.03062, in 0.307s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03389, val loss: 0.03427, in 0.350s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35938, val loss: 0.35908, in 0.424s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03519, val loss: 0.03559, in 0.433s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48464, val loss: 0.48459, in 0.416s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03509, val loss: 0.03591, in 0.465s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43612, val loss: 0.43637, in 0.450s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39440, val loss: 0.39487, in 0.455s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03284, val loss: 0.03320, in 0.447s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02919, val loss: 0.02971, in 0.470s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32811, val loss: 0.32770, in 0.358s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43621, val loss: 0.43617, in 0.347s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03401, val loss: 0.03440, in 0.367s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39476, val loss: 0.39503, in 0.343s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03398, val loss: 0.03482, in 0.353s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03221, val loss: 0.03259, in 0.290s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35855, val loss: 0.35916, in 0.309s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02859, val loss: 0.02911, in 0.354s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30057, val loss: 0.30016, in 0.323s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39468, val loss: 0.39468, in 0.308s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35880, val loss: 0.35912, in 0.288s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03383, in 0.300s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03313, val loss: 0.03349, in 0.325s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32714, val loss: 0.32781, in 0.302s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03174, in 0.322s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02771, val loss: 0.02824, in 0.307s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27657, val loss: 0.27609, in 0.321s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35864, val loss: 0.35865, in 0.301s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32744, val loss: 0.32784, in 0.302s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03195, val loss: 0.03278, in 0.309s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03199, val loss: 0.03232, in 0.312s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03066, val loss: 0.03107, in 0.289s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29967, val loss: 0.30046, in 0.309s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02672, val loss: 0.02730, in 0.323s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32727, val loss: 0.32732, in 0.309s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30022, val loss: 0.30065, in 0.312s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03111, val loss: 0.03193, in 0.300s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25557, val loss: 0.25511, in 0.331s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03101, val loss: 0.03131, in 0.307s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.03000, in 0.335s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27587, val loss: 0.27667, in 0.329s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02609, val loss: 0.02668, in 0.360s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30038, val loss: 0.30037, in 0.316s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23698, val loss: 0.23652, in 0.329s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27639, val loss: 0.27685, in 0.341s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03086, in 0.352s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03041, val loss: 0.03073, in 0.324s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25472, val loss: 0.25561, in 0.343s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02889, val loss: 0.02933, in 0.364s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02558, val loss: 0.02612, in 0.301s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27652, val loss: 0.27661, in 0.338s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22045, val loss: 0.22004, in 0.334s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03023, in 0.327s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25515, val loss: 0.25567, in 0.347s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.02985, in 0.353s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02837, val loss: 0.02881, in 0.301s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23622, val loss: 0.23706, in 0.326s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02542, in 0.296s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25527, val loss: 0.25542, in 0.337s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20566, val loss: 0.20523, in 0.325s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23663, val loss: 0.23728, in 0.331s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02848, val loss: 0.02922, in 0.340s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02847, val loss: 0.02874, in 0.340s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21971, val loss: 0.22059, in 0.317s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02741, val loss: 0.02784, in 0.332s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02490, in 0.318s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23644, val loss: 0.23659, in 0.321s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22006, val loss: 0.22074, in 0.320s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19251, val loss: 0.19206, in 0.342s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02777, val loss: 0.02849, in 0.347s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20473, val loss: 0.20560, in 0.346s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02751, val loss: 0.02777, in 0.386s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02658, val loss: 0.02706, in 0.376s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02363, val loss: 0.02421, in 0.348s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21968, val loss: 0.21988, in 0.378s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20522, val loss: 0.20597, in 0.382s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18059, val loss: 0.18008, in 0.394s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02692, val loss: 0.02761, in 0.376s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19142, val loss: 0.19235, in 0.391s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02672, val loss: 0.02695, in 0.388s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02571, val loss: 0.02622, in 0.382s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02304, val loss: 0.02358, in 0.404s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20501, val loss: 0.20526, in 0.430s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16979, val loss: 0.16931, in 0.395s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19196, val loss: 0.19274, in 0.436s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02628, val loss: 0.02698, in 0.442s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02508, val loss: 0.02554, in 0.355s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02606, in 0.411s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17961, val loss: 0.18051, in 0.435s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02255, val loss: 0.02310, in 0.432s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19175, val loss: 0.19213, in 0.363s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15983, val loss: 0.15928, in 0.409s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17987, val loss: 0.18076, in 0.401s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02534, val loss: 0.02598, in 0.403s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02534, in 0.360s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02438, val loss: 0.02481, in 0.396s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16880, val loss: 0.16985, in 0.386s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02199, val loss: 0.02253, in 0.365s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17985, val loss: 0.18030, in 0.390s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15072, val loss: 0.15026, in 0.374s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16904, val loss: 0.17010, in 0.361s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02465, in 0.370s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02362, val loss: 0.02406, in 0.381s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02447, val loss: 0.02507, in 0.413s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15893, val loss: 0.15995, in 0.382s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02139, val loss: 0.02191, in 0.371s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16888, val loss: 0.16955, in 0.330s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14290, val loss: 0.14250, in 0.353s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15908, val loss: 0.16021, in 0.360s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02385, val loss: 0.02407, in 0.329s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02403, val loss: 0.02463, in 0.304s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02311, val loss: 0.02355, in 0.371s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15024, val loss: 0.15132, in 0.333s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02152, in 0.342s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15914, val loss: 0.15989, in 0.345s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13553, val loss: 0.13507, in 0.326s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02313, val loss: 0.02334, in 0.312s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15042, val loss: 0.15162, in 0.348s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02357, val loss: 0.02420, in 0.346s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02239, val loss: 0.02286, in 0.355s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14169, val loss: 0.14288, in 0.358s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02043, val loss: 0.02091, in 0.389s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14991, val loss: 0.15081, in 0.374s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12906, val loss: 0.12866, in 0.383s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14226, val loss: 0.14360, in 0.379s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02289, val loss: 0.02352, in 0.365s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02255, val loss: 0.02275, in 0.428s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02194, val loss: 0.02239, in 0.338s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13435, val loss: 0.13565, in 0.350s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02027, in 0.322s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14140, val loss: 0.14237, in 0.343s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12275, val loss: 0.12241, in 0.345s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13499, val loss: 0.13639, in 0.349s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02219, val loss: 0.02282, in 0.380s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12761, val loss: 0.12894, in 0.351s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02155, val loss: 0.02198, in 0.371s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02200, val loss: 0.02220, in 0.386s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01934, val loss: 0.01982, in 0.401s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13377, val loss: 0.13478, in 0.342s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11700, val loss: 0.11675, in 0.343s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12851, val loss: 0.13002, in 0.358s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02164, val loss: 0.02229, in 0.341s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02092, val loss: 0.02133, in 0.319s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12159, val loss: 0.12292, in 0.342s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02139, val loss: 0.02155, in 0.392s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.01941, in 0.347s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12717, val loss: 0.12827, in 0.348s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11193, val loss: 0.11165, in 0.380s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02119, val loss: 0.02178, in 0.335s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12270, val loss: 0.12424, in 0.381s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02022, val loss: 0.02064, in 0.349s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11613, val loss: 0.11749, in 0.382s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02073, val loss: 0.02087, in 0.348s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01844, val loss: 0.01896, in 0.327s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.12121, val loss: 0.12244, in 0.353s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10718, val loss: 0.10699, in 0.367s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02074, val loss: 0.02133, in 0.336s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.02007, in 0.350s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11687, val loss: 0.11851, in 0.352s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11107, val loss: 0.11248, in 0.331s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02014, val loss: 0.02028, in 0.328s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01865, in 0.315s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11555, val loss: 0.11693, in 0.309s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02027, val loss: 0.02086, in 0.306s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10297, val loss: 0.10280, in 0.317s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11170, val loss: 0.11341, in 0.333s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01905, val loss: 0.01945, in 0.341s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01822, in 0.322s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10654, val loss: 0.10799, in 0.358s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01971, val loss: 0.01988, in 0.358s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11034, val loss: 0.11174, in 0.349s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01985, val loss: 0.02042, in 0.348s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09916, val loss: 0.09899, in 0.351s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01850, val loss: 0.01888, in 0.308s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10706, val loss: 0.10890, in 0.333s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01923, val loss: 0.01939, in 0.309s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01759, in 0.343s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10170, val loss: 0.10319, in 0.334s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10583, val loss: 0.10721, in 0.350s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01935, val loss: 0.01991, in 0.335s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01802, val loss: 0.01839, in 0.322s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09485, val loss: 0.09467, in 0.346s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10289, val loss: 0.10469, in 0.345s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01876, val loss: 0.01891, in 0.331s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01667, val loss: 0.01720, in 0.337s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09787, val loss: 0.09934, in 0.349s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10158, val loss: 0.10302, in 0.322s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01794, in 0.314s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09135, val loss: 0.09121, in 0.354s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01953, in 0.382s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09843, val loss: 0.10043, in 0.338s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01630, val loss: 0.01685, in 0.332s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01835, val loss: 0.01847, in 0.365s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09392, val loss: 0.09542, in 0.347s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09756, val loss: 0.09898, in 0.357s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01754, in 0.362s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01906, in 0.333s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08772, val loss: 0.08769, in 0.343s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09474, val loss: 0.09679, in 0.363s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01656, in 0.335s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01779, val loss: 0.01791, in 0.351s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09054, val loss: 0.09198, in 0.357s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09332, val loss: 0.09484, in 0.337s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01843, in 0.313s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08473, val loss: 0.08472, in 0.314s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01682, val loss: 0.01718, in 0.344s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09094, val loss: 0.09312, in 0.333s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01625, in 0.332s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08709, val loss: 0.08857, in 0.327s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01744, val loss: 0.01757, in 0.363s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08995, val loss: 0.09145, in 0.331s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01820, in 0.264s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08198, val loss: 0.08185, in 0.348s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01644, val loss: 0.01680, in 0.399s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01571, in 0.334s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08741, val loss: 0.08946, in 0.355s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01718, in 0.328s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08439, val loss: 0.08585, in 0.347s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08645, val loss: 0.08796, in 0.333s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01709, val loss: 0.01767, in 0.331s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01491, val loss: 0.01551, in 0.272s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07840, val loss: 0.07829, in 0.353s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01606, val loss: 0.01643, in 0.331s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08423, val loss: 0.08639, in 0.336s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01680, in 0.330s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08132, val loss: 0.08290, in 0.331s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08346, val loss: 0.08506, in 0.324s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01679, val loss: 0.01734, in 0.334s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01515, in 0.350s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07569, val loss: 0.07564, in 0.348s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01614, in 0.365s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08136, val loss: 0.08361, in 0.358s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07871, val loss: 0.08034, in 0.370s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01642, in 0.392s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08066, val loss: 0.08240, in 0.342s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01638, val loss: 0.01691, in 0.362s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01491, in 0.362s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01579, in 0.336s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07323, val loss: 0.07319, in 0.388s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07787, val loss: 0.08006, in 0.381s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07522, val loss: 0.07696, in 0.407s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01611, in 0.410s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07822, val loss: 0.08004, in 0.417s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01593, val loss: 0.01646, in 0.421s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01542, in 0.389s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01461, in 0.451s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07075, val loss: 0.07075, in 0.460s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07561, val loss: 0.07776, in 0.457s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01561, val loss: 0.01574, in 0.406s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07261, val loss: 0.07432, in 0.430s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07512, val loss: 0.07697, in 0.434s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01617, in 0.421s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01506, in 0.344s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01369, val loss: 0.01434, in 0.356s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06834, val loss: 0.06829, in 0.361s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07285, val loss: 0.07501, in 0.358s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01522, val loss: 0.01539, in 0.332s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06996, val loss: 0.07173, in 0.352s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01544, val loss: 0.01598, in 0.266s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07246, val loss: 0.07433, in 0.341s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01422, in 0.279s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01439, val loss: 0.01478, in 0.350s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06604, val loss: 0.06607, in 0.338s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07051, val loss: 0.07270, in 0.346s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06777, val loss: 0.06955, in 0.337s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01494, val loss: 0.01511, in 0.382s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01500, val loss: 0.01554, in 0.356s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06959, val loss: 0.07133, in 0.344s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01380, in 0.328s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01448, in 0.325s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06403, val loss: 0.06405, in 0.350s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06823, val loss: 0.07043, in 0.345s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06505, val loss: 0.06691, in 0.353s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01468, val loss: 0.01486, in 0.344s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01521, in 0.332s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06686, val loss: 0.06856, in 0.350s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01287, val loss: 0.01352, in 0.345s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01381, val loss: 0.01420, in 0.332s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06203, val loss: 0.06206, in 0.357s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06607, val loss: 0.06834, in 0.344s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01443, val loss: 0.01461, in 0.311s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06276, val loss: 0.06461, in 0.341s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01442, val loss: 0.01496, in 0.319s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06449, val loss: 0.06613, in 0.349s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01391, in 0.310s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01331, in 0.345s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06028, val loss: 0.06040, in 0.352s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06387, val loss: 0.06612, in 0.355s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01420, val loss: 0.01440, in 0.359s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01462, in 0.337s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06086, val loss: 0.06268, in 0.353s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06273, val loss: 0.06436, in 0.354s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01357, in 0.342s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01236, val loss: 0.01301, in 0.359s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05857, val loss: 0.05871, in 0.339s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01407, in 0.330s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06200, val loss: 0.06434, in 0.376s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01384, val loss: 0.01438, in 0.342s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05909, val loss: 0.06081, in 0.369s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06085, val loss: 0.06252, in 0.365s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01202, val loss: 0.01264, in 0.322s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01293, val loss: 0.01331, in 0.359s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05673, val loss: 0.05693, in 0.344s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01355, val loss: 0.01410, in 0.319s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06006, val loss: 0.06247, in 0.352s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01373, in 0.360s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05753, val loss: 0.05931, in 0.331s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05897, val loss: 0.06063, in 0.344s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01310, in 0.355s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01232, in 0.368s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05452, val loss: 0.05472, in 0.321s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01322, val loss: 0.01345, in 0.342s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05822, val loss: 0.06067, in 0.355s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05581, val loss: 0.05764, in 0.355s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01373, in 0.396s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01284, in 0.319s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05724, val loss: 0.05896, in 0.343s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01138, val loss: 0.01199, in 0.333s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05294, val loss: 0.05322, in 0.325s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01310, val loss: 0.01363, in 0.268s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05608, val loss: 0.05850, in 0.348s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05414, val loss: 0.05602, in 0.342s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01311, in 0.373s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05555, val loss: 0.05736, in 0.316s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01218, val loss: 0.01261, in 0.333s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01116, val loss: 0.01177, in 0.337s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05045, val loss: 0.05074, in 0.319s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01328, in 0.376s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05333, val loss: 0.05574, in 0.333s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01288, in 0.327s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05379, in 0.336s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01195, val loss: 0.01239, in 0.309s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05343, val loss: 0.05525, in 0.337s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01143, in 0.353s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04892, val loss: 0.04927, in 0.317s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01309, in 0.323s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05025, val loss: 0.05210, in 0.318s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01261, in 0.339s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05156, val loss: 0.05392, in 0.358s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05201, val loss: 0.05385, in 0.322s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01218, in 0.356s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01123, in 0.345s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04768, val loss: 0.04797, in 0.344s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01245, val loss: 0.01297, in 0.351s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04786, val loss: 0.04961, in 0.415s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04986, val loss: 0.05222, in 0.400s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01238, in 0.444s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01194, in 0.431s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05033, val loss: 0.05219, in 0.457s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01044, val loss: 0.01104, in 0.410s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04560, val loss: 0.04588, in 0.423s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01218, val loss: 0.01269, in 0.426s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04657, val loss: 0.04831, in 0.408s\n",
      "[49/200] 1 tree, 29 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01180, in 0.329s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04796, val loss: 0.05031, in 0.408s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01214, in 0.399s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04798, val loss: 0.04980, in 0.391s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01021, val loss: 0.01080, in 0.375s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04414, val loss: 0.04442, in 0.373s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01197, val loss: 0.01249, in 0.363s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01119, val loss: 0.01159, in 0.315s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04452, val loss: 0.04617, in 0.338s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01161, val loss: 0.01185, in 0.330s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04654, val loss: 0.04891, in 0.369s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04626, val loss: 0.04804, in 0.344s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01002, val loss: 0.01060, in 0.366s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04246, val loss: 0.04270, in 0.363s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01229, in 0.362s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04318, val loss: 0.04480, in 0.362s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01143, val loss: 0.01165, in 0.359s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01098, val loss: 0.01140, in 0.414s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04538, val loss: 0.04772, in 0.385s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04431, val loss: 0.04607, in 0.369s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04136, val loss: 0.04162, in 0.380s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.01039, in 0.452s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01154, val loss: 0.01208, in 0.337s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01144, in 0.373s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01073, val loss: 0.01115, in 0.383s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04158, val loss: 0.04316, in 0.424s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04345, val loss: 0.04573, in 0.368s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04291, val loss: 0.04467, in 0.431s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01146, val loss: 0.01201, in 0.280s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04018, val loss: 0.04040, in 0.385s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.01021, in 0.480s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01067, val loss: 0.01109, in 0.292s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01092, val loss: 0.01116, in 0.380s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03994, val loss: 0.04141, in 0.369s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04158, val loss: 0.04378, in 0.372s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04147, val loss: 0.04324, in 0.363s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03886, val loss: 0.03907, in 0.368s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01180, in 0.424s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.01002, in 0.319s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01046, val loss: 0.01088, in 0.344s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01093, in 0.392s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03884, val loss: 0.04025, in 0.383s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04056, val loss: 0.04273, in 0.407s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03982, val loss: 0.04153, in 0.358s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03805, in 0.370s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00985, in 0.312s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01160, in 0.361s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01024, val loss: 0.01065, in 0.323s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01050, val loss: 0.01075, in 0.314s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03765, val loss: 0.03904, in 0.314s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03910, val loss: 0.04126, in 0.320s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03868, val loss: 0.04037, in 0.340s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03687, val loss: 0.03713, in 0.316s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00914, val loss: 0.00970, in 0.354s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01008, val loss: 0.01048, in 0.305s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01139, in 0.365s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01054, in 0.312s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03629, val loss: 0.03759, in 0.317s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03994, in 0.322s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03953, in 0.324s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03601, val loss: 0.03631, in 0.352s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00948, in 0.351s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01063, val loss: 0.01120, in 0.306s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00991, val loss: 0.01032, in 0.378s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03550, val loss: 0.03687, in 0.341s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01008, val loss: 0.01036, in 0.358s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03658, val loss: 0.03872, in 0.340s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03645, val loss: 0.03811, in 0.315s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03523, in 0.307s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.01019, in 0.278s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01045, val loss: 0.01103, in 0.314s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00937, in 0.342s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03435, val loss: 0.03564, in 0.309s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00984, val loss: 0.01011, in 0.328s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03577, val loss: 0.03784, in 0.311s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03502, val loss: 0.03664, in 0.339s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03425, in 0.336s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01030, val loss: 0.01089, in 0.309s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00859, val loss: 0.00919, in 0.291s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00951, val loss: 0.00995, in 0.343s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03333, val loss: 0.03457, in 0.311s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.00996, in 0.313s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03456, val loss: 0.03662, in 0.331s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03395, val loss: 0.03548, in 0.322s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03313, val loss: 0.03342, in 0.294s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00851, val loss: 0.00910, in 0.286s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01009, val loss: 0.01067, in 0.344s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00935, val loss: 0.00979, in 0.333s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03211, val loss: 0.03335, in 0.376s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00979, in 0.369s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03329, val loss: 0.03535, in 0.351s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03325, val loss: 0.03478, in 0.329s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00897, in 0.298s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03246, val loss: 0.03277, in 0.367s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00985, val loss: 0.01043, in 0.362s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00918, val loss: 0.00962, in 0.353s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00942, val loss: 0.00972, in 0.245s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03434, in 0.286s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03264, in 0.341s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03251, val loss: 0.03404, in 0.308s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00818, val loss: 0.00876, in 0.301s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03177, val loss: 0.03209, in 0.312s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00904, val loss: 0.00950, in 0.319s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00959, val loss: 0.01017, in 0.351s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03159, val loss: 0.03360, in 0.288s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00921, val loss: 0.00951, in 0.366s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03179, val loss: 0.03331, in 0.304s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03024, val loss: 0.03147, in 0.337s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00806, val loss: 0.00863, in 0.318s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03130, in 0.322s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00889, val loss: 0.00935, in 0.260s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00943, val loss: 0.01002, in 0.334s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00934, in 0.283s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03302, in 0.317s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02934, val loss: 0.03059, in 0.294s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03084, val loss: 0.03232, in 0.315s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00795, val loss: 0.00853, in 0.327s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00925, in 0.270s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03036, val loss: 0.03070, in 0.331s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00927, in 0.265s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00926, val loss: 0.00986, in 0.343s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03029, val loss: 0.03228, in 0.301s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02851, val loss: 0.02976, in 0.310s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02966, val loss: 0.03113, in 0.325s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00784, val loss: 0.00842, in 0.285s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00865, val loss: 0.00910, in 0.306s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02928, val loss: 0.02962, in 0.318s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00911, in 0.298s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02926, val loss: 0.03123, in 0.309s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00836, in 0.252s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02769, val loss: 0.02890, in 0.305s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02877, val loss: 0.03018, in 0.284s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00972, in 0.377s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00853, val loss: 0.00899, in 0.307s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02871, val loss: 0.02905, in 0.307s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00863, val loss: 0.00895, in 0.349s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00825, in 0.276s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02688, val loss: 0.02806, in 0.295s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.03041, in 0.356s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02781, val loss: 0.02920, in 0.312s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00951, in 0.316s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00841, val loss: 0.00888, in 0.294s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02801, val loss: 0.02841, in 0.288s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00888, in 0.280s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02737, in 0.314s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00754, val loss: 0.00814, in 0.347s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00936, in 0.287s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02757, val loss: 0.02953, in 0.316s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02721, val loss: 0.02858, in 0.335s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00872, in 0.333s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02708, val loss: 0.02745, in 0.318s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00870, in 0.304s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02667, in 0.279s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00801, in 0.295s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02685, val loss: 0.02879, in 0.285s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00861, val loss: 0.00922, in 0.309s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02623, val loss: 0.02756, in 0.304s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00812, val loss: 0.00861, in 0.248s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02644, val loss: 0.02679, in 0.291s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00829, val loss: 0.00862, in 0.262s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02498, val loss: 0.02614, in 0.256s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00787, in 0.291s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00843, val loss: 0.00906, in 0.274s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00851, in 0.269s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02626, val loss: 0.02817, in 0.321s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02543, val loss: 0.02677, in 0.316s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02560, val loss: 0.02595, in 0.300s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00849, in 0.283s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02429, val loss: 0.02545, in 0.276s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00718, val loss: 0.00777, in 0.298s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00791, val loss: 0.00841, in 0.273s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00888, in 0.329s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02737, in 0.309s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02486, val loss: 0.02620, in 0.297s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02469, val loss: 0.02501, in 0.309s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00799, val loss: 0.00834, in 0.330s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02381, val loss: 0.02499, in 0.305s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00706, val loss: 0.00765, in 0.265s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02451, val loss: 0.02585, in 0.226s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00867, in 0.264s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02460, val loss: 0.02641, in 0.265s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00779, val loss: 0.00829, in 0.303s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02406, val loss: 0.02436, in 0.295s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00819, in 0.274s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02319, val loss: 0.02435, in 0.301s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00696, val loss: 0.00756, in 0.269s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00791, val loss: 0.00853, in 0.285s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00771, val loss: 0.00821, in 0.296s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02384, val loss: 0.02512, in 0.330s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02392, val loss: 0.02568, in 0.350s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02358, val loss: 0.02388, in 0.356s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00801, in 0.353s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02360, in 0.371s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00684, val loss: 0.00745, in 0.366s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00780, val loss: 0.00842, in 0.374s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02444, in 0.338s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00806, in 0.374s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02333, val loss: 0.02509, in 0.386s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02301, val loss: 0.02333, in 0.324s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00749, val loss: 0.00789, in 0.377s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02279, in 0.330s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00769, val loss: 0.00831, in 0.294s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00669, val loss: 0.00727, in 0.370s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02240, val loss: 0.02367, in 0.363s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00791, in 0.354s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02276, val loss: 0.02448, in 0.348s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02242, val loss: 0.02276, in 0.338s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00759, val loss: 0.00822, in 0.281s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00738, val loss: 0.00778, in 0.354s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02115, val loss: 0.02222, in 0.364s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00659, val loss: 0.00718, in 0.327s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02194, val loss: 0.02318, in 0.324s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00729, val loss: 0.00781, in 0.336s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02218, val loss: 0.02387, in 0.297s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02204, in 0.298s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00808, in 0.281s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00654, val loss: 0.00713, in 0.235s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02076, val loss: 0.02185, in 0.321s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00725, val loss: 0.00764, in 0.408s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02157, val loss: 0.02280, in 0.312s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00768, in 0.328s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02176, val loss: 0.02346, in 0.322s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00803, in 0.246s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02174, in 0.321s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00646, val loss: 0.00705, in 0.279s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02027, val loss: 0.02137, in 0.308s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00712, val loss: 0.00752, in 0.307s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02107, val loss: 0.02229, in 0.337s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00704, val loss: 0.00757, in 0.302s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02122, val loss: 0.02292, in 0.327s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02087, val loss: 0.02127, in 0.308s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00698, in 0.284s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00791, in 0.345s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00708, val loss: 0.00748, in 0.261s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02093, in 0.325s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00696, val loss: 0.00749, in 0.339s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02180, in 0.352s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02069, val loss: 0.02237, in 0.320s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00629, val loss: 0.00687, in 0.287s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02030, val loss: 0.02071, in 0.305s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00717, val loss: 0.00779, in 0.286s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00736, in 0.312s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01933, val loss: 0.02042, in 0.315s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00679, val loss: 0.00732, in 0.288s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02007, val loss: 0.02125, in 0.278s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02020, val loss: 0.02186, in 0.270s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02006, in 0.283s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00707, val loss: 0.00769, in 0.287s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00615, val loss: 0.00674, in 0.305s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00685, val loss: 0.00727, in 0.295s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01882, val loss: 0.01988, in 0.284s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00668, val loss: 0.00722, in 0.313s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01941, val loss: 0.01980, in 0.271s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02144, in 0.311s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01950, val loss: 0.02066, in 0.341s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00691, val loss: 0.00753, in 0.299s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00661, in 0.347s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01944, in 0.315s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00675, val loss: 0.00717, in 0.350s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00709, in 0.300s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01937, in 0.303s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01920, val loss: 0.02077, in 0.315s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01900, val loss: 0.02013, in 0.289s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00681, val loss: 0.00743, in 0.284s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00596, val loss: 0.00654, in 0.315s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01880, in 0.287s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00661, val loss: 0.00704, in 0.282s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.02052, in 0.230s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01842, val loss: 0.01883, in 0.281s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00645, val loss: 0.00698, in 0.287s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00670, val loss: 0.00733, in 0.269s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01958, in 0.288s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00645, in 0.290s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00647, val loss: 0.00690, in 0.262s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01751, val loss: 0.01850, in 0.282s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00636, val loss: 0.00689, in 0.260s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01913, in 0.251s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01852, val loss: 0.02004, in 0.341s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00661, val loss: 0.00724, in 0.299s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01848, in 0.323s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00635, in 0.256s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00635, val loss: 0.00678, in 0.303s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01715, val loss: 0.01814, in 0.308s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00715, in 0.246s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01767, val loss: 0.01870, in 0.288s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01773, val loss: 0.01814, in 0.264s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00627, val loss: 0.00680, in 0.330s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01807, val loss: 0.01957, in 0.299s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00567, val loss: 0.00627, in 0.257s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01745, val loss: 0.01848, in 0.216s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01670, val loss: 0.01769, in 0.295s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00646, val loss: 0.00708, in 0.265s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00623, val loss: 0.00666, in 0.313s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01768, in 0.287s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00558, val loss: 0.00618, in 0.283s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00668, in 0.312s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01749, val loss: 0.01896, in 0.318s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00656, in 0.259s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01809, in 0.304s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00636, val loss: 0.00698, in 0.322s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01719, in 0.335s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00550, val loss: 0.00612, in 0.255s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01698, val loss: 0.01740, in 0.289s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01711, val loss: 0.01856, in 0.296s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00603, val loss: 0.00659, in 0.323s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00605, val loss: 0.00649, in 0.219s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01671, val loss: 0.01774, in 0.293s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00689, in 0.272s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01705, in 0.285s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01675, in 0.317s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00538, val loss: 0.00600, in 0.316s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01821, in 0.280s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00653, in 0.273s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00595, val loss: 0.00640, in 0.274s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01631, val loss: 0.01736, in 0.278s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01637, val loss: 0.01679, in 0.294s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00616, val loss: 0.00681, in 0.332s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01797, in 0.256s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00530, val loss: 0.00592, in 0.301s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01640, in 0.317s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00589, val loss: 0.00646, in 0.283s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00585, val loss: 0.00632, in 0.290s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01604, val loss: 0.01711, in 0.312s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01601, val loss: 0.01643, in 0.267s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00608, val loss: 0.00673, in 0.278s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00639, in 0.277s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00584, in 0.292s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01747, in 0.319s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01611, in 0.301s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00623, in 0.275s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01569, val loss: 0.01671, in 0.266s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01553, val loss: 0.01597, in 0.276s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00663, in 0.283s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00630, in 0.273s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01572, val loss: 0.01712, in 0.265s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01580, in 0.264s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00515, val loss: 0.00577, in 0.304s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00568, val loss: 0.00615, in 0.272s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01641, in 0.287s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00592, val loss: 0.00657, in 0.245s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01553, in 0.265s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00565, val loss: 0.00622, in 0.289s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01678, in 0.289s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00571, in 0.252s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01545, in 0.282s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00556, val loss: 0.00603, in 0.305s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01600, in 0.265s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01522, in 0.312s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00580, val loss: 0.00645, in 0.316s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01522, in 0.287s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00565, in 0.293s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01651, in 0.312s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00557, val loss: 0.00615, in 0.335s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01584, in 0.235s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00548, val loss: 0.00596, in 0.316s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01464, val loss: 0.01505, in 0.257s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00559, in 0.276s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00570, val loss: 0.00635, in 0.337s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01620, in 0.278s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01494, in 0.304s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00608, in 0.299s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00539, val loss: 0.00587, in 0.283s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01557, in 0.321s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01431, val loss: 0.01474, in 0.278s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00492, val loss: 0.00551, in 0.263s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01477, in 0.248s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00562, val loss: 0.00629, in 0.267s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01456, val loss: 0.01592, in 0.291s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00544, val loss: 0.00602, in 0.296s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00578, in 0.292s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01434, val loss: 0.01530, in 0.271s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00484, val loss: 0.00543, in 0.251s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01439, in 0.314s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01342, val loss: 0.01432, in 0.316s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00621, in 0.324s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01434, val loss: 0.01571, in 0.339s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00534, val loss: 0.00593, in 0.309s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01403, val loss: 0.01499, in 0.340s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00522, val loss: 0.00571, in 0.366s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01372, val loss: 0.01416, in 0.355s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00474, val loss: 0.00532, in 0.374s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00547, val loss: 0.00614, in 0.314s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01414, val loss: 0.01552, in 0.271s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01407, in 0.344s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00527, val loss: 0.00587, in 0.320s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00514, val loss: 0.00563, in 0.306s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01474, in 0.339s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01343, val loss: 0.01386, in 0.281s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00470, val loss: 0.00527, in 0.266s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01386, in 0.268s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00540, val loss: 0.00607, in 0.319s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00583, in 0.261s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01529, in 0.342s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00505, val loss: 0.00555, in 0.309s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01350, val loss: 0.01445, in 0.295s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00464, val loss: 0.00522, in 0.264s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01369, in 0.243s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01308, val loss: 0.01349, in 0.336s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00517, val loss: 0.00577, in 0.287s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00531, val loss: 0.00599, in 0.321s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01485, in 0.313s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01319, val loss: 0.01415, in 0.284s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00546, in 0.306s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01346, in 0.298s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00514, in 0.343s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01281, val loss: 0.01322, in 0.287s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00511, val loss: 0.00573, in 0.291s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00592, in 0.308s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01451, in 0.309s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01317, in 0.296s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01396, in 0.369s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00487, val loss: 0.00536, in 0.371s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01299, in 0.306s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00451, val loss: 0.00509, in 0.352s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00565, in 0.348s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01432, in 0.293s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00517, val loss: 0.00587, in 0.340s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01303, in 0.262s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01270, in 0.297s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00530, in 0.313s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01377, in 0.344s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00502, in 0.322s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01408, in 0.313s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00550, in 0.320s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00580, in 0.317s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01269, in 0.335s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01348, in 0.345s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00525, in 0.353s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01244, in 0.371s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00436, val loss: 0.00494, in 0.320s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00544, in 0.286s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01252, val loss: 0.01385, in 0.328s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00574, in 0.324s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01156, val loss: 0.01240, in 0.296s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00487, in 0.289s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01233, val loss: 0.01327, in 0.328s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00537, in 0.280s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01180, val loss: 0.01220, in 0.311s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00466, val loss: 0.00517, in 0.329s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00569, in 0.271s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01223, val loss: 0.01355, in 0.322s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01132, val loss: 0.01214, in 0.296s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00530, in 0.282s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01298, in 0.297s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00459, val loss: 0.00511, in 0.300s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00420, val loss: 0.00477, in 0.322s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01200, in 0.322s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01197, val loss: 0.01333, in 0.270s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00490, val loss: 0.00563, in 0.320s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01109, val loss: 0.01191, in 0.275s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01179, val loss: 0.01273, in 0.258s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00517, in 0.305s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00454, val loss: 0.00505, in 0.297s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01310, in 0.274s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00412, val loss: 0.00469, in 0.321s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01139, val loss: 0.01181, in 0.310s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00482, val loss: 0.00555, in 0.308s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01171, in 0.317s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00449, val loss: 0.00501, in 0.256s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00451, val loss: 0.00511, in 0.279s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01297, in 0.243s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00407, val loss: 0.00464, in 0.259s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01248, in 0.334s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01114, val loss: 0.01158, in 0.312s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00475, val loss: 0.00548, in 0.264s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01067, val loss: 0.01150, in 0.290s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00495, in 0.280s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00505, in 0.282s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01228, in 0.277s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00458, in 0.284s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00542, in 0.268s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01267, in 0.345s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01134, in 0.291s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01053, val loss: 0.01136, in 0.294s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00491, in 0.265s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01115, val loss: 0.01208, in 0.277s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00454, in 0.285s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00436, val loss: 0.00499, in 0.321s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01071, val loss: 0.01115, in 0.261s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00537, in 0.287s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01111, val loss: 0.01243, in 0.310s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01113, in 0.247s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00485, in 0.275s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01195, in 0.258s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00491, in 0.272s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00446, in 0.300s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01051, val loss: 0.01096, in 0.278s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00530, in 0.301s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01095, val loss: 0.01227, in 0.279s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01095, in 0.264s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00479, in 0.250s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01174, in 0.271s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00485, in 0.273s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00381, val loss: 0.00439, in 0.336s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01080, val loss: 0.01211, in 0.294s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01035, val loss: 0.01082, in 0.325s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00450, val loss: 0.00525, in 0.329s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00990, val loss: 0.01066, in 0.313s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01060, val loss: 0.01153, in 0.274s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00418, val loss: 0.00473, in 0.325s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00435, in 0.245s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00479, in 0.325s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01045, val loss: 0.01171, in 0.277s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01019, val loss: 0.01067, in 0.304s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00518, in 0.322s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00970, val loss: 0.01046, in 0.336s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01033, val loss: 0.01123, in 0.284s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00412, val loss: 0.00467, in 0.283s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01034, val loss: 0.01160, in 0.229s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00414, val loss: 0.00473, in 0.265s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00431, in 0.289s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01054, in 0.255s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00513, in 0.269s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00406, val loss: 0.00463, in 0.253s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01106, in 0.266s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.01022, in 0.297s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01143, in 0.278s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00425, in 0.265s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00469, in 0.288s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00990, val loss: 0.01040, in 0.266s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00503, in 0.273s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00458, in 0.295s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00931, val loss: 0.01006, in 0.316s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00997, val loss: 0.01089, in 0.323s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00365, val loss: 0.00422, in 0.251s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00996, val loss: 0.01118, in 0.278s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00404, val loss: 0.00465, in 0.304s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.01028, in 0.299s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00422, val loss: 0.00496, in 0.304s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00397, val loss: 0.00454, in 0.338s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00359, val loss: 0.00418, in 0.295s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.01069, in 0.333s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00913, val loss: 0.00988, in 0.363s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.01020, in 0.272s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00979, val loss: 0.01101, in 0.353s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00399, val loss: 0.00462, in 0.327s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00490, in 0.269s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00449, in 0.263s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00970, val loss: 0.01062, in 0.250s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00412, in 0.273s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00899, val loss: 0.00974, in 0.285s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00952, val loss: 0.01003, in 0.291s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00396, val loss: 0.00458, in 0.276s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.01086, in 0.307s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00484, in 0.275s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00444, in 0.303s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00956, val loss: 0.01047, in 0.304s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00348, val loss: 0.00406, in 0.314s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00883, val loss: 0.00957, in 0.265s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00992, in 0.257s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00451, in 0.273s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00949, val loss: 0.01074, in 0.298s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00475, in 0.292s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00439, in 0.259s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00402, in 0.264s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00938, val loss: 0.01028, in 0.312s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00945, in 0.326s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00385, val loss: 0.00448, in 0.297s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00925, val loss: 0.00976, in 0.344s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00932, val loss: 0.01057, in 0.324s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00396, val loss: 0.00469, in 0.334s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00376, val loss: 0.00434, in 0.319s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00340, val loss: 0.00399, in 0.276s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00925, val loss: 0.01014, in 0.285s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00380, val loss: 0.00444, in 0.289s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00932, in 0.322s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00908, val loss: 0.00959, in 0.319s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00917, val loss: 0.01042, in 0.322s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00464, in 0.309s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00430, in 0.290s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00395, in 0.336s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00908, val loss: 0.00998, in 0.317s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00919, in 0.278s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00437, in 0.298s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00942, in 0.275s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00459, in 0.245s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.01025, in 0.326s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00330, val loss: 0.00391, in 0.236s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00367, val loss: 0.00425, in 0.305s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00888, val loss: 0.00976, in 0.274s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00370, val loss: 0.00432, in 0.278s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00904, in 0.290s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00926, in 0.291s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00455, in 0.296s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00884, val loss: 0.01010, in 0.285s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00389, in 0.254s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00362, val loss: 0.00420, in 0.273s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00960, in 0.283s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00366, val loss: 0.00429, in 0.281s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00891, in 0.278s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00916, in 0.298s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00375, val loss: 0.00448, in 0.309s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00384, in 0.290s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00996, in 0.340s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00358, val loss: 0.00417, in 0.304s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00945, in 0.266s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00810, val loss: 0.00882, in 0.240s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00424, in 0.288s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00850, val loss: 0.00903, in 0.306s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00445, in 0.281s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00378, in 0.259s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00981, in 0.302s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00412, in 0.288s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00420, in 0.282s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00925, in 0.342s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00869, in 0.339s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00365, val loss: 0.00440, in 0.243s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00889, in 0.283s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00373, in 0.298s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00409, in 0.245s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00970, in 0.322s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00416, in 0.280s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00784, val loss: 0.00857, in 0.311s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00825, val loss: 0.00880, in 0.287s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00905, in 0.362s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00435, in 0.309s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00308, val loss: 0.00368, in 0.327s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00404, in 0.318s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00959, in 0.262s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00412, in 0.289s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00774, val loss: 0.00849, in 0.288s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00868, in 0.272s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00891, in 0.300s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00432, in 0.287s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00366, in 0.245s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00824, val loss: 0.00948, in 0.260s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00344, val loss: 0.00408, in 0.228s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00339, val loss: 0.00400, in 0.317s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00757, val loss: 0.00831, in 0.324s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00428, in 0.308s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00856, in 0.340s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00874, in 0.331s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00359, in 0.309s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00404, in 0.267s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00937, in 0.299s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00394, in 0.309s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00745, val loss: 0.00820, in 0.312s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00420, in 0.285s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00792, val loss: 0.00848, in 0.300s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00777, val loss: 0.00863, in 0.328s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00401, in 0.289s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00355, in 0.320s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00926, in 0.310s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00329, val loss: 0.00389, in 0.288s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00731, val loss: 0.00804, in 0.312s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00341, val loss: 0.00416, in 0.317s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00778, val loss: 0.00835, in 0.397s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00351, in 0.340s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00766, val loss: 0.00853, in 0.400s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00914, in 0.379s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00325, val loss: 0.00385, in 0.368s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00331, val loss: 0.00395, in 0.437s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00793, in 0.367s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00337, val loss: 0.00413, in 0.360s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00288, val loss: 0.00349, in 0.358s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00767, val loss: 0.00824, in 0.382s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00839, in 0.351s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00903, in 0.351s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00328, val loss: 0.00392, in 0.368s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00382, in 0.384s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00408, in 0.302s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00707, val loss: 0.00780, in 0.390s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00758, val loss: 0.00814, in 0.301s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00345, in 0.327s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00388, in 0.307s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00738, val loss: 0.00825, in 0.405s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00380, in 0.328s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00888, in 0.391s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00405, in 0.364s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00696, val loss: 0.00769, in 0.381s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00282, val loss: 0.00342, in 0.352s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00803, in 0.386s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00385, in 0.291s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00878, in 0.298s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00376, in 0.354s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00815, in 0.379s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00402, in 0.365s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00792, in 0.313s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00687, val loss: 0.00761, in 0.392s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00277, val loss: 0.00336, in 0.438s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00316, val loss: 0.00382, in 0.418s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00373, in 0.328s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00864, in 0.450s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00714, val loss: 0.00804, in 0.415s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00323, val loss: 0.00399, in 0.333s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00781, in 0.337s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00753, in 0.355s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00333, in 0.291s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00313, val loss: 0.00379, in 0.321s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00369, in 0.387s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00732, val loss: 0.00853, in 0.334s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00395, in 0.302s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00705, val loss: 0.00796, in 0.352s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00713, val loss: 0.00769, in 0.381s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00666, val loss: 0.00739, in 0.338s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00375, in 0.314s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00270, val loss: 0.00329, in 0.377s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00317, val loss: 0.00393, in 0.282s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00723, val loss: 0.00843, in 0.320s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00366, in 0.373s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00693, val loss: 0.00784, in 0.355s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00727, in 0.373s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00372, in 0.351s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00702, val loss: 0.00760, in 0.416s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00325, in 0.376s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00388, in 0.374s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00714, val loss: 0.00835, in 0.352s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00363, in 0.384s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00683, val loss: 0.00773, in 0.415s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00696, val loss: 0.00754, in 0.263s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00370, in 0.322s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00643, val loss: 0.00716, in 0.330s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00322, in 0.315s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00385, in 0.281s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00705, val loss: 0.00826, in 0.304s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00295, val loss: 0.00359, in 0.345s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00762, in 0.384s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00299, val loss: 0.00365, in 0.356s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00683, val loss: 0.00741, in 0.392s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00319, in 0.346s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00817, in 0.312s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00382, in 0.345s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00633, val loss: 0.00706, in 0.404s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00355, in 0.333s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00660, val loss: 0.00750, in 0.318s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00361, in 0.276s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00317, in 0.283s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00304, val loss: 0.00380, in 0.276s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00672, val loss: 0.00731, in 0.337s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00687, val loss: 0.00806, in 0.319s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00624, val loss: 0.00698, in 0.324s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00289, val loss: 0.00352, in 0.298s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00740, in 0.285s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00293, val loss: 0.00358, in 0.298s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00255, val loss: 0.00313, in 0.289s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00677, val loss: 0.00798, in 0.279s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00616, val loss: 0.00691, in 0.262s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00657, val loss: 0.00717, in 0.317s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00376, in 0.346s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00350, in 0.309s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00729, in 0.337s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00354, in 0.330s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00372, in 0.277s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00309, in 0.350s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00609, val loss: 0.00683, in 0.322s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00667, val loss: 0.00787, in 0.345s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00708, in 0.341s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00346, in 0.301s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00286, val loss: 0.00350, in 0.403s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00628, val loss: 0.00714, in 0.439s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00368, in 0.423s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00671, in 0.408s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00658, val loss: 0.00779, in 0.417s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00636, val loss: 0.00695, in 0.425s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00343, in 0.371s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00283, val loss: 0.00347, in 0.300s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00696, in 0.311s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00661, in 0.300s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00363, in 0.312s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00628, val loss: 0.00688, in 0.323s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00769, in 0.351s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00338, in 0.358s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00343, in 0.317s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00688, in 0.372s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00651, in 0.349s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00360, in 0.379s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00636, val loss: 0.00755, in 0.324s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00618, val loss: 0.00678, in 0.369s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00335, in 0.399s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00594, val loss: 0.00677, in 0.364s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00644, in 0.364s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00281, val loss: 0.00357, in 0.417s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00627, val loss: 0.00745, in 0.406s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00671, in 0.377s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00332, in 0.421s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00636, in 0.420s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00663, in 0.462s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00619, val loss: 0.00735, in 0.350s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00605, val loss: 0.00665, in 0.354s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00329, in 0.365s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00574, val loss: 0.00656, in 0.348s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00629, in 0.399s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00606, val loss: 0.00721, in 0.415s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00594, val loss: 0.00654, in 0.400s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00326, in 0.428s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00566, val loss: 0.00647, in 0.354s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00547, val loss: 0.00622, in 0.345s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00587, val loss: 0.00648, in 0.316s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00713, in 0.376s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00260, val loss: 0.00323, in 0.278s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00559, val loss: 0.00640, in 0.277s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00639, in 0.322s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00539, val loss: 0.00613, in 0.350s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00589, val loss: 0.00705, in 0.289s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00321, in 0.275s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00633, in 0.364s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00632, in 0.297s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00695, in 0.310s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00532, val loss: 0.00607, in 0.348s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00564, val loss: 0.00625, in 0.340s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00687, in 0.308s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00543, val loss: 0.00626, in 0.375s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00525, val loss: 0.00600, in 0.341s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00554, val loss: 0.00616, in 0.366s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00676, in 0.378s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00618, in 0.376s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00517, val loss: 0.00592, in 0.362s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00546, val loss: 0.00609, in 0.341s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00612, in 0.347s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00666, in 0.375s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00510, val loss: 0.00585, in 0.352s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00542, val loss: 0.00606, in 0.287s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00607, in 0.324s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00505, val loss: 0.00580, in 0.337s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00547, val loss: 0.00659, in 0.391s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00572, in 0.283s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00518, val loss: 0.00601, in 0.337s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00533, val loss: 0.00597, in 0.417s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00541, val loss: 0.00654, in 0.308s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00526, val loss: 0.00589, in 0.342s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00594, in 0.386s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00488, val loss: 0.00563, in 0.397s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00530, val loss: 0.00641, in 0.400s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00583, in 0.387s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00481, val loss: 0.00555, in 0.353s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00587, in 0.386s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00516, val loss: 0.00625, in 0.388s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00578, in 0.349s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00579, in 0.353s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00476, val loss: 0.00549, in 0.387s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00618, in 0.406s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00306, in 0.381s\n",
      "Fit 200 trees in 66.592 s, (6200 total leaves)\n",
      "Time spent computing histograms: 38.951s\n",
      "Time spent finding best splits:  1.162s\n",
      "Time spent applying splits:      8.437s\n",
      "Time spent predicting:           0.491s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00506, val loss: 0.00571, in 0.395s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00541, in 0.352s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00571, in 0.381s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00503, val loss: 0.00611, in 0.359s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00500, val loss: 0.00565, in 0.371s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00459, val loss: 0.00530, in 0.425s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00564, in 0.406s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00496, val loss: 0.00604, in 0.383s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00491, val loss: 0.00556, in 0.396s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00557, in 0.375s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00525, in 0.389s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00488, val loss: 0.00596, in 0.338s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00340, in 0.344s\n",
      "Fit 200 trees in 66.478 s, (6198 total leaves)\n",
      "Time spent computing histograms: 38.749s\n",
      "Time spent finding best splits:  1.171s\n",
      "Time spent applying splits:      8.249s\n",
      "Time spent predicting:           0.542s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00472, val loss: 0.00553, in 0.364s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00448, val loss: 0.00520, in 0.363s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00485, val loss: 0.00548, in 0.421s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00588, in 0.409s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00354, in 0.402s\n",
      "Fit 200 trees in 66.908 s, (6200 total leaves)\n",
      "Time spent computing histograms: 39.439s\n",
      "Time spent finding best splits:  1.142s\n",
      "Time spent applying splits:      8.355s\n",
      "Time spent predicting:           0.529s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00542, in 0.424s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00542, in 0.415s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00515, in 0.456s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00473, val loss: 0.00582, in 0.450s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00511, in 0.342s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00455, val loss: 0.00535, in 0.424s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00536, in 0.448s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00467, val loss: 0.00574, in 0.433s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00531, in 0.358s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00433, val loss: 0.00505, in 0.444s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00529, in 0.497s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00569, in 0.442s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00461, val loss: 0.00524, in 0.373s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00502, in 0.407s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00524, in 0.375s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00560, in 0.443s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00519, in 0.384s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00498, in 0.350s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00318, in 0.334s\n",
      "Fit 200 trees in 67.726 s, (6200 total leaves)\n",
      "Time spent computing histograms: 39.827s\n",
      "Time spent finding best splits:  1.091s\n",
      "Time spent applying splits:      8.671s\n",
      "Time spent predicting:           0.579s\n",
      "Binning 0.119 GB of training data: 3.409 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 8, train loss: 0.00434, val loss: 0.00517, in 0.403s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00554, in 0.479s\n",
      "[166/200] 0.185 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00449, val loss: 0.00512, in 0.470s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00485, in 0.455s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00510, in 0.477s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61006, val loss: 0.61010, in 0.402s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00439, val loss: 0.00546, in 0.425s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00408, val loss: 0.00480, in 0.395s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00507, in 0.453s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00422, val loss: 0.00504, in 0.410s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54204, in 0.447s\n",
      "[3/200] 3.543 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 8, train loss: 0.00434, val loss: 0.00540, in 0.482s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00439, val loss: 0.00501, in 0.380s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00475, in 0.446s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00415, val loss: 0.00497, in 0.404s\n",
      "[168/200] 0.178 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48467, val loss: 0.48468, in 0.412s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00534, in 0.385s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00497, in 0.412s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00471, in 0.416s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.60938, val loss: 0.60934, in 0.434s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00492, in 0.499s\n",
      "[169/200] 3.661 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.43613, val loss: 0.43627, in 0.456s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00530, in 0.483s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00428, val loss: 0.00492, in 0.482s\n",
      "[174/200] 0.202 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00464, in 0.545s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54059, val loss: 0.54069, in 0.478s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00404, val loss: 0.00487, in 0.518s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39469, val loss: 0.39482, in 0.481s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00423, val loss: 0.00486, in 0.440s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00418, val loss: 0.00523, in 0.540s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61000, val loss: 0.60998, in 0.433s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00460, in 0.449s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48335, val loss: 0.48339, in 0.451s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00397, val loss: 0.00479, in 0.474s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35864, val loss: 0.35885, in 0.447s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00517, in 0.456s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00479, in 0.491s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54194, val loss: 0.54198, in 0.461s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00457, in 0.473s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00474, in 0.374s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43451, val loss: 0.43465, in 0.445s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32749, val loss: 0.32772, in 0.442s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00514, in 0.416s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48438, val loss: 0.48447, in 0.426s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00474, in 0.470s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00379, val loss: 0.00451, in 0.494s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00469, in 0.425s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39300, val loss: 0.39331, in 0.435s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30043, val loss: 0.30073, in 0.461s\n",
      "[9/200] 3.892 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00404, val loss: 0.00509, in 0.465s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00470, in 0.429s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43575, val loss: 0.43595, in 0.476s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00449, in 0.415s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00464, in 0.455s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35739, val loss: 0.35773, in 0.452s\n",
      "[7/200] 0.195 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27647, val loss: 0.27690, in 0.447s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39482, in 0.437s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00465, in 0.469s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00399, val loss: 0.00503, in 0.542s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00445, in 0.469s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61005, val loss: 0.61007, in 0.440s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32553, val loss: 0.32590, in 0.479s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00459, in 0.530s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25552, val loss: 0.25615, in 0.472s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35839, val loss: 0.35880, in 0.477s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00394, val loss: 0.00499, in 0.448s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00397, val loss: 0.00461, in 0.555s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00366, val loss: 0.00439, in 0.500s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54194, val loss: 0.54198, in 0.483s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29777, val loss: 0.29818, in 0.476s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00371, val loss: 0.00453, in 0.468s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23712, val loss: 0.23785, in 0.447s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32714, val loss: 0.32747, in 0.477s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00492, in 0.539s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00434, in 0.516s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00455, in 0.552s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48444, val loss: 0.48446, in 0.484s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27355, val loss: 0.27406, in 0.532s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00449, in 0.504s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22014, val loss: 0.22089, in 0.571s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29984, val loss: 0.30022, in 0.494s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00487, in 0.478s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00446, in 0.606s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43596, val loss: 0.43605, in 0.587s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00430, in 0.620s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25234, val loss: 0.25294, in 0.590s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00361, val loss: 0.00442, in 0.636s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20512, val loss: 0.20595, in 0.605s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00378, val loss: 0.00482, in 0.547s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27570, val loss: 0.27609, in 0.623s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39456, in 0.516s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00442, in 0.521s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00425, in 0.574s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00435, in 0.481s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23354, val loss: 0.23424, in 0.548s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19183, val loss: 0.19271, in 0.531s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00373, val loss: 0.00476, in 0.492s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25480, val loss: 0.25508, in 0.523s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00437, in 0.469s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35833, val loss: 0.35832, in 0.497s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00431, in 0.489s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21681, val loss: 0.21747, in 0.522s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00347, val loss: 0.00419, in 0.582s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17999, val loss: 0.18092, in 0.531s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00472, in 0.568s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23602, val loss: 0.23637, in 0.549s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00434, in 0.523s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32725, val loss: 0.32741, in 0.529s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00347, val loss: 0.00428, in 0.552s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20198, val loss: 0.20279, in 0.527s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00415, in 0.616s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16917, val loss: 0.17015, in 0.584s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00469, in 0.542s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21941, val loss: 0.21986, in 0.600s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30010, val loss: 0.30024, in 0.568s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00365, val loss: 0.00428, in 0.648s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00424, in 0.551s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18860, val loss: 0.18938, in 0.599s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00411, in 0.543s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15929, val loss: 0.16045, in 0.608s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20455, val loss: 0.20495, in 0.627s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00465, in 0.706s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27636, val loss: 0.27654, in 0.629s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00338, val loss: 0.00419, in 0.618s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00425, in 0.673s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17651, val loss: 0.17734, in 0.634s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00409, in 0.653s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15021, val loss: 0.15153, in 0.635s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00460, in 0.602s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19122, val loss: 0.19156, in 0.664s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00418, in 0.520s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25527, val loss: 0.25548, in 0.615s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00333, val loss: 0.00406, in 0.495s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00412, in 0.682s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16543, val loss: 0.16638, in 0.610s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14227, val loss: 0.14364, in 0.610s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00351, val loss: 0.00455, in 0.547s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17929, val loss: 0.17967, in 0.596s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00414, in 0.588s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23659, val loss: 0.23694, in 0.599s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00409, in 0.550s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00402, in 0.606s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15581, val loss: 0.15688, in 0.616s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13485, val loss: 0.13621, in 0.575s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00347, val loss: 0.00453, in 0.600s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16832, val loss: 0.16868, in 0.592s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21988, val loss: 0.22032, in 0.575s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00409, in 0.620s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00322, val loss: 0.00403, in 0.567s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00397, in 0.526s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14719, val loss: 0.14834, in 0.569s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12835, val loss: 0.12989, in 0.599s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00448, in 0.641s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00406, in 0.499s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15872, val loss: 0.15904, in 0.610s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00322, val loss: 0.00394, in 0.558s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20502, val loss: 0.20549, in 0.635s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13916, val loss: 0.14040, in 0.615s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00398, in 0.720s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12247, val loss: 0.12403, in 0.641s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00444, in 0.557s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14936, val loss: 0.14963, in 0.643s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00337, val loss: 0.00402, in 0.680s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19176, val loss: 0.19215, in 0.623s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00318, val loss: 0.00391, in 0.638s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00394, in 0.544s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13213, val loss: 0.13348, in 0.624s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11644, val loss: 0.11797, in 0.601s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00335, val loss: 0.00440, in 0.607s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00395, in 0.606s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14147, val loss: 0.14167, in 0.618s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00387, in 0.590s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17997, val loss: 0.18041, in 0.631s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00308, val loss: 0.00388, in 0.569s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12496, val loss: 0.12634, in 0.565s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11075, val loss: 0.11250, in 0.549s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00330, val loss: 0.00435, in 0.629s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00384, in 0.546s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00391, in 0.590s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13417, val loss: 0.13424, in 0.582s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16949, val loss: 0.16996, in 0.535s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00383, in 0.539s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11885, val loss: 0.12033, in 0.559s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10598, val loss: 0.10785, in 0.583s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00431, in 0.537s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00381, in 0.483s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12752, val loss: 0.12752, in 0.549s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00386, in 0.584s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16001, val loss: 0.16048, in 0.582s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00380, in 0.608s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11358, val loss: 0.11512, in 0.533s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10181, val loss: 0.10373, in 0.538s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00429, in 0.508s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00302, val loss: 0.00376, in 0.534s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00382, in 0.505s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12155, val loss: 0.12154, in 0.549s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15073, val loss: 0.15111, in 0.578s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00297, val loss: 0.00377, in 0.567s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10862, val loss: 0.11029, in 0.564s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09746, val loss: 0.09948, in 0.579s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00319, val loss: 0.00425, in 0.624s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00370, in 0.658s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00313, val loss: 0.00378, in 0.579s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11596, val loss: 0.11599, in 0.576s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14234, val loss: 0.14266, in 0.542s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10326, val loss: 0.10499, in 0.544s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00372, in 0.582s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09356, val loss: 0.09562, in 0.547s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00316, val loss: 0.00422, in 0.456s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00310, val loss: 0.00374, in 0.513s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11082, val loss: 0.11082, in 0.527s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13499, val loss: 0.13528, in 0.536s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00293, val loss: 0.00367, in 0.591s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00368, in 0.522s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09894, val loss: 0.10074, in 0.565s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09023, val loss: 0.09220, in 0.579s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00412, in 0.584s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00372, in 0.570s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00291, val loss: 0.00365, in 0.508s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10622, val loss: 0.10620, in 0.568s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12858, val loss: 0.12883, in 0.550s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09511, val loss: 0.09688, in 0.576s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00365, in 0.612s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08691, val loss: 0.08892, in 0.553s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00406, in 0.574s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.10210, val loss: 0.10211, in 0.593s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00303, val loss: 0.00369, in 0.625s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00287, val loss: 0.00361, in 0.614s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12215, val loss: 0.12232, in 0.619s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09087, val loss: 0.09276, in 0.579s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00360, in 0.594s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00402, in 0.471s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08415, val loss: 0.08612, in 0.549s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09770, val loss: 0.09769, in 0.532s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11679, val loss: 0.11690, in 0.574s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00356, in 0.633s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08731, val loss: 0.08919, in 0.564s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00357, in 0.604s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00399, in 0.479s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08135, val loss: 0.08340, in 0.574s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09367, val loss: 0.09375, in 0.585s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00352, in 0.560s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11140, val loss: 0.11151, in 0.600s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08386, val loss: 0.08589, in 0.587s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00274, val loss: 0.00355, in 0.513s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00396, in 0.555s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07775, val loss: 0.07977, in 0.622s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09044, val loss: 0.09043, in 0.616s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00272, val loss: 0.00353, in 0.564s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10688, val loss: 0.10701, in 0.623s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08045, val loss: 0.08263, in 0.621s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00291, val loss: 0.00393, in 0.563s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07499, val loss: 0.07701, in 0.598s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08689, val loss: 0.08697, in 0.593s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00269, val loss: 0.00351, in 0.536s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10243, val loss: 0.10255, in 0.570s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07679, val loss: 0.07893, in 0.612s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07239, val loss: 0.07445, in 0.622s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08359, val loss: 0.08370, in 0.551s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09781, val loss: 0.09794, in 0.579s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07413, val loss: 0.07632, in 0.623s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06986, val loss: 0.07190, in 0.668s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08063, val loss: 0.08070, in 0.684s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09418, val loss: 0.09437, in 0.695s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07088, val loss: 0.07298, in 0.687s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06769, val loss: 0.06978, in 0.624s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.07778, val loss: 0.07786, in 0.562s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09072, val loss: 0.09093, in 0.548s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06841, val loss: 0.07060, in 0.576s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06500, val loss: 0.06701, in 0.631s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07521, val loss: 0.07530, in 0.641s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08728, val loss: 0.08760, in 0.674s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06572, val loss: 0.06787, in 0.682s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06288, val loss: 0.06490, in 0.618s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07182, val loss: 0.07189, in 0.612s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08420, val loss: 0.08440, in 0.569s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06332, val loss: 0.06551, in 0.598s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06112, val loss: 0.06313, in 0.586s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06926, val loss: 0.06930, in 0.619s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08117, val loss: 0.08135, in 0.621s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06119, val loss: 0.06342, in 0.617s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05936, val loss: 0.06148, in 0.609s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06696, val loss: 0.06701, in 0.661s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07845, val loss: 0.07862, in 0.586s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05915, val loss: 0.06144, in 0.630s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05766, val loss: 0.05986, in 0.604s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06452, val loss: 0.06456, in 0.594s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07579, val loss: 0.07598, in 0.603s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05747, val loss: 0.05967, in 0.549s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05559, val loss: 0.05781, in 0.597s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06254, val loss: 0.06263, in 0.572s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07307, val loss: 0.07325, in 0.576s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05575, val loss: 0.05795, in 0.584s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05412, val loss: 0.05636, in 0.584s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06058, val loss: 0.06066, in 0.628s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07013, val loss: 0.07031, in 0.630s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05422, val loss: 0.05646, in 0.612s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05224, val loss: 0.05460, in 0.643s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06754, val loss: 0.06773, in 0.598s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05890, val loss: 0.05899, in 0.651s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05159, val loss: 0.05372, in 0.604s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05047, val loss: 0.05283, in 0.584s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05713, val loss: 0.05726, in 0.564s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06546, val loss: 0.06570, in 0.586s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04938, val loss: 0.05146, in 0.579s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04893, val loss: 0.05121, in 0.552s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06342, val loss: 0.06364, in 0.593s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05421, val loss: 0.05444, in 0.616s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.05024, in 0.590s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00365, in 0.587s\n",
      "Fit 200 trees in 76.281 s, (6200 total leaves)\n",
      "Time spent computing histograms: 45.533s\n",
      "Time spent finding best splits:  1.422s\n",
      "Time spent applying splits:      9.530s\n",
      "Time spent predicting:           0.574s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04742, val loss: 0.04973, in 0.647s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06131, val loss: 0.06155, in 0.564s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05262, val loss: 0.05286, in 0.565s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04641, val loss: 0.04859, in 0.534s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04524, val loss: 0.04747, in 0.534s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05018, val loss: 0.05044, in 0.508s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05864, val loss: 0.05898, in 0.531s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04488, val loss: 0.04705, in 0.496s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00349, in 0.545s\n",
      "Fit 200 trees in 77.053 s, (6200 total leaves)\n",
      "Time spent computing histograms: 45.752s\n",
      "Time spent finding best splits:  1.373s\n",
      "Time spent applying splits:      9.828s\n",
      "Time spent predicting:           0.568s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04360, val loss: 0.04579, in 0.500s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04804, val loss: 0.04837, in 0.540s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05711, val loss: 0.05742, in 0.557s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04365, val loss: 0.04583, in 0.519s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00389, in 0.578s\n",
      "Fit 200 trees in 77.527 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.234s\n",
      "Time spent finding best splits:  1.457s\n",
      "Time spent applying splits:      9.734s\n",
      "Time spent predicting:           0.608s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04189, val loss: 0.04401, in 0.521s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05434, val loss: 0.05470, in 0.556s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04610, val loss: 0.04651, in 0.602s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04165, val loss: 0.04376, in 0.537s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00265, val loss: 0.00347, in 0.620s\n",
      "Fit 200 trees in 77.827 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.805s\n",
      "Time spent finding best splits:  1.399s\n",
      "Time spent applying splits:      9.610s\n",
      "Time spent predicting:           0.663s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04086, val loss: 0.04297, in 0.539s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05287, val loss: 0.05322, in 0.515s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04484, val loss: 0.04528, in 0.531s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03985, val loss: 0.04189, in 0.551s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03975, val loss: 0.04185, in 0.500s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05090, val loss: 0.05128, in 0.515s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04356, val loss: 0.04399, in 0.543s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03860, val loss: 0.04061, in 0.543s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03882, val loss: 0.04094, in 0.576s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04969, val loss: 0.05006, in 0.500s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03765, val loss: 0.03970, in 0.513s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04226, val loss: 0.04255, in 0.567s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03728, val loss: 0.03939, in 0.465s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04734, val loss: 0.04768, in 0.518s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04056, val loss: 0.04091, in 0.514s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03600, val loss: 0.03799, in 0.564s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03598, val loss: 0.03808, in 0.516s\n",
      "[57/200] 4.419 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04532, val loss: 0.04569, in 0.496s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03532, val loss: 0.03731, in 0.443s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03961, val loss: 0.03997, in 0.553s\n",
      "[53/200] 0.220 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03507, val loss: 0.03716, in 0.548s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04382, val loss: 0.04422, in 0.547s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03431, val loss: 0.03624, in 0.628s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03849, val loss: 0.03886, in 0.555s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61002, val loss: 0.61001, in 0.602s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03408, val loss: 0.03614, in 0.623s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04283, val loss: 0.04319, in 0.612s\n",
      "[51/200] 4.602 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03293, val loss: 0.03481, in 0.608s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03681, val loss: 0.03723, in 0.601s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54181, val loss: 0.54183, in 0.629s\n",
      "[3/200] 0.229 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03272, val loss: 0.03477, in 0.663s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04141, in 0.602s\n",
      "[52/200] 4.679 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03225, val loss: 0.03410, in 0.606s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03541, val loss: 0.03585, in 0.623s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48432, val loss: 0.48437, in 0.501s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/200] 0.216 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61005, val loss: 0.60996, in 0.516s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03172, val loss: 0.03370, in 0.513s\n",
      "[61/200] 4.648 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03960, val loss: 0.03992, in 0.526s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03421, val loss: 0.03471, in 0.518s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03126, val loss: 0.03308, in 0.548s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43589, val loss: 0.43599, in 0.523s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61006, val loss: 0.61001, in 0.481s\n",
      "[2/200] 0.240 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54184, in 0.519s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03100, val loss: 0.03296, in 0.548s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.03878, in 0.510s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03332, val loss: 0.03382, in 0.496s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03027, val loss: 0.03205, in 0.574s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39461, val loss: 0.39460, in 0.567s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.60994, val loss: 0.61000, in 0.514s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54209, val loss: 0.54199, in 0.538s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48455, val loss: 0.48429, in 0.539s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02985, val loss: 0.03183, in 0.625s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03725, val loss: 0.03761, in 0.645s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03219, val loss: 0.03268, in 0.700s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35851, val loss: 0.35856, in 0.681s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03122, in 0.687s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54186, val loss: 0.54202, in 0.671s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48516, val loss: 0.48497, in 0.694s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43634, val loss: 0.43615, in 0.658s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02927, val loss: 0.03125, in 0.784s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03604, val loss: 0.03640, in 0.702s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03098, val loss: 0.03149, in 0.648s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32746, in 0.612s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02847, val loss: 0.03020, in 0.628s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43680, val loss: 0.43655, in 0.575s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48429, val loss: 0.48453, in 0.607s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39477, val loss: 0.39442, in 0.582s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03512, val loss: 0.03550, in 0.580s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.03045, in 0.637s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03008, val loss: 0.03062, in 0.590s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29991, val loss: 0.30007, in 0.568s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43627, val loss: 0.43664, in 0.524s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02748, val loss: 0.02915, in 0.640s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39506, val loss: 0.39475, in 0.611s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35875, val loss: 0.35842, in 0.620s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02748, val loss: 0.02946, in 0.586s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03389, val loss: 0.03427, in 0.607s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39440, val loss: 0.39487, in 0.545s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27605, val loss: 0.27620, in 0.591s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02919, val loss: 0.02971, in 0.600s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35938, val loss: 0.35908, in 0.548s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32688, in 0.538s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02691, val loss: 0.02855, in 0.593s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03284, val loss: 0.03320, in 0.563s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02693, val loss: 0.02888, in 0.579s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35855, val loss: 0.35916, in 0.557s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25499, val loss: 0.25518, in 0.558s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32811, val loss: 0.32770, in 0.515s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30012, val loss: 0.29964, in 0.514s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02859, val loss: 0.02911, in 0.609s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02588, val loss: 0.02747, in 0.584s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03221, val loss: 0.03259, in 0.472s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02651, val loss: 0.02845, in 0.494s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32714, val loss: 0.32781, in 0.479s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23648, val loss: 0.23663, in 0.547s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27633, val loss: 0.27593, in 0.533s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30057, val loss: 0.30016, in 0.555s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02771, val loss: 0.02824, in 0.522s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02530, val loss: 0.02691, in 0.511s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03174, in 0.562s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02575, val loss: 0.02766, in 0.651s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29967, val loss: 0.30046, in 0.580s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25511, val loss: 0.25475, in 0.609s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21977, val loss: 0.21998, in 0.628s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27657, val loss: 0.27609, in 0.599s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02672, val loss: 0.02730, in 0.608s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02604, in 0.598s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03066, val loss: 0.03107, in 0.522s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02488, val loss: 0.02677, in 0.614s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27587, val loss: 0.27667, in 0.593s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23651, val loss: 0.23628, in 0.546s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25557, val loss: 0.25511, in 0.552s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20503, val loss: 0.20532, in 0.577s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02552, in 0.524s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02609, val loss: 0.02668, in 0.587s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.03000, in 0.584s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02630, in 0.552s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25472, val loss: 0.25561, in 0.535s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02558, val loss: 0.02612, in 0.529s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23698, val loss: 0.23652, in 0.582s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22002, val loss: 0.21980, in 0.593s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19166, val loss: 0.19201, in 0.624s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02461, in 0.629s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02889, val loss: 0.02933, in 0.654s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02389, val loss: 0.02577, in 0.595s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23622, val loss: 0.23706, in 0.628s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02542, in 0.520s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22045, val loss: 0.22004, in 0.546s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20499, val loss: 0.20470, in 0.564s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17976, val loss: 0.18018, in 0.512s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02238, val loss: 0.02387, in 0.557s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02837, val loss: 0.02881, in 0.509s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21971, val loss: 0.22059, in 0.532s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02323, val loss: 0.02506, in 0.602s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02490, in 0.540s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19186, val loss: 0.19175, in 0.586s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20566, val loss: 0.20523, in 0.613s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16901, val loss: 0.16939, in 0.625s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02186, val loss: 0.02335, in 0.620s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02741, val loss: 0.02784, in 0.575s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20473, val loss: 0.20560, in 0.580s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02241, val loss: 0.02419, in 0.569s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02363, val loss: 0.02421, in 0.575s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17994, val loss: 0.17973, in 0.565s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19251, val loss: 0.19206, in 0.596s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15915, val loss: 0.15956, in 0.557s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02283, in 0.562s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02658, val loss: 0.02706, in 0.608s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02200, val loss: 0.02374, in 0.545s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19142, val loss: 0.19235, in 0.573s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02304, val loss: 0.02358, in 0.576s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15014, val loss: 0.15061, in 0.540s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16914, val loss: 0.16890, in 0.585s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02081, val loss: 0.02226, in 0.514s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18059, val loss: 0.18008, in 0.575s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02571, val loss: 0.02622, in 0.482s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02337, in 0.529s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17961, val loss: 0.18051, in 0.535s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02048, val loss: 0.02192, in 0.486s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02255, val loss: 0.02310, in 0.609s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14218, val loss: 0.14266, in 0.565s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15952, val loss: 0.15922, in 0.570s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16979, val loss: 0.16931, in 0.547s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02508, val loss: 0.02554, in 0.512s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16880, val loss: 0.16985, in 0.610s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02095, val loss: 0.02271, in 0.631s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02011, val loss: 0.02157, in 0.582s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02199, val loss: 0.02253, in 0.583s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13488, val loss: 0.13540, in 0.552s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15076, val loss: 0.15039, in 0.565s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15983, val loss: 0.15928, in 0.598s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02438, val loss: 0.02481, in 0.624s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02037, val loss: 0.02213, in 0.568s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15893, val loss: 0.15995, in 0.588s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01951, val loss: 0.02091, in 0.523s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12842, val loss: 0.12898, in 0.570s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02139, val loss: 0.02191, in 0.594s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14291, val loss: 0.14262, in 0.608s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15072, val loss: 0.15026, in 0.596s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02362, val loss: 0.02406, in 0.584s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02138, in 0.541s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15024, val loss: 0.15132, in 0.564s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01896, val loss: 0.02032, in 0.581s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02152, in 0.582s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12190, val loss: 0.12253, in 0.589s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13547, val loss: 0.13517, in 0.605s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14290, val loss: 0.14250, in 0.611s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02311, val loss: 0.02355, in 0.567s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14169, val loss: 0.14288, in 0.446s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01977, in 0.425s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01927, val loss: 0.02098, in 0.490s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11636, val loss: 0.11695, in 0.384s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02043, val loss: 0.02091, in 0.400s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12899, val loss: 0.12870, in 0.339s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13553, val loss: 0.13507, in 0.337s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02239, val loss: 0.02286, in 0.416s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01798, val loss: 0.01927, in 0.388s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13435, val loss: 0.13565, in 0.411s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02027, in 0.417s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11133, val loss: 0.11196, in 0.432s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12268, val loss: 0.12244, in 0.404s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12906, val loss: 0.12866, in 0.405s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01878, val loss: 0.02048, in 0.549s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02194, val loss: 0.02239, in 0.294s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12761, val loss: 0.12894, in 0.319s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01883, in 0.341s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10670, val loss: 0.10728, in 0.359s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.02007, in 0.282s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12275, val loss: 0.12241, in 0.336s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11711, val loss: 0.11687, in 0.371s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01934, val loss: 0.01982, in 0.380s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02155, val loss: 0.02198, in 0.346s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12159, val loss: 0.12292, in 0.325s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01709, val loss: 0.01834, in 0.328s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.01941, in 0.318s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10232, val loss: 0.10297, in 0.342s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11167, val loss: 0.11160, in 0.331s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11700, val loss: 0.11675, in 0.345s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01805, val loss: 0.01972, in 0.354s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02092, val loss: 0.02133, in 0.326s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11613, val loss: 0.11749, in 0.354s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01803, in 0.361s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01844, val loss: 0.01896, in 0.337s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09796, val loss: 0.09865, in 0.353s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10691, val loss: 0.10686, in 0.365s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11193, val loss: 0.11165, in 0.363s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01919, in 0.363s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02022, val loss: 0.02064, in 0.328s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11107, val loss: 0.11248, in 0.333s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01749, in 0.318s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01865, in 0.305s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01733, val loss: 0.01892, in 0.281s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09432, val loss: 0.09499, in 0.343s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10718, val loss: 0.10699, in 0.332s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10280, val loss: 0.10267, in 0.360s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.02007, in 0.334s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01590, val loss: 0.01709, in 0.360s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10654, val loss: 0.10799, in 0.368s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01822, in 0.332s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01690, val loss: 0.01848, in 0.360s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10297, val loss: 0.10280, in 0.343s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09068, val loss: 0.09137, in 0.358s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09844, val loss: 0.09827, in 0.343s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01905, val loss: 0.01945, in 0.359s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10170, val loss: 0.10319, in 0.353s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01666, in 0.365s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01759, in 0.354s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01646, val loss: 0.01804, in 0.380s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09916, val loss: 0.09899, in 0.364s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01850, val loss: 0.01888, in 0.323s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08763, val loss: 0.08834, in 0.370s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09434, val loss: 0.09416, in 0.371s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01529, val loss: 0.01646, in 0.329s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09787, val loss: 0.09934, in 0.369s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01667, val loss: 0.01720, in 0.362s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01802, val loss: 0.01839, in 0.318s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09485, val loss: 0.09467, in 0.355s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08464, val loss: 0.08541, in 0.353s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09071, val loss: 0.09051, in 0.345s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01614, val loss: 0.01769, in 0.395s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01492, val loss: 0.01606, in 0.353s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09392, val loss: 0.09542, in 0.355s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01630, val loss: 0.01685, in 0.361s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01794, in 0.365s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08183, val loss: 0.08265, in 0.369s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09135, val loss: 0.09121, in 0.385s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01568, val loss: 0.01720, in 0.369s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08745, val loss: 0.08726, in 0.389s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01571, in 0.360s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09054, val loss: 0.09198, in 0.389s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01656, in 0.358s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01548, val loss: 0.01698, in 0.335s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07852, val loss: 0.07938, in 0.366s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08432, val loss: 0.08409, in 0.352s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08772, val loss: 0.08769, in 0.380s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01754, in 0.525s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01419, val loss: 0.01528, in 0.345s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08709, val loss: 0.08857, in 0.348s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01625, in 0.345s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08129, val loss: 0.08119, in 0.354s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01671, in 0.381s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07618, val loss: 0.07689, in 0.380s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08473, val loss: 0.08472, in 0.366s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01682, val loss: 0.01718, in 0.340s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01389, val loss: 0.01496, in 0.404s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01571, in 0.349s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08439, val loss: 0.08585, in 0.375s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01642, in 0.360s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07792, val loss: 0.07789, in 0.366s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08198, val loss: 0.08185, in 0.371s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07334, val loss: 0.07404, in 0.389s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01491, val loss: 0.01551, in 0.299s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01644, val loss: 0.01680, in 0.437s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01466, in 0.340s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08132, val loss: 0.08290, in 0.370s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01599, in 0.351s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07508, val loss: 0.07506, in 0.374s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07092, val loss: 0.07163, in 0.395s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07840, val loss: 0.07829, in 0.412s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01606, val loss: 0.01643, in 0.374s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01455, val loss: 0.01515, in 0.390s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01330, val loss: 0.01438, in 0.396s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07871, val loss: 0.08034, in 0.379s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07225, val loss: 0.07232, in 0.395s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06864, val loss: 0.06940, in 0.370s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07569, val loss: 0.07564, in 0.374s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01560, in 0.480s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01491, in 0.351s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01614, in 0.390s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01407, in 0.373s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07522, val loss: 0.07696, in 0.396s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06992, val loss: 0.07003, in 0.394s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01533, in 0.377s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07323, val loss: 0.07319, in 0.394s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06648, val loss: 0.06722, in 0.419s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01579, in 0.364s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01461, in 0.422s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01376, in 0.400s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07261, val loss: 0.07432, in 0.435s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01512, in 0.388s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06765, val loss: 0.06776, in 0.437s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01542, in 0.356s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07075, val loss: 0.07075, in 0.446s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06415, val loss: 0.06497, in 0.436s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01369, val loss: 0.01434, in 0.431s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01247, val loss: 0.01349, in 0.456s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06996, val loss: 0.07173, in 0.483s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01335, val loss: 0.01476, in 0.482s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06475, val loss: 0.06499, in 0.509s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01506, in 0.469s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06834, val loss: 0.06829, in 0.484s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01423, in 0.406s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06232, val loss: 0.06315, in 0.505s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01322, in 0.411s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06777, val loss: 0.06955, in 0.406s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01312, val loss: 0.01450, in 0.420s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01380, in 0.386s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01439, val loss: 0.01478, in 0.427s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06275, val loss: 0.06299, in 0.432s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06604, val loss: 0.06607, in 0.435s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05927, val loss: 0.06004, in 0.425s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01297, in 0.398s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06505, val loss: 0.06691, in 0.410s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01298, val loss: 0.01435, in 0.401s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01448, in 0.412s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01287, val loss: 0.01352, in 0.455s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06403, val loss: 0.06405, in 0.434s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05701, val loss: 0.05780, in 0.441s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06048, val loss: 0.06069, in 0.491s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01263, in 0.456s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06276, val loss: 0.06461, in 0.444s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01410, in 0.383s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01381, val loss: 0.01420, in 0.436s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01331, in 0.481s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06203, val loss: 0.06206, in 0.470s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05453, val loss: 0.05535, in 0.467s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05839, val loss: 0.05868, in 0.458s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01140, val loss: 0.01236, in 0.500s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06086, val loss: 0.06268, in 0.500s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01375, in 0.487s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01391, in 0.430s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01236, val loss: 0.01301, in 0.493s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05539, val loss: 0.05570, in 0.489s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06028, val loss: 0.06040, in 0.519s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05311, val loss: 0.05395, in 0.503s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01215, in 0.432s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05909, val loss: 0.06081, in 0.504s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01343, in 0.462s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01357, in 0.497s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01202, val loss: 0.01264, in 0.464s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01199, in 0.483s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05857, val loss: 0.05871, in 0.490s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05186, val loss: 0.05274, in 0.493s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05381, val loss: 0.05418, in 0.526s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01196, val loss: 0.01328, in 0.391s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05753, val loss: 0.05931, in 0.456s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01293, val loss: 0.01331, in 0.472s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01232, in 0.507s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05050, val loss: 0.05138, in 0.452s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01085, val loss: 0.01181, in 0.469s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05673, val loss: 0.05693, in 0.473s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05218, val loss: 0.05261, in 0.475s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01308, in 0.515s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05581, val loss: 0.05764, in 0.499s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01310, in 0.505s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01138, val loss: 0.01199, in 0.490s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01162, in 0.477s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04828, val loss: 0.04917, in 0.493s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05452, val loss: 0.05472, in 0.482s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05079, val loss: 0.05121, in 0.531s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01287, in 0.462s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05414, val loss: 0.05602, in 0.526s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01284, in 0.488s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01151, in 0.414s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04662, val loss: 0.04751, in 0.436s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01116, val loss: 0.01177, in 0.489s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05294, val loss: 0.05322, in 0.482s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04879, val loss: 0.04924, in 0.483s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01132, val loss: 0.01262, in 0.481s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05197, val loss: 0.05379, in 0.443s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01218, val loss: 0.01261, in 0.439s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04470, val loss: 0.04558, in 0.454s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01034, val loss: 0.01128, in 0.537s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05045, val loss: 0.05074, in 0.469s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01143, in 0.504s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04665, val loss: 0.04705, in 0.504s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01244, in 0.482s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05025, val loss: 0.05210, in 0.486s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01195, val loss: 0.01239, in 0.457s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04301, val loss: 0.04392, in 0.472s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01017, val loss: 0.01111, in 0.422s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04892, val loss: 0.04927, in 0.448s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01123, in 0.455s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04503, val loss: 0.04544, in 0.442s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01090, val loss: 0.01220, in 0.457s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04786, val loss: 0.04961, in 0.439s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01218, in 0.470s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01098, in 0.418s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04172, val loss: 0.04263, in 0.427s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04768, val loss: 0.04797, in 0.426s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01044, val loss: 0.01105, in 0.439s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04311, val loss: 0.04349, in 0.414s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01073, val loss: 0.01202, in 0.435s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04657, val loss: 0.04831, in 0.426s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01194, in 0.407s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00983, val loss: 0.01075, in 0.466s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04053, val loss: 0.04138, in 0.465s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01021, val loss: 0.01082, in 0.374s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04560, val loss: 0.04588, in 0.437s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04145, val loss: 0.04185, in 0.439s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01055, val loss: 0.01183, in 0.431s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04452, val loss: 0.04617, in 0.423s\n",
      "[50/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01180, in 0.406s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01001, val loss: 0.01061, in 0.456s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04414, val loss: 0.04442, in 0.455s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03948, val loss: 0.04034, in 0.473s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00961, val loss: 0.01053, in 0.483s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04012, val loss: 0.04052, in 0.428s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01033, val loss: 0.01159, in 0.434s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04318, val loss: 0.04480, in 0.429s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01119, val loss: 0.01159, in 0.384s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04246, val loss: 0.04270, in 0.404s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03820, val loss: 0.03907, in 0.411s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00985, val loss: 0.01044, in 0.440s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.01039, in 0.451s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03916, val loss: 0.03959, in 0.452s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01016, val loss: 0.01143, in 0.473s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04158, val loss: 0.04316, in 0.490s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01098, val loss: 0.01140, in 0.478s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.01029, in 0.378s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04136, val loss: 0.04162, in 0.431s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03728, val loss: 0.03811, in 0.441s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.01025, in 0.410s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03780, val loss: 0.03819, in 0.454s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01103, in 0.424s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03994, val loss: 0.04141, in 0.430s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01073, val loss: 0.01115, in 0.449s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00954, val loss: 0.01015, in 0.405s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04018, val loss: 0.04040, in 0.476s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03588, val loss: 0.03669, in 0.473s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00919, val loss: 0.01009, in 0.464s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01067, val loss: 0.01109, in 0.339s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03643, val loss: 0.03681, in 0.503s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.01086, in 0.471s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03884, val loss: 0.04025, in 0.459s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.01002, in 0.422s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03886, val loss: 0.03907, in 0.404s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00993, in 0.388s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03509, val loss: 0.03591, in 0.466s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01046, val loss: 0.01088, in 0.393s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03519, val loss: 0.03559, in 0.443s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00948, val loss: 0.01070, in 0.478s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03765, val loss: 0.03904, in 0.470s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00921, val loss: 0.00981, in 0.495s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00892, val loss: 0.00981, in 0.428s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03805, in 0.500s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03398, val loss: 0.03482, in 0.462s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01024, val loss: 0.01065, in 0.443s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03401, val loss: 0.03440, in 0.449s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.01053, in 0.414s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03629, val loss: 0.03759, in 0.437s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00911, val loss: 0.00971, in 0.407s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03687, val loss: 0.03713, in 0.419s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00962, in 0.554s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01008, val loss: 0.01048, in 0.421s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03300, val loss: 0.03383, in 0.468s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03313, val loss: 0.03349, in 0.452s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00920, val loss: 0.01040, in 0.474s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03550, val loss: 0.03687, in 0.459s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00891, val loss: 0.00951, in 0.439s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03601, val loss: 0.03631, in 0.491s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03195, val loss: 0.03278, in 0.433s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00945, in 0.490s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00991, val loss: 0.01032, in 0.502s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03199, val loss: 0.03232, in 0.477s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00905, val loss: 0.01024, in 0.403s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03435, val loss: 0.03564, in 0.447s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00877, val loss: 0.00940, in 0.444s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03523, in 0.453s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03111, val loss: 0.03193, in 0.439s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.01019, in 0.404s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00927, in 0.457s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03101, val loss: 0.03131, in 0.431s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.01008, in 0.479s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00870, val loss: 0.00933, in 0.375s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03333, val loss: 0.03457, in 0.449s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03006, val loss: 0.03086, in 0.491s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03425, in 0.527s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00951, val loss: 0.00995, in 0.525s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00823, val loss: 0.00911, in 0.511s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03041, val loss: 0.03073, in 0.497s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00992, in 0.523s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00921, in 0.517s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03211, val loss: 0.03335, in 0.537s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03313, val loss: 0.03342, in 0.415s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03023, in 0.462s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00935, val loss: 0.00979, in 0.497s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00897, in 0.514s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00978, in 0.399s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02956, val loss: 0.02985, in 0.521s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00842, val loss: 0.00908, in 0.466s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03135, val loss: 0.03264, in 0.587s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02848, val loss: 0.02922, in 0.522s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03246, val loss: 0.03277, in 0.562s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00797, val loss: 0.00886, in 0.446s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00918, val loss: 0.00962, in 0.507s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00843, val loss: 0.00965, in 0.501s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00827, val loss: 0.00892, in 0.464s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02847, val loss: 0.02874, in 0.520s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03024, val loss: 0.03147, in 0.510s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02777, val loss: 0.02849, in 0.459s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03177, val loss: 0.03209, in 0.464s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00871, in 0.433s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00904, val loss: 0.00950, in 0.466s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00954, in 0.456s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00881, in 0.500s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02751, val loss: 0.02777, in 0.523s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02934, val loss: 0.03059, in 0.442s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02692, val loss: 0.02761, in 0.491s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03130, in 0.517s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00889, val loss: 0.00935, in 0.453s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00855, in 0.517s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00940, in 0.427s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00873, in 0.427s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02672, val loss: 0.02695, in 0.515s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02851, val loss: 0.02976, in 0.544s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00925, in 0.483s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00866, in 0.443s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03036, val loss: 0.03070, in 0.558s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02628, val loss: 0.02698, in 0.610s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00927, in 0.572s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00750, val loss: 0.00839, in 0.590s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02606, in 0.522s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02769, val loss: 0.02890, in 0.485s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00865, val loss: 0.00910, in 0.499s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00784, val loss: 0.00850, in 0.465s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00919, in 0.424s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00828, in 0.482s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02928, val loss: 0.02962, in 0.525s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02534, val loss: 0.02598, in 0.518s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02534, in 0.437s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02688, val loss: 0.02806, in 0.472s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00853, val loss: 0.00899, in 0.499s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00773, val loss: 0.00839, in 0.507s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00786, val loss: 0.00908, in 0.505s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00731, val loss: 0.00819, in 0.500s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02871, val loss: 0.02905, in 0.524s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02447, val loss: 0.02507, in 0.538s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02465, in 0.509s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02737, in 0.495s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00841, val loss: 0.00888, in 0.499s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00775, val loss: 0.00897, in 0.476s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00822, in 0.551s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02801, val loss: 0.02841, in 0.476s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02403, val loss: 0.02463, in 0.472s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00808, in 0.564s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02385, val loss: 0.02407, in 0.529s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02667, in 0.490s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00885, in 0.517s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00872, in 0.644s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02708, val loss: 0.02745, in 0.601s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02357, val loss: 0.02420, in 0.592s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00743, val loss: 0.00809, in 0.689s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00708, val loss: 0.00796, in 0.639s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02313, val loss: 0.02334, in 0.567s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02498, val loss: 0.02614, in 0.568s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00752, val loss: 0.00875, in 0.484s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00812, val loss: 0.00861, in 0.478s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02289, val loss: 0.02352, in 0.533s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00735, val loss: 0.00800, in 0.462s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02644, val loss: 0.02679, in 0.542s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00696, val loss: 0.00783, in 0.544s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02429, val loss: 0.02545, in 0.462s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02255, val loss: 0.02275, in 0.570s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00739, val loss: 0.00861, in 0.567s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00851, in 0.471s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00721, val loss: 0.00787, in 0.530s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02219, val loss: 0.02282, in 0.555s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02560, val loss: 0.02595, in 0.555s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00773, in 0.469s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02381, val loss: 0.02499, in 0.560s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02200, val loss: 0.02220, in 0.565s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00791, val loss: 0.00841, in 0.498s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00852, in 0.512s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02164, val loss: 0.02229, in 0.514s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00706, val loss: 0.00771, in 0.552s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02469, val loss: 0.02501, in 0.529s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00674, val loss: 0.00763, in 0.550s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02319, val loss: 0.02435, in 0.553s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02139, val loss: 0.02155, in 0.656s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00719, val loss: 0.00842, in 0.573s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00779, val loss: 0.00829, in 0.620s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02119, val loss: 0.02178, in 0.504s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00691, val loss: 0.00754, in 0.568s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02406, val loss: 0.02436, in 0.583s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00662, val loss: 0.00750, in 0.623s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02360, in 0.576s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02073, val loss: 0.02087, in 0.529s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00771, val loss: 0.00821, in 0.511s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00711, val loss: 0.00832, in 0.555s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02074, val loss: 0.02133, in 0.577s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00679, val loss: 0.00744, in 0.596s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02358, val loss: 0.02388, in 0.611s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00650, val loss: 0.00737, in 0.559s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02279, in 0.560s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02014, val loss: 0.02028, in 0.575s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00820, in 0.597s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00806, in 0.623s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02027, val loss: 0.02086, in 0.512s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00665, val loss: 0.00730, in 0.557s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02301, val loss: 0.02333, in 0.527s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00727, in 0.560s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02115, val loss: 0.02222, in 0.601s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01971, val loss: 0.01988, in 0.590s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00688, val loss: 0.00809, in 0.558s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00791, in 0.593s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01985, val loss: 0.02042, in 0.607s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02242, val loss: 0.02276, in 0.570s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00656, val loss: 0.00721, in 0.597s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00627, val loss: 0.00715, in 0.611s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02076, val loss: 0.02185, in 0.627s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01923, val loss: 0.01939, in 0.543s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00729, val loss: 0.00781, in 0.566s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00675, val loss: 0.00792, in 0.644s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01935, val loss: 0.01991, in 0.580s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00647, val loss: 0.00711, in 0.513s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02204, in 0.556s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00619, val loss: 0.00707, in 0.492s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02027, val loss: 0.02137, in 0.517s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01876, val loss: 0.01891, in 0.538s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00664, val loss: 0.00781, in 0.494s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00768, in 0.599s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01953, in 0.634s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00700, in 0.515s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02174, in 0.662s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00631, val loss: 0.00694, in 0.686s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01981, val loss: 0.02093, in 0.618s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01835, val loss: 0.01847, in 0.614s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00654, val loss: 0.00772, in 0.591s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00704, val loss: 0.00757, in 0.651s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00691, in 0.555s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01906, in 0.569s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02087, val loss: 0.02127, in 0.542s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00622, val loss: 0.00686, in 0.652s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01933, val loss: 0.02042, in 0.604s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01779, val loss: 0.01791, in 0.607s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00757, in 0.584s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00596, val loss: 0.00683, in 0.563s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00696, val loss: 0.00749, in 0.600s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01843, in 0.565s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02030, val loss: 0.02071, in 0.542s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00672, in 0.484s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01882, val loss: 0.01988, in 0.518s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01744, val loss: 0.01757, in 0.578s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00633, val loss: 0.00749, in 0.531s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01820, in 0.451s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00588, val loss: 0.00673, in 0.511s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00679, val loss: 0.00732, in 0.524s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02006, in 0.531s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00600, val loss: 0.00663, in 0.597s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01944, in 0.507s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01718, in 0.521s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00741, in 0.534s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01709, val loss: 0.01767, in 0.518s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00667, in 0.479s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01941, val loss: 0.01980, in 0.393s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00668, val loss: 0.00722, in 0.546s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00591, val loss: 0.00655, in 0.512s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01880, in 0.589s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01680, in 0.502s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00614, val loss: 0.00732, in 0.586s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01679, val loss: 0.01734, in 0.523s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01937, in 0.533s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00660, in 0.633s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00710, in 0.556s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01751, val loss: 0.01850, in 0.563s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00644, in 0.672s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01642, in 0.666s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01638, val loss: 0.01691, in 0.660s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00714, in 0.672s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01842, val loss: 0.01883, in 0.650s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00651, in 0.577s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00645, val loss: 0.00698, in 0.608s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00569, val loss: 0.00632, in 0.606s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01715, val loss: 0.01814, in 0.646s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01611, in 0.564s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00703, in 0.510s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00636, val loss: 0.00689, in 0.473s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00553, val loss: 0.00639, in 0.528s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01593, val loss: 0.01646, in 0.567s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01806, val loss: 0.01848, in 0.611s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00561, val loss: 0.00624, in 0.528s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01670, val loss: 0.01769, in 0.533s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00695, in 0.438s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01561, val loss: 0.01574, in 0.534s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01773, val loss: 0.01814, in 0.455s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01562, val loss: 0.01617, in 0.583s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00544, val loss: 0.00631, in 0.589s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00627, val loss: 0.00680, in 0.614s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00552, val loss: 0.00613, in 0.514s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01719, in 0.560s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01522, val loss: 0.01539, in 0.542s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00568, val loss: 0.00684, in 0.598s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01544, val loss: 0.01598, in 0.440s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01768, in 0.522s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00536, val loss: 0.00623, in 0.549s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00668, in 0.600s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00544, val loss: 0.00605, in 0.480s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00558, val loss: 0.00674, in 0.495s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01494, val loss: 0.01511, in 0.613s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01675, in 0.639s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01698, val loss: 0.01740, in 0.572s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01500, val loss: 0.01554, in 0.606s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00614, in 0.564s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00603, val loss: 0.00659, in 0.609s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00536, val loss: 0.00598, in 0.578s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00665, in 0.479s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01662, val loss: 0.01705, in 0.551s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01468, val loss: 0.01486, in 0.618s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01521, in 0.554s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01640, in 0.636s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00519, val loss: 0.00606, in 0.574s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00597, val loss: 0.00653, in 0.536s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00525, val loss: 0.00587, in 0.544s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00544, val loss: 0.00657, in 0.548s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01443, val loss: 0.01461, in 0.530s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01637, val loss: 0.01679, in 0.548s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01442, val loss: 0.01496, in 0.575s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00508, val loss: 0.00594, in 0.545s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01611, in 0.628s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00589, val loss: 0.00646, in 0.592s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00516, val loss: 0.00576, in 0.516s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00651, in 0.560s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01601, val loss: 0.01643, in 0.526s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01420, val loss: 0.01440, in 0.628s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01462, in 0.573s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01580, in 0.532s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00582, in 0.594s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00638, in 0.535s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00508, val loss: 0.00568, in 0.594s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00533, val loss: 0.00646, in 0.491s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01553, val loss: 0.01597, in 0.549s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01407, in 0.548s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01384, val loss: 0.01438, in 0.554s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01545, in 0.537s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00631, in 0.552s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00574, in 0.613s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00501, val loss: 0.00560, in 0.490s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00525, val loss: 0.00639, in 0.572s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01553, in 0.609s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01355, val loss: 0.01410, in 0.576s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01522, in 0.594s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01373, in 0.619s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00554, in 0.526s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00482, val loss: 0.00567, in 0.605s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00565, val loss: 0.00622, in 0.630s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00518, val loss: 0.00631, in 0.654s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01522, in 0.594s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01494, in 0.571s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00547, in 0.508s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01322, val loss: 0.01345, in 0.584s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00557, val loss: 0.00615, in 0.496s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01373, in 0.718s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00474, val loss: 0.00557, in 0.697s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00509, val loss: 0.00622, in 0.552s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01464, val loss: 0.01505, in 0.490s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01477, in 0.496s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00541, in 0.558s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01310, val loss: 0.01363, in 0.455s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01311, in 0.666s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00549, val loss: 0.00608, in 0.665s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00501, val loss: 0.00614, in 0.486s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00550, in 0.629s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01431, val loss: 0.01474, in 0.620s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01342, val loss: 0.01432, in 0.681s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00533, in 0.728s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01328, in 0.735s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01288, in 0.636s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00541, val loss: 0.00600, in 0.711s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00494, val loss: 0.00607, in 0.736s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00542, in 0.635s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01439, in 0.742s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01407, in 0.687s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01309, in 0.685s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00527, in 0.703s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01261, in 0.722s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00601, in 0.629s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00451, val loss: 0.00533, in 0.636s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00534, val loss: 0.00594, in 0.713s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01386, in 0.580s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01372, val loss: 0.01416, in 0.661s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01245, val loss: 0.01297, in 0.555s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00520, in 0.563s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00596, in 0.554s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01238, in 0.660s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00527, in 0.584s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00587, in 0.641s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01369, in 0.472s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00517, in 0.511s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01343, val loss: 0.01386, in 0.696s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01218, val loss: 0.01269, in 0.667s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00437, val loss: 0.00519, in 0.597s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00475, val loss: 0.00588, in 0.669s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00584, in 0.532s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01214, in 0.663s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01346, in 0.616s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00450, val loss: 0.00507, in 0.679s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01308, val loss: 0.01349, in 0.670s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01197, val loss: 0.01249, in 0.618s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00512, in 0.584s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00471, val loss: 0.00584, in 0.582s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00516, val loss: 0.00576, in 0.584s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01161, val loss: 0.01185, in 0.602s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01317, in 0.606s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01281, val loss: 0.01322, in 0.610s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00443, val loss: 0.00500, in 0.701s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01229, in 0.630s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00507, in 0.596s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00507, val loss: 0.00567, in 0.595s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01143, val loss: 0.01165, in 0.621s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01303, in 0.495s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00575, in 0.697s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00494, in 0.565s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01154, val loss: 0.01208, in 0.553s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01299, in 0.618s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00419, val loss: 0.00501, in 0.657s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00499, val loss: 0.00560, in 0.693s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01144, in 0.642s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01269, in 0.642s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00456, val loss: 0.00567, in 0.734s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01146, val loss: 0.01201, in 0.493s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00433, val loss: 0.00487, in 0.556s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01270, in 0.593s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00495, in 0.624s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00492, val loss: 0.00553, in 0.622s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01092, val loss: 0.01116, in 0.643s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01156, val loss: 0.01240, in 0.607s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00450, val loss: 0.00561, in 0.612s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00485, in 0.484s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01180, in 0.625s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01244, in 0.653s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00488, in 0.616s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00539, in 0.589s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01132, val loss: 0.01214, in 0.630s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01093, in 0.637s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00555, in 0.674s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00422, val loss: 0.00477, in 0.655s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01160, in 0.677s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01180, val loss: 0.01220, in 0.601s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00482, in 0.583s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01050, val loss: 0.01075, in 0.545s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01109, val loss: 0.01191, in 0.572s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00472, val loss: 0.00532, in 0.673s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00432, val loss: 0.00540, in 0.532s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00471, in 0.526s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01139, in 0.613s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01200, in 0.627s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00477, in 0.572s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01054, in 0.542s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01171, in 0.606s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00466, val loss: 0.00523, in 0.584s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00427, val loss: 0.00534, in 0.557s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00411, val loss: 0.00465, in 0.562s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01063, val loss: 0.01120, in 0.534s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00391, val loss: 0.00471, in 0.453s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01139, val loss: 0.01181, in 0.579s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01008, val loss: 0.01036, in 0.645s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01067, val loss: 0.01150, in 0.574s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00519, in 0.578s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00420, val loss: 0.00527, in 0.604s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00457, in 0.569s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01045, val loss: 0.01103, in 0.545s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00386, val loss: 0.00465, in 0.588s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01114, val loss: 0.01158, in 0.653s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00512, in 0.532s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00984, val loss: 0.01011, in 0.565s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01053, val loss: 0.01136, in 0.580s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00452, in 0.583s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00519, in 0.674s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01030, val loss: 0.01089, in 0.564s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00381, val loss: 0.00460, in 0.625s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01134, in 0.536s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01113, in 0.535s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.00996, in 0.573s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00507, in 0.596s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00394, val loss: 0.00448, in 0.490s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00514, in 0.477s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01009, val loss: 0.01067, in 0.596s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00455, in 0.491s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01071, val loss: 0.01115, in 0.545s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01095, in 0.520s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00404, val loss: 0.00510, in 0.479s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00979, in 0.603s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00441, val loss: 0.00502, in 0.615s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00443, in 0.612s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00985, val loss: 0.01043, in 0.647s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00444, in 0.597s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01051, val loss: 0.01096, in 0.538s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00942, val loss: 0.00972, in 0.464s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00990, val loss: 0.01066, in 0.640s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00435, val loss: 0.00495, in 0.648s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00504, in 0.697s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00437, in 0.640s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00959, val loss: 0.01017, in 0.642s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01035, val loss: 0.01082, in 0.654s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00438, in 0.735s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00921, val loss: 0.00951, in 0.697s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00393, val loss: 0.00499, in 0.496s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00970, val loss: 0.01046, in 0.703s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00488, in 0.598s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00432, in 0.611s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00943, val loss: 0.01002, in 0.602s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00434, in 0.552s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01019, val loss: 0.01067, in 0.621s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00934, in 0.508s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00495, in 0.577s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00372, val loss: 0.00427, in 0.509s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00423, val loss: 0.00484, in 0.623s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.01022, in 0.652s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00927, in 0.473s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01054, in 0.539s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00926, val loss: 0.00986, in 0.686s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00428, in 0.634s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00369, val loss: 0.00425, in 0.490s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00479, in 0.562s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00477, in 0.537s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00931, val loss: 0.01006, in 0.651s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00990, val loss: 0.01040, in 0.527s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00911, in 0.578s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00365, val loss: 0.00421, in 0.515s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00419, in 0.593s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00972, in 0.654s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00473, in 0.644s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00472, in 0.533s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00913, val loss: 0.00988, in 0.618s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.01028, in 0.540s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00417, in 0.480s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00863, val loss: 0.00895, in 0.625s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00415, in 0.485s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00405, val loss: 0.00468, in 0.528s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00951, in 0.589s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00464, in 0.556s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00899, val loss: 0.00974, in 0.484s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.01020, in 0.485s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00359, val loss: 0.00413, in 0.505s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00888, in 0.486s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00411, in 0.515s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00936, in 0.485s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00462, in 0.550s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00358, val loss: 0.00458, in 0.629s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00883, val loss: 0.00957, in 0.506s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00952, val loss: 0.01003, in 0.556s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00408, in 0.527s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00870, in 0.618s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00406, in 0.641s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00861, val loss: 0.00922, in 0.626s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00395, val loss: 0.00456, in 0.582s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00451, in 0.597s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00945, in 0.606s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00992, in 0.514s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00403, in 0.592s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00829, val loss: 0.00862, in 0.505s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00391, val loss: 0.00452, in 0.463s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00843, val loss: 0.00906, in 0.487s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00400, in 0.641s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00347, val loss: 0.00447, in 0.579s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00932, in 0.618s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00925, val loss: 0.00976, in 0.630s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00849, in 0.521s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00394, in 0.574s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00449, in 0.559s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00888, in 0.589s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00396, in 0.603s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00443, in 0.576s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00919, in 0.547s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00908, val loss: 0.00959, in 0.661s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00799, val loss: 0.00834, in 0.715s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00388, in 0.703s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00381, val loss: 0.00443, in 0.638s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00867, in 0.625s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00393, in 0.685s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00434, in 0.573s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00904, in 0.587s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00942, in 0.579s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00384, in 0.506s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00819, in 0.551s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00438, in 0.516s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00791, val loss: 0.00853, in 0.523s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00312, val loss: 0.00388, in 0.608s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00331, val loss: 0.00429, in 0.566s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00891, in 0.520s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00926, in 0.512s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00801, in 0.574s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00433, in 0.541s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00380, in 0.649s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00780, val loss: 0.00842, in 0.576s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00810, val loss: 0.00882, in 0.476s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00421, in 0.542s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00307, val loss: 0.00382, in 0.592s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00916, in 0.546s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00375, in 0.507s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00366, val loss: 0.00427, in 0.530s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00769, val loss: 0.00831, in 0.477s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00749, val loss: 0.00789, in 0.632s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00419, in 0.579s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00377, in 0.569s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00869, in 0.695s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00850, val loss: 0.00903, in 0.670s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00759, val loss: 0.00822, in 0.527s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00372, in 0.548s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00423, in 0.556s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00738, val loss: 0.00778, in 0.650s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00299, val loss: 0.00375, in 0.506s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00415, in 0.560s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00784, val loss: 0.00857, in 0.578s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00808, in 0.531s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00889, in 0.563s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00367, in 0.596s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00418, in 0.669s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00725, val loss: 0.00764, in 0.548s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00296, val loss: 0.00370, in 0.479s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00409, in 0.522s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00774, val loss: 0.00849, in 0.572s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00803, in 0.477s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00825, val loss: 0.00880, in 0.549s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00308, val loss: 0.00363, in 0.564s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00414, in 0.490s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00712, val loss: 0.00752, in 0.502s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00309, val loss: 0.00405, in 0.406s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00292, val loss: 0.00367, in 0.482s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00757, val loss: 0.00831, in 0.412s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00791, in 0.394s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00868, in 0.308s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00708, val loss: 0.00748, in 0.289s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00305, val loss: 0.00360, in 0.447s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00410, in 0.486s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00401, in 0.467s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00364, in 0.504s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00745, val loss: 0.00820, in 0.508s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00717, val loss: 0.00779, in 0.477s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00856, in 0.545s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00736, in 0.481s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00352, in 0.398s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00287, val loss: 0.00362, in 0.270s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00406, in 0.414s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00302, val loss: 0.00399, in 0.373s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00731, val loss: 0.00804, in 0.323s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00707, val loss: 0.00769, in 0.327s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00792, val loss: 0.00848, in 0.297s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00348, in 0.273s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00685, val loss: 0.00727, in 0.318s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00404, in 0.266s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00359, in 0.321s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00394, in 0.313s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00793, in 0.271s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00691, val loss: 0.00753, in 0.270s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00281, val loss: 0.00356, in 0.244s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00778, val loss: 0.00835, in 0.340s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00342, in 0.331s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00675, val loss: 0.00717, in 0.313s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00400, in 0.319s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00392, in 0.273s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00681, val loss: 0.00743, in 0.291s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00707, val loss: 0.00780, in 0.351s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00279, val loss: 0.00354, in 0.319s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00661, val loss: 0.00704, in 0.299s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00767, val loss: 0.00824, in 0.336s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00339, in 0.333s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00293, val loss: 0.00389, in 0.326s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00332, val loss: 0.00396, in 0.331s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00670, val loss: 0.00733, in 0.290s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00696, val loss: 0.00769, in 0.312s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00277, val loss: 0.00353, in 0.260s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00758, val loss: 0.00814, in 0.329s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00647, val loss: 0.00690, in 0.353s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00283, val loss: 0.00336, in 0.352s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00328, val loss: 0.00393, in 0.340s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00387, in 0.352s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00661, val loss: 0.00724, in 0.386s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00274, val loss: 0.00349, in 0.313s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00687, val loss: 0.00761, in 0.411s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00334, in 0.316s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00803, in 0.352s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00635, val loss: 0.00678, in 0.355s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00377, in 0.358s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00715, in 0.285s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00388, in 0.401s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00347, in 0.373s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00753, in 0.369s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00330, in 0.323s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00792, in 0.324s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00373, in 0.304s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00623, val loss: 0.00666, in 0.383s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00646, val loss: 0.00708, in 0.312s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00383, in 0.335s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00666, val loss: 0.00739, in 0.323s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00269, val loss: 0.00344, in 0.405s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00781, in 0.335s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00325, in 0.369s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00656, in 0.333s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00371, in 0.417s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00314, val loss: 0.00379, in 0.358s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00636, val loss: 0.00698, in 0.417s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00342, in 0.290s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00727, in 0.392s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00605, val loss: 0.00649, in 0.306s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00713, val loss: 0.00769, in 0.391s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00322, in 0.378s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00374, in 0.314s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00689, in 0.347s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00271, val loss: 0.00365, in 0.416s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00336, in 0.360s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00643, val loss: 0.00716, in 0.327s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00595, val loss: 0.00640, in 0.305s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00318, in 0.331s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00702, val loss: 0.00760, in 0.365s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00305, val loss: 0.00370, in 0.318s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00616, val loss: 0.00681, in 0.373s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00265, val loss: 0.00356, in 0.342s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00258, val loss: 0.00333, in 0.383s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00585, val loss: 0.00632, in 0.334s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00633, val loss: 0.00706, in 0.352s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00696, val loss: 0.00754, in 0.278s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00315, in 0.324s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00303, val loss: 0.00367, in 0.337s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00608, val loss: 0.00673, in 0.315s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00353, in 0.368s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00329, in 0.338s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00623, in 0.368s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00624, val loss: 0.00698, in 0.389s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00683, val loss: 0.00741, in 0.396s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00312, in 0.371s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00299, val loss: 0.00364, in 0.332s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00663, in 0.347s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00616, val loss: 0.00691, in 0.282s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00252, val loss: 0.00326, in 0.345s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00568, val loss: 0.00615, in 0.338s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00361, in 0.302s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00257, val loss: 0.00310, in 0.346s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00672, val loss: 0.00731, in 0.388s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00592, val loss: 0.00657, in 0.318s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00609, val loss: 0.00683, in 0.401s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00358, in 0.382s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00248, val loss: 0.00322, in 0.450s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00556, val loss: 0.00603, in 0.445s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00254, val loss: 0.00307, in 0.403s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00657, val loss: 0.00717, in 0.430s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00580, val loss: 0.00645, in 0.442s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00671, in 0.401s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00355, in 0.373s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00548, val loss: 0.00596, in 0.380s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00708, in 0.367s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00570, val loss: 0.00635, in 0.370s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00661, in 0.272s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00350, in 0.320s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00539, val loss: 0.00587, in 0.310s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00636, val loss: 0.00695, in 0.354s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00562, val loss: 0.00629, in 0.298s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00651, in 0.332s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00347, in 0.310s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00578, in 0.337s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00628, val loss: 0.00688, in 0.324s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00621, in 0.358s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00644, in 0.347s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00344, in 0.373s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00522, val loss: 0.00571, in 0.377s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00618, val loss: 0.00678, in 0.353s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00547, val loss: 0.00614, in 0.334s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00636, in 0.376s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00341, in 0.361s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00514, val loss: 0.00563, in 0.373s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00671, in 0.355s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00540, val loss: 0.00607, in 0.388s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00629, in 0.395s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00505, val loss: 0.00555, in 0.394s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00605, val loss: 0.00665, in 0.349s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00531, val loss: 0.00599, in 0.390s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00547, val loss: 0.00622, in 0.322s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00546, in 0.330s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00594, val loss: 0.00654, in 0.351s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00592, in 0.308s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00539, val loss: 0.00613, in 0.319s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00587, val loss: 0.00648, in 0.274s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00487, val loss: 0.00536, in 0.333s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00517, val loss: 0.00587, in 0.315s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00532, val loss: 0.00607, in 0.333s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00578, val loss: 0.00639, in 0.340s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00530, in 0.344s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00580, in 0.337s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00525, val loss: 0.00600, in 0.367s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00632, in 0.306s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00525, in 0.361s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00574, in 0.373s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00517, val loss: 0.00592, in 0.363s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00564, val loss: 0.00625, in 0.338s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00466, val loss: 0.00517, in 0.360s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00569, in 0.304s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00510, val loss: 0.00585, in 0.357s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00554, val loss: 0.00616, in 0.384s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00459, val loss: 0.00511, in 0.367s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00490, val loss: 0.00563, in 0.370s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00505, val loss: 0.00580, in 0.310s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00546, val loss: 0.00609, in 0.326s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00454, val loss: 0.00505, in 0.339s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00482, val loss: 0.00555, in 0.364s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00572, in 0.293s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00542, val loss: 0.00606, in 0.274s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00449, val loss: 0.00501, in 0.290s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00475, val loss: 0.00548, in 0.304s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00488, val loss: 0.00563, in 0.354s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00533, val loss: 0.00597, in 0.394s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00258, val loss: 0.00349, in 0.340s\n",
      "Fit 200 trees in 108.811 s, (6200 total leaves)\n",
      "Time spent computing histograms: 65.233s\n",
      "Time spent finding best splits:  2.147s\n",
      "Time spent applying splits:      12.874s\n",
      "Time spent predicting:           0.869s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00495, in 0.340s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00542, in 0.314s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00481, val loss: 0.00555, in 0.332s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00526, val loss: 0.00589, in 0.322s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00491, in 0.304s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00537, in 0.343s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00476, val loss: 0.00549, in 0.300s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00583, in 0.331s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00320, in 0.341s\n",
      "Fit 200 trees in 108.675 s, (6200 total leaves)\n",
      "Time spent computing histograms: 65.242s\n",
      "Time spent finding best splits:  1.686s\n",
      "Time spent applying splits:      13.221s\n",
      "Time spent predicting:           1.159s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00485, in 0.304s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00250, val loss: 0.00302, in 0.384s\n",
      "Fit 200 trees in 108.170 s, (6200 total leaves)\n",
      "Time spent computing histograms: 64.690s\n",
      "Time spent finding best splits:  1.972s\n",
      "Time spent applying splits:      13.047s\n",
      "Time spent predicting:           1.034s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00530, in 0.334s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00541, in 0.328s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00578, in 0.380s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00479, in 0.389s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00450, val loss: 0.00525, in 0.484s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00459, val loss: 0.00530, in 0.481s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00506, val loss: 0.00571, in 0.383s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00418, val loss: 0.00473, in 0.412s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00518, in 0.394s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00525, in 0.376s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00500, val loss: 0.00565, in 0.370s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00412, val loss: 0.00467, in 0.385s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00513, in 0.388s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00448, val loss: 0.00520, in 0.382s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00491, val loss: 0.00556, in 0.383s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00406, val loss: 0.00463, in 0.353s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00503, in 0.339s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00515, in 0.404s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00485, val loss: 0.00548, in 0.440s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00458, in 0.409s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00422, val loss: 0.00496, in 0.365s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00511, in 0.291s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00338, in 0.390s\n",
      "Fit 200 trees in 108.176 s, (6199 total leaves)\n",
      "Time spent computing histograms: 65.013s\n",
      "Time spent finding best splits:  1.777s\n",
      "Time spent applying splits:      12.479s\n",
      "Time spent predicting:           0.961s\n",
      "Binning 0.119 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00542, in 0.331s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00397, val loss: 0.00454, in 0.341s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00490, in 0.343s\n",
      "[169/200] 3.133 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00433, val loss: 0.00505, in 0.407s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00449, in 0.355s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00536, in 0.431s\n",
      "[166/200] 0.194 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00484, in 0.383s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00502, in 0.385s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00531, in 0.304s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00444, in 0.380s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61008, val loss: 0.61009, in 0.329s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00475, in 0.366s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00498, in 0.277s\n",
      "[167/200] 3.244 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00439, in 0.271s\n",
      "[168/200] 3.225 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00461, val loss: 0.00524, in 0.309s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54204, val loss: 0.54216, in 0.317s\n",
      "[3/200] 0.142 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.146 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00485, in 0.315s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00396, val loss: 0.00469, in 0.360s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00519, in 0.287s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00376, val loss: 0.00434, in 0.365s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48465, val loss: 0.48476, in 0.299s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61012, val loss: 0.61020, in 0.295s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61006, val loss: 0.61010, in 0.292s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00408, val loss: 0.00480, in 0.306s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00464, in 0.333s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00449, val loss: 0.00512, in 0.346s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00430, in 0.334s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43612, val loss: 0.43637, in 0.350s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54199, in 0.381s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54203, val loss: 0.54204, in 0.377s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00459, in 0.322s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00475, in 0.388s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00507, in 0.379s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00367, val loss: 0.00425, in 0.404s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39476, val loss: 0.39503, in 0.374s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48464, val loss: 0.48459, in 0.339s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48467, val loss: 0.48468, in 0.328s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00471, in 0.307s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00455, in 0.333s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00439, val loss: 0.00501, in 0.275s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00362, val loss: 0.00420, in 0.268s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35880, val loss: 0.35912, in 0.302s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43621, val loss: 0.43617, in 0.300s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43613, val loss: 0.43627, in 0.307s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00464, in 0.344s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00375, val loss: 0.00448, in 0.340s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00497, in 0.311s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00358, val loss: 0.00417, in 0.354s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32744, val loss: 0.32784, in 0.330s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39468, val loss: 0.39468, in 0.335s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39469, val loss: 0.39482, in 0.317s\n",
      "[6/200] 2.987 s\n",
      "Binning 0.013 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00460, in 0.311s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00445, in 0.324s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00428, val loss: 0.00492, in 0.328s\n",
      "[174/200] 0.134 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00412, in 0.340s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30022, val loss: 0.30065, in 0.329s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35864, val loss: 0.35865, in 0.330s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35864, val loss: 0.35885, in 0.340s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00365, val loss: 0.00440, in 0.294s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00457, in 0.346s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00423, val loss: 0.00486, in 0.303s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00409, in 0.271s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.60938, val loss: 0.60934, in 0.313s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27639, val loss: 0.27685, in 0.349s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32727, val loss: 0.32732, in 0.339s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32749, val loss: 0.32772, in 0.330s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00435, in 0.346s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00379, val loss: 0.00451, in 0.361s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00479, in 0.348s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54059, val loss: 0.54069, in 0.340s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00404, in 0.344s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30038, val loss: 0.30037, in 0.308s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25515, val loss: 0.25567, in 0.320s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30043, val loss: 0.30073, in 0.280s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00449, in 0.266s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00432, in 0.320s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00474, in 0.304s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48335, val loss: 0.48339, in 0.276s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00339, val loss: 0.00400, in 0.315s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23663, val loss: 0.23728, in 0.283s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27652, val loss: 0.27661, in 0.303s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27647, val loss: 0.27690, in 0.293s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00445, in 0.285s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00470, in 0.255s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00428, in 0.299s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43451, val loss: 0.43465, in 0.285s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00394, in 0.307s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22006, val loss: 0.22074, in 0.277s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25527, val loss: 0.25542, in 0.282s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25552, val loss: 0.25615, in 0.287s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00366, val loss: 0.00439, in 0.286s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00420, in 0.267s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00465, in 0.299s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39300, val loss: 0.39331, in 0.268s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00329, val loss: 0.00389, in 0.254s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23644, val loss: 0.23659, in 0.290s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20522, val loss: 0.20597, in 0.311s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23712, val loss: 0.23785, in 0.290s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00434, in 0.297s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00341, val loss: 0.00416, in 0.309s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00397, val loss: 0.00461, in 0.329s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35739, val loss: 0.35773, in 0.285s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00325, val loss: 0.00385, in 0.285s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21968, val loss: 0.21988, in 0.310s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22014, val loss: 0.22089, in 0.309s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19196, val loss: 0.19274, in 0.317s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00337, val loss: 0.00413, in 0.262s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00430, in 0.297s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32553, val loss: 0.32590, in 0.263s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00455, in 0.314s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00382, in 0.311s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00408, in 0.258s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20501, val loss: 0.20526, in 0.305s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17987, val loss: 0.18076, in 0.302s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20512, val loss: 0.20595, in 0.314s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00425, in 0.325s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29777, val loss: 0.29818, in 0.300s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00446, in 0.277s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00380, in 0.270s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19175, val loss: 0.19213, in 0.294s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16904, val loss: 0.17010, in 0.302s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00405, in 0.317s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19183, val loss: 0.19271, in 0.317s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27355, val loss: 0.27406, in 0.285s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00442, in 0.291s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00347, val loss: 0.00419, in 0.336s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00376, in 0.281s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17985, val loss: 0.18030, in 0.308s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00402, in 0.288s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15908, val loss: 0.16021, in 0.304s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17999, val loss: 0.18092, in 0.304s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00437, in 0.274s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25234, val loss: 0.25294, in 0.311s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00373, in 0.257s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00415, in 0.302s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00323, val loss: 0.00399, in 0.274s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16888, val loss: 0.16955, in 0.293s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15042, val loss: 0.15162, in 0.308s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16917, val loss: 0.17015, in 0.322s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00434, in 0.292s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23354, val loss: 0.23424, in 0.305s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00411, in 0.304s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00369, in 0.330s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00395, in 0.247s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15914, val loss: 0.15989, in 0.323s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14226, val loss: 0.14360, in 0.310s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15929, val loss: 0.16045, in 0.322s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00365, val loss: 0.00428, in 0.339s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00409, in 0.297s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21681, val loss: 0.21747, in 0.307s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00366, in 0.323s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00317, val loss: 0.00393, in 0.257s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14991, val loss: 0.15081, in 0.311s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13499, val loss: 0.13639, in 0.300s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15021, val loss: 0.15153, in 0.308s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00333, val loss: 0.00406, in 0.271s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20198, val loss: 0.20279, in 0.318s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00425, in 0.342s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00388, in 0.302s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00363, in 0.325s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14140, val loss: 0.14237, in 0.317s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12851, val loss: 0.13002, in 0.327s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00402, in 0.322s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14227, val loss: 0.14364, in 0.334s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00418, in 0.291s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18860, val loss: 0.18938, in 0.314s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00385, in 0.276s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00295, val loss: 0.00359, in 0.304s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13377, val loss: 0.13478, in 0.295s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12270, val loss: 0.12424, in 0.313s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00324, val loss: 0.00396, in 0.310s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13485, val loss: 0.13621, in 0.307s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00414, in 0.307s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00382, in 0.303s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17651, val loss: 0.17734, in 0.313s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00355, in 0.318s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12717, val loss: 0.12827, in 0.302s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11687, val loss: 0.11851, in 0.304s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00393, in 0.308s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00304, val loss: 0.00380, in 0.278s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12835, val loss: 0.12989, in 0.328s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16543, val loss: 0.16638, in 0.315s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00344, val loss: 0.00409, in 0.336s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00289, val loss: 0.00352, in 0.296s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.12121, val loss: 0.12244, in 0.301s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11170, val loss: 0.11341, in 0.313s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00315, val loss: 0.00389, in 0.314s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00406, in 0.280s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12247, val loss: 0.12403, in 0.326s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00376, in 0.354s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15581, val loss: 0.15688, in 0.330s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00350, in 0.303s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11555, val loss: 0.11693, in 0.330s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10706, val loss: 0.10890, in 0.320s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00372, in 0.272s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00346, in 0.283s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11644, val loss: 0.11797, in 0.317s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00310, val loss: 0.00384, in 0.371s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00337, val loss: 0.00402, in 0.345s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14719, val loss: 0.14834, in 0.326s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.11034, val loss: 0.11174, in 0.328s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10289, val loss: 0.10469, in 0.333s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00368, in 0.347s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00343, in 0.320s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11075, val loss: 0.11250, in 0.322s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00395, in 0.327s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00379, in 0.342s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13916, val loss: 0.14040, in 0.327s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10583, val loss: 0.10721, in 0.324s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09843, val loss: 0.10043, in 0.328s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00363, in 0.316s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00376, in 0.285s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10598, val loss: 0.10785, in 0.344s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00338, in 0.356s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00391, in 0.351s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13213, val loss: 0.13348, in 0.345s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10158, val loss: 0.10302, in 0.323s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09474, val loss: 0.09679, in 0.331s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00299, val loss: 0.00372, in 0.302s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00360, in 0.325s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10181, val loss: 0.10373, in 0.319s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00335, in 0.345s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12496, val loss: 0.12634, in 0.310s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00386, in 0.327s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09756, val loss: 0.09898, in 0.329s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09094, val loss: 0.09312, in 0.327s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00369, in 0.317s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00281, val loss: 0.00357, in 0.345s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09746, val loss: 0.09948, in 0.322s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11885, val loss: 0.12033, in 0.325s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00382, in 0.323s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00332, in 0.340s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09332, val loss: 0.09484, in 0.313s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00365, in 0.281s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08741, val loss: 0.08946, in 0.328s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09356, val loss: 0.09562, in 0.313s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11358, val loss: 0.11512, in 0.318s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00329, in 0.321s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00313, val loss: 0.00378, in 0.338s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.08995, val loss: 0.09145, in 0.329s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08423, val loss: 0.08639, in 0.309s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00361, in 0.335s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09023, val loss: 0.09220, in 0.327s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00310, val loss: 0.00374, in 0.289s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10862, val loss: 0.11029, in 0.320s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00326, in 0.349s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08645, val loss: 0.08796, in 0.313s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00358, in 0.308s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08136, val loss: 0.08361, in 0.314s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08691, val loss: 0.08892, in 0.312s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00372, in 0.311s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00260, val loss: 0.00323, in 0.271s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10326, val loss: 0.10499, in 0.328s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08346, val loss: 0.08506, in 0.307s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00355, in 0.299s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07787, val loss: 0.08006, in 0.336s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00321, in 0.275s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08415, val loss: 0.08612, in 0.338s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09894, val loss: 0.10074, in 0.326s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00303, val loss: 0.00369, in 0.368s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00352, in 0.273s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08066, val loss: 0.08240, in 0.331s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07561, val loss: 0.07776, in 0.358s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08135, val loss: 0.08340, in 0.343s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09511, val loss: 0.09688, in 0.350s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07822, val loss: 0.08004, in 0.363s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07285, val loss: 0.07501, in 0.349s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07775, val loss: 0.07977, in 0.349s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09087, val loss: 0.09276, in 0.332s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07512, val loss: 0.07697, in 0.370s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07051, val loss: 0.07270, in 0.404s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07499, val loss: 0.07701, in 0.388s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08731, val loss: 0.08919, in 0.406s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07246, val loss: 0.07433, in 0.380s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06823, val loss: 0.07043, in 0.321s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07239, val loss: 0.07445, in 0.354s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08386, val loss: 0.08589, in 0.326s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06959, val loss: 0.07133, in 0.336s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06607, val loss: 0.06834, in 0.362s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06986, val loss: 0.07190, in 0.347s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08045, val loss: 0.08263, in 0.353s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06686, val loss: 0.06856, in 0.417s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06387, val loss: 0.06612, in 0.405s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06769, val loss: 0.06978, in 0.406s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07679, val loss: 0.07893, in 0.413s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06449, val loss: 0.06613, in 0.342s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06200, val loss: 0.06434, in 0.363s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06500, val loss: 0.06701, in 0.350s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07413, val loss: 0.07632, in 0.343s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06273, val loss: 0.06436, in 0.360s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06006, val loss: 0.06247, in 0.338s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06288, val loss: 0.06490, in 0.345s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07088, val loss: 0.07298, in 0.343s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06085, val loss: 0.06252, in 0.344s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05822, val loss: 0.06067, in 0.368s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06112, val loss: 0.06313, in 0.333s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06841, val loss: 0.07060, in 0.331s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05897, val loss: 0.06063, in 0.331s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05608, val loss: 0.05850, in 0.308s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05936, val loss: 0.06148, in 0.305s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06572, val loss: 0.06787, in 0.335s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05724, val loss: 0.05896, in 0.323s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05333, val loss: 0.05574, in 0.323s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05766, val loss: 0.05986, in 0.323s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06332, val loss: 0.06551, in 0.326s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05555, val loss: 0.05736, in 0.323s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05559, val loss: 0.05781, in 0.328s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05156, val loss: 0.05392, in 0.354s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06119, val loss: 0.06342, in 0.351s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05343, val loss: 0.05525, in 0.338s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04986, val loss: 0.05222, in 0.335s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05412, val loss: 0.05636, in 0.351s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05915, val loss: 0.06144, in 0.355s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05201, val loss: 0.05385, in 0.310s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04796, val loss: 0.05031, in 0.293s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05224, val loss: 0.05460, in 0.301s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05747, val loss: 0.05967, in 0.261s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05033, val loss: 0.05219, in 0.269s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04654, val loss: 0.04891, in 0.268s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05047, val loss: 0.05283, in 0.267s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05575, val loss: 0.05795, in 0.276s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04798, val loss: 0.04980, in 0.240s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04538, val loss: 0.04772, in 0.244s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04893, val loss: 0.05121, in 0.233s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05422, val loss: 0.05646, in 0.223s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04626, val loss: 0.04804, in 0.227s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04345, val loss: 0.04573, in 0.233s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04742, val loss: 0.04973, in 0.272s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05159, val loss: 0.05372, in 0.257s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04431, val loss: 0.04607, in 0.230s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04158, val loss: 0.04378, in 0.255s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04524, val loss: 0.04747, in 0.238s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04938, val loss: 0.05146, in 0.269s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04291, val loss: 0.04467, in 0.274s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04056, val loss: 0.04273, in 0.260s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04360, val loss: 0.04579, in 0.229s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.05024, in 0.254s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04147, val loss: 0.04324, in 0.228s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04189, val loss: 0.04401, in 0.235s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03910, val loss: 0.04126, in 0.244s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04641, val loss: 0.04859, in 0.252s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03982, val loss: 0.04153, in 0.252s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04086, val loss: 0.04297, in 0.245s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03994, in 0.242s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04488, val loss: 0.04705, in 0.251s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03868, val loss: 0.04037, in 0.256s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03975, val loss: 0.04185, in 0.234s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03658, val loss: 0.03872, in 0.246s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04365, val loss: 0.04583, in 0.247s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03783, val loss: 0.03953, in 0.244s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03577, val loss: 0.03784, in 0.257s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03882, val loss: 0.04094, in 0.281s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04165, val loss: 0.04376, in 0.257s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03645, val loss: 0.03811, in 0.233s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03728, val loss: 0.03939, in 0.239s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03456, val loss: 0.03662, in 0.251s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03985, val loss: 0.04189, in 0.245s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03502, val loss: 0.03664, in 0.249s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03598, val loss: 0.03808, in 0.228s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03329, val loss: 0.03535, in 0.246s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03395, val loss: 0.03548, in 0.253s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03860, val loss: 0.04061, in 0.270s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03434, in 0.221s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03507, val loss: 0.03716, in 0.261s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03325, val loss: 0.03478, in 0.235s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03765, val loss: 0.03970, in 0.232s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03159, val loss: 0.03360, in 0.238s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03408, val loss: 0.03614, in 0.265s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03251, val loss: 0.03404, in 0.248s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03600, val loss: 0.03799, in 0.294s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03302, in 0.249s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03272, val loss: 0.03477, in 0.273s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03179, val loss: 0.03331, in 0.239s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03532, val loss: 0.03731, in 0.244s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03029, val loss: 0.03228, in 0.240s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03172, val loss: 0.03370, in 0.246s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03084, val loss: 0.03232, in 0.246s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03431, val loss: 0.03624, in 0.261s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02926, val loss: 0.03123, in 0.241s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03100, val loss: 0.03296, in 0.219s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02966, val loss: 0.03113, in 0.240s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03293, val loss: 0.03481, in 0.241s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.03041, in 0.264s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02985, val loss: 0.03183, in 0.239s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02877, val loss: 0.03018, in 0.221s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03225, val loss: 0.03410, in 0.235s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02757, val loss: 0.02953, in 0.232s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02927, val loss: 0.03125, in 0.233s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02781, val loss: 0.02920, in 0.233s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03126, val loss: 0.03308, in 0.236s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02685, val loss: 0.02879, in 0.215s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.03045, in 0.231s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02721, val loss: 0.02858, in 0.237s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03027, val loss: 0.03205, in 0.216s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02626, val loss: 0.02817, in 0.250s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02748, val loss: 0.02946, in 0.245s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02623, val loss: 0.02756, in 0.236s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02946, val loss: 0.03122, in 0.231s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02551, val loss: 0.02737, in 0.230s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02693, val loss: 0.02888, in 0.240s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02543, val loss: 0.02677, in 0.228s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02847, val loss: 0.03020, in 0.214s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02460, val loss: 0.02641, in 0.218s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02651, val loss: 0.02845, in 0.199s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02486, val loss: 0.02620, in 0.230s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02748, val loss: 0.02915, in 0.238s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02392, val loss: 0.02568, in 0.245s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02451, val loss: 0.02585, in 0.176s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02575, val loss: 0.02766, in 0.255s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02691, val loss: 0.02855, in 0.239s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02384, val loss: 0.02512, in 0.227s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02488, val loss: 0.02677, in 0.227s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02333, val loss: 0.02509, in 0.271s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02588, val loss: 0.02747, in 0.234s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02444, in 0.233s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02276, val loss: 0.02448, in 0.230s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02630, in 0.240s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02530, val loss: 0.02691, in 0.224s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02218, val loss: 0.02387, in 0.241s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02389, val loss: 0.02577, in 0.244s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02240, val loss: 0.02367, in 0.262s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02604, in 0.259s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02194, val loss: 0.02318, in 0.261s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02176, val loss: 0.02346, in 0.282s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02323, val loss: 0.02506, in 0.288s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02552, in 0.237s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02122, val loss: 0.02292, in 0.229s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02157, val loss: 0.02280, in 0.246s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02241, val loss: 0.02419, in 0.230s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02461, in 0.237s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02200, val loss: 0.02374, in 0.212s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02069, val loss: 0.02237, in 0.236s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02107, val loss: 0.02229, in 0.242s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02238, val loss: 0.02387, in 0.228s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02020, val loss: 0.02186, in 0.219s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02337, in 0.230s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02180, in 0.257s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02186, val loss: 0.02335, in 0.259s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02144, in 0.218s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02095, val loss: 0.02271, in 0.251s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02007, val loss: 0.02125, in 0.223s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02283, in 0.221s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01920, val loss: 0.02077, in 0.229s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02037, val loss: 0.02213, in 0.219s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01950, val loss: 0.02066, in 0.245s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02081, val loss: 0.02226, in 0.213s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.02052, in 0.173s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.02138, in 0.215s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01900, val loss: 0.02013, in 0.211s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02048, val loss: 0.02192, in 0.196s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01852, val loss: 0.02004, in 0.267s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01927, val loss: 0.02098, in 0.223s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01958, in 0.209s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02011, val loss: 0.02157, in 0.227s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01807, val loss: 0.01957, in 0.237s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01913, in 0.199s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01878, val loss: 0.02048, in 0.258s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01951, val loss: 0.02091, in 0.221s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01767, val loss: 0.01870, in 0.224s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01749, val loss: 0.01896, in 0.260s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.02007, in 0.224s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01896, val loss: 0.02032, in 0.221s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01745, val loss: 0.01848, in 0.169s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01711, val loss: 0.01856, in 0.230s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01805, val loss: 0.01972, in 0.247s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01846, val loss: 0.01977, in 0.228s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01809, in 0.236s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01821, in 0.213s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01798, val loss: 0.01927, in 0.212s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01919, in 0.233s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01671, val loss: 0.01774, in 0.230s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01797, in 0.188s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01733, val loss: 0.01892, in 0.196s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01756, val loss: 0.01883, in 0.233s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01631, val loss: 0.01736, in 0.220s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01747, in 0.251s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01690, val loss: 0.01848, in 0.237s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01709, val loss: 0.01834, in 0.225s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01604, val loss: 0.01711, in 0.247s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01572, val loss: 0.01712, in 0.210s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01803, in 0.224s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01646, val loss: 0.01804, in 0.245s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01569, val loss: 0.01671, in 0.204s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01678, in 0.218s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01626, val loss: 0.01749, in 0.227s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01614, val loss: 0.01769, in 0.250s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01540, val loss: 0.01641, in 0.230s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01651, in 0.239s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01590, val loss: 0.01709, in 0.227s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01568, val loss: 0.01720, in 0.220s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01600, in 0.208s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01620, in 0.206s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01548, val loss: 0.01698, in 0.195s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01550, val loss: 0.01666, in 0.224s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01584, in 0.164s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01456, val loss: 0.01592, in 0.214s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01529, val loss: 0.01646, in 0.212s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01671, in 0.225s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01557, in 0.246s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01434, val loss: 0.01571, in 0.220s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01642, in 0.210s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01492, val loss: 0.01606, in 0.218s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01434, val loss: 0.01530, in 0.199s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01414, val loss: 0.01552, in 0.172s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01599, in 0.194s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01571, in 0.225s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01403, val loss: 0.01499, in 0.209s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01529, in 0.244s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01560, in 0.226s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01419, val loss: 0.01528, in 0.216s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01474, in 0.234s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01485, in 0.223s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01533, in 0.208s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01389, val loss: 0.01496, in 0.233s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01350, val loss: 0.01445, in 0.212s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01451, in 0.197s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01512, in 0.183s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01358, val loss: 0.01466, in 0.192s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01319, val loss: 0.01415, in 0.197s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01432, in 0.191s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01335, val loss: 0.01476, in 0.212s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01330, val loss: 0.01438, in 0.220s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01408, in 0.218s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01396, in 0.256s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01312, val loss: 0.01450, in 0.227s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01407, in 0.233s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01252, val loss: 0.01385, in 0.228s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01279, val loss: 0.01377, in 0.244s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01298, val loss: 0.01435, in 0.210s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01376, in 0.217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01223, val loss: 0.01355, in 0.224s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01348, in 0.227s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01274, val loss: 0.01410, in 0.198s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01247, val loss: 0.01349, in 0.210s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01197, val loss: 0.01333, in 0.208s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01233, val loss: 0.01327, in 0.222s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01375, in 0.232s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01322, in 0.210s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01310, in 0.208s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01343, in 0.197s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01298, in 0.224s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01297, in 0.201s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01297, in 0.171s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01196, val loss: 0.01328, in 0.193s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01179, val loss: 0.01273, in 0.189s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01263, in 0.227s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01267, in 0.252s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01308, in 0.235s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01248, in 0.244s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01140, val loss: 0.01236, in 0.233s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01111, val loss: 0.01243, in 0.249s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01287, in 0.212s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01228, in 0.217s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01215, in 0.212s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01095, val loss: 0.01227, in 0.211s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01132, val loss: 0.01262, in 0.231s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01115, val loss: 0.01208, in 0.211s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01199, in 0.245s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01080, val loss: 0.01211, in 0.248s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01195, in 0.218s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01244, in 0.234s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01085, val loss: 0.01181, in 0.227s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01045, val loss: 0.01171, in 0.216s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01174, in 0.214s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01090, val loss: 0.01220, in 0.222s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01162, in 0.187s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01034, val loss: 0.01160, in 0.155s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01060, val loss: 0.01153, in 0.188s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01073, val loss: 0.01202, in 0.208s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01151, in 0.158s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01143, in 0.187s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01033, val loss: 0.01123, in 0.192s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01055, val loss: 0.01183, in 0.176s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01034, val loss: 0.01128, in 0.214s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00996, val loss: 0.01118, in 0.191s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01106, in 0.179s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.01033, val loss: 0.01159, in 0.187s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01017, val loss: 0.01111, in 0.183s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00979, val loss: 0.01101, in 0.203s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00997, val loss: 0.01089, in 0.217s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01016, val loss: 0.01143, in 0.200s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01098, in 0.178s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.01086, in 0.210s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.01069, in 0.199s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01103, in 0.188s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00983, val loss: 0.01075, in 0.210s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00970, val loss: 0.01062, in 0.153s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00949, val loss: 0.01074, in 0.213s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.01086, in 0.196s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00961, val loss: 0.01053, in 0.203s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00956, val loss: 0.01047, in 0.197s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00932, val loss: 0.01057, in 0.193s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00948, val loss: 0.01070, in 0.205s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.01039, in 0.190s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00938, val loss: 0.01028, in 0.203s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00917, val loss: 0.01042, in 0.205s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.01053, in 0.175s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.01025, in 0.192s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00925, val loss: 0.01014, in 0.181s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00920, val loss: 0.01040, in 0.204s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.01025, in 0.210s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00919, val loss: 0.01009, in 0.191s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00908, val loss: 0.00998, in 0.204s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00884, val loss: 0.01010, in 0.174s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00905, val loss: 0.01024, in 0.176s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00993, in 0.166s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00888, val loss: 0.00976, in 0.175s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.01008, in 0.194s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00996, in 0.226s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00892, val loss: 0.00981, in 0.183s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00960, in 0.187s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00992, in 0.225s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00981, in 0.209s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00962, in 0.238s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00945, in 0.182s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00978, in 0.163s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00970, in 0.200s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00945, in 0.205s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00925, in 0.224s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00843, val loss: 0.00965, in 0.191s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00836, val loss: 0.00959, in 0.173s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00927, in 0.192s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00905, in 0.217s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00954, in 0.200s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00824, val loss: 0.00948, in 0.170s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00823, val loss: 0.00911, in 0.198s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00940, in 0.180s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00891, in 0.205s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00937, in 0.191s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00897, in 0.215s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00926, in 0.183s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00927, in 0.212s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00874, in 0.213s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00797, val loss: 0.00886, in 0.165s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00919, in 0.163s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00914, in 0.192s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00777, val loss: 0.00863, in 0.200s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00871, in 0.174s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00786, val loss: 0.00908, in 0.184s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00903, in 0.183s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00766, val loss: 0.00853, in 0.198s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00855, in 0.195s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00775, val loss: 0.00897, in 0.182s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00888, in 0.204s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00839, in 0.178s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00750, val loss: 0.00839, in 0.204s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00885, in 0.169s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00878, in 0.168s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00738, val loss: 0.00825, in 0.212s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00828, in 0.177s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00752, val loss: 0.00875, in 0.163s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00864, in 0.217s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00815, in 0.213s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00731, val loss: 0.00819, in 0.185s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00739, val loss: 0.00861, in 0.199s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00732, val loss: 0.00853, in 0.175s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00714, val loss: 0.00804, in 0.207s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00808, in 0.207s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00852, in 0.193s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00723, val loss: 0.00843, in 0.164s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00705, val loss: 0.00796, in 0.199s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00708, val loss: 0.00796, in 0.210s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00719, val loss: 0.00842, in 0.190s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00714, val loss: 0.00835, in 0.183s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00693, val loss: 0.00784, in 0.191s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00696, val loss: 0.00783, in 0.202s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00711, val loss: 0.00832, in 0.196s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00705, val loss: 0.00826, in 0.177s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00773, in 0.177s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00817, in 0.162s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00683, val loss: 0.00773, in 0.218s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00820, in 0.201s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00673, val loss: 0.00762, in 0.181s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00687, val loss: 0.00806, in 0.198s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00762, in 0.217s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00688, val loss: 0.00809, in 0.203s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00662, val loss: 0.00750, in 0.177s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00677, val loss: 0.00798, in 0.167s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00660, val loss: 0.00750, in 0.194s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00675, val loss: 0.00792, in 0.214s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00738, in 0.180s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00667, val loss: 0.00787, in 0.204s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00740, in 0.168s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00664, val loss: 0.00781, in 0.169s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00726, in 0.201s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00658, val loss: 0.00779, in 0.198s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00654, val loss: 0.00772, in 0.168s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00729, in 0.208s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00629, val loss: 0.00714, in 0.217s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00769, in 0.200s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00757, in 0.196s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00628, val loss: 0.00714, in 0.211s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00636, val loss: 0.00755, in 0.180s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00618, val loss: 0.00702, in 0.193s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00633, val loss: 0.00749, in 0.188s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00696, in 0.188s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00609, val loss: 0.00693, in 0.172s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00627, val loss: 0.00745, in 0.193s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00741, in 0.191s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00688, in 0.199s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00619, val loss: 0.00735, in 0.172s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00599, val loss: 0.00682, in 0.200s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00614, val loss: 0.00732, in 0.192s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00594, val loss: 0.00677, in 0.180s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00589, val loss: 0.00672, in 0.186s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00606, val loss: 0.00721, in 0.207s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00714, in 0.192s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00581, val loss: 0.00663, in 0.206s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00703, in 0.169s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00660, in 0.210s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00713, in 0.201s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00574, val loss: 0.00656, in 0.186s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00695, in 0.168s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00573, val loss: 0.00653, in 0.171s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00589, val loss: 0.00705, in 0.176s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00566, val loss: 0.00647, in 0.178s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00695, in 0.168s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00568, val loss: 0.00684, in 0.203s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00564, val loss: 0.00645, in 0.205s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00559, val loss: 0.00640, in 0.183s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00687, in 0.177s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00558, val loss: 0.00674, in 0.169s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00556, val loss: 0.00637, in 0.185s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00633, in 0.208s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00665, in 0.160s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00547, val loss: 0.00627, in 0.172s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00676, in 0.217s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00543, val loss: 0.00626, in 0.210s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00544, val loss: 0.00657, in 0.169s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00536, val loss: 0.00616, in 0.189s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00666, in 0.199s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00618, in 0.215s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00651, in 0.187s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00608, in 0.205s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00547, val loss: 0.00659, in 0.213s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00533, val loss: 0.00646, in 0.163s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00612, in 0.175s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00519, val loss: 0.00600, in 0.193s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00541, val loss: 0.00654, in 0.177s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00525, val loss: 0.00639, in 0.180s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00607, in 0.174s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00514, val loss: 0.00595, in 0.172s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00530, val loss: 0.00641, in 0.209s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00518, val loss: 0.00601, in 0.187s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00518, val loss: 0.00631, in 0.217s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00505, val loss: 0.00585, in 0.238s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00516, val loss: 0.00625, in 0.241s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00509, val loss: 0.00622, in 0.232s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00594, in 0.267s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00576, in 0.209s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00618, in 0.248s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00501, val loss: 0.00614, in 0.211s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00587, in 0.247s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00569, in 0.213s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00503, val loss: 0.00611, in 0.203s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00494, val loss: 0.00607, in 0.221s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00579, in 0.185s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00483, val loss: 0.00562, in 0.195s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00496, val loss: 0.00604, in 0.195s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00601, in 0.176s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00571, in 0.205s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00556, in 0.190s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00488, val loss: 0.00596, in 0.203s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00596, in 0.203s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00564, in 0.217s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00471, val loss: 0.00549, in 0.202s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00588, in 0.219s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00475, val loss: 0.00588, in 0.219s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00478, val loss: 0.00559, in 0.220s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00464, val loss: 0.00542, in 0.195s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00473, val loss: 0.00582, in 0.202s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00471, val loss: 0.00584, in 0.179s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00472, val loss: 0.00553, in 0.183s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00534, in 0.209s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00467, val loss: 0.00574, in 0.206s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00575, in 0.213s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00543, in 0.202s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00450, val loss: 0.00528, in 0.211s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00569, in 0.241s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00456, val loss: 0.00567, in 0.256s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00537, in 0.218s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00445, val loss: 0.00523, in 0.253s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00560, in 0.260s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00450, val loss: 0.00561, in 0.240s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00450, val loss: 0.00531, in 0.243s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00517, in 0.243s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00555, in 0.300s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00445, val loss: 0.00527, in 0.300s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00554, in 0.312s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00509, in 0.330s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00438, val loss: 0.00519, in 0.234s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00432, val loss: 0.00540, in 0.247s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00439, val loss: 0.00546, in 0.239s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00424, val loss: 0.00504, in 0.195s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00427, val loss: 0.00534, in 0.199s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00432, val loss: 0.00514, in 0.209s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00434, val loss: 0.00540, in 0.226s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00499, in 0.195s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00427, val loss: 0.00509, in 0.201s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00534, in 0.179s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00420, val loss: 0.00527, in 0.221s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00414, val loss: 0.00493, in 0.219s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00530, in 0.195s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00421, val loss: 0.00503, in 0.223s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00519, in 0.227s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00488, in 0.188s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00514, in 0.169s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00415, val loss: 0.00499, in 0.192s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00418, val loss: 0.00523, in 0.224s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00483, in 0.168s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00404, val loss: 0.00510, in 0.165s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00396, val loss: 0.00476, in 0.182s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00517, in 0.201s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00492, in 0.225s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00472, in 0.195s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00504, in 0.239s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00514, in 0.196s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00487, in 0.222s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00393, val loss: 0.00499, in 0.186s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00404, val loss: 0.00509, in 0.210s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00385, val loss: 0.00464, in 0.223s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00482, in 0.216s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00495, in 0.200s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00381, val loss: 0.00460, in 0.202s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00399, val loss: 0.00503, in 0.243s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00391, val loss: 0.00474, in 0.224s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00479, in 0.193s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00455, in 0.213s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00394, val loss: 0.00499, in 0.184s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00386, val loss: 0.00468, in 0.192s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00473, in 0.230s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00492, in 0.212s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00450, in 0.224s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00382, val loss: 0.00465, in 0.194s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00464, in 0.206s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00487, in 0.188s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00379, val loss: 0.00461, in 0.185s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00447, in 0.209s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00378, val loss: 0.00482, in 0.188s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00358, val loss: 0.00458, in 0.242s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00373, val loss: 0.00456, in 0.216s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00442, in 0.221s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00373, val loss: 0.00476, in 0.212s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00359, val loss: 0.00439, in 0.199s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00352, val loss: 0.00451, in 0.229s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00366, val loss: 0.00449, in 0.221s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00472, in 0.237s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00354, val loss: 0.00435, in 0.203s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00347, val loss: 0.00447, in 0.212s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00442, in 0.222s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00350, val loss: 0.00431, in 0.167s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00469, in 0.198s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00443, in 0.214s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00435, in 0.222s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00427, in 0.174s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00434, in 0.173s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00465, in 0.218s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00349, val loss: 0.00431, in 0.180s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00422, in 0.195s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00331, val loss: 0.00429, in 0.185s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00460, in 0.189s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00428, in 0.204s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00338, val loss: 0.00418, in 0.202s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00421, in 0.179s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00351, val loss: 0.00455, in 0.176s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00423, in 0.211s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00334, val loss: 0.00414, in 0.196s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00419, in 0.186s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00347, val loss: 0.00453, in 0.193s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00419, in 0.200s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00415, in 0.181s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00330, val loss: 0.00409, in 0.200s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00448, in 0.209s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00332, val loss: 0.00416, in 0.197s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00409, in 0.171s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00405, in 0.167s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00444, in 0.184s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00328, val loss: 0.00413, in 0.157s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00309, val loss: 0.00405, in 0.168s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00400, in 0.186s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00335, val loss: 0.00440, in 0.184s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00410, in 0.177s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00401, in 0.173s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00395, in 0.192s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00330, val loss: 0.00435, in 0.221s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00404, in 0.199s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00302, val loss: 0.00399, in 0.207s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00390, in 0.225s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00315, val loss: 0.00401, in 0.160s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00431, in 0.192s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00394, in 0.174s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00308, val loss: 0.00387, in 0.179s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00310, val loss: 0.00394, in 0.178s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00429, in 0.181s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00392, in 0.170s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00384, in 0.198s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00390, in 0.214s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00319, val loss: 0.00425, in 0.214s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00293, val loss: 0.00389, in 0.188s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00379, in 0.177s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00316, val loss: 0.00422, in 0.159s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00301, val loss: 0.00386, in 0.202s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00387, in 0.188s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00373, in 0.213s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00412, in 0.199s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00382, in 0.196s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00377, in 0.195s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00368, in 0.176s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00294, val loss: 0.00379, in 0.176s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00406, in 0.197s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00373, in 0.167s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00366, in 0.177s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00402, in 0.165s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00291, val loss: 0.00376, in 0.169s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00371, in 0.211s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00364, in 0.182s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00399, in 0.154s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00372, in 0.211s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00271, val loss: 0.00365, in 0.223s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00360, in 0.187s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00396, in 0.181s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00364, in 0.176s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00265, val loss: 0.00356, in 0.198s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00279, val loss: 0.00359, in 0.175s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00291, val loss: 0.00393, in 0.186s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00360, in 0.204s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00356, in 0.175s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00353, in 0.222s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00357, in 0.202s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00273, val loss: 0.00353, in 0.201s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00354, in 0.216s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00349, in 0.216s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00346, in 0.174s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00264, val loss: 0.00344, in 0.190s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00261, val loss: 0.00341, in 0.166s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00339, in 0.187s\n",
      "[200/200] \n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([53.75888138, 54.21396203, 87.48220234, 85.59146543, 45.2094981 ,\n",
      "       43.1425056 , 79.7596185 , 81.75491595]), 'std_fit_time': array([ 0.59344021,  0.76802223,  0.64581344,  0.71232976,  4.76468446,\n",
      "        1.1919533 , 15.40487391, 24.63864113]), 'mean_score_time': array([2.80370207, 3.24002523, 5.02647707, 5.19694133, 2.44586546,\n",
      "       2.44533279, 5.5651963 , 3.36876194]), 'std_score_time': array([0.17659818, 0.14974989, 0.3096817 , 0.48339441, 0.03619606,\n",
      "       0.1538266 , 1.50141317, 0.94251175]), 'param_clf_GBC__learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_GBC__max_depth': masked_array(data=[3, 3, 10, 10, 3, 3, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_GBC__min_samples_leaf': masked_array(data=[1, 3, 1, 3, 1, 3, 1, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 3}], 'split0_test_accuracy': array([0.97533802, 0.97538249, 0.9961973 , 0.9961973 , 0.98723537,\n",
      "       0.98696851, 0.99846558, 0.99851005]), 'split1_test_accuracy': array([0.97636097, 0.97636097, 0.99704234, 0.99704234, 0.98781356,\n",
      "       0.98781356, 0.99948853, 0.99948853]), 'split2_test_accuracy': array([0.97622701, 0.97622701, 0.99735361, 0.99735361, 0.98788   ,\n",
      "       0.98788   , 0.99948851, 0.99948851]), 'split3_test_accuracy': array([0.97664954, 0.97664954, 0.99697556, 0.99697556, 0.98788   ,\n",
      "       0.9881691 , 0.9994218 , 0.9994218 ]), 'split4_test_accuracy': array([0.97716103, 0.97716103, 0.99673094, 0.99673094, 0.98779105,\n",
      "       0.98783552, 0.9994218 , 0.9994218 ]), 'split5_test_accuracy': array([0.97627149, 0.97629373, 0.99695332, 0.99695332, 0.98745747,\n",
      "       0.98783552, 0.9994218 , 0.99939956]), 'split6_test_accuracy': array([0.97753908, 0.97753908, 0.99681989, 0.99681989, 0.98821358,\n",
      "       0.98785776, 0.99957747, 0.99957747]), 'split7_test_accuracy': array([0.97700536, 0.97700536, 0.99708675, 0.99708675, 0.98832477,\n",
      "       0.98876954, 0.99951075, 0.99953299]), 'split8_test_accuracy': array([0.9760491 , 0.9760491 , 0.99650855, 0.99650855, 0.98794672,\n",
      "       0.98799119, 0.9991327 , 0.9991327 ]), 'split9_test_accuracy': array([0.96822114, 0.96986679, 0.98739075, 0.98739075, 0.97271332,\n",
      "       0.96795428, 0.99777615, 0.99753152]), 'mean_test_accuracy': array([0.97568227, 0.97585351, 0.9959059 , 0.9959059 , 0.98632558,\n",
      "       0.9859075 , 0.99917051, 0.99915049]), 'std_test_accuracy': array([0.0025563 , 0.00207853, 0.00285473, 0.00285473, 0.00454737,\n",
      "       0.00599878, 0.00055818, 0.00061627]), 'rank_test_accuracy': array([8, 7, 3, 3, 5, 6, 1, 2], dtype=int32), 'split0_test_precision': array([0.95725838, 0.95730116, 0.99459148, 0.99459148, 0.97788344,\n",
      "       0.97770506, 0.99902044, 0.99897609]), 'split1_test_precision': array([0.95734233, 0.95734233, 0.99460058, 0.99460058, 0.97820021,\n",
      "       0.97820021, 0.99906679, 0.99906679]), 'split2_test_precision': array([0.95858318, 0.95858318, 0.99504162, 0.99504162, 0.97849415,\n",
      "       0.97849415, 0.99897805, 0.99897805]), 'split3_test_precision': array([0.95853836, 0.95853836, 0.99433703, 0.99433703, 0.97720352,\n",
      "       0.97796455, 0.99897791, 0.99897791]), 'split4_test_precision': array([0.96011323, 0.96011323, 0.99402813, 0.99402813, 0.97798989,\n",
      "       0.97803347, 0.99884491, 0.99884491]), 'split5_test_precision': array([0.95788078, 0.95784343, 0.99420559, 0.99420559, 0.97697698,\n",
      "       0.97761714, 0.99884491, 0.99880053]), 'split6_test_precision': array([0.96010456, 0.96010456, 0.99407316, 0.99407316, 0.97850915,\n",
      "       0.9777439 , 0.99920004, 0.99920004]), 'split7_test_precision': array([0.95868617, 0.95868617, 0.99446976, 0.99446976, 0.9780971 ,\n",
      "       0.97894966, 0.99902248, 0.99906687]), 'split8_test_precision': array([0.9578254 , 0.9578254 , 0.99402576, 0.99402576, 0.97874847,\n",
      "       0.97875033, 0.99888864, 0.99888864]), 'split9_test_precision': array([0.95789657, 0.95727828, 0.99561304, 0.99561304, 0.97917136,\n",
      "       0.97901206, 0.99888562, 0.99884058]), 'mean_test_precision': array([0.95842289, 0.95836161, 0.99449861, 0.99449861, 0.97812743,\n",
      "       0.97824705, 0.99897298, 0.99896404]), 'std_test_precision': array([0.00096152, 0.0010092 , 0.00047902, 0.00047902, 0.00063384,\n",
      "       0.00049644, 0.00010614, 0.00011799]), 'rank_test_precision': array([7, 8, 3, 3, 6, 5, 1, 2], dtype=int32), 'split0_test_recall': array([0.99510763, 0.99515211, 0.99782067, 0.99782067, 0.9970201 ,\n",
      "       0.99666429, 0.99790962, 0.99804305]), 'split1_test_recall': array([0.99715353, 0.99715353, 0.99951076, 0.99951076, 0.99786515,\n",
      "       0.99786515, 0.99991105, 0.99991105]), 'split2_test_recall': array([0.99546324, 0.99546324, 0.99968865, 0.99968865, 0.99768714,\n",
      "       0.99768714, 1.        , 1.        ]), 'split3_test_recall': array([0.99639728, 0.99639728, 0.99964418, 0.99964418, 0.99906596,\n",
      "       0.99884357, 0.99986657, 0.99986657]), 'split4_test_recall': array([0.99568563, 0.99568563, 0.99946626, 0.99946626, 0.99804297,\n",
      "       0.99808744, 1.        , 1.        ]), 'split5_test_recall': array([0.9963528 , 0.99644176, 0.99973313, 0.99973313, 0.99844327,\n",
      "       0.99853222, 1.        , 1.        ]), 'split6_test_recall': array([0.99648639, 0.99648639, 0.99959972, 0.99959972, 0.99835439,\n",
      "       0.99844334, 0.99995552, 0.99995552]), 'split7_test_recall': array([0.99697563, 0.99697563, 0.99973314, 0.99973314, 0.99902153,\n",
      "       0.99902153, 1.        , 1.        ]), 'split8_test_recall': array([0.99595268, 0.99595268, 0.99902153, 0.99902153, 0.99755382,\n",
      "       0.99764277, 0.99937733, 0.99937733]), 'split9_test_recall': array([0.97949653, 0.98363281, 0.97909625, 0.97909625, 0.96597581,\n",
      "       0.95641345, 0.99666429, 0.99621953]), 'mean_test_recall': array([0.99450713, 0.9949341 , 0.99733143, 0.99733143, 0.99490301,\n",
      "       0.99392009, 0.99936844, 0.99933731]), 'std_test_recall': array([0.00504048, 0.00381532, 0.00610337, 0.00610337, 0.00966134,\n",
      "       0.01251901, 0.00109194, 0.00118934]), 'rank_test_recall': array([7, 5, 3, 3, 6, 8, 1, 2], dtype=int32), 'split0_test_roc_auc': array([0.99580154, 0.99580194, 0.99994026, 0.99994026, 0.99917497,\n",
      "       0.99909964, 0.99997816, 0.99997911]), 'split1_test_roc_auc': array([0.99613041, 0.99613048, 0.99997882, 0.99997882, 0.99923414,\n",
      "       0.99923406, 0.9999993 , 0.99999933]), 'split2_test_roc_auc': array([0.99617857, 0.99617857, 0.99998951, 0.99998951, 0.99928971,\n",
      "       0.99928971, 0.99999985, 0.99999985]), 'split3_test_roc_auc': array([0.99640077, 0.99640077, 0.99998854, 0.99998854, 0.99923652,\n",
      "       0.99933494, 0.99999951, 0.99999951]), 'split4_test_roc_auc': array([0.99605594, 0.99605594, 0.9999842 , 0.9999842 , 0.99926355,\n",
      "       0.9992699 , 0.99999987, 0.99999987]), 'split5_test_roc_auc': array([0.99563658, 0.99565134, 0.99998491, 0.99998491, 0.99915959,\n",
      "       0.99917705, 0.99999954, 0.99999963]), 'split6_test_roc_auc': array([0.99652036, 0.99652046, 0.99998195, 0.99998195, 0.9993109 ,\n",
      "       0.99928081, 0.99999955, 0.99999955]), 'split7_test_roc_auc': array([0.99628253, 0.99628253, 0.99998831, 0.99998831, 0.9993159 ,\n",
      "       0.99935964, 0.99999971, 0.99999971]), 'split8_test_roc_auc': array([0.9961558 , 0.9961558 , 0.99996801, 0.99996801, 0.99914822,\n",
      "       0.9991947 , 0.99999518, 0.99999518]), 'split9_test_roc_auc': array([0.99240352, 0.99252148, 0.99957526, 0.99957526, 0.99687109,\n",
      "       0.9968391 , 0.99998469, 0.9999749 ]), 'mean_test_roc_auc': array([0.9957566 , 0.99576993, 0.99993798, 0.99993798, 0.99900046,\n",
      "       0.99900796, 0.99999554, 0.99999466]), 'std_test_roc_auc': array([1.14460436e-03, 1.10992040e-03, 1.21718969e-04, 1.21718969e-04,\n",
      "       7.12103000e-04, 7.26635537e-04, 7.32601274e-06, 8.97711642e-06]), 'rank_test_roc_auc': array([8, 7, 3, 3, 6, 5, 1, 2], dtype=int32), 'split0_test_f1': array([0.97581612, 0.97585974, 0.99620346, 0.99620346, 0.98735906,\n",
      "       0.98709365, 0.99846472, 0.99850936]), 'split1_test_f1': array([0.97684247, 0.97684247, 0.99704962, 0.99704962, 0.98793483,\n",
      "       0.98793483, 0.99948874, 0.99948874]), 'split2_test_f1': array([0.97667518, 0.97667518, 0.99735972, 0.99735972, 0.98799745,\n",
      "       0.98799745, 0.99948876, 0.99948876]), 'split3_test_f1': array([0.97710123, 0.97710123, 0.99698354, 0.99698354, 0.98801381,\n",
      "       0.9882938 , 0.99942204, 0.99942204]), 'split4_test_f1': array([0.97757593, 0.97757593, 0.99673978, 0.99673978, 0.98791468,\n",
      "       0.9879587 , 0.99942212, 0.99942212]), 'split5_test_f1': array([0.9767381 , 0.97676142, 0.9969617 , 0.9969617 , 0.98759349,\n",
      "       0.987964  , 0.99942212, 0.99939991]), 'split6_test_f1': array([0.97795722, 0.97795722, 0.99682878, 0.99682878, 0.98833216,\n",
      "       0.98798521, 0.99957764, 0.99957764]), 'split7_test_f1': array([0.97745607, 0.97745607, 0.99709451, 0.99709451, 0.98844859,\n",
      "       0.98888375, 0.999511  , 0.99953322]), 'split8_test_f1': array([0.97651702, 0.97651702, 0.99651738, 0.99651738, 0.98806167,\n",
      "       0.98810625, 0.99913293, 0.99913293]), 'split9_test_f1': array([0.96857614, 0.97027661, 0.98728557, 0.98728557, 0.97252883,\n",
      "       0.96758082, 0.99777372, 0.99752834]), 'mean_test_f1': array([0.97612555, 0.97630229, 0.99590241, 0.99590241, 0.98641846,\n",
      "       0.98597985, 0.99917038, 0.9991503 ]), 'std_test_f1': array([0.00258098, 0.00208621, 0.00288842, 0.00288842, 0.00463948,\n",
      "       0.00614687, 0.00055899, 0.00061727]), 'rank_test_f1': array([8, 7, 3, 3, 5, 6, 1, 2], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST AOC-RUC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.133 GB of training data: 1.014 s\n",
      "Binning 0.015 GB of validation data: 0.038 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61014, val loss: 0.60993, in 0.129s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54199, val loss: 0.54159, in 0.129s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48464, val loss: 0.48422, in 0.111s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43626, val loss: 0.43580, in 0.111s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39484, val loss: 0.39435, in 0.110s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35862, val loss: 0.35817, in 0.109s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32682, in 0.111s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30025, val loss: 0.29972, in 0.112s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27652, val loss: 0.27611, in 0.112s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25542, val loss: 0.25512, in 0.112s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23669, val loss: 0.23634, in 0.113s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22005, val loss: 0.21976, in 0.113s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20520, val loss: 0.20492, in 0.112s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19210, val loss: 0.19184, in 0.119s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18016, val loss: 0.17998, in 0.122s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16945, val loss: 0.16940, in 0.110s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15920, val loss: 0.15920, in 0.120s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15043, val loss: 0.15049, in 0.116s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14251, val loss: 0.14268, in 0.116s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13544, val loss: 0.13574, in 0.110s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12860, val loss: 0.12895, in 0.120s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12230, val loss: 0.12285, in 0.117s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11687, val loss: 0.11753, in 0.115s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11126, val loss: 0.11198, in 0.116s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10605, val loss: 0.10684, in 0.119s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10145, val loss: 0.10235, in 0.115s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09763, val loss: 0.09859, in 0.116s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09364, val loss: 0.09463, in 0.114s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08997, val loss: 0.09098, in 0.118s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08673, val loss: 0.08781, in 0.118s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08378, val loss: 0.08481, in 0.115s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08063, val loss: 0.08177, in 0.109s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07782, val loss: 0.07904, in 0.114s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07443, val loss: 0.07566, in 0.125s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07151, val loss: 0.07284, in 0.115s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06918, val loss: 0.07053, in 0.115s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06665, val loss: 0.06801, in 0.115s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06441, val loss: 0.06578, in 0.118s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06214, val loss: 0.06348, in 0.116s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06031, val loss: 0.06167, in 0.181s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05823, val loss: 0.05958, in 0.136s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05536, val loss: 0.05669, in 0.126s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05370, val loss: 0.05510, in 0.118s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05213, val loss: 0.05356, in 0.138s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05007, val loss: 0.05153, in 0.134s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04787, val loss: 0.04932, in 0.133s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04657, val loss: 0.04804, in 0.141s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04522, val loss: 0.04674, in 0.143s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04340, val loss: 0.04485, in 0.116s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04207, val loss: 0.04353, in 0.134s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04106, val loss: 0.04255, in 0.133s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03928, val loss: 0.04080, in 0.110s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03839, val loss: 0.03997, in 0.120s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03717, val loss: 0.03875, in 0.120s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03573, val loss: 0.03732, in 0.111s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03502, val loss: 0.03665, in 0.112s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03421, val loss: 0.03580, in 0.108s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03447, in 0.118s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03179, val loss: 0.03337, in 0.110s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03259, in 0.118s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02990, val loss: 0.03149, in 0.113s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02917, val loss: 0.03077, in 0.113s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02860, val loss: 0.03023, in 0.116s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02803, val loss: 0.02965, in 0.118s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02722, val loss: 0.02884, in 0.111s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02660, val loss: 0.02823, in 0.121s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02595, val loss: 0.02757, in 0.117s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02515, val loss: 0.02677, in 0.108s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02441, val loss: 0.02603, in 0.110s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02374, val loss: 0.02537, in 0.122s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02331, val loss: 0.02491, in 0.115s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02290, val loss: 0.02453, in 0.110s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02231, val loss: 0.02388, in 0.108s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02175, val loss: 0.02332, in 0.112s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02135, val loss: 0.02291, in 0.112s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02084, val loss: 0.02239, in 0.107s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02046, val loss: 0.02203, in 0.113s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01991, val loss: 0.02146, in 0.111s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01944, val loss: 0.02100, in 0.104s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01897, val loss: 0.02054, in 0.107s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01851, val loss: 0.02004, in 0.108s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01966, in 0.142s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01749, val loss: 0.01899, in 0.122s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01728, val loss: 0.01878, in 0.102s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01689, val loss: 0.01840, in 0.109s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01806, in 0.114s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01618, val loss: 0.01768, in 0.111s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01584, val loss: 0.01731, in 0.113s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01543, val loss: 0.01689, in 0.122s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01650, in 0.109s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01626, in 0.109s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01445, val loss: 0.01586, in 0.116s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01551, in 0.113s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01515, in 0.120s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01489, in 0.107s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01448, in 0.112s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01297, val loss: 0.01428, in 0.113s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01407, in 0.115s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01374, in 0.105s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01217, val loss: 0.01348, in 0.120s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01328, in 0.105s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01295, in 0.119s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01140, val loss: 0.01267, in 0.116s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01118, val loss: 0.01244, in 0.101s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01098, val loss: 0.01225, in 0.119s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01077, val loss: 0.01204, in 0.108s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01066, val loss: 0.01195, in 0.099s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01048, val loss: 0.01179, in 0.120s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01163, in 0.105s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01145, in 0.103s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01125, in 0.119s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00987, val loss: 0.01118, in 0.101s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.01098, in 0.108s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00948, val loss: 0.01076, in 0.106s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.01063, in 0.102s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00915, val loss: 0.01044, in 0.121s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00899, val loss: 0.01027, in 0.125s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.01013, in 0.107s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.01000, in 0.109s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00987, in 0.114s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00847, val loss: 0.00976, in 0.113s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00958, in 0.119s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00944, in 0.110s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00936, in 0.101s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00926, in 0.110s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00786, val loss: 0.00914, in 0.116s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00905, in 0.108s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00764, val loss: 0.00892, in 0.117s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00875, in 0.121s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00734, val loss: 0.00861, in 0.122s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00842, in 0.122s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00700, val loss: 0.00825, in 0.116s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00692, val loss: 0.00818, in 0.111s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00683, val loss: 0.00808, in 0.113s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00669, val loss: 0.00794, in 0.116s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00656, val loss: 0.00782, in 0.117s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00777, in 0.092s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00764, in 0.128s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00751, in 0.116s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00617, val loss: 0.00741, in 0.110s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00608, val loss: 0.00732, in 0.112s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00600, val loss: 0.00725, in 0.119s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00710, in 0.122s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00699, in 0.116s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00567, val loss: 0.00688, in 0.119s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00561, val loss: 0.00682, in 0.124s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00676, in 0.114s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00546, val loss: 0.00669, in 0.112s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00657, in 0.103s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00638, in 0.111s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00512, val loss: 0.00627, in 0.120s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00618, in 0.121s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00601, in 0.109s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00484, val loss: 0.00595, in 0.114s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00585, in 0.122s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00572, in 0.104s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00566, in 0.114s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00452, val loss: 0.00561, in 0.116s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00548, in 0.110s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00541, in 0.114s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00535, in 0.131s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00530, in 0.124s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00418, val loss: 0.00523, in 0.116s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00411, val loss: 0.00516, in 0.112s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00512, in 0.128s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00506, in 0.115s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00394, val loss: 0.00500, in 0.115s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00495, in 0.113s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00383, val loss: 0.00488, in 0.168s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00378, val loss: 0.00482, in 0.159s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00479, in 0.145s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00369, val loss: 0.00473, in 0.116s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00467, in 0.136s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00463, in 0.134s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00355, val loss: 0.00457, in 0.140s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00453, in 0.140s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00346, val loss: 0.00449, in 0.132s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00445, in 0.133s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00443, in 0.134s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00336, val loss: 0.00439, in 0.116s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00330, val loss: 0.00433, in 0.123s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00428, in 0.117s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00423, in 0.117s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00315, val loss: 0.00419, in 0.115s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00416, in 0.104s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00413, in 0.118s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00304, val loss: 0.00408, in 0.112s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00404, in 0.120s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00297, val loss: 0.00400, in 0.111s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00398, in 0.107s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00394, in 0.109s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00285, val loss: 0.00389, in 0.123s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00281, val loss: 0.00385, in 0.119s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00383, in 0.105s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00276, val loss: 0.00379, in 0.113s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00377, in 0.110s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00376, in 0.110s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00268, val loss: 0.00372, in 0.115s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00367, in 0.118s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00365, in 0.104s\n",
      "Fit 200 trees in 24.919 s, (6200 total leaves)\n",
      "Time spent computing histograms: 11.475s\n",
      "Time spent finding best splits:  2.926s\n",
      "Time spent applying splits:      4.542s\n",
      "Time spent predicting:           0.188s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74946\n",
      "           1       0.11      0.17      0.13        54\n",
      "\n",
      "    accuracy                           1.00     75000\n",
      "   macro avg       0.55      0.58      0.57     75000\n",
      "weighted avg       1.00      1.00      1.00     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8840\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9984\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.1314\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n",
      "Binning 0.133 GB of training data: 0.986 s\n",
      "Binning 0.015 GB of validation data: 0.036 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61014, val loss: 0.60993, in 0.116s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54199, val loss: 0.54159, in 0.127s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48464, val loss: 0.48422, in 0.109s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43626, val loss: 0.43580, in 0.111s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39484, val loss: 0.39435, in 0.111s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35862, val loss: 0.35817, in 0.115s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32682, in 0.118s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30025, val loss: 0.29972, in 0.127s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27652, val loss: 0.27611, in 0.143s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25542, val loss: 0.25512, in 0.145s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23669, val loss: 0.23634, in 0.132s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22005, val loss: 0.21976, in 0.112s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20520, val loss: 0.20492, in 0.118s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19210, val loss: 0.19184, in 0.133s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18016, val loss: 0.17998, in 0.118s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16945, val loss: 0.16940, in 0.113s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15920, val loss: 0.15920, in 0.111s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15043, val loss: 0.15049, in 0.115s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14251, val loss: 0.14268, in 0.116s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13544, val loss: 0.13574, in 0.116s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12860, val loss: 0.12895, in 0.116s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12230, val loss: 0.12285, in 0.119s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11687, val loss: 0.11753, in 0.111s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11126, val loss: 0.11198, in 0.112s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10605, val loss: 0.10684, in 0.115s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10145, val loss: 0.10235, in 0.112s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09763, val loss: 0.09859, in 0.113s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09364, val loss: 0.09463, in 0.115s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08997, val loss: 0.09098, in 0.122s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08673, val loss: 0.08781, in 0.112s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08378, val loss: 0.08481, in 0.116s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08063, val loss: 0.08177, in 0.117s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07782, val loss: 0.07904, in 0.152s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07443, val loss: 0.07566, in 0.139s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07151, val loss: 0.07284, in 0.123s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06918, val loss: 0.07053, in 0.122s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06665, val loss: 0.06801, in 0.121s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06441, val loss: 0.06578, in 0.121s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06214, val loss: 0.06348, in 0.115s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06031, val loss: 0.06167, in 0.115s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05823, val loss: 0.05958, in 0.116s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05536, val loss: 0.05669, in 0.113s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05370, val loss: 0.05510, in 0.119s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05213, val loss: 0.05356, in 0.113s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05007, val loss: 0.05153, in 0.111s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04787, val loss: 0.04932, in 0.110s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04657, val loss: 0.04804, in 0.115s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04522, val loss: 0.04674, in 0.122s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04340, val loss: 0.04485, in 0.108s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04207, val loss: 0.04353, in 0.115s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04106, val loss: 0.04255, in 0.128s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03928, val loss: 0.04080, in 0.112s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03839, val loss: 0.03997, in 0.118s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03717, val loss: 0.03875, in 0.115s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03573, val loss: 0.03732, in 0.112s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03502, val loss: 0.03665, in 0.112s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03421, val loss: 0.03580, in 0.107s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03447, in 0.111s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03179, val loss: 0.03337, in 0.111s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03259, in 0.114s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02990, val loss: 0.03149, in 0.115s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02917, val loss: 0.03077, in 0.111s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02860, val loss: 0.03023, in 0.107s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02803, val loss: 0.02965, in 0.111s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02722, val loss: 0.02884, in 0.111s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02660, val loss: 0.02823, in 0.117s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02595, val loss: 0.02757, in 0.111s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02515, val loss: 0.02677, in 0.112s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02441, val loss: 0.02603, in 0.109s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02374, val loss: 0.02537, in 0.108s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02331, val loss: 0.02491, in 0.121s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02290, val loss: 0.02453, in 0.106s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02231, val loss: 0.02388, in 0.111s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02175, val loss: 0.02332, in 0.176s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02135, val loss: 0.02291, in 0.121s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02084, val loss: 0.02239, in 0.119s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02046, val loss: 0.02203, in 0.116s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01991, val loss: 0.02146, in 0.133s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01944, val loss: 0.02100, in 0.127s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01897, val loss: 0.02054, in 0.132s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01851, val loss: 0.02004, in 0.135s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01966, in 0.131s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01749, val loss: 0.01899, in 0.129s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01728, val loss: 0.01878, in 0.121s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01689, val loss: 0.01840, in 0.112s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01806, in 0.115s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01618, val loss: 0.01768, in 0.116s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01584, val loss: 0.01731, in 0.124s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01543, val loss: 0.01689, in 0.110s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01650, in 0.107s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01626, in 0.106s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01445, val loss: 0.01586, in 0.115s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01551, in 0.115s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01515, in 0.134s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01489, in 0.122s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01448, in 0.120s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01297, val loss: 0.01428, in 0.131s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01407, in 0.143s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01374, in 0.140s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01217, val loss: 0.01348, in 0.141s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01328, in 0.110s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01295, in 0.115s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01140, val loss: 0.01267, in 0.110s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01118, val loss: 0.01244, in 0.096s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01098, val loss: 0.01225, in 0.117s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01077, val loss: 0.01204, in 0.113s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01066, val loss: 0.01195, in 0.099s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01048, val loss: 0.01179, in 0.108s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01163, in 0.108s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01145, in 0.104s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01125, in 0.117s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00987, val loss: 0.01118, in 0.100s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.01098, in 0.109s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00948, val loss: 0.01076, in 0.104s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.01063, in 0.103s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00915, val loss: 0.01044, in 0.122s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00899, val loss: 0.01027, in 0.137s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.01013, in 0.105s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.01000, in 0.110s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00987, in 0.151s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00847, val loss: 0.00976, in 0.120s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00958, in 0.118s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00944, in 0.114s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00936, in 0.101s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00926, in 0.112s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00786, val loss: 0.00914, in 0.125s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00905, in 0.107s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00764, val loss: 0.00892, in 0.112s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00875, in 0.117s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00734, val loss: 0.00861, in 0.122s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00842, in 0.118s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00700, val loss: 0.00825, in 0.116s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00692, val loss: 0.00818, in 0.111s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00683, val loss: 0.00808, in 0.108s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00669, val loss: 0.00794, in 0.115s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00656, val loss: 0.00782, in 0.114s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00777, in 0.094s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00764, in 0.112s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00751, in 0.117s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00617, val loss: 0.00741, in 0.111s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00608, val loss: 0.00732, in 0.114s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00600, val loss: 0.00725, in 0.116s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00710, in 0.112s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00699, in 0.127s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00567, val loss: 0.00688, in 0.120s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00561, val loss: 0.00682, in 0.110s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00676, in 0.110s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00546, val loss: 0.00669, in 0.109s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00657, in 0.104s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00638, in 0.107s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00512, val loss: 0.00627, in 0.118s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00618, in 0.112s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00601, in 0.110s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00484, val loss: 0.00595, in 0.114s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00585, in 0.119s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00572, in 0.104s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00566, in 0.109s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00452, val loss: 0.00561, in 0.111s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00548, in 0.111s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00541, in 0.108s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00535, in 0.117s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00530, in 0.115s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00418, val loss: 0.00523, in 0.120s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00411, val loss: 0.00516, in 0.114s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00512, in 0.113s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00506, in 0.115s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00394, val loss: 0.00500, in 0.130s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00495, in 0.108s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00383, val loss: 0.00488, in 0.115s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00378, val loss: 0.00482, in 0.118s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00479, in 0.111s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00369, val loss: 0.00473, in 0.109s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00467, in 0.117s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00463, in 0.110s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00355, val loss: 0.00457, in 0.113s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00453, in 0.113s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00346, val loss: 0.00449, in 0.109s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00445, in 0.113s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00443, in 0.110s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00336, val loss: 0.00439, in 0.113s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00330, val loss: 0.00433, in 0.111s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00428, in 0.109s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00423, in 0.124s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00315, val loss: 0.00419, in 0.115s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00416, in 0.108s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00413, in 0.118s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00304, val loss: 0.00408, in 0.116s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00404, in 0.115s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00297, val loss: 0.00400, in 0.113s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00398, in 0.107s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00394, in 0.107s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00285, val loss: 0.00389, in 0.119s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00281, val loss: 0.00385, in 0.123s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00383, in 0.105s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00276, val loss: 0.00379, in 0.124s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00377, in 0.124s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00376, in 0.106s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00268, val loss: 0.00372, in 0.115s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00367, in 0.117s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00365, in 0.106s\n",
      "Fit 200 trees in 24.710 s, (6200 total leaves)\n",
      "Time spent computing histograms: 11.442s\n",
      "Time spent finding best splits:  2.901s\n",
      "Time spent applying splits:      4.483s\n",
      "Time spent predicting:           0.187s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74946\n",
      "           1       0.11      0.17      0.13        54\n",
      "\n",
      "    accuracy                           1.00     75000\n",
      "   macro avg       0.55      0.58      0.57     75000\n",
      "weighted avg       1.00      1.00      1.00     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8840\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9984\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.1314\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n",
      "Binning 0.133 GB of training data: 0.974 s\n",
      "Binning 0.015 GB of validation data: 0.036 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61014, val loss: 0.60993, in 0.111s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54199, val loss: 0.54159, in 0.125s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48464, val loss: 0.48422, in 0.108s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43626, val loss: 0.43580, in 0.107s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39484, val loss: 0.39435, in 0.108s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35862, val loss: 0.35817, in 0.110s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32730, val loss: 0.32682, in 0.112s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30025, val loss: 0.29972, in 0.107s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27652, val loss: 0.27611, in 0.113s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25542, val loss: 0.25512, in 0.111s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23669, val loss: 0.23634, in 0.109s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.22005, val loss: 0.21976, in 0.110s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20520, val loss: 0.20492, in 0.110s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19210, val loss: 0.19184, in 0.114s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18016, val loss: 0.17998, in 0.116s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16945, val loss: 0.16940, in 0.120s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15920, val loss: 0.15920, in 0.115s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15043, val loss: 0.15049, in 0.118s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14251, val loss: 0.14268, in 0.115s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13544, val loss: 0.13574, in 0.111s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12860, val loss: 0.12895, in 0.117s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12230, val loss: 0.12285, in 0.115s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11687, val loss: 0.11753, in 0.113s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11126, val loss: 0.11198, in 0.119s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10605, val loss: 0.10684, in 0.117s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10145, val loss: 0.10235, in 0.114s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.09763, val loss: 0.09859, in 0.114s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09364, val loss: 0.09463, in 0.113s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08997, val loss: 0.09098, in 0.120s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08673, val loss: 0.08781, in 0.130s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08378, val loss: 0.08481, in 0.114s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08063, val loss: 0.08177, in 0.111s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07782, val loss: 0.07904, in 0.112s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07443, val loss: 0.07566, in 0.122s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07151, val loss: 0.07284, in 0.112s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06918, val loss: 0.07053, in 0.119s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06665, val loss: 0.06801, in 0.109s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06441, val loss: 0.06578, in 0.113s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06214, val loss: 0.06348, in 0.114s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06031, val loss: 0.06167, in 0.113s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05823, val loss: 0.05958, in 0.114s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05536, val loss: 0.05669, in 0.112s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05370, val loss: 0.05510, in 0.117s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05213, val loss: 0.05356, in 0.112s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05007, val loss: 0.05153, in 0.111s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04787, val loss: 0.04932, in 0.109s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04657, val loss: 0.04804, in 0.112s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04522, val loss: 0.04674, in 0.116s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04340, val loss: 0.04485, in 0.106s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04207, val loss: 0.04353, in 0.111s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04106, val loss: 0.04255, in 0.115s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03928, val loss: 0.04080, in 0.113s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03839, val loss: 0.03997, in 0.126s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03717, val loss: 0.03875, in 0.117s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03573, val loss: 0.03732, in 0.113s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03502, val loss: 0.03665, in 0.108s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03421, val loss: 0.03580, in 0.108s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03447, in 0.113s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03179, val loss: 0.03337, in 0.109s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03099, val loss: 0.03259, in 0.119s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02990, val loss: 0.03149, in 0.111s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02917, val loss: 0.03077, in 0.112s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02860, val loss: 0.03023, in 0.108s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02803, val loss: 0.02965, in 0.109s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02722, val loss: 0.02884, in 0.110s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02660, val loss: 0.02823, in 0.111s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02595, val loss: 0.02757, in 0.113s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02515, val loss: 0.02677, in 0.107s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02441, val loss: 0.02603, in 0.108s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02374, val loss: 0.02537, in 0.111s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02331, val loss: 0.02491, in 0.112s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02290, val loss: 0.02453, in 0.109s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02231, val loss: 0.02388, in 0.121s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02175, val loss: 0.02332, in 0.129s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02135, val loss: 0.02291, in 0.136s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02084, val loss: 0.02239, in 0.108s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02046, val loss: 0.02203, in 0.110s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01991, val loss: 0.02146, in 0.110s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01944, val loss: 0.02100, in 0.106s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01897, val loss: 0.02054, in 0.105s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01851, val loss: 0.02004, in 0.108s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01966, in 0.110s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01749, val loss: 0.01899, in 0.109s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01728, val loss: 0.01878, in 0.100s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01689, val loss: 0.01840, in 0.106s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01806, in 0.113s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01618, val loss: 0.01768, in 0.115s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01584, val loss: 0.01731, in 0.113s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01543, val loss: 0.01689, in 0.107s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01509, val loss: 0.01650, in 0.111s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01484, val loss: 0.01626, in 0.108s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01445, val loss: 0.01586, in 0.115s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01551, in 0.116s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01515, in 0.117s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01489, in 0.106s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01448, in 0.114s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01297, val loss: 0.01428, in 0.114s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01407, in 0.113s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01374, in 0.106s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01217, val loss: 0.01348, in 0.124s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01328, in 0.106s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01167, val loss: 0.01295, in 0.116s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01140, val loss: 0.01267, in 0.108s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01118, val loss: 0.01244, in 0.100s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01098, val loss: 0.01225, in 0.117s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01077, val loss: 0.01204, in 0.111s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01066, val loss: 0.01195, in 0.098s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01048, val loss: 0.01179, in 0.106s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01163, in 0.110s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01145, in 0.105s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01125, in 0.118s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00987, val loss: 0.01118, in 0.172s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.01098, in 0.132s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00948, val loss: 0.01076, in 0.112s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.01063, in 0.104s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00915, val loss: 0.01044, in 0.139s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00899, val loss: 0.01027, in 0.144s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.01013, in 0.129s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.01000, in 0.130s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00987, in 0.137s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00847, val loss: 0.00976, in 0.127s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00958, in 0.147s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00944, in 0.122s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00936, in 0.096s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00926, in 0.110s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00786, val loss: 0.00914, in 0.116s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00905, in 0.108s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00764, val loss: 0.00892, in 0.107s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00875, in 0.124s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00734, val loss: 0.00861, in 0.125s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00842, in 0.118s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00700, val loss: 0.00825, in 0.113s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00692, val loss: 0.00818, in 0.110s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00683, val loss: 0.00808, in 0.109s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00669, val loss: 0.00794, in 0.115s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00656, val loss: 0.00782, in 0.134s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00777, in 0.099s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00764, in 0.113s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00751, in 0.121s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00617, val loss: 0.00741, in 0.109s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00608, val loss: 0.00732, in 0.113s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00600, val loss: 0.00725, in 0.117s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00710, in 0.110s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00699, in 0.112s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00567, val loss: 0.00688, in 0.118s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00561, val loss: 0.00682, in 0.110s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00676, in 0.109s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00546, val loss: 0.00669, in 0.118s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00657, in 0.103s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00638, in 0.112s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00512, val loss: 0.00627, in 0.118s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00618, in 0.111s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00601, in 0.111s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00484, val loss: 0.00595, in 0.112s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00585, in 0.125s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00572, in 0.103s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00566, in 0.109s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00452, val loss: 0.00561, in 0.116s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00548, in 0.128s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00541, in 0.113s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00429, val loss: 0.00535, in 0.111s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00530, in 0.126s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00418, val loss: 0.00523, in 0.144s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00411, val loss: 0.00516, in 0.111s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00512, in 0.114s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00506, in 0.119s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00394, val loss: 0.00500, in 0.116s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00390, val loss: 0.00495, in 0.110s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00383, val loss: 0.00488, in 0.111s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00378, val loss: 0.00482, in 0.113s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00479, in 0.106s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00369, val loss: 0.00473, in 0.107s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00364, val loss: 0.00467, in 0.115s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00360, val loss: 0.00463, in 0.110s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00355, val loss: 0.00457, in 0.120s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00453, in 0.113s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00346, val loss: 0.00449, in 0.109s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00445, in 0.108s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00339, val loss: 0.00443, in 0.110s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00336, val loss: 0.00439, in 0.113s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00330, val loss: 0.00433, in 0.111s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00428, in 0.111s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00423, in 0.118s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00315, val loss: 0.00419, in 0.115s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00416, in 0.110s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00413, in 0.121s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00304, val loss: 0.00408, in 0.116s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00404, in 0.117s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.00297, val loss: 0.00400, in 0.107s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00398, in 0.106s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00394, in 0.107s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00285, val loss: 0.00389, in 0.119s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00281, val loss: 0.00385, in 0.121s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00383, in 0.107s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00276, val loss: 0.00379, in 0.113s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00377, in 0.105s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00376, in 0.109s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00268, val loss: 0.00372, in 0.108s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00367, in 0.118s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00365, in 0.101s\n",
      "Fit 200 trees in 24.297 s, (6200 total leaves)\n",
      "Time spent computing histograms: 11.236s\n",
      "Time spent finding best splits:  2.814s\n",
      "Time spent applying splits:      4.416s\n",
      "Time spent predicting:           0.186s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     74946\n",
      "           1       0.11      0.17      0.13        54\n",
      "\n",
      "    accuracy                           1.00     75000\n",
      "   macro avg       0.55      0.58      0.57     75000\n",
      "weighted avg       1.00      1.00      1.00     75000\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8840\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9984\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.1314\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "# class sklearn.ensemble.GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "clf_GBC = HistGradientBoostingClassifier(\n",
    "    loss='log_loss',\n",
    "    learning_rate=0.05,\n",
    "    max_iter=200,\n",
    "    max_leaf_nodes=31,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=1,\n",
    "    l2_regularization=1.0,\n",
    "    max_bins=255,\n",
    "    categorical_features=None,\n",
    "    early_stopping='auto',\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1e-7,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# estimator details for GradientBoostingr.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_GBC_pipeline = Pipeline([\n",
    "    ('clf_GBC', \n",
    "     clf_GBC) # GradientBoostingClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for GradientBoostingr.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_GBC_param_grid = {\n",
    "    # The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance. Values must be in the range [1, inf).\n",
    "#     'clf_GBC__n_estimators': [50, \n",
    "#                               100], \n",
    "    # Learning rate shrinks the contribution of each tree by learning_rate.\n",
    "    'clf_GBC__learning_rate': [0.05,\n",
    "                               0.1],\n",
    "    # Maximum depth of the individual regression estimators. \n",
    "    'clf_GBC__max_depth': [3, \n",
    "                           10],  \n",
    "    # The minimum number of samples required to split an internal node.\n",
    "#     'clf_GBC__min_samples_split': [2, \n",
    "#                                    5], \n",
    "    # The minimum number of samples required to be at a leaf node.\n",
    "    'clf_GBC__min_samples_leaf': [1, \n",
    "                                  3]  \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_GBC_pipeline,\n",
    "                                   param_grid=clf_GBC_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                    y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST AOC-RUC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_GBC_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_GBC_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_GBC_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f03914",
   "metadata": {},
   "source": [
    "# Model-5: SVC (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a130643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n",
      "..............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.020030, rho = 1.025093\n",
      "nSV = 3102, nBSV = 2958\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.018921, rho = 1.051148\n",
      "nSV = 3102, nBSV = 2959\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.900659, rho = 1.030529\n",
      "nSV = 3090, nBSV = 2978\n",
      "Total nSV = 3090\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.041500, rho = 1.019119\n",
      "nSV = 3105, nBSV = 2984\n",
      "Total nSV = 3105\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.415126, rho = -0.764647\n",
      "nSV = 3151, nBSV = 2997\n",
      "Total nSV = 3151\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.497153, rho = -0.856214\n",
      "nSV = 3157, nBSV = 2998\n",
      "Total nSV = 3157\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.937886, rho = 0.824264\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "obj = -60.001317, rho = 0.586182\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "......WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.102323, rho = 1.023415\n",
      "nSV = 3111, nBSV = 2967\n",
      "Total nSV = 3111\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.001973, rho = 1.022972\n",
      "nSV = 3102, nBSV = 2943\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.120281, rho = 1.015673\n",
      "nSV = 3112, nBSV = 2951\n",
      "Total nSV = 3112\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.041958, rho = 1.017725\n",
      "nSV = 3105, nBSV = 2966\n",
      "Total nSV = 3105\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.319390, rho = -0.861533\n",
      "nSV = 3138, nBSV = 2998\n",
      "Total nSV = 3138\n",
      "obj = -31.360949, rho = -0.781105\n",
      "nSV = 3147, nBSV = 2998\n",
      "Total nSV = 3147\n",
      "..............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.838539, rho = 1.038182\n",
      "nSV = 3085, nBSV = 2967\n",
      "Total nSV = 3085\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.878971, rho = 1.046456\n",
      "nSV = 3089, nBSV = 2935\n",
      "Total nSV = 3089\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.976706, rho = 1.039543\n",
      "nSV = 3099, nBSV = 2943\n",
      "Total nSV = 3099\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.793171, rho = 1.027323\n",
      "nSV = 3081, nBSV = 2943\n",
      "Total nSV = 3081\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.226863, rho = -0.769271\n",
      "nSV = 3133, nBSV = 2999\n",
      "Total nSV = 3133\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.317861, rho = -0.828632\n",
      "nSV = 3137, nBSV = 2998\n",
      "Total nSV = 3137\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -60.061293, rho = 0.606903\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.896162, rho = 0.654899\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "......WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.861151, rho = 1.075268\n",
      "nSV = 3086, nBSV = 2956\n",
      "Total nSV = 3086\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.979960, rho = 1.022844\n",
      "nSV = 3098, nBSV = 2978\n",
      "Total nSV = 3098\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.682122, rho = 1.037231\n",
      "nSV = 3068, nBSV = 2911\n",
      "Total nSV = 3068\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.780689, rho = 0.997273\n",
      "nSV = 3079, nBSV = 2971\n",
      "Total nSV = 3079\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.180638, rho = -0.858733\n",
      "nSV = 3124, nBSV = 2998\n",
      "Total nSV = 3124\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.377210, rho = -0.809705\n",
      "nSV = 3153, nBSV = 2999\n",
      "Total nSV = 3153\n",
      "..............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.946092, rho = 1.087992\n",
      "nSV = 3094, nBSV = 2921\n",
      "Total nSV = 3094\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.937205, rho = 1.029124\n",
      "nSV = 3095, nBSV = 2928\n",
      "Total nSV = 3095\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.060561, rho = 0.986504\n",
      "nSV = 3107, nBSV = 2984\n",
      "Total nSV = 3107\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.159926, rho = 1.002886\n",
      "nSV = 3117, nBSV = 2979\n",
      "Total nSV = 3117\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.681163, rho = -0.926702\n",
      "nSV = 3171, nBSV = 2998\n",
      "Total nSV = 3171\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.861001, rho = -0.867912\n",
      "nSV = 3198, nBSV = 2999\n",
      "Total nSV = 3198\n",
      "Line search fails in two-class probability estimates\n",
      "..........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -60.003226, rho = 0.137656\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.942149, rho = 0.673479\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -35.199445, rho = 0.325957\n",
      "nSV = 4585, nBSV = 3000\n",
      "Total nSV = 4585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -36.519616, rho = 0.201453\n",
      "nSV = 4670, nBSV = 2999\n",
      "Total nSV = 4670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -34.825756, rho = 0.366912\n",
      "nSV = 4555, nBSV = 2997\n",
      "Total nSV = 4555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -36.239115, rho = 0.227130\n",
      "nSV = 4663, nBSV = 2997\n",
      "Total nSV = 4663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -54.779973, rho = 0.981943\n",
      "nSV = 5478, nBSV = 2971\n",
      "Total nSV = 5478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -54.073748, rho = 0.973645\n",
      "nSV = 5408, nBSV = 2906\n",
      "Total nSV = 5408\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.203335, rho = -0.827760\n",
      "nSV = 3128, nBSV = 2999\n",
      "Total nSV = 3128\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.104237, rho = -0.519881\n",
      "nSV = 3140, nBSV = 2999\n",
      "Total nSV = 3140\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3152.593895, rho = 1.397104\n",
      "nSV = 3181, nBSV = 2877\n",
      "Total nSV = 3181\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3189.836351, rho = 1.687997\n",
      "nSV = 3191, nBSV = 2935\n",
      "Total nSV = 3191\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5933.788866, rho = 0.878833\n",
      "nSV = 5988, nBSV = 5988\n",
      "Total nSV = 5988\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6428.441211, rho = 0.650748\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.701288, rho = 0.821378\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.816774, rho = 0.589007\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.891529, rho = -0.460292\n",
      "nSV = 3118, nBSV = 2999\n",
      "Total nSV = 3118\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.367127, rho = -0.803275\n",
      "nSV = 3145, nBSV = 2998\n",
      "Total nSV = 3145\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3168.403762, rho = 1.665637\n",
      "nSV = 3180, nBSV = 2960\n",
      "Total nSV = 3180\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3200.351609, rho = 1.191254\n",
      "nSV = 3189, nBSV = 2872\n",
      "Total nSV = 3189\n",
      "............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.085608, rho = -0.580565\n",
      "nSV = 3128, nBSV = 2999\n",
      "Total nSV = 3128\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.380005, rho = -0.850187\n",
      "nSV = 3147, nBSV = 2999\n",
      "Total nSV = 3147\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3192.816276, rho = 1.481499\n",
      "nSV = 3177, nBSV = 2901\n",
      "Total nSV = 3177\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3159.527099, rho = 1.208885\n",
      "nSV = 3173, nBSV = 2870\n",
      "Total nSV = 3173\n",
      "....WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6214.433759, rho = 1.081703\n",
      "nSV = 5992, nBSV = 5992\n",
      "Total nSV = 5992\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6364.080290, rho = 0.608938\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "....WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -60.010750, rho = 0.159431\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.907922, rho = 0.633760\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.180430, rho = -0.838622\n",
      "nSV = 3126, nBSV = 2998\n",
      "Total nSV = 3126\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.639587, rho = -0.715300\n",
      "nSV = 3192, nBSV = 2999\n",
      "Total nSV = 3192\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3178.036410, rho = 1.581453\n",
      "nSV = 3166, nBSV = 2808\n",
      "Total nSV = 3166\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3236.070719, rho = 1.601887\n",
      "nSV = 3182, nBSV = 2921\n",
      "Total nSV = 3182\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.999142, rho = -0.018330\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.999224, rho = -0.006861\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.252877, rho = -0.795432\n",
      "nSV = 3134, nBSV = 3000\n",
      "Total nSV = 3134\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.775857, rho = -0.475139\n",
      "nSV = 3102, nBSV = 2993\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3175.093063, rho = 1.635692\n",
      "nSV = 3162, nBSV = 2781\n",
      "Total nSV = 3162\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3172.717946, rho = 1.565614\n",
      "nSV = 3193, nBSV = 2922\n",
      "Total nSV = 3193\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6567.177118, rho = 0.413296\n",
      "nSV = 5984, nBSV = 5984\n",
      "Total nSV = 5984\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6271.261859, rho = 1.007239\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3156.876113, rho = 1.709070\n",
      "nSV = 3184, nBSV = 2874\n",
      "Total nSV = 3184\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3197.412744, rho = 1.346691\n",
      "nSV = 3194, nBSV = 2741\n",
      "Total nSV = 3194\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.237260, rho = 0.977653\n",
      "nSV = 5324, nBSV = 2939\n",
      "Total nSV = 5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -54.040124, rho = 0.980466\n",
      "nSV = 5404, nBSV = 2894\n",
      "Total nSV = 5404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3803.551546, rho = -1.639404\n",
      "nSV = 4794, nBSV = 2996\n",
      "Total nSV = 4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3830.410256, rho = -1.313776\n",
      "nSV = 4816, nBSV = 2997\n",
      "Total nSV = 4816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "..............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3152.736591, rho = -0.041344\n",
      "nSV = 3094, nBSV = 2995\n",
      "Total nSV = 3094\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3164.351703, rho = 0.065784\n",
      "nSV = 3132, nBSV = 2993\n",
      "Total nSV = 3132\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3206.971257, rho = 1.101467\n",
      "nSV = 3172, nBSV = 2862\n",
      "Total nSV = 3172\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3223.376041, rho = 1.624831\n",
      "nSV = 3194, nBSV = 2782\n",
      "Total nSV = 3194\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3120.583644, rho = 0.196071\n",
      "nSV = 3136, nBSV = 2989\n",
      "Total nSV = 3136\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3173.884809, rho = -0.613177\n",
      "nSV = 3204, nBSV = 2994\n",
      "Total nSV = 3204\n",
      "............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6137.884118, rho = 1.458613\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6112.403157, rho = 1.347118\n",
      "nSV = 5988, nBSV = 5988\n",
      "Total nSV = 5988\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3108.891265, rho = 0.483025\n",
      "nSV = 3127, nBSV = 2993\n",
      "Total nSV = 3127\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3107.964627, rho = 0.230068\n",
      "nSV = 3134, nBSV = 2988\n",
      "Total nSV = 3134\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3136.235890, rho = 1.456970\n",
      "nSV = 3189, nBSV = 2850\n",
      "Total nSV = 3189\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3199.197444, rho = 1.129553\n",
      "nSV = 3192, nBSV = 2965\n",
      "Total nSV = 3192\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3055.986244, rho = -0.322714\n",
      "nSV = 3106, nBSV = 2990\n",
      "Total nSV = 3106\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3282.027357, rho = -0.771095\n",
      "nSV = 3141, nBSV = 2990\n",
      "Total nSV = 3141\n",
      ".............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3148.622296, rho = -0.230700\n",
      "nSV = 3097, nBSV = 2994\n",
      "Total nSV = 3097\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3131.195992, rho = -0.016541\n",
      "nSV = 3122, nBSV = 2994\n",
      "Total nSV = 3122\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3211.958356, rho = 1.740604\n",
      "nSV = 3178, nBSV = 2873\n",
      "Total nSV = 3178\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3206.629912, rho = 1.567756\n",
      "nSV = 3206, nBSV = 2990\n",
      "Total nSV = 3206\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3147.280127, rho = -0.089831\n",
      "nSV = 3152, nBSV = 2992\n",
      "Total nSV = 3152\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3202.736601, rho = -1.109273\n",
      "nSV = 3202, nBSV = 2995\n",
      "Total nSV = 3202\n",
      ".....WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6075.798379, rho = 0.963512\n",
      "nSV = 5988, nBSV = 5988\n",
      "Total nSV = 5988\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6301.633809, rho = 0.501606\n",
      "nSV = 5992, nBSV = 5992\n",
      "Total nSV = 5992\n",
      ".....WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3139.734155, rho = 0.624958\n",
      "nSV = 3153, nBSV = 2989\n",
      "Total nSV = 3153\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3170.459092, rho = 0.308717\n",
      "nSV = 3169, nBSV = 2987\n",
      "Total nSV = 3169\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3190.695588, rho = 1.658320\n",
      "nSV = 3198, nBSV = 2873\n",
      "Total nSV = 3198\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3219.327228, rho = 1.556583\n",
      "nSV = 3179, nBSV = 2896\n",
      "Total nSV = 3179\n",
      "Line search fails in two-class probability estimates\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3111.825367, rho = 0.488373\n",
      "nSV = 3122, nBSV = 2990\n",
      "Total nSV = 3122\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3198.095291, rho = -0.882547\n",
      "nSV = 3215, nBSV = 2994\n",
      "Total nSV = 3215\n",
      "......WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5998.484715, rho = -0.282579\n",
      "nSV = 6000, nBSV = 5998\n",
      "Total nSV = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5997.243963, rho = -0.761115\n",
      "nSV = 6000, nBSV = 5996\n",
      "Total nSV = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3817.753168, rho = -1.058626\n",
      "nSV = 4792, nBSV = 2995\n",
      "Total nSV = 4792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3792.139938, rho = -0.924472\n",
      "nSV = 4755, nBSV = 2997\n",
      "Total nSV = 4755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3180.655105, rho = 0.290215\n",
      "nSV = 3179, nBSV = 2994\n",
      "Total nSV = 3179\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3144.096195, rho = 0.297693\n",
      "nSV = 3137, nBSV = 2987\n",
      "Total nSV = 3137\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3151.022208, rho = 0.531486\n",
      "nSV = 3154, nBSV = 2991\n",
      "Total nSV = 3154\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3168.452632, rho = -1.206148\n",
      "nSV = 3190, nBSV = 2994\n",
      "Total nSV = 3190\n",
      "...WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5567.084688, rho = 0.069096\n",
      "nSV = 5563, nBSV = 2977\n",
      "Total nSV = 5563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5568.476488, rho = -0.265609\n",
      "nSV = 5570, nBSV = 2997\n",
      "Total nSV = 5570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".1 tree, 31 leaves, max depth = 9, train loss: 0.00275, val loss: 0.00350, in 0.321s\n",
      "Fit 200 trees in 97.002 s, (6200 total leaves)\n",
      "Time spent computing histograms: 56.905s\n",
      "Time spent finding best splits:  1.750s\n",
      "Time spent applying splits:      11.562s\n",
      "Time spent predicting:           0.807s\n",
      "[LibSVM][LibSVM]WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5522.408134, rho = -0.318461\n",
      "nSV = 5522, nBSV = 2979\n",
      "Total nSV = 5522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".1 tree, 31 leaves, max depth = 10, train loss: 0.00268, val loss: 0.00350, in 0.193s\n",
      "Fit 200 trees in 51.981 s, (6200 total leaves)\n",
      "Time spent computing histograms: 30.153s\n",
      "Time spent finding best splits:  0.875s\n",
      "Time spent applying splits:      6.000s\n",
      "Time spent predicting:           0.354s\n",
      "[LibSVM][LibSVM]WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5279.824106, rho = 0.060093\n",
      "nSV = 5268, nBSV = 2968\n",
      "Total nSV = 5268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([2850.54418797, 2724.2780977 ]), 'std_fit_time': array([798.80324485, 829.22396878]), 'mean_score_time': array([35.37918861, 25.30690477]), 'std_score_time': array([2.16431788, 8.26817169]), 'param_clf_csv__C': masked_array(data=[0.01, 1],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_csv__kernel': masked_array(data=['linear', 'linear'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_csv__C': 0.01, 'clf_csv__kernel': 'linear'}, {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}], 'split0_test_accuracy': array([0.77386141, 0.68177371]), 'split1_test_accuracy': array([0.68230742, 0.65388721]), 'split2_test_accuracy': array([0.49998888, 0.77476816]), 'split3_test_accuracy': array([0.49998888, 0.75143994]), 'split4_test_accuracy': array([0.49998888, 0.70820824]), 'split5_test_accuracy': array([0.49998888, 0.69760046]), 'split6_test_accuracy': array([0.50001112, 0.55716414]), 'split7_test_accuracy': array([0.50001112, 0.55629684]), 'split8_test_accuracy': array([0.50001112, 0.56032201]), 'split9_test_accuracy': array([0.50001112, 0.53701603]), 'mean_test_accuracy': array([0.54561688, 0.64784768]), 'std_test_accuracy': array([0.09350244, 0.0840808 ]), 'rank_test_accuracy': array([2, 1], dtype=int32), 'split0_test_precision': array([0.73114606, 0.62140566]), 'split1_test_precision': array([0.64508707, 0.599431  ]), 'split2_test_precision': array([0.49998888, 0.8717131 ]), 'split3_test_precision': array([0.49998888, 0.80999123]), 'split4_test_precision': array([0.49998888, 0.71853408]), 'split5_test_precision': array([0.49998888, 0.67186352]), 'split6_test_precision': array([0.50001112, 0.53032054]), 'split7_test_precision': array([0.50001112, 0.52983316]), 'split8_test_precision': array([0.50001112, 0.53210271]), 'split9_test_precision': array([0.50001112, 0.519225  ]), 'mean_test_precision': array([0.53762331, 0.640442  ]), 'std_test_precision': array([0.07766829, 0.11922887]), 'rank_test_precision': array([2, 1], dtype=int32), 'split0_test_recall': array([0.86626045, 0.93039495]), 'split1_test_recall': array([0.81057641, 0.92772638]), 'split2_test_recall': array([1.        , 0.64435351]), 'split3_test_recall': array([1.        , 0.65698528]), 'split4_test_recall': array([1.        , 0.68456167]), 'split5_test_recall': array([1.       , 0.7724503]), 'split6_test_recall': array([1., 1.]), 'split7_test_recall': array([1., 1.]), 'split8_test_recall': array([1., 1.]), 'split9_test_recall': array([1., 1.]), 'mean_test_recall': array([0.96768369, 0.86164721]), 'std_test_recall': array([0.06582106, 0.14631375]), 'rank_test_recall': array([1, 2], dtype=int32), 'split0_test_roc_auc': array([0.87076984, 0.87892524]), 'split1_test_roc_auc': array([0.78602738, 0.81895379]), 'split2_test_roc_auc': array([0.82979197, 0.8779586 ]), 'split3_test_roc_auc': array([0.88318103, 0.85567176]), 'split4_test_roc_auc': array([0.87982426, 0.76906076]), 'split5_test_roc_auc': array([0.79749347, 0.74675676]), 'split6_test_roc_auc': array([0.86091956, 0.82155773]), 'split7_test_roc_auc': array([0.79222901, 0.7451151 ]), 'split8_test_roc_auc': array([0.81112846, 0.8081871 ]), 'split9_test_roc_auc': array([0.8502191 , 0.67541908]), 'mean_test_roc_auc': array([0.83615841, 0.79976059]), 'std_test_roc_auc': array([0.03568126, 0.06214608]), 'rank_test_roc_auc': array([1, 2], dtype=int32), 'split0_test_f1': array([0.79298903, 0.74513785]), 'split1_test_f1': array([0.71842479, 0.72829161]), 'split2_test_f1': array([0.66665678, 0.74098512]), 'split3_test_f1': array([0.66665678, 0.72550898]), 'split4_test_f1': array([0.66665678, 0.7011366 ]), 'split5_test_f1': array([0.66665678, 0.71865431]), 'split6_test_f1': array([0.66667655, 0.69308426]), 'split7_test_f1': array([0.66667655, 0.6926679 ]), 'split8_test_f1': array([0.66667655, 0.69460449]), 'split9_test_f1': array([0.66667655, 0.6835393 ]), 'mean_test_f1': array([0.68447471, 0.71236104]), 'std_test_f1': array([0.03932553, 0.02095544]), 'rank_test_f1': array([2, 1], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST AOC-RUC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_csv__C': 0.01, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM]1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00354, in 0.328s\n",
      "Fit 200 trees in 97.751 s, (6200 total leaves)\n",
      "Time spent computing histograms: 57.297s\n",
      "Time spent finding best splits:  1.757s\n",
      "Time spent applying splits:      11.725s\n",
      "Time spent predicting:           0.875s\n",
      "[LibSVM][LibSVM]1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00337, in 0.189s\n",
      "Fit 200 trees in 50.755 s, (6200 total leaves)\n",
      "Time spent computing histograms: 29.339s\n",
      "Time spent finding best splits:  0.850s\n",
      "Time spent applying splits:      6.055s\n",
      "Time spent predicting:           0.350s\n",
      "[LibSVM][LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.794258, rho = 0.647591\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00365, in 0.360s\n",
      "Fit 200 trees in 97.371 s, (6200 total leaves)\n",
      "Time spent computing histograms: 57.810s\n",
      "Time spent finding best splits:  1.664s\n",
      "Time spent applying splits:      11.007s\n",
      "Time spent predicting:           0.754s\n",
      "[LibSVM][LibSVM][LibSVM]1 tree, 31 leaves, max depth = 9, train loss: 0.00258, val loss: 0.00349, in 0.180s\n",
      "Fit 200 trees in 51.586 s, (6200 total leaves)\n",
      "Time spent computing histograms: 29.981s\n",
      "Time spent finding best splits:  0.880s\n",
      "Time spent applying splits:      5.977s\n",
      "Time spent predicting:           0.348s\n",
      "[LibSVM][LibSVM][LibSVM]1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00389, in 0.186s\n",
      "Fit 200 trees in 52.109 s, (6200 total leaves)\n",
      "Time spent computing histograms: 30.168s\n",
      "Time spent finding best splits:  0.887s\n",
      "Time spent applying splits:      6.072s\n",
      "Time spent predicting:           0.367s\n",
      "[LibSVM][LibSVM][LibSVM]1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00318, in 0.356s\n",
      "Fit 200 trees in 97.794 s, (6200 total leaves)\n",
      "Time spent computing histograms: 58.234s\n",
      "Time spent finding best splits:  1.666s\n",
      "Time spent applying splits:      11.190s\n",
      "Time spent predicting:           0.868s\n",
      "[LibSVM][LibSVM][LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.837752, rho = 0.697182\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.830065, rho = 0.753750\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.974468, rho = 0.198894\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.836304, rho = 0.856104\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -59.998983, rho = -0.005715\n",
      "nSV = 6000, nBSV = 6000\n",
      "Total nSV = 6000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.71      0.83     74946\n",
      "           1       0.00      0.81      0.00        54\n",
      "\n",
      "    accuracy                           0.71     75000\n",
      "   macro avg       0.50      0.76      0.42     75000\n",
      "weighted avg       1.00      0.71      0.83     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8491\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.7123\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0041\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6209.063099, rho = 0.811044\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6191.828963, rho = 1.183697\n",
      "nSV = 5980, nBSV = 5980\n",
      "Total nSV = 5980\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5959.120741, rho = 0.161598\n",
      "nSV = 5958, nBSV = 5958\n",
      "Total nSV = 5958\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6471.104585, rho = 0.422503\n",
      "nSV = 5992, nBSV = 5992\n",
      "Total nSV = 5992\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6559.730246, rho = 0.715842\n",
      "nSV = 5980, nBSV = 5980\n",
      "Total nSV = 5980\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5995.029511, rho = -0.516915\n",
      "nSV = 5999, nBSV = 5989\n",
      "Total nSV = 5999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32     74946\n",
      "           1       0.00      0.96      0.00        54\n",
      "\n",
      "    accuracy                           0.19     75000\n",
      "   macro avg       0.50      0.58      0.16     75000\n",
      "weighted avg       1.00      0.19      0.32     75000\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8518\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.1890\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0017\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6209.063099, rho = 0.811044\n",
      "nSV = 5990, nBSV = 5990\n",
      "Total nSV = 5990\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6191.828963, rho = 1.183697\n",
      "nSV = 5980, nBSV = 5980\n",
      "Total nSV = 5980\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5959.120741, rho = 0.161598\n",
      "nSV = 5958, nBSV = 5958\n",
      "Total nSV = 5958\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6471.104585, rho = 0.422503\n",
      "nSV = 5992, nBSV = 5992\n",
      "Total nSV = 5992\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -6559.730246, rho = 0.715842\n",
      "nSV = 5980, nBSV = 5980\n",
      "Total nSV = 5980\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5995.029511, rho = -0.516915\n",
      "nSV = 5999, nBSV = 5989\n",
      "Total nSV = 5999\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:299: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.19      0.32     74946\n",
      "           1       0.00      0.96      0.00        54\n",
      "\n",
      "    accuracy                           0.19     75000\n",
      "   macro avg       0.50      0.58      0.16     75000\n",
      "weighted avg       1.00      0.19      0.32     75000\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8518\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.1890\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0017\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "clf_csv = SVC(class_weight='balanced',\n",
    "              degree=3, \n",
    "              coef0=0.0, \n",
    "              shrinking=True, \n",
    "              tol=0.001, \n",
    "              cache_size=700, \n",
    "              verbose=1, \n",
    "              max_iter=3000, \n",
    "              decision_function_shape='ovr', \n",
    "              break_ties=False,\n",
    "              probability=True, \n",
    "              random_state=42)\n",
    "\n",
    "# estimator details for pipeline.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_csv_pipeline = Pipeline([\n",
    "    ('clf_csv', \n",
    "     clf_csv) # SVC\n",
    "])\n",
    "\n",
    "# Parameter details for SVC.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_csv_param_grid = {\n",
    "    # Regularization parameter. \n",
    "    'clf_csv__C': [0.01, 1],\n",
    "    # Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. But, rbf takes too much time to run. So, I used linear.\n",
    "    'clf_csv__kernel': ['linear'],  \n",
    "    # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. if ‘auto’, uses 1 / n_features.\n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_csv_pipeline,\n",
    "                                   param_grid=clf_csv_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                        y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST AOC-RUC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_csv_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_csv_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_csv_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                             y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "21424ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    74946\n",
       "1       54\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5be951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
