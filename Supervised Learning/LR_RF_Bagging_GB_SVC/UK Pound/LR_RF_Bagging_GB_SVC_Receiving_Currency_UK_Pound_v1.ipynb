{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03426497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b3eb5d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: HI_Small_Trans (shape: (5078345, 11))\n",
      "Loaded: LI_Small_Trans (shape: (6924049, 11))\n"
     ]
    }
   ],
   "source": [
    "# (My Code from ITMD 522 - HW#2)\n",
    "\n",
    "# import pandas as pd.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Folder path: '/Users/harshpatel/Desktop/MS-ITM/ITMD 524/project_dataset'\n",
    "folder_path = Path('/Users/harshpatel/Desktop/MS-ITM/ITMD 524/project_dataset')  \n",
    "\n",
    "# Read the excel file and specific 'Data' spreadsheet from CSV file. Get all CSV files in the folder.\n",
    "# pandas.read_csv(filepath_or_buffer, *, sep=<no_default>, delimiter=None, header='infer', names=<no_default>, index_col=None, usecols=None, dtype=None, engine=None, converters=None, true_values=None, false_values=None, skipinitialspace=False, skiprows=None, skipfooter=0, nrows=None, na_values=None, keep_default_na=True, na_filter=True, verbose=<no_default>, skip_blank_lines=True, parse_dates=None, infer_datetime_format=<no_default>, keep_date_col=<no_default>, date_parser=<no_default>, date_format=None, dayfirst=False, cache_dates=True, iterator=False, chunksize=None, compression='infer', thousands=None, decimal='.', lineterminator=None, quotechar='\"', quoting=0, doublequote=True, escapechar=None, comment=None, encoding=None, encoding_errors='strict', dialect=None, on_bad_lines='error', delim_whitespace=<no_default>, low_memory=True, memory_map=False, float_precision=None, storage_options=None, dtype_backend=<no_default>)\n",
    "# csv_files = [f for f in folder_path.glob('*.csv') if 'Small' in f.name]\n",
    "csv_files = [f for f in folder_path.glob('*.csv') if 'Small' in f.name]\n",
    "\n",
    "# To assign names for each datafile as a dataframe.\n",
    "for file in csv_files:\n",
    "    var_name = file.stem.replace(\" \", \"_\").replace(\"-\", \"_\")\n",
    "    globals()[var_name] = pd.read_csv(file)\n",
    "    print(f\"Loaded: {var_name} (shape: {globals()[var_name].shape})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eef1c6c",
   "metadata": {},
   "source": [
    "# HI_Small_Trans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd6c82ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:08</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:21</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>1120</td>\n",
       "      <td>8006AA910</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924044</th>\n",
       "      <td>2022/09/10 23:39</td>\n",
       "      <td>71696</td>\n",
       "      <td>81B2518F1</td>\n",
       "      <td>71528</td>\n",
       "      <td>81C0482E1</td>\n",
       "      <td>3.346900e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.346900e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924045</th>\n",
       "      <td>2022/09/10 23:48</td>\n",
       "      <td>271241</td>\n",
       "      <td>81B567481</td>\n",
       "      <td>173457</td>\n",
       "      <td>81C0DA751</td>\n",
       "      <td>1.313000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.313000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924046</th>\n",
       "      <td>2022/09/10 23:50</td>\n",
       "      <td>271241</td>\n",
       "      <td>81B567481</td>\n",
       "      <td>173457</td>\n",
       "      <td>81C0DA751</td>\n",
       "      <td>1.305800e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.305800e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924047</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>170558</td>\n",
       "      <td>81A2206B1</td>\n",
       "      <td>275798</td>\n",
       "      <td>81C1D5CA1</td>\n",
       "      <td>4.145370e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>4.145370e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6924048</th>\n",
       "      <td>2022/09/10 23:31</td>\n",
       "      <td>170558</td>\n",
       "      <td>81A2206B1</td>\n",
       "      <td>275798</td>\n",
       "      <td>81C1D5CA1</td>\n",
       "      <td>3.427700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.427700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6924049 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0        2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
       "1        2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
       "2        2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
       "3        2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
       "4        2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
       "...                   ...        ...        ...      ...        ...   \n",
       "6924044  2022/09/10 23:39      71696  81B2518F1    71528  81C0482E1   \n",
       "6924045  2022/09/10 23:48     271241  81B567481   173457  81C0DA751   \n",
       "6924046  2022/09/10 23:50     271241  81B567481   173457  81C0DA751   \n",
       "6924047  2022/09/10 23:57     170558  81A2206B1   275798  81C1D5CA1   \n",
       "6924048  2022/09/10 23:31     170558  81A2206B1   275798  81C1D5CA1   \n",
       "\n",
       "         Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0           3.195403e+06          US Dollar  3.195403e+06        US Dollar   \n",
       "1           1.858960e+03          US Dollar  1.858960e+03        US Dollar   \n",
       "2           5.925710e+05          US Dollar  5.925710e+05        US Dollar   \n",
       "3           1.232000e+01          US Dollar  1.232000e+01        US Dollar   \n",
       "4           2.941560e+03          US Dollar  2.941560e+03        US Dollar   \n",
       "...                  ...                ...           ...              ...   \n",
       "6924044     3.346900e-02            Bitcoin  3.346900e-02          Bitcoin   \n",
       "6924045     1.313000e-03            Bitcoin  1.313000e-03          Bitcoin   \n",
       "6924046     1.305800e-02            Bitcoin  1.305800e-02          Bitcoin   \n",
       "6924047     4.145370e-01            Bitcoin  4.145370e-01          Bitcoin   \n",
       "6924048     3.427700e-02            Bitcoin  3.427700e-02          Bitcoin   \n",
       "\n",
       "        Payment Format  Is Laundering  \n",
       "0         Reinvestment              0  \n",
       "1         Reinvestment              0  \n",
       "2               Cheque              0  \n",
       "3         Reinvestment              0  \n",
       "4         Reinvestment              0  \n",
       "...                ...            ...  \n",
       "6924044        Bitcoin              0  \n",
       "6924045        Bitcoin              0  \n",
       "6924046        Bitcoin              0  \n",
       "6924047        Bitcoin              0  \n",
       "6924048        Bitcoin              0  \n",
       "\n",
       "[6924049 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LI_Small_Trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "829b89a8",
   "metadata": {},
   "source": [
    "# LI_Small_Trans dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3978ffb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>10</td>\n",
       "      <td>8000EBD30</td>\n",
       "      <td>3697.340000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3697.340000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:20</td>\n",
       "      <td>3208</td>\n",
       "      <td>8000F4580</td>\n",
       "      <td>1</td>\n",
       "      <td>8000F5340</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>3209</td>\n",
       "      <td>8000F4670</td>\n",
       "      <td>14675.570000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>14675.570000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:02</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>12</td>\n",
       "      <td>8000F5030</td>\n",
       "      <td>2806.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2806.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:06</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>10</td>\n",
       "      <td>8000F5200</td>\n",
       "      <td>36682.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>36682.970000</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078340</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>54219</td>\n",
       "      <td>8148A6631</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.154978</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078341</th>\n",
       "      <td>2022/09/10 23:35</td>\n",
       "      <td>15</td>\n",
       "      <td>8148A8671</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.108128</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.108128</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078342</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>154365</td>\n",
       "      <td>8148A6771</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.004988</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078343</th>\n",
       "      <td>2022/09/10 23:46</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A6311</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.038417</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5078344</th>\n",
       "      <td>2022/09/10 23:37</td>\n",
       "      <td>154518</td>\n",
       "      <td>8148A6091</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>0.281983</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0.281983</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5078345 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0        2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
       "1        2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
       "2        2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
       "3        2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
       "4        2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
       "...                   ...        ...        ...      ...        ...   \n",
       "5078340  2022/09/10 23:57      54219  8148A6631   256398  8148A8711   \n",
       "5078341  2022/09/10 23:35         15  8148A8671   256398  8148A8711   \n",
       "5078342  2022/09/10 23:52     154365  8148A6771   256398  8148A8711   \n",
       "5078343  2022/09/10 23:46     256398  8148A6311   256398  8148A8711   \n",
       "5078344  2022/09/10 23:37     154518  8148A6091   256398  8148A8711   \n",
       "\n",
       "         Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0            3697.340000          US Dollar   3697.340000        US Dollar   \n",
       "1               0.010000          US Dollar      0.010000        US Dollar   \n",
       "2           14675.570000          US Dollar  14675.570000        US Dollar   \n",
       "3            2806.970000          US Dollar   2806.970000        US Dollar   \n",
       "4           36682.970000          US Dollar  36682.970000        US Dollar   \n",
       "...                  ...                ...           ...              ...   \n",
       "5078340         0.154978            Bitcoin      0.154978          Bitcoin   \n",
       "5078341         0.108128            Bitcoin      0.108128          Bitcoin   \n",
       "5078342         0.004988            Bitcoin      0.004988          Bitcoin   \n",
       "5078343         0.038417            Bitcoin      0.038417          Bitcoin   \n",
       "5078344         0.281983            Bitcoin      0.281983          Bitcoin   \n",
       "\n",
       "        Payment Format  Is Laundering  \n",
       "0         Reinvestment              0  \n",
       "1               Cheque              0  \n",
       "2         Reinvestment              0  \n",
       "3         Reinvestment              0  \n",
       "4         Reinvestment              0  \n",
       "...                ...            ...  \n",
       "5078340        Bitcoin              0  \n",
       "5078341        Bitcoin              0  \n",
       "5078342        Bitcoin              0  \n",
       "5078343        Bitcoin              0  \n",
       "5078344        Bitcoin              0  \n",
       "\n",
       "[5078345 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "HI_Small_Trans"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259f4376",
   "metadata": {},
   "source": [
    "# Merge two dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eec4ac62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022/09/01 00:08</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>3.195403e+06</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022/09/01 00:21</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>3402</td>\n",
       "      <td>80021DAD0</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.858960e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>8000ECA90</td>\n",
       "      <td>1120</td>\n",
       "      <td>8006AA910</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>5.925710e+05</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>3814</td>\n",
       "      <td>8006AD080</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>1.232000e+01</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022/09/01 00:00</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>20</td>\n",
       "      <td>8006AD530</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>2.941560e+03</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>Reinvestment</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002389</th>\n",
       "      <td>2022/09/10 23:57</td>\n",
       "      <td>54219</td>\n",
       "      <td>8148A6631</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>1.549780e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.549780e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002390</th>\n",
       "      <td>2022/09/10 23:35</td>\n",
       "      <td>15</td>\n",
       "      <td>8148A8671</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>1.081280e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>1.081280e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002391</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>154365</td>\n",
       "      <td>8148A6771</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>4.988000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>4.988000e-03</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002392</th>\n",
       "      <td>2022/09/10 23:46</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A6311</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>3.841700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>3.841700e-02</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12002393</th>\n",
       "      <td>2022/09/10 23:37</td>\n",
       "      <td>154518</td>\n",
       "      <td>8148A6091</td>\n",
       "      <td>256398</td>\n",
       "      <td>8148A8711</td>\n",
       "      <td>2.819830e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>2.819830e-01</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>Bitcoin</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12002394 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "0         2022/09/01 00:08         11  8000ECA90       11  8000ECA90   \n",
       "1         2022/09/01 00:21       3402  80021DAD0     3402  80021DAD0   \n",
       "2         2022/09/01 00:00         11  8000ECA90     1120  8006AA910   \n",
       "3         2022/09/01 00:16       3814  8006AD080     3814  8006AD080   \n",
       "4         2022/09/01 00:00         20  8006AD530       20  8006AD530   \n",
       "...                    ...        ...        ...      ...        ...   \n",
       "12002389  2022/09/10 23:57      54219  8148A6631   256398  8148A8711   \n",
       "12002390  2022/09/10 23:35         15  8148A8671   256398  8148A8711   \n",
       "12002391  2022/09/10 23:52     154365  8148A6771   256398  8148A8711   \n",
       "12002392  2022/09/10 23:46     256398  8148A6311   256398  8148A8711   \n",
       "12002393  2022/09/10 23:37     154518  8148A6091   256398  8148A8711   \n",
       "\n",
       "          Amount Received Receiving Currency   Amount Paid Payment Currency  \\\n",
       "0            3.195403e+06          US Dollar  3.195403e+06        US Dollar   \n",
       "1            1.858960e+03          US Dollar  1.858960e+03        US Dollar   \n",
       "2            5.925710e+05          US Dollar  5.925710e+05        US Dollar   \n",
       "3            1.232000e+01          US Dollar  1.232000e+01        US Dollar   \n",
       "4            2.941560e+03          US Dollar  2.941560e+03        US Dollar   \n",
       "...                   ...                ...           ...              ...   \n",
       "12002389     1.549780e-01            Bitcoin  1.549780e-01          Bitcoin   \n",
       "12002390     1.081280e-01            Bitcoin  1.081280e-01          Bitcoin   \n",
       "12002391     4.988000e-03            Bitcoin  4.988000e-03          Bitcoin   \n",
       "12002392     3.841700e-02            Bitcoin  3.841700e-02          Bitcoin   \n",
       "12002393     2.819830e-01            Bitcoin  2.819830e-01          Bitcoin   \n",
       "\n",
       "         Payment Format  Is Laundering  \n",
       "0          Reinvestment              0  \n",
       "1          Reinvestment              0  \n",
       "2                Cheque              0  \n",
       "3          Reinvestment              0  \n",
       "4          Reinvestment              0  \n",
       "...                 ...            ...  \n",
       "12002389        Bitcoin              0  \n",
       "12002390        Bitcoin              0  \n",
       "12002391        Bitcoin              0  \n",
       "12002392        Bitcoin              0  \n",
       "12002393        Bitcoin              0  \n",
       "\n",
       "[12002394 rows x 11 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12002394 entries, 0 to 12002393\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   Timestamp           object \n",
      " 1   From Bank           int64  \n",
      " 2   Account             object \n",
      " 3   To Bank             int64  \n",
      " 4   Account.1           object \n",
      " 5   Amount Received     float64\n",
      " 6   Receiving Currency  object \n",
      " 7   Amount Paid         float64\n",
      " 8   Payment Currency    object \n",
      " 9   Payment Format      object \n",
      " 10  Is Laundering       int64  \n",
      "dtypes: float64(2), int64(3), object(6)\n",
      "memory usage: 1007.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp               15133\n",
       "From Bank               57222\n",
       "Account               1166980\n",
       "To Bank                 33608\n",
       "Account.1              988911\n",
       "Amount Received       1835635\n",
       "Receiving Currency         15\n",
       "Amount Paid           1850741\n",
       "Payment Currency           15\n",
       "Payment Format              7\n",
       "Is Laundering               2\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    11993652\n",
      "1        8742\n",
      "Name: Is Laundering, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Is Laundering</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>18.76</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>133936</td>\n",
       "      <td>815FF9670</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60425</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>45.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60426</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>35358</td>\n",
       "      <td>80CF6C5E0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63557</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>18903</td>\n",
       "      <td>809F0F740</td>\n",
       "      <td>18903</td>\n",
       "      <td>809F0F740</td>\n",
       "      <td>70.29</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>90.80</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001610</th>\n",
       "      <td>2022/09/10 23:30</td>\n",
       "      <td>26</td>\n",
       "      <td>808B34470</td>\n",
       "      <td>121580</td>\n",
       "      <td>8138107B0</td>\n",
       "      <td>434.16</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>434.16</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001611</th>\n",
       "      <td>2022/09/10 23:45</td>\n",
       "      <td>21568</td>\n",
       "      <td>8089D7850</td>\n",
       "      <td>21884</td>\n",
       "      <td>8138145E0</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001612</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>124.80</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>124.80</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001613</th>\n",
       "      <td>2022/09/10 23:33</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>19.01</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>19.01</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001614</th>\n",
       "      <td>2022/09/10 23:36</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>20.54</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>20.54</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279255 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "12948     2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
       "12949     2022/09/01 00:17       1439  8014545C0   133936  815FF9670   \n",
       "60425     2022/09/01 00:16      13210  809570DE0    13210  809570DE0   \n",
       "60426     2022/09/01 00:16      13210  809570DE0    35358  80CF6C5E0   \n",
       "63557     2022/09/01 00:17      18903  809F0F740    18903  809F0F740   \n",
       "...                    ...        ...        ...      ...        ...   \n",
       "12001610  2022/09/10 23:30         26  808B34470   121580  8138107B0   \n",
       "12001611  2022/09/10 23:45      21568  8089D7850    21884  8138145E0   \n",
       "12001612  2022/09/10 23:52      23700  81381D5A0    23700  8138E9020   \n",
       "12001613  2022/09/10 23:33      23700  81381D5A0    23700  8138E9020   \n",
       "12001614  2022/09/10 23:36      23700  81381D5A0    23700  8138E9020   \n",
       "\n",
       "          Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "12948               14.52           UK Pound        18.76        US Dollar   \n",
       "12949               14.52           UK Pound        14.52         UK Pound   \n",
       "60425               35.10           UK Pound        45.34        US Dollar   \n",
       "60426               35.10           UK Pound        35.10         UK Pound   \n",
       "63557               70.29           UK Pound        90.80        US Dollar   \n",
       "...                   ...                ...          ...              ...   \n",
       "12001610           434.16           UK Pound       434.16         UK Pound   \n",
       "12001611         19098.02           UK Pound     19098.02         UK Pound   \n",
       "12001612           124.80           UK Pound       124.80         UK Pound   \n",
       "12001613            19.01           UK Pound        19.01         UK Pound   \n",
       "12001614            20.54           UK Pound        20.54         UK Pound   \n",
       "\n",
       "         Payment Format  Is Laundering  \n",
       "12948               ACH              0  \n",
       "12949       Credit Card              0  \n",
       "60425               ACH              0  \n",
       "60426       Credit Card              0  \n",
       "63557               ACH              0  \n",
       "...                 ...            ...  \n",
       "12001610    Credit Card              0  \n",
       "12001611         Cheque              0  \n",
       "12001612         Cheque              0  \n",
       "12001613    Credit Card              0  \n",
       "12001614            ACH              0  \n",
       "\n",
       "[279255 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_Small_df = pd.concat([LI_Small_Trans, HI_Small_Trans], ignore_index=True)\n",
    "display(merged_Small_df)\n",
    "display(merged_Small_df.info())\n",
    "display(merged_Small_df.nunique())\n",
    "value_counts = merged_Small_df['Is Laundering'].value_counts()\n",
    "print(value_counts)\n",
    "\n",
    "merged_Small_df = merged_Small_df[merged_Small_df['Receiving Currency'] == 'UK Pound']\n",
    "merged_Small_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23ae0ee",
   "metadata": {},
   "source": [
    "# X independent and Y dependent variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7f3f50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>From Bank</th>\n",
       "      <th>Account</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Account.1</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Receiving Currency</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>Payment Currency</th>\n",
       "      <th>Payment Format</th>\n",
       "      <th>Account_Grouped</th>\n",
       "      <th>Account1_Grouped</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>18.76</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>45C0</td>\n",
       "      <td>45C0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>1439</td>\n",
       "      <td>8014545C0</td>\n",
       "      <td>133936</td>\n",
       "      <td>815FF9670</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>14.52</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>45C0</td>\n",
       "      <td>9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60425</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>45.34</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>0DE0</td>\n",
       "      <td>0DE0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60426</th>\n",
       "      <td>2022/09/01 00:16</td>\n",
       "      <td>13210</td>\n",
       "      <td>809570DE0</td>\n",
       "      <td>35358</td>\n",
       "      <td>80CF6C5E0</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>35.10</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>0DE0</td>\n",
       "      <td>C5E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63557</th>\n",
       "      <td>2022/09/01 00:17</td>\n",
       "      <td>18903</td>\n",
       "      <td>809F0F740</td>\n",
       "      <td>18903</td>\n",
       "      <td>809F0F740</td>\n",
       "      <td>70.29</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>90.80</td>\n",
       "      <td>US Dollar</td>\n",
       "      <td>ACH</td>\n",
       "      <td>F740</td>\n",
       "      <td>F740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001610</th>\n",
       "      <td>2022/09/10 23:30</td>\n",
       "      <td>26</td>\n",
       "      <td>808B34470</td>\n",
       "      <td>121580</td>\n",
       "      <td>8138107B0</td>\n",
       "      <td>434.16</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>434.16</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>4470</td>\n",
       "      <td>07B0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001611</th>\n",
       "      <td>2022/09/10 23:45</td>\n",
       "      <td>21568</td>\n",
       "      <td>8089D7850</td>\n",
       "      <td>21884</td>\n",
       "      <td>8138145E0</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>7850</td>\n",
       "      <td>45E0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001612</th>\n",
       "      <td>2022/09/10 23:52</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>124.80</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>124.80</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Cheque</td>\n",
       "      <td>D5A0</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001613</th>\n",
       "      <td>2022/09/10 23:33</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>19.01</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>19.01</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>Credit Card</td>\n",
       "      <td>D5A0</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001614</th>\n",
       "      <td>2022/09/10 23:36</td>\n",
       "      <td>23700</td>\n",
       "      <td>81381D5A0</td>\n",
       "      <td>23700</td>\n",
       "      <td>8138E9020</td>\n",
       "      <td>20.54</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>20.54</td>\n",
       "      <td>UK Pound</td>\n",
       "      <td>ACH</td>\n",
       "      <td>D5A0</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279255 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
       "12948     2022/09/01 00:17       1439  8014545C0     1439  8014545C0   \n",
       "12949     2022/09/01 00:17       1439  8014545C0   133936  815FF9670   \n",
       "60425     2022/09/01 00:16      13210  809570DE0    13210  809570DE0   \n",
       "60426     2022/09/01 00:16      13210  809570DE0    35358  80CF6C5E0   \n",
       "63557     2022/09/01 00:17      18903  809F0F740    18903  809F0F740   \n",
       "...                    ...        ...        ...      ...        ...   \n",
       "12001610  2022/09/10 23:30         26  808B34470   121580  8138107B0   \n",
       "12001611  2022/09/10 23:45      21568  8089D7850    21884  8138145E0   \n",
       "12001612  2022/09/10 23:52      23700  81381D5A0    23700  8138E9020   \n",
       "12001613  2022/09/10 23:33      23700  81381D5A0    23700  8138E9020   \n",
       "12001614  2022/09/10 23:36      23700  81381D5A0    23700  8138E9020   \n",
       "\n",
       "          Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
       "12948               14.52           UK Pound        18.76        US Dollar   \n",
       "12949               14.52           UK Pound        14.52         UK Pound   \n",
       "60425               35.10           UK Pound        45.34        US Dollar   \n",
       "60426               35.10           UK Pound        35.10         UK Pound   \n",
       "63557               70.29           UK Pound        90.80        US Dollar   \n",
       "...                   ...                ...          ...              ...   \n",
       "12001610           434.16           UK Pound       434.16         UK Pound   \n",
       "12001611         19098.02           UK Pound     19098.02         UK Pound   \n",
       "12001612           124.80           UK Pound       124.80         UK Pound   \n",
       "12001613            19.01           UK Pound        19.01         UK Pound   \n",
       "12001614            20.54           UK Pound        20.54         UK Pound   \n",
       "\n",
       "         Payment Format Account_Grouped Account1_Grouped  \n",
       "12948               ACH            45C0             45C0  \n",
       "12949       Credit Card            45C0             9670  \n",
       "60425               ACH            0DE0             0DE0  \n",
       "60426       Credit Card            0DE0             C5E0  \n",
       "63557               ACH            F740             F740  \n",
       "...                 ...             ...              ...  \n",
       "12001610    Credit Card            4470             07B0  \n",
       "12001611         Cheque            7850             45E0  \n",
       "12001612         Cheque            D5A0             9020  \n",
       "12001613    Credit Card            D5A0             9020  \n",
       "12001614            ACH            D5A0             9020  \n",
       "\n",
       "[279255 rows x 12 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12948       0\n",
       "12949       0\n",
       "60425       0\n",
       "60426       0\n",
       "63557       0\n",
       "           ..\n",
       "12001610    0\n",
       "12001611    0\n",
       "12001612    0\n",
       "12001613    0\n",
       "12001614    0\n",
       "Name: Is Laundering, Length: 279255, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define a function to extract last 4 characters from account (as string)\n",
    "def last_4_digits(val):\n",
    "    if pd.isna(val):\n",
    "        return 'UNK'  # For missing values\n",
    "    return str(val)[-4:]\n",
    "\n",
    "# Apply it to high-cardinality object columns\n",
    "merged_Small_df['Account_Grouped'] = merged_Small_df['Account'].apply(last_4_digits)\n",
    "merged_Small_df['Account1_Grouped'] = merged_Small_df['Account.1'].apply(last_4_digits)\n",
    "\n",
    "X = merged_Small_df.drop(columns='Is Laundering')\n",
    "y = merged_Small_df['Is Laundering']\n",
    "\n",
    "print(\"X:\\n\")\n",
    "display(X)\n",
    "\n",
    "print(\"Y:\\n\")\n",
    "display(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd87c767",
   "metadata": {},
   "source": [
    "# Things I did for X.\n",
    "\n",
    "- Convert Timestamp into columns like i.e., {hour, day, weekday, and month}.\n",
    "- For Account_Grouped and Account1_Grouped columns,\n",
    "    - Extract first two letters (if present)\n",
    "    - Collect the digits at the end (whatever part is numeric) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc00b78a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/preprocessing/_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>timestamp_column_name</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>...</th>\n",
       "      <th>Payment Format_Cheque</th>\n",
       "      <th>Payment Format_Credit Card</th>\n",
       "      <th>Payment Format_Reinvestment</th>\n",
       "      <th>Payment Format_Wire</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>1439</td>\n",
       "      <td>1439</td>\n",
       "      <td>14.52</td>\n",
       "      <td>18.76</td>\n",
       "      <td>2022-09-01 00:17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>1439</td>\n",
       "      <td>133936</td>\n",
       "      <td>14.52</td>\n",
       "      <td>14.52</td>\n",
       "      <td>2022-09-01 00:17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60425</th>\n",
       "      <td>13210</td>\n",
       "      <td>13210</td>\n",
       "      <td>35.10</td>\n",
       "      <td>45.34</td>\n",
       "      <td>2022-09-01 00:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60426</th>\n",
       "      <td>13210</td>\n",
       "      <td>35358</td>\n",
       "      <td>35.10</td>\n",
       "      <td>35.10</td>\n",
       "      <td>2022-09-01 00:16:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63557</th>\n",
       "      <td>18903</td>\n",
       "      <td>18903</td>\n",
       "      <td>70.29</td>\n",
       "      <td>90.80</td>\n",
       "      <td>2022-09-01 00:17:00</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>740</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001610</th>\n",
       "      <td>26</td>\n",
       "      <td>121580</td>\n",
       "      <td>434.16</td>\n",
       "      <td>434.16</td>\n",
       "      <td>2022-09-10 23:30:00</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4470</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001611</th>\n",
       "      <td>21568</td>\n",
       "      <td>21884</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>2022-09-10 23:45:00</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7850</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001612</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>124.80</td>\n",
       "      <td>124.80</td>\n",
       "      <td>2022-09-10 23:52:00</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001613</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>19.01</td>\n",
       "      <td>19.01</td>\n",
       "      <td>2022-09-10 23:33:00</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001614</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>20.54</td>\n",
       "      <td>20.54</td>\n",
       "      <td>2022-09-10 23:36:00</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279255 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          From Bank  To Bank  Amount Received  Amount Paid  \\\n",
       "12948          1439     1439            14.52        18.76   \n",
       "12949          1439   133936            14.52        14.52   \n",
       "60425         13210    13210            35.10        45.34   \n",
       "60426         13210    35358            35.10        35.10   \n",
       "63557         18903    18903            70.29        90.80   \n",
       "...             ...      ...              ...          ...   \n",
       "12001610         26   121580           434.16       434.16   \n",
       "12001611      21568    21884         19098.02     19098.02   \n",
       "12001612      23700    23700           124.80       124.80   \n",
       "12001613      23700    23700            19.01        19.01   \n",
       "12001614      23700    23700            20.54        20.54   \n",
       "\n",
       "         timestamp_column_name  hour  day  weekday  month  \\\n",
       "12948      2022-09-01 00:17:00     0    1        3      9   \n",
       "12949      2022-09-01 00:17:00     0    1        3      9   \n",
       "60425      2022-09-01 00:16:00     0    1        3      9   \n",
       "60426      2022-09-01 00:16:00     0    1        3      9   \n",
       "63557      2022-09-01 00:17:00     0    1        3      9   \n",
       "...                        ...   ...  ...      ...    ...   \n",
       "12001610   2022-09-10 23:30:00    23   10        5      9   \n",
       "12001611   2022-09-10 23:45:00    23   10        5      9   \n",
       "12001612   2022-09-10 23:52:00    23   10        5      9   \n",
       "12001613   2022-09-10 23:33:00    23   10        5      9   \n",
       "12001614   2022-09-10 23:36:00    23   10        5      9   \n",
       "\n",
       "          Receiving Currency_UK Pound  ...  Payment Format_Cheque  \\\n",
       "12948                             1.0  ...                    0.0   \n",
       "12949                             1.0  ...                    0.0   \n",
       "60425                             1.0  ...                    0.0   \n",
       "60426                             1.0  ...                    0.0   \n",
       "63557                             1.0  ...                    0.0   \n",
       "...                               ...  ...                    ...   \n",
       "12001610                          1.0  ...                    0.0   \n",
       "12001611                          1.0  ...                    1.0   \n",
       "12001612                          1.0  ...                    1.0   \n",
       "12001613                          1.0  ...                    0.0   \n",
       "12001614                          1.0  ...                    0.0   \n",
       "\n",
       "          Payment Format_Credit Card  Payment Format_Reinvestment  \\\n",
       "12948                            0.0                          0.0   \n",
       "12949                            1.0                          0.0   \n",
       "60425                            0.0                          0.0   \n",
       "60426                            1.0                          0.0   \n",
       "63557                            0.0                          0.0   \n",
       "...                              ...                          ...   \n",
       "12001610                         1.0                          0.0   \n",
       "12001611                         0.0                          0.0   \n",
       "12001612                         0.0                          0.0   \n",
       "12001613                         1.0                          0.0   \n",
       "12001614                         0.0                          0.0   \n",
       "\n",
       "          Payment Format_Wire  AG_L1  AG_L2  AG_Num  AG1_L1  AG1_L2  AG1_Num  \n",
       "12948                     0.0     -1     -1      45      -1      -1       45  \n",
       "12949                     0.0     -1     -1      45      -1      -1     9670  \n",
       "60425                     0.0     -1     -1       0      -1      -1        0  \n",
       "60426                     0.0     -1     -1       0       2      -1        5  \n",
       "63557                     0.0      5     -1     740       5      -1      740  \n",
       "...                       ...    ...    ...     ...     ...     ...      ...  \n",
       "12001610                  0.0     -1     -1    4470      -1      -1        7  \n",
       "12001611                  0.0     -1     -1    7850      -1      -1       45  \n",
       "12001612                  0.0      3     -1       5      -1      -1     9020  \n",
       "12001613                  0.0      3     -1       5      -1      -1     9020  \n",
       "12001614                  0.0      3     -1       5      -1      -1     9020  \n",
       "\n",
       "[279255 rows x 38 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import re\n",
    "\n",
    "# Drop redundant columns\n",
    "X = X.drop(columns=['Account', 'Account.1'])\n",
    "\n",
    "# Convert string to datetime\n",
    "X['timestamp_column_name'] = pd.to_datetime(X['Timestamp'])\n",
    "\n",
    "# Extract datetime features\n",
    "X['hour'] = X['timestamp_column_name'].dt.hour\n",
    "X['day'] = X['timestamp_column_name'].dt.day\n",
    "X['weekday'] = X['timestamp_column_name'].dt.weekday\n",
    "X['month'] = X['timestamp_column_name'].dt.month\n",
    "\n",
    "X = X.drop(['Timestamp'], axis=1)\n",
    "\n",
    "# One-hot encode selected categorical columns\n",
    "categorical_cols = ['Receiving Currency', 'Payment Currency', 'Payment Format']\n",
    "\n",
    "encoder = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "encoded_array = encoder.fit_transform(X[categorical_cols])\n",
    "\n",
    "encoded_df = pd.DataFrame(\n",
    "    encoded_array,\n",
    "    columns=encoder.get_feature_names_out(categorical_cols),\n",
    "    index=X.index\n",
    ")\n",
    "\n",
    "X = pd.concat([X.drop(columns=categorical_cols), encoded_df], axis=1)\n",
    "\n",
    "def fast_encode_account_grouped(df, column_name, prefix):\n",
    "    col = df[column_name].astype(str).str.strip()\n",
    "\n",
    "    # Extract first two letters\n",
    "    letters = col.str.extract(r'([A-Za-z])?([A-Za-z])?')\n",
    "    digits = col.str.extract(r'(\\d+)')\n",
    "\n",
    "    l1 = letters[0].str.upper().apply(lambda x: ord(x) - ord('A') if pd.notnull(x) else -1)\n",
    "    l2 = letters[1].str.upper().apply(lambda x: ord(x) - ord('A') if pd.notnull(x) else -1)\n",
    "    num = digits[0].fillna(-1).astype(int)\n",
    "\n",
    "    return pd.DataFrame({\n",
    "        f'{prefix}_L1': l1,\n",
    "        f'{prefix}_L2': l2,\n",
    "        f'{prefix}_Num': num\n",
    "    }, index=df.index)\n",
    "\n",
    "# Apply vectorized encoding\n",
    "X = pd.concat([\n",
    "    X,\n",
    "    fast_encode_account_grouped(X, 'Account_Grouped', 'AG'),\n",
    "    fast_encode_account_grouped(X, 'Account1_Grouped', 'AG1')\n",
    "], axis=1)\n",
    "\n",
    "X.drop(columns=['Account_Grouped', 'Account1_Grouped'], inplace=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f1307d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12948       0\n",
       "12949       0\n",
       "60425       0\n",
       "60426       0\n",
       "63557       0\n",
       "           ..\n",
       "12001610    0\n",
       "12001611    0\n",
       "12001612    0\n",
       "12001613    0\n",
       "12001614    0\n",
       "Name: Is Laundering, Length: 279255, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33222f07",
   "metadata": {},
   "source": [
    "# Now, Oversample (SMOTE) and Undersample Majority Class.\n",
    "\n",
    "- We will get new balanced data -- X and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcf0c2d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['timestamp_column_name'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12948</th>\n",
       "      <td>1439</td>\n",
       "      <td>1439</td>\n",
       "      <td>14.52</td>\n",
       "      <td>18.76</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12949</th>\n",
       "      <td>1439</td>\n",
       "      <td>133936</td>\n",
       "      <td>14.52</td>\n",
       "      <td>14.52</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9670</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60425</th>\n",
       "      <td>13210</td>\n",
       "      <td>13210</td>\n",
       "      <td>35.10</td>\n",
       "      <td>45.34</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60426</th>\n",
       "      <td>13210</td>\n",
       "      <td>35358</td>\n",
       "      <td>35.10</td>\n",
       "      <td>35.10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63557</th>\n",
       "      <td>18903</td>\n",
       "      <td>18903</td>\n",
       "      <td>70.29</td>\n",
       "      <td>90.80</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>740</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>740</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001610</th>\n",
       "      <td>26</td>\n",
       "      <td>121580</td>\n",
       "      <td>434.16</td>\n",
       "      <td>434.16</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4470</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001611</th>\n",
       "      <td>21568</td>\n",
       "      <td>21884</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>19098.02</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>7850</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>45</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001612</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>124.80</td>\n",
       "      <td>124.80</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001613</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>19.01</td>\n",
       "      <td>19.01</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12001614</th>\n",
       "      <td>23700</td>\n",
       "      <td>23700</td>\n",
       "      <td>20.54</td>\n",
       "      <td>20.54</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>5</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>9020</td>\n",
       "      <td>2022</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279255 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          From Bank  To Bank  Amount Received  Amount Paid  hour  day  \\\n",
       "12948          1439     1439            14.52        18.76     0    1   \n",
       "12949          1439   133936            14.52        14.52     0    1   \n",
       "60425         13210    13210            35.10        45.34     0    1   \n",
       "60426         13210    35358            35.10        35.10     0    1   \n",
       "63557         18903    18903            70.29        90.80     0    1   \n",
       "...             ...      ...              ...          ...   ...  ...   \n",
       "12001610         26   121580           434.16       434.16    23   10   \n",
       "12001611      21568    21884         19098.02     19098.02    23   10   \n",
       "12001612      23700    23700           124.80       124.80    23   10   \n",
       "12001613      23700    23700            19.01        19.01    23   10   \n",
       "12001614      23700    23700            20.54        20.54    23   10   \n",
       "\n",
       "          weekday  month  Receiving Currency_UK Pound  \\\n",
       "12948           3      9                          1.0   \n",
       "12949           3      9                          1.0   \n",
       "60425           3      9                          1.0   \n",
       "60426           3      9                          1.0   \n",
       "63557           3      9                          1.0   \n",
       "...           ...    ...                          ...   \n",
       "12001610        5      9                          1.0   \n",
       "12001611        5      9                          1.0   \n",
       "12001612        5      9                          1.0   \n",
       "12001613        5      9                          1.0   \n",
       "12001614        5      9                          1.0   \n",
       "\n",
       "          Payment Currency_Australian Dollar  ...  AG_L1  AG_L2  AG_Num  \\\n",
       "12948                                    0.0  ...     -1     -1      45   \n",
       "12949                                    0.0  ...     -1     -1      45   \n",
       "60425                                    0.0  ...     -1     -1       0   \n",
       "60426                                    0.0  ...     -1     -1       0   \n",
       "63557                                    0.0  ...      5     -1     740   \n",
       "...                                      ...  ...    ...    ...     ...   \n",
       "12001610                                 0.0  ...     -1     -1    4470   \n",
       "12001611                                 0.0  ...     -1     -1    7850   \n",
       "12001612                                 0.0  ...      3     -1       5   \n",
       "12001613                                 0.0  ...      3     -1       5   \n",
       "12001614                                 0.0  ...      3     -1       5   \n",
       "\n",
       "          AG1_L1  AG1_L2  AG1_Num  timestamp_column_name_year  \\\n",
       "12948         -1      -1       45                        2022   \n",
       "12949         -1      -1     9670                        2022   \n",
       "60425         -1      -1        0                        2022   \n",
       "60426          2      -1        5                        2022   \n",
       "63557          5      -1      740                        2022   \n",
       "...          ...     ...      ...                         ...   \n",
       "12001610      -1      -1        7                        2022   \n",
       "12001611      -1      -1       45                        2022   \n",
       "12001612      -1      -1     9020                        2022   \n",
       "12001613      -1      -1     9020                        2022   \n",
       "12001614      -1      -1     9020                        2022   \n",
       "\n",
       "          timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "12948                               9                          1   \n",
       "12949                               9                          1   \n",
       "60425                               9                          1   \n",
       "60426                               9                          1   \n",
       "63557                               9                          1   \n",
       "...                               ...                        ...   \n",
       "12001610                            9                         10   \n",
       "12001611                            9                         10   \n",
       "12001612                            9                         10   \n",
       "12001613                            9                         10   \n",
       "12001614                            9                         10   \n",
       "\n",
       "          timestamp_column_name_minute  \n",
       "12948                               17  \n",
       "12949                               17  \n",
       "60425                               16  \n",
       "60426                               16  \n",
       "63557                               17  \n",
       "...                                ...  \n",
       "12001610                            30  \n",
       "12001611                            45  \n",
       "12001612                            52  \n",
       "12001613                            33  \n",
       "12001614                            36  \n",
       "\n",
       "[279255 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify datetime columns\n",
    "datetime_cols = X.select_dtypes(include=['datetime64']).columns\n",
    "print(datetime_cols)\n",
    "\n",
    "# Convert them into numeric features (like year, month, etc.)\n",
    "for col in datetime_cols:\n",
    "    X[f'{col}_year'] = X[col].dt.year\n",
    "    X[f'{col}_month'] = X[col].dt.month\n",
    "    X[f'{col}_day'] = X[col].dt.day\n",
    "    X[f'{col}_minute'] = X[col].dt.minute\n",
    "    # drop original datetime column\n",
    "    X.drop(columns=col, inplace=True)\n",
    "    \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cc194708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From Bank                               int64\n",
      "To Bank                                 int64\n",
      "Amount Received                       float64\n",
      "Amount Paid                           float64\n",
      "hour                                    int64\n",
      "day                                     int64\n",
      "weekday                                 int64\n",
      "month                                   int64\n",
      "Receiving Currency_UK Pound           float64\n",
      "Payment Currency_Australian Dollar    float64\n",
      "Payment Currency_Bitcoin              float64\n",
      "Payment Currency_Brazil Real          float64\n",
      "Payment Currency_Canadian Dollar      float64\n",
      "Payment Currency_Euro                 float64\n",
      "Payment Currency_Mexican Peso         float64\n",
      "Payment Currency_Ruble                float64\n",
      "Payment Currency_Rupee                float64\n",
      "Payment Currency_Saudi Riyal          float64\n",
      "Payment Currency_Shekel               float64\n",
      "Payment Currency_Swiss Franc          float64\n",
      "Payment Currency_UK Pound             float64\n",
      "Payment Currency_US Dollar            float64\n",
      "Payment Currency_Yen                  float64\n",
      "Payment Currency_Yuan                 float64\n",
      "Payment Format_ACH                    float64\n",
      "Payment Format_Bitcoin                float64\n",
      "Payment Format_Cash                   float64\n",
      "Payment Format_Cheque                 float64\n",
      "Payment Format_Credit Card            float64\n",
      "Payment Format_Reinvestment           float64\n",
      "Payment Format_Wire                   float64\n",
      "AG_L1                                   int64\n",
      "AG_L2                                   int64\n",
      "AG_Num                                  int64\n",
      "AG1_L1                                  int64\n",
      "AG1_L2                                  int64\n",
      "AG1_Num                                 int64\n",
      "timestamp_column_name_year              int64\n",
      "timestamp_column_name_month             int64\n",
      "timestamp_column_name_day               int64\n",
      "timestamp_column_name_minute            int64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>1.038160e-08</td>\n",
       "      <td>1.342225e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.357506</td>\n",
       "      <td>1.038160e-08</td>\n",
       "      <td>1.038862e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>2.510616e-08</td>\n",
       "      <td>3.243969e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.094379</td>\n",
       "      <td>2.510616e-08</td>\n",
       "      <td>2.511318e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>5.028386e-08</td>\n",
       "      <td>6.496536e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279250</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>3.106252e-07</td>\n",
       "      <td>3.106322e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.508475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279251</th>\n",
       "      <td>0.057570</td>\n",
       "      <td>0.058413</td>\n",
       "      <td>1.366423e-05</td>\n",
       "      <td>1.366423e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785786</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279252</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>8.928462e-08</td>\n",
       "      <td>8.929165e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279253</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>1.359410e-08</td>\n",
       "      <td>1.360112e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279254</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>1.468878e-08</td>\n",
       "      <td>1.469581e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>279255 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid  hour     day  \\\n",
       "0        0.003841  0.003841     1.038160e-08  1.342225e-08   0.0  0.0000   \n",
       "1        0.003841  0.357506     1.038160e-08  1.038862e-08   0.0  0.0000   \n",
       "2        0.035261  0.035261     2.510616e-08  3.243969e-08   0.0  0.0000   \n",
       "3        0.035261  0.094379     2.510616e-08  2.511318e-08   0.0  0.0000   \n",
       "4        0.050456  0.050456     5.028386e-08  6.496536e-08   0.0  0.0000   \n",
       "...           ...       ...              ...           ...   ...     ...   \n",
       "279250   0.000069  0.324525     3.106252e-07  3.106322e-07   1.0  0.5625   \n",
       "279251   0.057570  0.058413     1.366423e-05  1.366423e-05   1.0  0.5625   \n",
       "279252   0.063261  0.063261     8.928462e-08  8.929165e-08   1.0  0.5625   \n",
       "279253   0.063261  0.063261     1.359410e-08  1.360112e-08   1.0  0.5625   \n",
       "279254   0.063261  0.063261     1.468878e-08  1.469581e-08   1.0  0.5625   \n",
       "\n",
       "         weekday  month  Receiving Currency_UK Pound  \\\n",
       "0       0.500000    0.0                          0.0   \n",
       "1       0.500000    0.0                          0.0   \n",
       "2       0.500000    0.0                          0.0   \n",
       "3       0.500000    0.0                          0.0   \n",
       "4       0.500000    0.0                          0.0   \n",
       "...          ...    ...                          ...   \n",
       "279250  0.833333    0.0                          0.0   \n",
       "279251  0.833333    0.0                          0.0   \n",
       "279252  0.833333    0.0                          0.0   \n",
       "279253  0.833333    0.0                          0.0   \n",
       "279254  0.833333    0.0                          0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...  0.000000    0.0  0.004505   \n",
       "1                                      0.0  ...  0.000000    0.0  0.004505   \n",
       "2                                      0.0  ...  0.000000    0.0  0.000000   \n",
       "3                                      0.0  ...  0.000000    0.0  0.000000   \n",
       "4                                      0.0  ...  1.000000    0.0  0.074074   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "279250                                 0.0  ...  0.000000    0.0  0.447447   \n",
       "279251                                 0.0  ...  0.000000    0.0  0.785786   \n",
       "279252                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "279253                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "279254                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "\n",
       "        AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0          0.0     0.0  0.004505                         0.0   \n",
       "1          0.0     0.0  0.967968                         0.0   \n",
       "2          0.0     0.0  0.000000                         0.0   \n",
       "3          0.5     0.0  0.000501                         0.0   \n",
       "4          1.0     0.0  0.074074                         0.0   \n",
       "...        ...     ...       ...                         ...   \n",
       "279250     0.0     0.0  0.000701                         0.0   \n",
       "279251     0.0     0.0  0.004505                         0.0   \n",
       "279252     0.0     0.0  0.902903                         0.0   \n",
       "279253     0.0     0.0  0.902903                         0.0   \n",
       "279254     0.0     0.0  0.902903                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                     0.0000   \n",
       "1                               0.0                     0.0000   \n",
       "2                               0.0                     0.0000   \n",
       "3                               0.0                     0.0000   \n",
       "4                               0.0                     0.0000   \n",
       "...                             ...                        ...   \n",
       "279250                          0.0                     0.5625   \n",
       "279251                          0.0                     0.5625   \n",
       "279252                          0.0                     0.5625   \n",
       "279253                          0.0                     0.5625   \n",
       "279254                          0.0                     0.5625   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.288136  \n",
       "1                           0.288136  \n",
       "2                           0.271186  \n",
       "3                           0.271186  \n",
       "4                           0.288136  \n",
       "...                              ...  \n",
       "279250                      0.508475  \n",
       "279251                      0.762712  \n",
       "279252                      0.881356  \n",
       "279253                      0.559322  \n",
       "279254                      0.610169  \n",
       "\n",
       "[279255 rows x 41 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.dtypes)\n",
    "\n",
    "# Normalization on X\n",
    "# y is already normalized.\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "original_columns = X.columns\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)  # Returns a NumPy array\n",
    "\n",
    "# Optionally convert back to DataFrame (to keep column names)\n",
    "X = pd.DataFrame(X, columns=original_columns)\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6332d481",
   "metadata": {},
   "source": [
    "# Split the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c5ecfeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "y = y.reset_index(drop=True)\n",
    "\n",
    "# Source: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
    "# sklearn.model_selection.train_test_split(*arrays, test_size=None, train_size=None, random_state=None, shuffle=True, stratify=None)\n",
    "# Example: X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, # X scalered data.\n",
    "                                                    y, # y\n",
    "                                                    test_size=0.25, # test_size : float or int, default=None\n",
    "                                                    random_state=42, # random_state : int, RandomState instance or None, default=None\n",
    "                                                    shuffle=True, # shuffle : bool, default=True\n",
    "                                                    stratify=y) # stratify : array-like, default=None\n",
    "\n",
    "# Sort the index of X_train\n",
    "X_train = X_train.sort_index()\n",
    "\n",
    "# Sort the index of X_test\n",
    "X_test = X_test.sort_index()\n",
    "\n",
    "# Sort the index of y_train\n",
    "y_train = y_train.sort_index()\n",
    "\n",
    "# Sort the index of y_test\n",
    "y_test = y_test.sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d7e7b56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The predict_cols_scaled_df_X_train dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.003841</td>\n",
       "      <td>1.038160e-08</td>\n",
       "      <td>1.342225e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.003841</td>\n",
       "      <td>0.357506</td>\n",
       "      <td>1.038160e-08</td>\n",
       "      <td>1.038862e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.967968</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.094379</td>\n",
       "      <td>2.510616e-08</td>\n",
       "      <td>2.511318e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.050456</td>\n",
       "      <td>5.028386e-08</td>\n",
       "      <td>6.496536e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.035645</td>\n",
       "      <td>0.035645</td>\n",
       "      <td>9.950882e-08</td>\n",
       "      <td>1.285357e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.033898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279247</th>\n",
       "      <td>0.588757</td>\n",
       "      <td>0.062730</td>\n",
       "      <td>1.197211e-06</td>\n",
       "      <td>1.197218e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.048048</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.898305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279249</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>7.211027e-07</td>\n",
       "      <td>7.211097e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.447447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279252</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>8.928462e-08</td>\n",
       "      <td>8.929165e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.881356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279253</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>1.359410e-08</td>\n",
       "      <td>1.360112e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.559322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279254</th>\n",
       "      <td>0.063261</td>\n",
       "      <td>0.063261</td>\n",
       "      <td>1.468878e-08</td>\n",
       "      <td>1.469581e-08</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.902903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.610169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>209441 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid  hour     day  \\\n",
       "0        0.003841  0.003841     1.038160e-08  1.342225e-08   0.0  0.0000   \n",
       "1        0.003841  0.357506     1.038160e-08  1.038862e-08   0.0  0.0000   \n",
       "3        0.035261  0.094379     2.510616e-08  2.511318e-08   0.0  0.0000   \n",
       "4        0.050456  0.050456     5.028386e-08  6.496536e-08   0.0  0.0000   \n",
       "6        0.035645  0.035645     9.950882e-08  1.285357e-07   0.0  0.0000   \n",
       "...           ...       ...              ...           ...   ...     ...   \n",
       "279247   0.588757  0.062730     1.197211e-06  1.197218e-06   1.0  0.5625   \n",
       "279249   0.000069  0.324525     7.211027e-07  7.211097e-07   1.0  0.5625   \n",
       "279252   0.063261  0.063261     8.928462e-08  8.929165e-08   1.0  0.5625   \n",
       "279253   0.063261  0.063261     1.359410e-08  1.360112e-08   1.0  0.5625   \n",
       "279254   0.063261  0.063261     1.468878e-08  1.469581e-08   1.0  0.5625   \n",
       "\n",
       "         weekday  month  Receiving Currency_UK Pound  \\\n",
       "0       0.500000    0.0                          0.0   \n",
       "1       0.500000    0.0                          0.0   \n",
       "3       0.500000    0.0                          0.0   \n",
       "4       0.500000    0.0                          0.0   \n",
       "6       0.500000    0.0                          0.0   \n",
       "...          ...    ...                          ...   \n",
       "279247  0.833333    0.0                          0.0   \n",
       "279249  0.833333    0.0                          0.0   \n",
       "279252  0.833333    0.0                          0.0   \n",
       "279253  0.833333    0.0                          0.0   \n",
       "279254  0.833333    0.0                          0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...  0.000000    0.0  0.004505   \n",
       "1                                      0.0  ...  0.000000    0.0  0.004505   \n",
       "3                                      0.0  ...  0.000000    0.0  0.000000   \n",
       "4                                      0.0  ...  1.000000    0.0  0.074074   \n",
       "6                                      0.0  ...  0.000000    0.0  0.000300   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "279247                                 0.0  ...  0.666667    0.0  0.048048   \n",
       "279249                                 0.0  ...  0.000000    0.0  0.447447   \n",
       "279252                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "279253                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "279254                                 0.0  ...  0.666667    0.0  0.000501   \n",
       "\n",
       "        AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0          0.0     0.0  0.004505                         0.0   \n",
       "1          0.0     0.0  0.967968                         0.0   \n",
       "3          0.5     0.0  0.000501                         0.0   \n",
       "4          1.0     0.0  0.074074                         0.0   \n",
       "6          0.0     0.0  0.000300                         0.0   \n",
       "...        ...     ...       ...                         ...   \n",
       "279247     0.0     0.0  0.000801                         0.0   \n",
       "279249     0.0     0.0  0.000701                         0.0   \n",
       "279252     0.0     0.0  0.902903                         0.0   \n",
       "279253     0.0     0.0  0.902903                         0.0   \n",
       "279254     0.0     0.0  0.902903                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                     0.0000   \n",
       "1                               0.0                     0.0000   \n",
       "3                               0.0                     0.0000   \n",
       "4                               0.0                     0.0000   \n",
       "6                               0.0                     0.0000   \n",
       "...                             ...                        ...   \n",
       "279247                          0.0                     0.5625   \n",
       "279249                          0.0                     0.5625   \n",
       "279252                          0.0                     0.5625   \n",
       "279253                          0.0                     0.5625   \n",
       "279254                          0.0                     0.5625   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.288136  \n",
       "1                           0.288136  \n",
       "3                           0.271186  \n",
       "4                           0.288136  \n",
       "6                           0.033898  \n",
       "...                              ...  \n",
       "279247                      0.898305  \n",
       "279249                      0.711864  \n",
       "279252                      0.881356  \n",
       "279253                      0.559322  \n",
       "279254                      0.610169  \n",
       "\n",
       "[209441 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe predict_cols_scaled_df_y_train dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "3         0\n",
       "4         0\n",
       "6         0\n",
       "         ..\n",
       "279247    0\n",
       "279249    0\n",
       "279252    0\n",
       "279253    0\n",
       "279254    0\n",
       "Name: Is Laundering, Length: 209441, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    209312\n",
       "1       129\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the training dataset. X_train and y_train.\n",
    "display(\"The predict_cols_scaled_df_X_train dataset: \\n\", X_train)\n",
    "# y_train\n",
    "display(\"\\n\\nThe predict_cols_scaled_df_y_train dataset: \\n\", y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5d2d33a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The predict_cols_scaled_df_X_test dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.035261</td>\n",
       "      <td>0.035261</td>\n",
       "      <td>2.510616e-08</td>\n",
       "      <td>3.243969e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.271186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.050456</td>\n",
       "      <td>0.356000</td>\n",
       "      <td>5.028386e-08</td>\n",
       "      <td>5.029089e-08</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.288136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.056222</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>2.289533e-09</td>\n",
       "      <td>2.296556e-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.152542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.893823</td>\n",
       "      <td>0.893823</td>\n",
       "      <td>2.624284e-06</td>\n",
       "      <td>2.624291e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002903</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.118644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.890975</td>\n",
       "      <td>0.890975</td>\n",
       "      <td>3.898853e-06</td>\n",
       "      <td>3.898860e-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.689690</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.689690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.305085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279237</th>\n",
       "      <td>0.057570</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>1.076774e-06</td>\n",
       "      <td>1.076781e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.661017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279245</th>\n",
       "      <td>0.591942</td>\n",
       "      <td>0.063189</td>\n",
       "      <td>1.294523e-06</td>\n",
       "      <td>1.294530e-06</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.614615</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006106</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.779661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279248</th>\n",
       "      <td>0.062164</td>\n",
       "      <td>0.332452</td>\n",
       "      <td>1.286496e-05</td>\n",
       "      <td>1.286496e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000501</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.091091</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279250</th>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.324525</td>\n",
       "      <td>3.106252e-07</td>\n",
       "      <td>3.106322e-07</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.447447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.508475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279251</th>\n",
       "      <td>0.057570</td>\n",
       "      <td>0.058413</td>\n",
       "      <td>1.366423e-05</td>\n",
       "      <td>1.366423e-05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.785786</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.004505</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5625</td>\n",
       "      <td>0.762712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69814 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid  hour     day  \\\n",
       "2        0.035261  0.035261     2.510616e-08  3.243969e-08   0.0  0.0000   \n",
       "5        0.050456  0.356000     5.028386e-08  5.029089e-08   0.0  0.0000   \n",
       "9        0.056222  0.000064     2.289533e-09  2.296556e-09   0.0  0.0000   \n",
       "10       0.893823  0.893823     2.624284e-06  2.624291e-06   0.0  0.0000   \n",
       "13       0.890975  0.890975     3.898853e-06  3.898860e-06   0.0  0.0000   \n",
       "...           ...       ...              ...           ...   ...     ...   \n",
       "279237   0.057570  0.000069     1.076774e-06  1.076781e-06   1.0  0.5625   \n",
       "279245   0.591942  0.063189     1.294523e-06  1.294530e-06   1.0  0.5625   \n",
       "279248   0.062164  0.332452     1.286496e-05  1.286496e-05   1.0  0.5625   \n",
       "279250   0.000069  0.324525     3.106252e-07  3.106322e-07   1.0  0.5625   \n",
       "279251   0.057570  0.058413     1.366423e-05  1.366423e-05   1.0  0.5625   \n",
       "\n",
       "         weekday  month  Receiving Currency_UK Pound  \\\n",
       "2       0.500000    0.0                          0.0   \n",
       "5       0.500000    0.0                          0.0   \n",
       "9       0.500000    0.0                          0.0   \n",
       "10      0.500000    0.0                          0.0   \n",
       "13      0.500000    0.0                          0.0   \n",
       "...          ...    ...                          ...   \n",
       "279237  0.833333    0.0                          0.0   \n",
       "279245  0.833333    0.0                          0.0   \n",
       "279248  0.833333    0.0                          0.0   \n",
       "279250  0.833333    0.0                          0.0   \n",
       "279251  0.833333    0.0                          0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1     AG_L2    AG_Num  \\\n",
       "2                                      0.0  ...  0.000000  0.000000  0.000000   \n",
       "5                                      0.0  ...  1.000000  0.000000  0.074074   \n",
       "9                                      0.0  ...  1.000000  0.666667  0.000000   \n",
       "10                                     0.0  ...  0.000000  0.000000  0.002903   \n",
       "13                                     0.0  ...  0.000000  0.000000  0.689690   \n",
       "...                                    ...  ...       ...       ...       ...   \n",
       "279237                                 0.0  ...  0.666667  0.833333  0.000000   \n",
       "279245                                 0.0  ...  0.000000  0.000000  0.614615   \n",
       "279248                                 0.0  ...  0.000000  0.000000  0.000501   \n",
       "279250                                 0.0  ...  0.000000  0.000000  0.447447   \n",
       "279251                                 0.0  ...  0.000000  0.000000  0.785786   \n",
       "\n",
       "          AG1_L1  AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "2       0.000000     0.0  0.000000                         0.0   \n",
       "5       0.000000     0.0  0.000100                         0.0   \n",
       "9       0.000000     0.0  0.000601                         0.0   \n",
       "10      0.000000     0.0  0.002903                         0.0   \n",
       "13      0.000000     0.0  0.689690                         0.0   \n",
       "...          ...     ...       ...                         ...   \n",
       "279237  0.000000     0.0  0.000701                         0.0   \n",
       "279245  0.000000     0.0  0.006106                         0.0   \n",
       "279248  0.666667     0.0  0.091091                         0.0   \n",
       "279250  0.000000     0.0  0.000701                         0.0   \n",
       "279251  0.000000     0.0  0.004505                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "2                               0.0                     0.0000   \n",
       "5                               0.0                     0.0000   \n",
       "9                               0.0                     0.0000   \n",
       "10                              0.0                     0.0000   \n",
       "13                              0.0                     0.0000   \n",
       "...                             ...                        ...   \n",
       "279237                          0.0                     0.5625   \n",
       "279245                          0.0                     0.5625   \n",
       "279248                          0.0                     0.5625   \n",
       "279250                          0.0                     0.5625   \n",
       "279251                          0.0                     0.5625   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "2                           0.271186  \n",
       "5                           0.288136  \n",
       "9                           0.152542  \n",
       "10                          0.118644  \n",
       "13                          0.305085  \n",
       "...                              ...  \n",
       "279237                      0.661017  \n",
       "279245                      0.779661  \n",
       "279248                      0.711864  \n",
       "279250                      0.508475  \n",
       "279251                      0.762712  \n",
       "\n",
       "[69814 rows x 41 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'\\n\\nThe predict_cols_scaled_df_y_test dataset: \\n'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2         0\n",
       "5         0\n",
       "9         0\n",
       "10        0\n",
       "13        0\n",
       "         ..\n",
       "279237    0\n",
       "279245    0\n",
       "279248    0\n",
       "279250    0\n",
       "279251    0\n",
       "Name: Is Laundering, Length: 69814, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    69771\n",
       "1       43\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the testing dataset. X_test and y_test.\n",
    "display(\"The predict_cols_scaled_df_X_test dataset: \\n\", X_test)\n",
    "# y_test\n",
    "display(\"\\n\\nThe predict_cols_scaled_df_y_test dataset: \\n\", y_test)\n",
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "090c24c2",
   "metadata": {},
   "source": [
    "# Balance the train dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "754c9a2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting parallel processing with 2 batches...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/imblearn/over_sampling/_smote/base.py:345: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 2 done\n",
      "All batches processed and combined.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>From Bank</th>\n",
       "      <th>To Bank</th>\n",
       "      <th>Amount Received</th>\n",
       "      <th>Amount Paid</th>\n",
       "      <th>hour</th>\n",
       "      <th>day</th>\n",
       "      <th>weekday</th>\n",
       "      <th>month</th>\n",
       "      <th>Receiving Currency_UK Pound</th>\n",
       "      <th>Payment Currency_Australian Dollar</th>\n",
       "      <th>...</th>\n",
       "      <th>AG_L1</th>\n",
       "      <th>AG_L2</th>\n",
       "      <th>AG_Num</th>\n",
       "      <th>AG1_L1</th>\n",
       "      <th>AG1_L2</th>\n",
       "      <th>AG1_Num</th>\n",
       "      <th>timestamp_column_name_year</th>\n",
       "      <th>timestamp_column_name_month</th>\n",
       "      <th>timestamp_column_name_day</th>\n",
       "      <th>timestamp_column_name_minute</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>9.594573e-09</td>\n",
       "      <td>9.601597e-09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.588674</td>\n",
       "      <td>3.466496e-08</td>\n",
       "      <td>3.467198e-08</td>\n",
       "      <td>0.826087</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.796610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.588757</td>\n",
       "      <td>0.054682</td>\n",
       "      <td>3.244411e-07</td>\n",
       "      <td>3.244481e-07</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.325325</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.813559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.621549</td>\n",
       "      <td>3.211427e-07</td>\n",
       "      <td>3.211498e-07</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000801</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.389831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>1.024852e-07</td>\n",
       "      <td>1.024922e-07</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.559560</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.312500</td>\n",
       "      <td>0.711864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418610</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.315649</td>\n",
       "      <td>2.350103e-06</td>\n",
       "      <td>2.350110e-06</td>\n",
       "      <td>0.446054</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.485597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.516082</td>\n",
       "      <td>0.228396</td>\n",
       "      <td>0.304528</td>\n",
       "      <td>0.003861</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.432099</td>\n",
       "      <td>0.355094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418611</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.061576</td>\n",
       "      <td>6.732187e-05</td>\n",
       "      <td>6.732188e-05</td>\n",
       "      <td>0.573821</td>\n",
       "      <td>0.344081</td>\n",
       "      <td>0.366313</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.802651</td>\n",
       "      <td>0.082450</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.344081</td>\n",
       "      <td>0.476792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418612</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.048430</td>\n",
       "      <td>1.333702e-06</td>\n",
       "      <td>1.333709e-06</td>\n",
       "      <td>0.572721</td>\n",
       "      <td>0.396574</td>\n",
       "      <td>0.390863</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.881882</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005898</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.396574</td>\n",
       "      <td>0.434741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418613</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.081360</td>\n",
       "      <td>5.994580e-04</td>\n",
       "      <td>5.994580e-04</td>\n",
       "      <td>0.647810</td>\n",
       "      <td>0.106415</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.299874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.161463</td>\n",
       "      <td>0.749686</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000821</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.106415</td>\n",
       "      <td>0.030496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418614</th>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.019680</td>\n",
       "      <td>1.420398e-04</td>\n",
       "      <td>1.420398e-04</td>\n",
       "      <td>0.617949</td>\n",
       "      <td>0.406888</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.711449</td>\n",
       "      <td>0.177356</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.406888</td>\n",
       "      <td>0.007214</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>418615 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        From Bank   To Bank  Amount Received   Amount Paid      hour  \\\n",
       "0        0.000019  0.000019     9.594573e-09  9.601597e-09  0.000000   \n",
       "1        0.000187  0.588674     3.466496e-08  3.467198e-08  0.826087   \n",
       "2        0.588757  0.054682     3.244411e-07  3.244481e-07  0.652174   \n",
       "3        0.000067  0.621549     3.211427e-07  3.211498e-07  0.347826   \n",
       "4        0.000077  0.000067     1.024852e-07  1.024922e-07  0.739130   \n",
       "...           ...       ...              ...           ...       ...   \n",
       "418610   0.000187  0.315649     2.350103e-06  2.350110e-06  0.446054   \n",
       "418611   0.000187  0.061576     6.732187e-05  6.732188e-05  0.573821   \n",
       "418612   0.000187  0.048430     1.333702e-06  1.333709e-06  0.572721   \n",
       "418613   0.000187  0.081360     5.994580e-04  5.994580e-04  0.647810   \n",
       "418614   0.000187  0.019680     1.420398e-04  1.420398e-04  0.617949   \n",
       "\n",
       "             day   weekday  month  Receiving Currency_UK Pound  \\\n",
       "0       0.000000  0.500000    0.0                          0.0   \n",
       "1       0.500000  0.666667    0.0                          0.0   \n",
       "2       0.375000  0.333333    0.0                          0.0   \n",
       "3       0.500000  0.666667    0.0                          0.0   \n",
       "4       0.312500  0.166667    0.0                          0.0   \n",
       "...          ...       ...    ...                          ...   \n",
       "418610  0.432099  0.485597    0.0                          0.0   \n",
       "418611  0.344081  0.366313    0.0                          0.0   \n",
       "418612  0.396574  0.390863    0.0                          0.0   \n",
       "418613  0.106415  0.666667    0.0                          0.0   \n",
       "418614  0.406888  0.666667    0.0                          0.0   \n",
       "\n",
       "        Payment Currency_Australian Dollar  ...     AG_L1  AG_L2    AG_Num  \\\n",
       "0                                      0.0  ...  0.833333    0.5  0.000000   \n",
       "1                                      0.0  ...  0.000000    0.0  0.881882   \n",
       "2                                      0.0  ...  0.000000    0.0  0.000200   \n",
       "3                                      0.0  ...  0.000000    0.0  0.000300   \n",
       "4                                      0.0  ...  0.000000    0.0  0.000300   \n",
       "...                                    ...  ...       ...    ...       ...   \n",
       "418610                                 0.0  ...  0.152264    0.0  0.516082   \n",
       "418611                                 0.0  ...  0.032980    0.0  0.802651   \n",
       "418612                                 0.0  ...  0.000000    0.0  0.881882   \n",
       "418613                                 0.0  ...  0.299874    0.0  0.161463   \n",
       "418614                                 0.0  ...  0.070942    0.0  0.711449   \n",
       "\n",
       "          AG1_L1    AG1_L2   AG1_Num  timestamp_column_name_year  \\\n",
       "0       0.833333  0.500000  0.000000                         0.0   \n",
       "1       0.000000  0.000000  0.000300                         0.0   \n",
       "2       0.000000  0.000000  0.325325                         0.0   \n",
       "3       0.000000  0.000000  0.000801                         0.0   \n",
       "4       0.000000  0.000000  0.559560                         0.0   \n",
       "...          ...       ...       ...                         ...   \n",
       "418610  0.228396  0.304528  0.003861                         0.0   \n",
       "418611  0.082450  0.000000  0.006493                         0.0   \n",
       "418612  0.000000  0.000000  0.005898                         0.0   \n",
       "418613  0.749686  0.000000  0.000821                         0.0   \n",
       "418614  0.177356  0.000000  0.000271                         0.0   \n",
       "\n",
       "        timestamp_column_name_month  timestamp_column_name_day  \\\n",
       "0                               0.0                   0.000000   \n",
       "1                               0.0                   0.500000   \n",
       "2                               0.0                   0.375000   \n",
       "3                               0.0                   0.500000   \n",
       "4                               0.0                   0.312500   \n",
       "...                             ...                        ...   \n",
       "418610                          0.0                   0.432099   \n",
       "418611                          0.0                   0.344081   \n",
       "418612                          0.0                   0.396574   \n",
       "418613                          0.0                   0.106415   \n",
       "418614                          0.0                   0.406888   \n",
       "\n",
       "        timestamp_column_name_minute  \n",
       "0                           0.016949  \n",
       "1                           0.796610  \n",
       "2                           0.813559  \n",
       "3                           0.389831  \n",
       "4                           0.711864  \n",
       "...                              ...  \n",
       "418610                      0.355094  \n",
       "418611                      0.476792  \n",
       "418612                      0.434741  \n",
       "418613                      0.030496  \n",
       "418614                      0.007214  \n",
       "\n",
       "[418615 rows x 41 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.combine import SMOTEENN\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import EditedNearestNeighbours\n",
    "from sklearn.utils import shuffle\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create a valid SMOTEENN instance with actual SMOTE\n",
    "def create_smoteenn():\n",
    "    return SMOTEENN(\n",
    "        sampling_strategy='auto',\n",
    "        random_state=42,\n",
    "        smote=SMOTE(k_neighbors=3, n_jobs=-1),\n",
    "        enn=EditedNearestNeighbours(n_neighbors=3, n_jobs=-1),\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "# Process one batch safely\n",
    "def process_batch(X_batch, y_batch, i):\n",
    "    try:\n",
    "        sme = create_smoteenn()\n",
    "        X_res, y_res = sme.fit_resample(X_batch, y_batch)\n",
    "        print(f\"Batch {i+1} done\")\n",
    "        return X_res, y_res\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping batch {i+1}: {e}\")\n",
    "        return None\n",
    "\n",
    "# Main function: parallel + SMOTEENN\n",
    "def batchwise_smoteenn_fast(X, y, batch_size=200000, n_jobs=-1):\n",
    "    # Optional shuffle to randomize order\n",
    "    X, y = shuffle(X, y, random_state=42)\n",
    "\n",
    "    # Convert to NumPy for slicing\n",
    "    X_np = X.values if isinstance(X, pd.DataFrame) else X\n",
    "    y_np = y.values if isinstance(y, pd.Series) else y\n",
    "\n",
    "    num_rows = len(X_np)\n",
    "    num_batches = (num_rows + batch_size - 1) // batch_size\n",
    "\n",
    "    # Prepare batches\n",
    "    batches = [\n",
    "        (X_np[i * batch_size : min((i + 1) * batch_size, num_rows)],\n",
    "         y_np[i * batch_size : min((i + 1) * batch_size, num_rows)], i)\n",
    "        for i in range(num_batches)\n",
    "    ]\n",
    "\n",
    "    print(f\"Starting parallel processing with {num_batches} batches...\")\n",
    "\n",
    "    # Run in parallel\n",
    "    results = Parallel(n_jobs=n_jobs)(\n",
    "        delayed(process_batch)(*args) for args in batches\n",
    "    )\n",
    "\n",
    "    # Filter out failed batches\n",
    "    X_resampled_list = [r[0] for r in results if r is not None]\n",
    "    y_resampled_list = [r[1] for r in results if r is not None]\n",
    "\n",
    "    if not X_resampled_list:\n",
    "        raise ValueError(\"All batches failed. Nothing to concatenate.\")\n",
    "\n",
    "    # Combine\n",
    "    X_final = np.vstack(X_resampled_list)\n",
    "    y_final = np.hstack(y_resampled_list)\n",
    "\n",
    "    # Convert back to DataFrame/Series if needed\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_final = pd.DataFrame(X_final, columns=X.columns)\n",
    "    if isinstance(y, pd.Series):\n",
    "        y_final = pd.Series(y_final, name=y.name)\n",
    "\n",
    "    print(\"All batches processed and combined.\")\n",
    "    return X_final, y_final\n",
    "\n",
    "X_train, y_train = batchwise_smoteenn_fast(X_train, y_train, batch_size=200000, n_jobs=4)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "932abf80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "418610    1\n",
       "418611    1\n",
       "418612    1\n",
       "418613    1\n",
       "418614    1\n",
       "Name: Is Laundering, Length: 418615, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    209312\n",
       "1    209303\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y_train)\n",
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c59b490f",
   "metadata": {},
   "source": [
    "# Compute the weight to y_train as we already balanced it in the earlier code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "125b5b53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 0.9999785009937319, 1: 1.0000214999307224}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# numpy.ravel(a, order='C') : Return a contiguous flattened array.\n",
    "# A 1-D array, containing the elements of the input, is returned. A copy is made only if needed.\n",
    "y_train = y_train.values.ravel()\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.utils.class_weight.compute_class_weight.html\n",
    "# sklearn.utils.class_weight.compute_class_weight(class_weight, *, classes, y)\n",
    "# Returns: class_weight_vect : ndarray of shape (n_classes,) : Array with class_weight_vect[i] the weight for i-th class.\n",
    "temp_compute_class_weight = compute_class_weight(class_weight=\"balanced\", # class_weight : dict, “balanced” or None\n",
    "                                                 classes=np.unique(y_train), # classes : ndarray\n",
    "                                                 y=y_train) # y : array-like of shape (n_samples,)\n",
    "\n",
    "# Classification and weighting.\n",
    "tempResClassWeight = {tempIdx: tempData1 for tempIdx, tempData1 in zip(np.unique(y_train, \n",
    "                                                                                 return_index=False, \n",
    "                                                                                 return_inverse=False, \n",
    "                                                                                 return_counts=False, \n",
    "                                                                                 axis=None, \n",
    "                                                                                 equal_nan=True), \n",
    "                                                                      temp_compute_class_weight)}\n",
    "\n",
    "# Show weight.\n",
    "tempResClassWeight"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daec5a38",
   "metadata": {},
   "source": [
    "# So, now, Data Processing work over. It's the most important step. Otherwise, we won't get best results. Now, off to 5 models to test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bacf8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer, accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "\n",
    "# Source: https://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.htmls\n",
    "# sklearn.metrics.make_scorer(score_func, *, response_method='default', greater_is_better=True, **kwargs)\n",
    "# Make a scorer from a performance metric or loss function.\n",
    "# A scorer is a wrapper around an arbitrary metric or loss function that is called with the signature scorer(estimator, X, y_true, **kwargs).\n",
    "# It is accepted in all scikit-learn estimators or functions allowing a scoring parameter.\n",
    "# The parameter response_method allows to specify which method of the estimator should be used to feed the scoring/loss function.\n",
    "# response_method{“predict_proba”, “decision_function”, “predict”} or list/tuple of such str, default=None\n",
    "# metrics_score_list = {\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "#     'accuracy_score' : make_scorer(accuracy_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "#     'precision_score' : make_scorer(precision_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.htmls\n",
    "#     'recall_scores' : make_scorer(recall_score),\n",
    "#     # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "#     'roc_auc_score' : make_scorer(roc_auc_score),\n",
    "# }\n",
    "\n",
    "metrics_score_list = ['accuracy', # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "                      'precision', \n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.htmls\n",
    "                      'recall', \n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "                      'roc_auc',\n",
    "                      # https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "                     'f1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7afd834",
   "metadata": {},
   "source": [
    "# Model-1: Logistic Regression (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b65ce254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 1 done\n",
      "Fitting 10 folds for each of 5 candidates, totalling 50 fits\n",
      "\n",
      " The clf_LR_grid_search's results are: \n",
      " {'mean_fit_time': array([ 20.08437512,  27.13457103,  27.58118849,  34.60173354,\n",
      "       152.40297651]), 'std_fit_time': array([ 1.51823134,  1.14947796,  1.88313625,  1.97301157, 21.95843292]), 'mean_score_time': array([0.22755995, 0.23643918, 0.21783025, 0.21558061, 0.19697595]), 'std_score_time': array([0.01998972, 0.01720095, 0.01224086, 0.0240086 , 0.03081637]), 'param_clf_LR__C': masked_array(data=[0.01, 0.1, 0.2, 1, 10],\n",
      "             mask=[False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_LR__C': 0.01}, {'clf_LR__C': 0.1}, {'clf_LR__C': 0.2}, {'clf_LR__C': 1}, {'clf_LR__C': 10}], 'split0_test_accuracy': array([0.89914481, 0.8993598 , 0.89933591, 0.8993598 , 0.89907315]), 'split1_test_accuracy': array([0.90260857, 0.90244135, 0.90220247, 0.90241747, 0.90222636]), 'split2_test_accuracy': array([0.90086475, 0.90086475, 0.90074531, 0.90076919, 0.90086475]), 'split3_test_accuracy': array([0.89914481, 0.89952702, 0.89924036, 0.89931203, 0.89945535]), 'split4_test_accuracy': array([0.90100807, 0.90057809, 0.90067364, 0.90074531, 0.90064975]), 'split5_test_accuracy': array([0.90014572, 0.89985906, 0.89988295, 0.89964406, 0.89964406]), 'split6_test_accuracy': array([0.90105349, 0.9008146 , 0.90086238, 0.90055183, 0.90062349]), 'split7_test_accuracy': array([0.90126848, 0.9005996 , 0.90057571, 0.90038461, 0.90036072]), 'split8_test_accuracy': array([0.90184181, 0.90153126, 0.9012446 , 0.90129237, 0.90122071]), 'split9_test_accuracy': array([0.75695755, 0.75898808, 0.75886864, 0.75889253, 0.75865364]), 'mean_test_accuracy': array([0.88640381, 0.88645636, 0.8863632 , 0.88633692, 0.8862772 ]), 'std_test_accuracy': array([0.04316103, 0.04249838, 0.04250642, 0.04249076, 0.04255004]), 'rank_test_accuracy': array([2, 1, 3, 4, 5], dtype=int32), 'split0_test_precision': array([0.85887963, 0.85844161, 0.85849704, 0.85865694, 0.85867651]), 'split1_test_precision': array([0.8632895 , 0.86256026, 0.86237624, 0.86271048, 0.86272567]), 'split2_test_precision': array([0.86018459, 0.86027738, 0.8601855 , 0.86022244, 0.86033927]), 'split3_test_precision': array([0.85870079, 0.85845943, 0.85832511, 0.85858933, 0.85877961]), 'split4_test_precision': array([0.86022059, 0.85967998, 0.8598584 , 0.8600309 , 0.86000687]), 'split5_test_precision': array([0.86015309, 0.85943137, 0.85956094, 0.85962423, 0.85971703]), 'split6_test_precision': array([0.85923992, 0.85871889, 0.85879234, 0.85871379, 0.85876262]), 'split7_test_precision': array([0.86071383, 0.8600816 , 0.86010652, 0.8600275 , 0.86014527]), 'split8_test_precision': array([0.86203779, 0.86140019, 0.86111111, 0.86118517, 0.86116726]), 'split9_test_precision': array([0.8178487 , 0.81834733, 0.81833137, 0.81856664, 0.81849738]), 'mean_test_precision': array([0.85612684, 0.8557398 , 0.85571446, 0.85583274, 0.85588175]), 'std_test_precision': array([0.01282899, 0.01252565, 0.0125151 , 0.0124798 , 0.01251658]), 'rank_test_precision': array([1, 4, 5, 3, 2], dtype=int32), 'split0_test_recall': array([0.95523172, 0.95642618, 0.95628285, 0.95609173, 0.95537506]), 'split1_test_recall': array([0.95671285, 0.95742953, 0.95714286, 0.95714286, 0.95666507]), 'split2_test_recall': array([0.95733601, 0.95719268, 0.95704935, 0.95704935, 0.95709713]), 'split3_test_recall': array([0.95552052, 0.95681047, 0.95633271, 0.95609383, 0.95614161]), 'split4_test_recall': array([0.95762266, 0.95743156, 0.95738378, 0.95728823, 0.95709713]), 'split5_test_recall': array([0.95566173, 0.95609173, 0.9559484 , 0.9552795 , 0.95513617]), 'split6_test_recall': array([0.9592451 , 0.95948399, 0.95948399, 0.95886288, 0.95895843]), 'split7_test_recall': array([0.95747731, 0.95685619, 0.95676063, 0.95642618, 0.95618729]), 'split8_test_recall': array([0.95680841, 0.9570473 , 0.95680841, 0.95680841, 0.95666507]), 'split9_test_recall': array([0.66115624, 0.66574295, 0.66545628, 0.66521739, 0.66469183]), 'mean_test_recall': array([0.92727726, 0.92805126, 0.92786493, 0.92762604, 0.92740148]), 'std_test_recall': array([0.08871421, 0.08744036, 0.0874744 , 0.08747419, 0.08757564]), 'rank_test_recall': array([5, 1, 2, 3, 4], dtype=int32), 'split0_test_roc_auc': array([0.93270441, 0.93321388, 0.93339273, 0.93369338, 0.93386739]), 'split1_test_roc_auc': array([0.93616559, 0.93651378, 0.9366383 , 0.9368825 , 0.93701148]), 'split2_test_roc_auc': array([0.93487265, 0.93536586, 0.93552128, 0.93580142, 0.93594347]), 'split3_test_roc_auc': array([0.93247665, 0.9329726 , 0.93313147, 0.93344992, 0.93361729]), 'split4_test_roc_auc': array([0.93297562, 0.93342768, 0.93358644, 0.93387798, 0.93403159]), 'split5_test_roc_auc': array([0.93615116, 0.93657552, 0.9367085 , 0.93694661, 0.93709065]), 'split6_test_roc_auc': array([0.93377692, 0.93430959, 0.93449183, 0.93482025, 0.93498083]), 'split7_test_roc_auc': array([0.93404382, 0.93441223, 0.93455454, 0.93480761, 0.93494203]), 'split8_test_roc_auc': array([0.93430899, 0.93482403, 0.9349813 , 0.93523675, 0.93534001]), 'split9_test_roc_auc': array([0.8574835 , 0.85931813, 0.85953396, 0.85963782, 0.85959962]), 'mean_test_roc_auc': array([0.92649593, 0.92709333, 0.92725404, 0.92751543, 0.92764244]), 'std_test_roc_auc': array([0.02303679, 0.02262327, 0.02260426, 0.02265555, 0.02270999]), 'rank_test_roc_auc': array([5, 4, 3, 2, 1], dtype=int32), 'split0_test_f1': array([0.90449692, 0.90478881, 0.90475545, 0.90475868, 0.90444852]), 'split1_test_f1': array([0.9076034 , 0.9075223 , 0.90729167, 0.90747661, 0.90727021]), 'split2_test_f1': array([0.9061638 , 0.90615106, 0.90603587, 0.90605636, 0.90614257]), 'split3_test_f1': array([0.90452716, 0.90497063, 0.90468227, 0.90472208, 0.9048491 ]), 'split4_test_f1': array([0.90631217, 0.9059265 , 0.90600416, 0.90605711, 0.90595817]), 'split5_test_f1': array([0.90539562, 0.9051884 , 0.90519601, 0.90493109, 0.90491818]), 'split6_test_f1': array([0.90649269, 0.90630923, 0.90635014, 0.90602921, 0.90609905]), 'split7_test_f1': array([0.90652071, 0.90589167, 0.90586266, 0.90566891, 0.90562708]), 'split8_test_f1': array([0.9069541 , 0.90670831, 0.90644095, 0.90648198, 0.90640773]), 'split9_test_f1': array([0.73120211, 0.73419923, 0.73401845, 0.73396768, 0.73361985]), 'mean_test_f1': array([0.88856687, 0.88876561, 0.88866376, 0.88861497, 0.88853405]), 'std_test_f1': array([0.05246339, 0.05152806, 0.05155399, 0.05155538, 0.05164414]), 'rank_test_f1': array([4, 1, 2, 3, 5], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON LOGISTIC REGRESSION CLASSIFIER's BEST AUC-ROC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_LR__C': 10}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92     69771\n",
      "           1       0.00      0.67      0.01        43\n",
      "\n",
      "    accuracy                           0.85     69814\n",
      "   macro avg       0.50      0.76      0.46     69814\n",
      "weighted avg       1.00      0.85      0.92     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8475\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8468\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0054\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RLOGISTIC REGRESSION CLASSIFIER's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_LR__C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92     69771\n",
      "           1       0.00      0.65      0.01        43\n",
      "\n",
      "    accuracy                           0.85     69814\n",
      "   macro avg       0.50      0.75      0.46     69814\n",
      "weighted avg       1.00      0.85      0.92     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8448\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8465\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0052\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON LOGISTIC REGRESSION CLASSIFIER's BEST F-1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_LR__C': 0.1}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.85      0.92     69771\n",
      "           1       0.00      0.65      0.01        43\n",
      "\n",
      "    accuracy                           0.85     69814\n",
      "   macro avg       0.50      0.75      0.46     69814\n",
      "weighted avg       1.00      0.85      0.92     69814\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8448\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.8465\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0052\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.linear_model.LogisticRegression(penalty='l2', *, dual=False, tol=0.0001, C=1.0, fit_intercept=True, intercept_scaling=1, class_weight=None, random_state=None, solver='lbfgs', max_iter=100, multi_class='deprecated', verbose=0, warm_start=False, n_jobs=None, l1_ratio=None)\n",
    "clf_LR = LogisticRegression(penalty='l2', \n",
    "                            dual=False, \n",
    "                            tol=0.0001, \n",
    "                            fit_intercept=True, \n",
    "                            intercept_scaling=1, \n",
    "                            solver='sag', \n",
    "                            max_iter=10000, \n",
    "                            multi_class='auto', \n",
    "                            warm_start=False, \n",
    "                            l1_ratio=None,\n",
    "                            class_weight='balanced', \n",
    "                            random_state=42)\n",
    "\n",
    "# estimator details for LogisticRegressions.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline_LR = Pipeline([\n",
    "    ('clf_LR', \n",
    "     clf_LR) # LogisticRegression\n",
    "])\n",
    "\n",
    "# Inverse of regularization strength; must be a positive float.\n",
    "# C : float, default=1.0\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_LR_param_grid = {'clf_LR__C': [0.01, \n",
    "                                   0.1, \n",
    "                                   0.2, \n",
    "                                   1, \n",
    "                                   10]}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_LR_grid_search = GridSearchCV(estimator=pipeline_LR,\n",
    "                                   param_grid=clf_LR_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_LR_grid_search.fit(X_train, # X\n",
    "                       y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_LR_grid_search.cv_results_\n",
    "print(\"\\n The clf_LR_grid_search's results are: \\n\", clf_LR_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON LOGISTIC REGRESSION CLASSIFIER's BEST AUC-ROC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = pipeline_LR.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RLOGISTIC REGRESSION CLASSIFIER's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = pipeline_LR.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON LOGISTIC REGRESSION CLASSIFIER's BEST F-1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_LR_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = pipeline_LR.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d54eef8",
   "metadata": {},
   "source": [
    "# Model-2: RandomForestClassifier (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9d2fbce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n",
      "\n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([ 36.58209105, 169.08688977, 335.40685351,  35.56585121,\n",
      "       170.69706776, 333.85240734,  35.47058649, 168.18175323,\n",
      "       328.05586026,  34.14297318, 163.9955595 , 328.06981761,\n",
      "        44.89659963, 218.09286089, 429.12162724,  44.84568033,\n",
      "       217.46508141, 429.99482667,  44.57981315, 267.24760547,\n",
      "       549.12698715,  52.47833493, 274.12176363, 600.8196347 ]), 'std_fit_time': array([ 1.75611328,  3.32947335,  4.01773212,  0.94913201,  3.04968013,\n",
      "        3.49921989,  1.51593335,  2.59997695,  3.38025445,  1.67841603,\n",
      "        1.90363948,  4.04358174,  1.00355569,  2.02410823,  3.43389579,\n",
      "        1.31237478,  2.46971501,  4.40673264,  1.41124801, 47.87895643,\n",
      "       31.44388877,  2.94305544,  7.13831086, 26.65987025]), 'mean_score_time': array([0.75300925, 2.13920345, 4.02275779, 0.65101027, 2.1302546 ,\n",
      "       3.79241087, 0.60783396, 2.0131809 , 3.88093936, 0.63061781,\n",
      "       2.04663589, 3.69616239, 0.65111558, 2.36681144, 3.77156575,\n",
      "       0.60335639, 2.44179626, 4.67621434, 0.69098241, 3.42727354,\n",
      "       4.46551907, 0.81769407, 2.60660896, 6.94298069]), 'std_score_time': array([0.07234352, 0.07743183, 0.30176233, 0.05167846, 0.13508894,\n",
      "       0.16987022, 0.0417553 , 0.08534028, 0.25986812, 0.04816749,\n",
      "       0.10696619, 0.17823981, 0.02967544, 0.15508148, 0.13166221,\n",
      "       0.03810803, 0.16520344, 1.26754535, 0.10499453, 0.48813786,\n",
      "       0.35065958, 0.1342356 , 0.19436541, 2.84492112]), 'param_clf_RFC__max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 15, 15,\n",
      "                   15, 15, 15, 15, 15, 15, 15, 15, 15, 15],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__min_samples_leaf': masked_array(data=[1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
      "                   2, 2, 2, 2, 2, 2],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__min_samples_split': masked_array(data=[2, 2, 2, 5, 5, 5, 2, 2, 2, 5, 5, 5, 2, 2, 2, 5, 5, 5,\n",
      "                   2, 2, 2, 5, 5, 5],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_RFC__n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100, 10,\n",
      "                   50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 10, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 100}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 10}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 50}, {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 2, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}], 'split0_test_accuracy': array([0.97274378, 0.97405762, 0.97357986, 0.97484592, 0.97303043,\n",
      "       0.97324543, 0.97016387, 0.97286322, 0.97331709, 0.97298266,\n",
      "       0.97298266, 0.97338875, 0.98738713, 0.98518943, 0.98442502,\n",
      "       0.98303951, 0.9854522 , 0.98464001, 0.98053127, 0.98487889,\n",
      "       0.98394726, 0.98301562, 0.98473556, 0.98430558]), 'split1_test_accuracy': array([0.97286322, 0.97577755, 0.97682863, 0.96784673, 0.97491759,\n",
      "       0.97670919, 0.96875448, 0.97498925, 0.97620754, 0.96748841,\n",
      "       0.9754909 , 0.9770914 , 0.98521332, 0.98796044, 0.98710047,\n",
      "       0.98411447, 0.9868377 , 0.98628828, 0.98581052, 0.98710047,\n",
      "       0.98678993, 0.98447279, 0.98652716, 0.98762601]), 'split2_test_accuracy': array([0.9722899 , 0.97642253, 0.97582533, 0.97460704, 0.97740194,\n",
      "       0.97701973, 0.97283933, 0.9774736 , 0.97685252, 0.97432039,\n",
      "       0.97635087, 0.97690029, 0.98530887, 0.98750657, 0.98707658,\n",
      "       0.98337394, 0.98521332, 0.9858583 , 0.98693326, 0.98712436,\n",
      "       0.98669438, 0.98502222, 0.98647938, 0.98640772]), 'split3_test_accuracy': array([0.97059386, 0.97360375, 0.97458315, 0.97174048, 0.97400984,\n",
      "       0.97539535, 0.97135827, 0.97522813, 0.97498925, 0.97197936,\n",
      "       0.97498925, 0.97546701, 0.98719603, 0.98686159, 0.9862405 ,\n",
      "       0.98483111, 0.98614495, 0.98628828, 0.98817543, 0.98595385,\n",
      "       0.98595385, 0.98779323, 0.98755435, 0.9866466 ]), 'split4_test_accuracy': array([0.97346042, 0.97405762, 0.97379485, 0.97133438, 0.97417706,\n",
      "       0.97496536, 0.97362763, 0.97501314, 0.97486981, 0.97355597,\n",
      "       0.9748937 , 0.97451149, 0.98442502, 0.98621662, 0.98583441,\n",
      "       0.98499833, 0.98528498, 0.98552386, 0.98487889, 0.98440113,\n",
      "       0.9846639 , 0.98368449, 0.98378004, 0.98440113]), 'split5_test_accuracy': array([0.97343589, 0.97453477, 0.97560976, 0.97267146, 0.97560976,\n",
      "       0.97560976, 0.96980483, 0.9755142 , 0.97560976, 0.97150092,\n",
      "       0.97651752, 0.97596808, 0.98678961, 0.98710016, 0.98743461,\n",
      "       0.98339743, 0.98614462, 0.98645517, 0.98592962, 0.98571463,\n",
      "       0.98609684, 0.9843052 , 0.98638351, 0.98633573]), 'split6_test_accuracy': array([0.96963761, 0.97288646, 0.97283868, 0.97345978, 0.97434366,\n",
      "       0.974057  , 0.97412866, 0.97522754, 0.97486921, 0.97372256,\n",
      "       0.97472588, 0.97470199, 0.98239411, 0.98432909, 0.98459186,\n",
      "       0.98332577, 0.9851413 , 0.98463964, 0.98607296, 0.98521297,\n",
      "       0.98559518, 0.98686128, 0.98753016, 0.98652684]), 'split7_test_accuracy': array([0.97465421, 0.97367478, 0.97396144, 0.97293423, 0.97453477,\n",
      "       0.97386589, 0.97379422, 0.974272  , 0.97436755, 0.97233702,\n",
      "       0.97415255, 0.97381811, 0.98146246, 0.98382743, 0.98387521,\n",
      "       0.98270467, 0.98566685, 0.98487853, 0.98354077, 0.98468742,\n",
      "       0.98425742, 0.98549963, 0.98406631, 0.98389909]), 'split8_test_accuracy': array([0.97522754, 0.97699529, 0.97689974, 0.97207425, 0.97615919,\n",
      "       0.97608753, 0.97532309, 0.97654141, 0.97644586, 0.97207425,\n",
      "       0.97575309, 0.97611142, 0.98810349, 0.98824682, 0.98743461,\n",
      "       0.98595351, 0.98688517, 0.98595351, 0.98547574, 0.98600129,\n",
      "       0.98581018, 0.98583407, 0.9861924 , 0.98631184]), 'split9_test_accuracy': array([0.81013354, 0.81192518, 0.81608179, 0.81075464, 0.81316739,\n",
      "       0.81223573, 0.81725234, 0.81689401, 0.81789733, 0.81106519,\n",
      "       0.84051982, 0.82730943, 0.82585223, 0.82167172, 0.82260338,\n",
      "       0.8187812 , 0.82040563, 0.8231767 , 0.80779246, 0.82224505,\n",
      "       0.82224505, 0.81128019, 0.82365448, 0.82312893]), 'mean_test_accuracy': array([0.956504  , 0.95839356, 0.95900032, 0.95622689, 0.95873516,\n",
      "       0.9589191 , 0.95670467, 0.95940165, 0.95954259, 0.95610267,\n",
      "       0.96163762, 0.9605268 , 0.96941323, 0.96989099, 0.96966166,\n",
      "       0.967452  , 0.96931767, 0.96937023, 0.96751409, 0.969332  ,\n",
      "       0.9692054 , 0.96777687, 0.96969033, 0.96955895]), 'std_test_accuracy': array([0.04881607, 0.04883895, 0.04765763, 0.04852656, 0.04853661,\n",
      "       0.0489083 , 0.04652811, 0.04751671, 0.04722558, 0.04837895,\n",
      "       0.04038465, 0.04442124, 0.04789746, 0.04942682, 0.04903529,\n",
      "       0.04956633, 0.04964101, 0.04873552, 0.05327643, 0.0490369 ,\n",
      "       0.04899536, 0.05218319, 0.04869469, 0.04882362]), 'rank_test_accuracy': array([22, 20, 17, 23, 19, 18, 21, 16, 15, 24, 13, 14,  5,  1,  3, 12,  8,\n",
      "        6, 11,  7,  9, 10,  2,  4], dtype=int32), 'split0_test_precision': array([0.94997499, 0.95223336, 0.95120175, 0.95391642, 0.9502069 ,\n",
      "       0.95051396, 0.94525135, 0.95002728, 0.95084877, 0.95069429,\n",
      "       0.95024333, 0.95085548, 0.97757491, 0.97338244, 0.97184475,\n",
      "       0.96953372, 0.97379343, 0.97251595, 0.96465696, 0.97292511,\n",
      "       0.97111628, 0.96927076, 0.97238907, 0.97166256]), 'split1_test_precision': array([0.94884354, 0.9538742 , 0.95579101, 0.93973415, 0.95239396,\n",
      "       0.95561441, 0.94217595, 0.95248282, 0.95469891, 0.93902275,\n",
      "       0.95339408, 0.95627142, 0.97136227, 0.97653042, 0.97489286,\n",
      "       0.96933624, 0.97448196, 0.97339535, 0.9724468 , 0.97498136,\n",
      "       0.97439121, 0.97005377, 0.97389241, 0.97598172]), 'split2_test_precision': array([0.94748993, 0.95505157, 0.95392188, 0.95207973, 0.9568    ,\n",
      "       0.95610068, 0.9491287 , 0.95726574, 0.95579505, 0.95114969,\n",
      "       0.95487933, 0.95584072, 0.97145642, 0.97562226, 0.9748044 ,\n",
      "       0.96786127, 0.97131984, 0.97249454, 0.97457627, 0.9748952 ,\n",
      "       0.97407856, 0.97100306, 0.97371482, 0.97353488]), 'split3_test_precision': array([0.94489612, 0.9499773 , 0.9517486 , 0.94662566, 0.95067   ,\n",
      "       0.95318122, 0.9460217 , 0.95287744, 0.9524438 , 0.9470945 ,\n",
      "       0.95248498, 0.95331147, 0.97503144, 0.97439598, 0.97326203,\n",
      "       0.97059915, 0.97303705, 0.97330853, 0.97703081, 0.97280714,\n",
      "       0.97280714, 0.97625711, 0.97580194, 0.97412028]), 'split4_test_precision': array([0.94967783, 0.95083829, 0.95036331, 0.94674637, 0.95105435,\n",
      "       0.95248282, 0.95018392, 0.95273439, 0.95230944, 0.95013624,\n",
      "       0.95235278, 0.95165985, 0.96983458, 0.97321678, 0.97249326,\n",
      "       0.97095801, 0.97149886, 0.97195003, 0.97073284, 0.96983318,\n",
      "       0.97032779, 0.96853017, 0.96866611, 0.96983318]), 'split5_test_precision': array([0.94967326, 0.95170093, 0.95352863, 0.94878425, 0.9536113 ,\n",
      "       0.95352863, 0.94360733, 0.95343751, 0.95356996, 0.94667994,\n",
      "       0.95526544, 0.95422214, 0.97434704, 0.97493711, 0.97552904,\n",
      "       0.96794783, 0.97312378, 0.97371237, 0.97271671, 0.97230998,\n",
      "       0.97303329, 0.96965204, 0.97357648, 0.97348591]), 'split6_test_precision': array([0.94354948, 0.94872376, 0.94859707, 0.9499614 , 0.95131376,\n",
      "       0.95079509, 0.95182807, 0.95295778, 0.95230727, 0.9524092 ,\n",
      "       0.95204732, 0.95196288, 0.96607118, 0.96969697, 0.97014787,\n",
      "       0.96785681, 0.97122703, 0.97023782, 0.97298805, 0.97136227,\n",
      "       0.97208417, 0.97452734, 0.97575532, 0.9738483 ]), 'split7_test_precision': array([0.95199964, 0.95006356, 0.95054047, 0.94880979, 0.95161877,\n",
      "       0.95044963, 0.95036105, 0.95114303, 0.951357  , 0.94773551,\n",
      "       0.95092694, 0.9503224 , 0.9642923 , 0.96866756, 0.96875723,\n",
      "       0.96669438, 0.97221964, 0.97073148, 0.9681732 , 0.97032779,\n",
      "       0.9695622 , 0.97199127, 0.96920298, 0.96888889]), 'split8_test_precision': array([0.95349473, 0.95609667, 0.95592198, 0.9472231 , 0.95457033,\n",
      "       0.95443973, 0.95309013, 0.95526748, 0.9550931 , 0.94718262,\n",
      "       0.95383073, 0.95448326, 0.97684839, 0.9770775 , 0.97548471,\n",
      "       0.97271798, 0.97452852, 0.97276192, 0.97181464, 0.97285236,\n",
      "       0.97249071, 0.97257982, 0.97321429, 0.97344063]), 'split9_test_precision': array([0.92463692, 0.92908314, 0.93145503, 0.93446894, 0.93284026,\n",
      "       0.933643  , 0.93116883, 0.93250734, 0.93286058, 0.92616351,\n",
      "       0.93627571, 0.93514578, 0.96087309, 0.95771296, 0.96007086,\n",
      "       0.95711154, 0.96171853, 0.96051198, 0.95616768, 0.95902811,\n",
      "       0.95803056, 0.95738557, 0.96321116, 0.96170126]), 'mean_test_precision': array([0.94642364, 0.94976428, 0.95030697, 0.94683498, 0.95050796,\n",
      "       0.95107492, 0.9462817 , 0.95107008, 0.95112839, 0.94582682,\n",
      "       0.95117006, 0.95140754, 0.97076916, 0.972124  , 0.9717287 ,\n",
      "       0.96806169, 0.97169486, 0.971162  , 0.9701304 , 0.97113225,\n",
      "       0.97079219, 0.97012509, 0.97194246, 0.97164976]), 'std_test_precision': array([0.00779168, 0.00724482, 0.00668061, 0.00546508, 0.00619457,\n",
      "       0.00611786, 0.00608792, 0.00647204, 0.00628144, 0.00744769,\n",
      "       0.00518858, 0.00574993, 0.00527157, 0.00545491, 0.00445202,\n",
      "       0.00402704, 0.00352484, 0.0037061 , 0.00565286, 0.00433865,\n",
      "       0.00449536, 0.00482761, 0.00367884, 0.0038695 ]), 'rank_test_precision': array([22, 20, 19, 21, 18, 16, 23, 17, 15, 24, 14, 13,  9,  1,  3, 12,  4,\n",
      "        6, 10,  7,  8, 11,  2,  5], dtype=int32), 'split0_test_recall': array([0.99804109, 0.99818442, 0.99837554, 0.99789775, 0.99837554,\n",
      "       0.99847109, 0.99813665, 0.9982322 , 0.9982322 , 0.99770664,\n",
      "       0.9982322 , 0.99837554, 0.99765886, 0.99765886, 0.99775442,\n",
      "       0.99741997, 0.99775442, 0.99746775, 0.99761108, 0.99751553,\n",
      "       0.99756331, 0.99765886, 0.9978022 , 0.99770664]), 'split1_test_recall': array([0.99961777, 0.99990444, 0.99990444, 0.99980889, 0.99980889,\n",
      "       0.99985667, 0.99880554, 0.99985667, 0.99985667, 0.99990444,\n",
      "       0.99985667, 0.99990444, 0.99990444, 0.99995222, 0.99995222,\n",
      "       0.99985667, 0.99985667, 0.99990444, 0.99995222, 0.99985667,\n",
      "       0.99985667, 0.99980889, 0.99985667, 0.99985667]), 'split2_test_recall': array([1.        , 0.99990445, 0.99995222, 0.99952224, 0.99995222,\n",
      "       0.99995222, 0.99923558, 0.99957002, 0.99995222, 1.        ,\n",
      "       0.99995222, 1.        , 1.        , 1.        , 1.        ,\n",
      "       0.99995222, 0.99995222, 1.        , 0.99995222, 1.        ,\n",
      "       1.        , 0.99990445, 0.99995222, 1.        ]), 'split3_test_recall': array([0.99947446, 0.99985667, 0.99985667, 0.99985667, 0.99990445,\n",
      "       0.99990445, 0.99976112, 0.99990445, 0.99990445, 0.9998089 ,\n",
      "       0.99985667, 0.99990445, 1.        , 1.        , 0.99995222,\n",
      "       0.99995222, 1.        , 1.        , 0.99985667, 0.99985667,\n",
      "       0.99985667, 0.99990445, 0.99990445, 0.99985667]), 'split4_test_recall': array([0.99990445, 0.9998089 , 0.9998089 , 0.99885338, 0.9998089 ,\n",
      "       0.9998089 , 0.99966557, 0.99961779, 0.9998089 , 0.99957002,\n",
      "       0.9998089 , 0.9998089 , 0.99995222, 0.99995222, 0.99995222,\n",
      "       0.99990445, 0.99990445, 0.99990445, 0.99990445, 0.99990445,\n",
      "       0.99990445, 0.99985667, 0.99990445, 0.99990445]), 'split5_test_recall': array([0.99985667, 0.99980889, 0.99995222, 0.99928333, 0.99985667,\n",
      "       0.99995222, 0.9993311 , 0.99985667, 0.99990444, 0.99928333,\n",
      "       0.99985667, 0.99990444, 0.99990444, 0.99990444, 0.99995222,\n",
      "       0.99990444, 0.99990444, 0.99990444, 0.99990444, 0.99990444,\n",
      "       0.99990444, 0.99990444, 0.99990444, 0.99990444]), 'split6_test_recall': array([0.99904443, 0.99980889, 0.99985667, 0.99957   , 0.99985667,\n",
      "       0.99985667, 0.99880554, 0.99980889, 0.99980889, 0.99727664,\n",
      "       0.99980889, 0.99985667, 0.99990444, 0.99990444, 0.99995222,\n",
      "       0.99985667, 0.99990444, 0.99995222, 0.99990444, 0.99990444,\n",
      "       0.99990444, 0.99985667, 0.99990444, 0.99990444]), 'split7_test_recall': array([0.99971333, 0.99990444, 0.99995222, 0.99980889, 0.99990444,\n",
      "       0.99985667, 0.99980889, 0.99990444, 0.99985667, 0.99980889,\n",
      "       0.99990444, 0.99990444, 0.99995222, 1.        , 1.        ,\n",
      "       0.99985667, 0.99990444, 0.99990444, 0.99995222, 0.99995222,\n",
      "       0.99990444, 0.99980889, 0.99990444, 0.99990444]), 'split8_test_recall': array([0.99918777, 0.99990444, 0.99990444, 0.99985667, 0.99990444,\n",
      "       0.99990444, 0.99985667, 0.99990444, 0.99990444, 0.99990444,\n",
      "       0.99990444, 0.99990444, 0.99990444, 0.99995222, 1.        ,\n",
      "       0.99995222, 0.99990444, 0.99990444, 0.99995222, 0.99990444,\n",
      "       0.99990444, 0.99985667, 0.99990444, 0.99990444]), 'split9_test_recall': array([0.67529861, 0.67539417, 0.6823698 , 0.66837076, 0.67491639,\n",
      "       0.6722408 , 0.68514095, 0.68322981, 0.68509317, 0.67601529,\n",
      "       0.73076923, 0.70339226, 0.67935977, 0.67305303, 0.67319637,\n",
      "       0.66746297, 0.66736742, 0.67405638, 0.6451505 , 0.67324415,\n",
      "       0.6740086 , 0.6515528 , 0.67300526, 0.67305303]), 'mean_test_recall': array([0.96701386, 0.96724797, 0.96799331, 0.96628286, 0.96722886,\n",
      "       0.96698041, 0.96785476, 0.96798854, 0.9682322 , 0.96692786,\n",
      "       0.97279503, 0.97009556, 0.96765409, 0.96703775, 0.96707119,\n",
      "       0.96641185, 0.96644529, 0.96709986, 0.96421405, 0.9670043 ,\n",
      "       0.96708075, 0.96481128, 0.9670043 , 0.96699952]), 'std_test_recall': array([0.09723995, 0.09728589, 0.09520893, 0.09930572, 0.09743852,\n",
      "       0.09824745, 0.0942394 , 0.0949208 , 0.09438096, 0.0969752 ,\n",
      "       0.08067675, 0.08890227, 0.09610052, 0.09799731, 0.0979605 ,\n",
      "       0.09965239, 0.09969472, 0.09768393, 0.10635675, 0.09792266,\n",
      "       0.09769322, 0.10442157, 0.09800169, 0.09798436]), 'rank_test_recall': array([14,  8,  4, 22,  9, 18,  6,  5,  3, 19,  1,  2,  7, 13, 12, 21, 20,\n",
      "       10, 24, 15, 11, 23, 15, 17], dtype=int32), 'split0_test_roc_auc': array([0.99354754, 0.9963074 , 0.99600637, 0.99413529, 0.99580932,\n",
      "       0.99621382, 0.99278796, 0.99544222, 0.99591768, 0.99265795,\n",
      "       0.99540679, 0.99597749, 0.99866349, 0.99971668, 0.99974089,\n",
      "       0.99834925, 0.99967194, 0.99967748, 0.99809652, 0.99942187,\n",
      "       0.99960085, 0.99796621, 0.99938655, 0.99947936]), 'split1_test_roc_auc': array([0.99358385, 0.9967067 , 0.99667603, 0.9948169 , 0.99693375,\n",
      "       0.99716626, 0.99395445, 0.99639616, 0.9965891 , 0.9936442 ,\n",
      "       0.99650765, 0.99680076, 0.99788614, 0.9998602 , 0.99994315,\n",
      "       0.99911322, 0.99982203, 0.99991938, 0.99837409, 0.99979987,\n",
      "       0.99983009, 0.99889283, 0.99968359, 0.99992218]), 'split2_test_roc_auc': array([0.99209116, 0.99663689, 0.9963485 , 0.99471686, 0.99661804,\n",
      "       0.99677574, 0.99365224, 0.99689134, 0.99694589, 0.99464569,\n",
      "       0.99649648, 0.99690267, 0.99905555, 0.99986038, 0.99984216,\n",
      "       0.99808227, 0.99964507, 0.99972049, 0.99951538, 0.99987792,\n",
      "       0.99989263, 0.99887926, 0.99983387, 0.9999159 ]), 'split3_test_roc_auc': array([0.99239294, 0.99644667, 0.99629972, 0.99217412, 0.99588954,\n",
      "       0.99585097, 0.99290853, 0.99622734, 0.99591547, 0.99433319,\n",
      "       0.99668853, 0.99624313, 0.99931189, 0.99986781, 0.99992228,\n",
      "       0.99897943, 0.9999277 , 0.99991691, 0.99905642, 0.99968681,\n",
      "       0.99979304, 0.99806452, 0.99988062, 0.9999022 ]), 'split4_test_roc_auc': array([0.99365368, 0.9960772 , 0.99622803, 0.99493107, 0.99637715,\n",
      "       0.99615853, 0.99543353, 0.99655326, 0.9961995 , 0.99495249,\n",
      "       0.99687489, 0.99657331, 0.99869847, 0.99967249, 0.99973827,\n",
      "       0.99817983, 0.99988531, 0.99990283, 0.99900731, 0.99984459,\n",
      "       0.99988281, 0.99865148, 0.9996935 , 0.99984016]), 'split5_test_roc_auc': array([0.99297022, 0.99579685, 0.99640121, 0.99326081, 0.99596137,\n",
      "       0.99610641, 0.98999706, 0.99608887, 0.9963772 , 0.99021289,\n",
      "       0.99564273, 0.99609873, 0.99895915, 0.99980025, 0.99983219,\n",
      "       0.99879464, 0.99975176, 0.99990738, 0.99918161, 0.9998483 ,\n",
      "       0.99993504, 0.99859236, 0.99993394, 0.99993869]), 'split6_test_roc_auc': array([0.9903688 , 0.99513947, 0.9958161 , 0.99250276, 0.99558044,\n",
      "       0.9960086 , 0.99178854, 0.99486956, 0.99585068, 0.99129866,\n",
      "       0.99517075, 0.99614024, 0.99799472, 0.99974731, 0.99977423,\n",
      "       0.99848419, 0.99974621, 0.99977386, 0.9989652 , 0.9999244 ,\n",
      "       0.9999326 , 0.99914627, 0.99994327, 0.99994264]), 'split7_test_roc_auc': array([0.99503343, 0.99631371, 0.99599469, 0.99484778, 0.99622342,\n",
      "       0.9962353 , 0.99387493, 0.99638326, 0.99632039, 0.99472279,\n",
      "       0.99615969, 0.99650036, 0.99825616, 0.99977006, 0.99982775,\n",
      "       0.99891255, 0.99983113, 0.99986295, 0.99918033, 0.99980088,\n",
      "       0.99987161, 0.99945896, 0.9997821 , 0.99988068]), 'split8_test_roc_auc': array([0.99466491, 0.99706243, 0.99711946, 0.99409111, 0.996091  ,\n",
      "       0.99635681, 0.99422521, 0.99652177, 0.9965246 , 0.99305086,\n",
      "       0.99620277, 0.99648554, 0.99787848, 0.99982574, 0.99987089,\n",
      "       0.99869956, 0.99982932, 0.99990167, 0.99907848, 0.99980949,\n",
      "       0.99987076, 0.99967543, 0.99996119, 0.9999624 ]), 'split9_test_roc_auc': array([0.96688505, 0.97197104, 0.97126548, 0.95028015, 0.96560083,\n",
      "       0.96638911, 0.95911462, 0.9693655 , 0.96936805, 0.95435031,\n",
      "       0.97297575, 0.97222885, 0.95964024, 0.97835306, 0.97786331,\n",
      "       0.94062669, 0.97889918, 0.98079936, 0.97681637, 0.97878403,\n",
      "       0.97688434, 0.91044697, 0.97750952, 0.97618054]), 'mean_test_roc_auc': array([0.99051916, 0.99384584, 0.99381556, 0.98957569, 0.99310849,\n",
      "       0.99332616, 0.98977371, 0.99347393, 0.99360086, 0.9893869 ,\n",
      "       0.9938126 , 0.99399511, 0.99463443, 0.9976474 , 0.99763551,\n",
      "       0.99282216, 0.99770097, 0.99793823, 0.99672717, 0.99767982,\n",
      "       0.99754938, 0.98997743, 0.99756081, 0.99749648]), 'std_test_roc_auc': array([0.00797833, 0.0073089 , 0.00752494, 0.01313238, 0.00917705,\n",
      "       0.00898643, 0.01031597, 0.0080555 , 0.00808418, 0.01177165,\n",
      "       0.00696596, 0.00726107, 0.01167466, 0.00643175, 0.00659106,\n",
      "       0.01740156, 0.00626782, 0.00571357, 0.00664835, 0.00630001,\n",
      "       0.00688895, 0.02651512, 0.00668576, 0.00710656]), 'rank_test_roc_auc': array([20, 12, 13, 23, 18, 17, 22, 16, 15, 24, 14, 11, 10,  4,  5, 19,  2,\n",
      "        1,  9,  3,  7, 21,  6,  8], dtype=int32), 'split0_test_f1': array([0.97341504, 0.9746676 , 0.97421791, 0.97541156, 0.97369586,\n",
      "       0.97390251, 0.97097441, 0.97353339, 0.97396452, 0.97363329,\n",
      "       0.97364681, 0.97403627, 0.98751478, 0.98537115, 0.98462917,\n",
      "       0.98327917, 0.98562832, 0.98483383, 0.98085731, 0.98506688,\n",
      "       0.98416215, 0.98325995, 0.98493173, 0.98451239]), 'split1_test_f1': array([0.9735691 , 0.9763471 , 0.97735021, 0.96884115, 0.97552562,\n",
      "       0.97723505, 0.96966464, 0.97559497, 0.97675613, 0.96850776,\n",
      "       0.97607276, 0.97760131, 0.98542672, 0.98810254, 0.98726355,\n",
      "       0.98435993, 0.98700625, 0.98647184, 0.98600773, 0.98726235,\n",
      "       0.9869597 , 0.9847066 , 0.98670376, 0.98777495]), 'split2_test_f1': array([0.97303705, 0.97696347, 0.97639485, 0.97522433, 0.97790029,\n",
      "       0.97753491, 0.97353783, 0.9779606 , 0.97737514, 0.97496332,\n",
      "       0.97689615, 0.97742184, 0.98552158, 0.98766073, 0.98724147,\n",
      "       0.98364508, 0.98542809, 0.9860555 , 0.98710119, 0.98728804,\n",
      "       0.98686909, 0.98524185, 0.98665912, 0.98658999]), 'split3_test_f1': array([0.97141928, 0.974279  , 0.97520969, 0.9725133 , 0.97466586,\n",
      "       0.97598396, 0.97214931, 0.97582469, 0.97559725, 0.97273805,\n",
      "       0.97559611, 0.97605223, 0.98735789, 0.98703197, 0.98642662,\n",
      "       0.98505707, 0.98633429, 0.98647375, 0.98831196, 0.98614645,\n",
      "       0.98614645, 0.9879393 , 0.98770618, 0.9868207 ]), 'split4_test_f1': array([0.97414415, 0.9747089 , 0.97445927, 0.97210211, 0.97482241,\n",
      "       0.97557223, 0.97429689, 0.97561317, 0.97548128, 0.97422644,\n",
      "       0.97550402, 0.97514037, 0.98466315, 0.98640337, 0.98603161,\n",
      "       0.98521866, 0.98549701, 0.98572909, 0.98510273, 0.98463927,\n",
      "       0.98489412, 0.98394415, 0.98403743, 0.98463927]), 'split5_test_f1': array([0.97411907, 0.97516194, 0.97618881, 0.97337925, 0.97618659,\n",
      "       0.97618881, 0.97067013, 0.97609552, 0.9761877 , 0.97227065,\n",
      "       0.97705255, 0.97652933, 0.98696032, 0.98726295, 0.98758966,\n",
      "       0.98366666, 0.98633236, 0.98663461, 0.98612322, 0.98591417,\n",
      "       0.98628588, 0.9845459 , 0.98656484, 0.98651834]), 'split6_test_f1': array([0.97050428, 0.97359667, 0.9735526 , 0.97413452, 0.97498136,\n",
      "       0.9747089 , 0.97475112, 0.97582131, 0.97548014, 0.97432666,\n",
      "       0.97534374, 0.97532216, 0.98269669, 0.98456906, 0.9848246 ,\n",
      "       0.98359654, 0.98535713, 0.98487094, 0.98626264, 0.98542672,\n",
      "       0.98579806, 0.98702953, 0.98768229, 0.98670438]), 'split7_test_f1': array([0.97527325, 0.97434704, 0.97462047, 0.97364197, 0.97516425,\n",
      "       0.97452734, 0.97445808, 0.9749144 , 0.97500408, 0.97307603,\n",
      "       0.97480088, 0.97448314, 0.98179856, 0.98408444, 0.98413072,\n",
      "       0.98299591, 0.98586772, 0.98510203, 0.98380614, 0.98491729,\n",
      "       0.98449959, 0.98570386, 0.98431437, 0.98415236]), 'split8_test_f1': array([0.97580664, 0.97750998, 0.97741868, 0.97282849, 0.97671163,\n",
      "       0.97664326, 0.97591345, 0.97707643, 0.9769852 , 0.97282975,\n",
      "       0.97632432, 0.97666604, 0.98824196, 0.98838253, 0.98759024,\n",
      "       0.9861471 , 0.98705341, 0.98614645, 0.98568266, 0.98619292,\n",
      "       0.98600707, 0.98602964, 0.98637885, 0.98649509]), 'split9_test_f1': array([0.78053899, 0.78218287, 0.78768993, 0.77933148, 0.78318964,\n",
      "       0.78166667, 0.78943022, 0.78863918, 0.79000578, 0.78156158,\n",
      "       0.82085547, 0.8028795 , 0.79595835, 0.79053846, 0.79143965,\n",
      "       0.78646625, 0.78795058, 0.79218373, 0.77045532, 0.7911181 ,\n",
      "       0.79130557, 0.77540229, 0.79237217, 0.79189387]), 'mean_test_f1': array([0.95418269, 0.95597646, 0.95671024, 0.95374082, 0.95628435,\n",
      "       0.95639636, 0.95458461, 0.95710737, 0.95728372, 0.95381335,\n",
      "       0.96020928, 0.95861322, 0.966614  , 0.96694072, 0.96671673,\n",
      "       0.96444324, 0.96624552, 0.96645018, 0.96397109, 0.96639722,\n",
      "       0.96629277, 0.96438031, 0.96673507, 0.96661013]), 'std_test_f1': array([0.05790091, 0.05794359, 0.05635408, 0.05816297, 0.05770906,\n",
      "       0.0582539 , 0.05508505, 0.05616708, 0.05576752, 0.05744191,\n",
      "       0.04646094, 0.05192338, 0.05691982, 0.05881704, 0.05843836,\n",
      "       0.05933311, 0.05943456, 0.05809232, 0.06453339, 0.0584327 ,\n",
      "       0.05833596, 0.06300658, 0.05813375, 0.05824962]), 'rank_test_f1': array([22, 20, 17, 24, 19, 18, 21, 16, 15, 23, 13, 14,  4,  1,  3, 10,  9,\n",
      "        6, 12,  7,  8, 11,  2,  5], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST AUC-ROC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 5, 'clf_RFC__n_estimators': 100}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     69771\n",
      "           1       0.01      0.28      0.01        43\n",
      "\n",
      "    accuracy                           0.97     69814\n",
      "   macro avg       0.50      0.63      0.50     69814\n",
      "weighted avg       1.00      0.97      0.99     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8678\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9733\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0127\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     69771\n",
      "           1       0.01      0.26      0.01        43\n",
      "\n",
      "    accuracy                           0.97     69814\n",
      "   macro avg       0.50      0.61      0.50     69814\n",
      "weighted avg       1.00      0.97      0.99     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8834\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9734\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0117\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON RANDOM FOREST CLASSIFIER's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_RFC__max_depth': 15, 'clf_RFC__min_samples_leaf': 1, 'clf_RFC__min_samples_split': 2, 'clf_RFC__n_estimators': 50}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     69771\n",
      "           1       0.01      0.26      0.01        43\n",
      "\n",
      "    accuracy                           0.97     69814\n",
      "   macro avg       0.50      0.61      0.50     69814\n",
      "weighted avg       1.00      0.97      0.99     69814\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8834\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9734\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0117\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.svm.RandomForestClassifier(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "clf_RFC = RandomForestClassifier(n_estimators=100, \n",
    "                                 criterion='gini', \n",
    "                                 max_depth=None, \n",
    "                                 min_samples_split=10, \n",
    "                                 min_samples_leaf=5, \n",
    "                                 min_weight_fraction_leaf=0.0, \n",
    "                                 max_features='sqrt', \n",
    "                                 max_leaf_nodes=None, \n",
    "                                 min_impurity_decrease=0.0, \n",
    "                                 bootstrap=True, \n",
    "                                 oob_score=False, \n",
    "                                 random_state=42, \n",
    "                                 warm_start=False, \n",
    "                                 ccp_alpha=0.0, \n",
    "                                 max_samples=None, \n",
    "                                 class_weight='balanced')\n",
    "\n",
    "# estimator details for RandomForestClassifier.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_RFC_pipeline = Pipeline([\n",
    "    ('clf_RFC', \n",
    "     clf_RFC) # RandomForestClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for RandomForestClassifier.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_param_grid = {\n",
    "    # The number of trees in the forest.\n",
    "    'clf_RFC__n_estimators': [10, \n",
    "                              50, \n",
    "                              100], \n",
    "    # The maximum depth of the tree.\n",
    "    'clf_RFC__max_depth': [10, \n",
    "                           15], \n",
    "    # The minimum number of samples required to split an internal node:\n",
    "    'clf_RFC__min_samples_split': [2, \n",
    "                                   5], \n",
    "    # The minimum number of samples required to be at a leaf node. \n",
    "    'clf_RFC__min_samples_leaf': [1, \n",
    "                                  2]  \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_RFC_pipeline,\n",
    "                                   param_grid=clf_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                    y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST AUC-ROC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_RFC_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_RFC_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON RANDOM FOREST CLASSIFIER's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_RFC_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8d6e47",
   "metadata": {},
   "source": [
    "# Model-3: Bagging (using Naïve Bayes as classifier) (Choosing the best AUC ROC parameter)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d596634e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on /usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/loc/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "al/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation./usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "py:824: UserWarning: Scoring f/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "ailed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/loc/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "al/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y,/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      " y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklear/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_p/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_search.py:976: UserWarning: One or more of the test scores are non-finite: [0.8601892  0.88623981 0.89706422 0.5        0.5        0.5\n",
      "        nan        nan        nan        nan        nan        nan]\n",
      "  warnings.warn(\n",
      "rior_[i])\n",
      "n/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kw/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "args)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/loc/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "al/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in subtract\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: divide by zero encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:510: RuntimeWarning: divide by zero encountered in log\n",
      "  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:511: RuntimeWarning: invalid value encountered in divide\n",
      "  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/naive_bayes.py:509: RuntimeWarning: divide by zero encountered in log\n",
      "  jointi = np.log(self.class_prior_[i])\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py:824: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/model_selection/_validation.py\", line 813, in _score\n",
      "    scores = scorer(estimator, X_test, y_test)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 266, in __call__\n",
      "    return self._score(partial(_cached_call, None), estimator, X, y_true, **_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_scorer.py\", line 471, in _score\n",
      "    return self._sign * self._score_func(y, y_pred, **scoring_kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/_param_validation.py\", line 211, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/metrics/_ranking.py\", line 605, in roc_auc_score\n",
      "    y_score = check_array(y_score, ensure_2d=False)\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 959, in check_array\n",
      "    _assert_all_finite(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 124, in _assert_all_finite\n",
      "    _assert_all_finite_element_wise(\n",
      "  File \"/usr/local/lib/python3.10/site-packages/sklearn/utils/validation.py\", line 173, in _assert_all_finite_element_wise\n",
      "    raise ValueError(msg_err)\n",
      "ValueError: Input contains NaN.\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The clf_grid_search_BGC's results are: \n",
      " {'mean_fit_time': array([16.03006983, 40.94212351, 74.21013753, 10.67069838, 33.08081112,\n",
      "       61.64138236,  2.84624784,  4.60986748,  8.53035741,  2.93049867,\n",
      "        7.8916286 ,  4.9867563 ]), 'std_fit_time': array([2.88747481, 1.99915191, 1.53177258, 0.76833572, 1.00757718,\n",
      "       2.07610394, 0.42562188, 0.23714035, 1.01756134, 0.26832141,\n",
      "       0.6906751 , 2.24105832]), 'mean_score_time': array([ 0.82277956,  3.73345058,  7.84426401,  1.09231188,  3.7440299 ,\n",
      "       18.78065639,  0.14009743,  0.64545155,  1.78097286,  0.10399256,\n",
      "       23.29164965, 13.87416394]), 'std_score_time': array([1.32637018e-01, 1.51481854e-01, 9.56005333e-01, 1.62518658e-01,\n",
      "       3.41126036e-01, 2.07600288e+01, 6.54364306e-02, 4.38354965e-02,\n",
      "       5.00837485e-01, 1.61167678e-02, 2.15981181e+01, 1.11563439e+01]), 'param_clf_BGC__max_features': masked_array(data=[0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 1, 1, 1, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_BGC__max_samples': masked_array(data=[0.5, 0.5, 0.5, 1, 1, 1, 0.5, 0.5, 0.5, 1, 1, 1],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_BGC__n_estimators': masked_array(data=[10, 50, 100, 10, 50, 100, 10, 50, 100, 10, 50, 100],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 10}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 50}, {'clf_BGC__max_features': 1, 'clf_BGC__max_samples': 1, 'clf_BGC__n_estimators': 100}], 'split0_test_score': array([0.90659707, 0.90814896, 0.91642901, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split1_test_score': array([0.91070346, 0.91183776, 0.91257596, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split2_test_score': array([0.87409631, 0.8960498 , 0.90027926, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split3_test_score': array([0.87109991, 0.89476405, 0.89791515, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split4_test_score': array([0.85593268, 0.89572961, 0.90098781, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split5_test_score': array([0.86603448, 0.89609855, 0.91661469, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split6_test_score': array([0.84106245, 0.89384679, 0.91375809, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split7_test_score': array([0.86877267, 0.89561555, 0.91343395, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split8_test_score': array([0.86765358, 0.89554444, 0.91104055, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'split9_test_score': array([0.73993942, 0.7747626 , 0.78760775, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'mean_test_score': array([0.8601892 , 0.88623981, 0.89706422, 0.5       , 0.5       ,\n",
      "       0.5       ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'std_test_score': array([0.0447497 , 0.03761772, 0.03707694, 0.        , 0.        ,\n",
      "       0.        ,        nan,        nan,        nan,        nan,\n",
      "              nan,        nan]), 'rank_test_score': array([3, 2, 1, 4, 4, 4, 7, 7, 7, 7, 7, 7], dtype=int32)}\n",
      "\n",
      "The Best Parameters from tempBestClassifierModelBaggingClassifierRegression:\n",
      " {'clf_BGC__max_features': 0.5, 'clf_BGC__max_samples': 0.5, 'clf_BGC__n_estimators': 100}\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.02      0.04     69771\n",
      "           1       0.00      1.00      0.00        43\n",
      "\n",
      "    accuracy                           0.02     69814\n",
      "   macro avg       0.50      0.51      0.02     69814\n",
      "weighted avg       1.00      0.02      0.04     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.7893\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.0186\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# class sklearn.naive_bayes.GaussianNB(*, priors=None, var_smoothing=1e-09)\n",
    "clf = GaussianNB(priors=None, # priors : array-like of shape (n_classes,), default=None\n",
    "                 var_smoothing=1e-09) # var_smoothing : float, default=1e-9\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.BaggingClassifier.html\n",
    "# class sklearn.ensemble.BaggingClassifier(estimator=None, n_estimators=10, *, max_samples=1.0, max_features=1.0, bootstrap=True, bootstrap_features=False, oob_score=False, warm_start=False, n_jobs=None, random_state=None, verbose=0)\n",
    "clf_BGC = BaggingClassifier(\n",
    "          estimator=clf, \n",
    "          n_estimators=10, \n",
    "          max_samples=1.0, \n",
    "          max_features=1.0,\n",
    "          bootstrap=True,  \n",
    "          bootstrap_features=False, \n",
    "          oob_score=False, \n",
    "          warm_start=False,\n",
    "          n_jobs=4,       \n",
    "          random_state=42,\n",
    "          verbose=0\n",
    ")\n",
    "\n",
    "# estimator details for RandomForestClassifier.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "pipeline_BGC = Pipeline([\n",
    "    ('clf_BGC', \n",
    "     clf_BGC) # BaggingClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for RandomForestClassifier.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_param_grid_BGC = {\n",
    "    # The number of base estimators in the ensemble.\n",
    "    'clf_BGC__n_estimators': [10,\n",
    "                              50,\n",
    "                              100], \n",
    "    # max_samplesint or float, default=1.0\n",
    "    'clf_BGC__max_samples': [0.5,\n",
    "                             1], \n",
    "    # The number of features to draw from X to train each base estimator.\n",
    "    'clf_BGC__max_features': [0.5,\n",
    "                              1], \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search_BGC = GridSearchCV(estimator=pipeline_BGC,\n",
    "                                   param_grid=clf_param_grid_BGC, \n",
    "                                   scoring='roc_auc', \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=True, \n",
    "                                   verbose=0, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search_BGC.fit(X_train, # X\n",
    "                        y_train) # y\n",
    "\n",
    "print(\"\\n The clf_grid_search_BGC's results are: \\n\", clf_grid_search_BGC.cv_results_)\n",
    "\n",
    "# best_estimator_ : estimator\n",
    "# Estimator that was chosen by the search, i.e. estimator which gave highest score (or smallest loss if specified) on the left out data. Not available if refit=False.\n",
    "# See refit parameter for more information on allowed values.\n",
    "\n",
    "tempBestClassifierModelBaggingClassifieregression = clf_grid_search_BGC.best_estimator_\n",
    "\n",
    "# best_params_ : dict\n",
    "# Parameter setting that gave the best results on the hold out data.\n",
    "# For multi-metric evaluation, this is present only if refit is specified.\n",
    "\n",
    "# best_params_dict\n",
    "# Parameter setting that gave the best results on the hold out data.\n",
    "\n",
    "# For multi-metric evaluation, this is present only if refit is specified.\n",
    "\n",
    "print(f\"\\nThe Best Parameters from tempBestClassifierModelBaggingClassifierRegression:\\n {clf_grid_search_BGC.best_params_}\")\n",
    "\n",
    "# \n",
    "# predict(X)[source]\n",
    "# Call predict on the estimator with the best found parameters.\n",
    "\n",
    "# Only available if refit=True and the underlying estimator supports predict.\n",
    "\n",
    "# Parameters\n",
    "# :\n",
    "# X\n",
    "# indexable, length n_samples\n",
    "# Must fulfill the input assumptions of the underlying estimator.\n",
    "\n",
    "# Returns\n",
    "# :\n",
    "# tempYPred\n",
    "# ndarray of shape (n_samples,)\n",
    "# The predicted labels or values for X based on the estimator with the best found parameters.\n",
    "\n",
    "tempYPred = tempBestClassifierModelBaggingClassifieregression.predict(X_test)\n",
    "\n",
    "# Call predict_proba on the estimator with the best found parameters.\n",
    "\n",
    "# Only available if refit=True and the underlying estimator supports predict_proba.\n",
    "\n",
    "# Parameters\n",
    "# :\n",
    "# X\n",
    "# indexable, length n_samples\n",
    "# Must fulfill the input assumptions of the underlying estimator.\n",
    "\n",
    "# Returns\n",
    "# :\n",
    "# tempYPred\n",
    "# ndarray of shape (n_samples,) or (n_samples, n_classes)\n",
    "# Predicted class probabilities for X based on the estimator with the \n",
    "\n",
    "tempYPred_probability = tempBestClassifierModelBaggingClassifieregression.predict_proba(X_test)[:, \n",
    "                                                                                             # Probability of the positive class (class 1)\n",
    "                                                                                             1]\n",
    "\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7d345e",
   "metadata": {},
   "source": [
    "# Model-4: GradientBoostingClassifier techniques (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f39e6e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 8 candidates, totalling 80 fits\n",
      "Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: Binning 0.111 GB of training data: 14.875 s\n",
      "Binning 0.012 GB of validation data: 15.660 s\n",
      "Binning 0.012 GB of validation data: 15.982 s\n",
      "Binning 0.012 GB of validation data: 15.893 s\n",
      "Binning 0.012 GB of validation data: 1.269 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.887 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.928 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.910 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65910, val loss: 0.65907, in 1.457s\n",
      "[2/200] 17.380 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62826, val loss: 0.62825, in 0.672s\n",
      "[3/200] 17.536 s\n",
      "Binning 0.012 GB of validation data: 18.451 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.65912, val loss: 0.65900, in 1.108s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65904, in 1.370s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65911, val loss: 0.65914, in 1.259s\n",
      "[2/200] 1.097 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60024, val loss: 0.60019, in 1.208s\n",
      "[4/200] 18.382 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62823, val loss: 0.62806, in 1.057s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62829, val loss: 0.62810, in 1.243s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62828, val loss: 0.62831, in 1.223s\n",
      "[3/200] 0.933 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.952 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57466, val loss: 0.57463, in 1.110s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65908, val loss: 0.65906, in 1.202s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60029, val loss: 0.59997, in 1.006s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60020, val loss: 0.59997, in 1.169s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60027, val loss: 0.60031, in 1.000s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65910, in 1.264s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65908, val loss: 0.65905, in 1.262s\n",
      "[2/200] 1.199 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55129, val loss: 0.55122, in 1.051s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62820, val loss: 0.62820, in 0.998s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57473, val loss: 0.57434, in 1.162s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57461, val loss: 0.57425, in 1.204s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57471, val loss: 0.57473, in 1.217s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62822, val loss: 0.62823, in 1.134s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62821, val loss: 0.62821, in 1.123s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52981, val loss: 0.52971, in 0.947s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60016, val loss: 0.60013, in 1.110s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55136, val loss: 0.55085, in 1.159s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65910, val loss: 0.65906, in 1.567s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55123, val loss: 0.55075, in 1.124s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55133, val loss: 0.55136, in 1.106s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60018, val loss: 0.60017, in 0.998s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60017, val loss: 0.60016, in 1.025s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51005, val loss: 0.50991, in 0.984s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57456, val loss: 0.57454, in 0.934s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52989, val loss: 0.52927, in 0.926s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52974, val loss: 0.52916, in 0.913s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62824, val loss: 0.62823, in 0.930s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52987, val loss: 0.52983, in 0.954s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57458, val loss: 0.57459, in 0.879s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57458, val loss: 0.57456, in 0.913s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49183, val loss: 0.49166, in 0.881s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55116, val loss: 0.55111, in 0.890s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51013, val loss: 0.50944, in 0.778s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60022, val loss: 0.60017, in 0.811s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50995, val loss: 0.50933, in 0.919s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51011, val loss: 0.51007, in 0.890s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55120, val loss: 0.55117, in 0.829s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55118, val loss: 0.55116, in 0.842s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47499, val loss: 0.47474, in 0.862s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52967, val loss: 0.52959, in 0.961s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49191, val loss: 0.49106, in 1.003s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57464, val loss: 0.57460, in 0.978s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49189, val loss: 0.49181, in 0.991s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52970, val loss: 0.52959, in 1.022s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52968, val loss: 0.52971, in 1.047s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49173, val loss: 0.49096, in 1.084s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45937, val loss: 0.45907, in 1.055s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50988, val loss: 0.50976, in 1.077s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47507, val loss: 0.47418, in 1.005s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55125, val loss: 0.55117, in 0.886s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50991, val loss: 0.50991, in 0.748s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47506, val loss: 0.47497, in 0.855s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47487, val loss: 0.47406, in 0.844s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50990, val loss: 0.50978, in 0.937s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44215, val loss: 0.44181, in 0.943s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49165, val loss: 0.49147, in 0.902s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45946, val loss: 0.45850, in 0.887s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52977, val loss: 0.52969, in 0.905s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49167, val loss: 0.49164, in 0.884s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45944, val loss: 0.45934, in 0.890s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45924, val loss: 0.45839, in 0.893s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49168, val loss: 0.49151, in 0.995s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42620, val loss: 0.42584, in 0.946s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47479, val loss: 0.47458, in 0.801s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44227, val loss: 0.44122, in 0.851s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51000, val loss: 0.50989, in 0.821s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47482, val loss: 0.47483, in 0.795s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44226, val loss: 0.44216, in 0.912s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44205, val loss: 0.44111, in 0.916s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47481, val loss: 0.47461, in 0.772s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41140, val loss: 0.41103, in 0.792s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45916, val loss: 0.45892, in 0.781s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49177, val loss: 0.49161, in 0.755s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45919, val loss: 0.45911, in 0.745s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42637, val loss: 0.42526, in 0.870s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42634, val loss: 0.42624, in 0.845s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45917, val loss: 0.45895, in 0.755s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42614, val loss: 0.42513, in 0.795s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39765, val loss: 0.39723, in 0.895s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44195, val loss: 0.44168, in 0.951s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47493, val loss: 0.47473, in 0.863s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44199, val loss: 0.44188, in 0.944s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41160, val loss: 0.41042, in 0.928s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44198, val loss: 0.44176, in 0.865s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41157, val loss: 0.41146, in 0.879s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41136, val loss: 0.41033, in 0.943s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45930, val loss: 0.45906, in 0.771s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38483, val loss: 0.38437, in 0.889s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42603, val loss: 0.42573, in 0.837s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42608, val loss: 0.42594, in 0.869s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39787, val loss: 0.39666, in 0.886s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39784, val loss: 0.39772, in 0.861s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42606, val loss: 0.42583, in 0.935s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39761, val loss: 0.39655, in 0.877s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37290, val loss: 0.37241, in 0.910s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44208, val loss: 0.44182, in 0.977s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41124, val loss: 0.41096, in 0.943s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41129, val loss: 0.41112, in 0.959s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38509, val loss: 0.38380, in 0.966s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38504, val loss: 0.38492, in 0.899s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41127, val loss: 0.41102, in 0.850s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38482, val loss: 0.38370, in 0.900s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36179, val loss: 0.36125, in 0.899s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39750, val loss: 0.39716, in 0.811s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42615, val loss: 0.42588, in 0.884s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39754, val loss: 0.39740, in 0.884s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37319, val loss: 0.37185, in 0.826s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39752, val loss: 0.39725, in 0.837s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37314, val loss: 0.37300, in 0.925s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37293, val loss: 0.37175, in 0.901s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38471, val loss: 0.38434, in 0.797s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41135, val loss: 0.41106, in 0.775s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35141, val loss: 0.35090, in 0.907s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38476, val loss: 0.38457, in 0.867s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38474, val loss: 0.38446, in 0.826s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36209, val loss: 0.36069, in 0.868s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36204, val loss: 0.36191, in 0.808s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36182, val loss: 0.36062, in 0.802s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37281, val loss: 0.37240, in 0.805s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39759, val loss: 0.39734, in 0.810s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34170, val loss: 0.34116, in 0.817s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37283, val loss: 0.37254, in 0.822s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37286, val loss: 0.37264, in 0.866s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35173, val loss: 0.35030, in 0.820s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35146, val loss: 0.35024, in 0.790s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35169, val loss: 0.35154, in 0.879s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38478, val loss: 0.38453, in 0.755s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36169, val loss: 0.36126, in 0.791s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33264, val loss: 0.33206, in 0.854s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34205, val loss: 0.34056, in 0.845s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36173, val loss: 0.36143, in 0.866s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36176, val loss: 0.36151, in 0.874s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34200, val loss: 0.34184, in 0.807s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34178, val loss: 0.34048, in 0.857s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37287, val loss: 0.37259, in 0.829s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35131, val loss: 0.35090, in 0.871s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32417, val loss: 0.32354, in 0.868s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33300, val loss: 0.33147, in 0.796s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35136, val loss: 0.35103, in 0.818s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35139, val loss: 0.35119, in 0.843s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33296, val loss: 0.33279, in 0.860s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33273, val loss: 0.33140, in 0.883s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36175, val loss: 0.36146, in 0.828s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34162, val loss: 0.34119, in 0.816s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31617, val loss: 0.31552, in 0.881s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32454, val loss: 0.32296, in 0.827s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34168, val loss: 0.34133, in 0.869s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34170, val loss: 0.34148, in 0.840s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32449, val loss: 0.32430, in 0.801s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32427, val loss: 0.32291, in 0.898s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35137, val loss: 0.35114, in 0.936s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33256, val loss: 0.33211, in 0.897s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30834, val loss: 0.30761, in 0.825s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31656, val loss: 0.31492, in 0.905s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33266, val loss: 0.33241, in 0.879s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33262, val loss: 0.33227, in 0.957s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31657, val loss: 0.31635, in 0.929s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31628, val loss: 0.31495, in 0.927s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34167, val loss: 0.34142, in 0.935s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32409, val loss: 0.32362, in 0.952s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30128, val loss: 0.30053, in 0.971s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30876, val loss: 0.30704, in 0.916s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32418, val loss: 0.32392, in 0.958s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32415, val loss: 0.32377, in 0.924s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30877, val loss: 0.30850, in 1.001s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30846, val loss: 0.30704, in 1.046s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33261, val loss: 0.33236, in 0.921s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31610, val loss: 0.31560, in 0.968s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29435, val loss: 0.29356, in 0.926s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30172, val loss: 0.29999, in 0.912s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31619, val loss: 0.31586, in 0.907s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31588, val loss: 0.31543, in 0.919s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30171, val loss: 0.30140, in 0.950s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30142, val loss: 0.29998, in 0.899s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30828, val loss: 0.30776, in 0.823s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32413, val loss: 0.32386, in 0.936s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28812, val loss: 0.28729, in 0.897s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29480, val loss: 0.29303, in 0.919s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30874, val loss: 0.30843, in 0.905s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30837, val loss: 0.30790, in 0.918s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29480, val loss: 0.29440, in 0.819s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29450, val loss: 0.29302, in 0.811s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30125, val loss: 0.30064, in 0.841s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31615, val loss: 0.31585, in 0.827s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28194, val loss: 0.28102, in 0.762s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28858, val loss: 0.28678, in 0.776s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30134, val loss: 0.30095, in 0.777s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30102, val loss: 0.30048, in 0.794s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28857, val loss: 0.28809, in 0.801s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28829, val loss: 0.28675, in 0.748s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29431, val loss: 0.29366, in 0.720s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30832, val loss: 0.30800, in 0.832s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27643, val loss: 0.27543, in 0.807s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28243, val loss: 0.28054, in 0.811s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29471, val loss: 0.29428, in 0.905s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28243, val loss: 0.28191, in 0.903s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29440, val loss: 0.29377, in 0.948s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28212, val loss: 0.28050, in 0.920s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28809, val loss: 0.28738, in 0.977s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30129, val loss: 0.30090, in 0.967s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27095, val loss: 0.26988, in 0.986s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27682, val loss: 0.27490, in 0.950s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28817, val loss: 0.28767, in 0.937s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27689, val loss: 0.27633, in 0.913s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28791, val loss: 0.28721, in 0.969s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27660, val loss: 0.27497, in 0.929s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28195, val loss: 0.28120, in 0.937s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29432, val loss: 0.29387, in 0.962s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26594, val loss: 0.26485, in 0.973s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27162, val loss: 0.26968, in 1.089s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28219, val loss: 0.28170, in 1.007s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27145, val loss: 0.27084, in 1.007s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28204, val loss: 0.28130, in 1.024s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27113, val loss: 0.26945, in 1.000s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27633, val loss: 0.27556, in 0.964s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28810, val loss: 0.28766, in 1.003s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26129, val loss: 0.26018, in 0.947s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26672, val loss: 0.26475, in 0.911s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27665, val loss: 0.27612, in 0.975s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26645, val loss: 0.26577, in 0.944s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27628, val loss: 0.27548, in 0.894s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26612, val loss: 0.26441, in 0.896s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27110, val loss: 0.27028, in 0.901s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28192, val loss: 0.28143, in 0.905s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25684, val loss: 0.25571, in 0.955s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26179, val loss: 0.25974, in 0.855s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27146, val loss: 0.27088, in 0.843s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26179, val loss: 0.26110, in 0.806s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26148, val loss: 0.25978, in 0.780s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27106, val loss: 0.27021, in 0.870s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26619, val loss: 0.26540, in 0.808s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27639, val loss: 0.27588, in 0.833s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25269, val loss: 0.25151, in 0.781s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25743, val loss: 0.25538, in 0.817s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26625, val loss: 0.26560, in 0.901s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25742, val loss: 0.25667, in 0.906s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25704, val loss: 0.25531, in 0.902s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26590, val loss: 0.26502, in 0.886s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26127, val loss: 0.26044, in 0.940s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27091, val loss: 0.27035, in 1.014s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24880, val loss: 0.24766, in 0.958s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25322, val loss: 0.25115, in 0.940s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26150, val loss: 0.26087, in 0.851s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25321, val loss: 0.25238, in 0.856s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25266, val loss: 0.25085, in 0.903s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26127, val loss: 0.26035, in 0.906s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25689, val loss: 0.25602, in 0.856s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26589, val loss: 0.26534, in 0.843s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24465, val loss: 0.24344, in 0.861s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24895, val loss: 0.24683, in 0.894s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25713, val loss: 0.25645, in 0.809s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24928, val loss: 0.24839, in 0.915s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24872, val loss: 0.24686, in 0.882s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25681, val loss: 0.25584, in 0.843s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25268, val loss: 0.25179, in 0.915s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24108, val loss: 0.23981, in 0.864s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26124, val loss: 0.26066, in 1.021s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24524, val loss: 0.24312, in 1.005s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25292, val loss: 0.25226, in 1.064s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25268, val loss: 0.25167, in 0.894s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24489, val loss: 0.24300, in 0.923s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24530, val loss: 0.24438, in 0.999s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24876, val loss: 0.24782, in 0.911s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23765, val loss: 0.23635, in 0.795s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25679, val loss: 0.25621, in 0.784s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24158, val loss: 0.23936, in 0.795s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24864, val loss: 0.24794, in 0.768s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24130, val loss: 0.23939, in 0.783s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24852, val loss: 0.24744, in 0.789s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24167, val loss: 0.24065, in 0.771s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24496, val loss: 0.24400, in 0.808s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23401, val loss: 0.23269, in 0.745s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25263, val loss: 0.25203, in 0.813s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23811, val loss: 0.23597, in 0.690s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23785, val loss: 0.23600, in 0.667s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23823, val loss: 0.23718, in 0.699s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24489, val loss: 0.24418, in 0.781s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24471, val loss: 0.24357, in 0.809s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24111, val loss: 0.24008, in 0.714s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23088, val loss: 0.22951, in 0.653s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24836, val loss: 0.24771, in 0.789s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23476, val loss: 0.23257, in 0.754s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23450, val loss: 0.23256, in 0.737s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.23466, val loss: 0.23354, in 0.746s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24121, val loss: 0.24051, in 0.722s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24114, val loss: 0.23995, in 0.716s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23766, val loss: 0.23658, in 0.661s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22769, val loss: 0.22632, in 0.846s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23160, val loss: 0.22947, in 0.731s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24453, val loss: 0.24388, in 0.804s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23132, val loss: 0.22940, in 0.734s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23155, val loss: 0.23034, in 0.755s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23776, val loss: 0.23700, in 0.820s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23771, val loss: 0.23647, in 0.807s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23432, val loss: 0.23321, in 0.842s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22485, val loss: 0.22344, in 0.672s\n",
      "[42/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22829, val loss: 0.22610, in 0.795s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22799, val loss: 0.22604, in 0.823s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24094, val loss: 0.24026, in 0.848s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22837, val loss: 0.22711, in 0.803s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23441, val loss: 0.23367, in 0.822s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23435, val loss: 0.23306, in 0.778s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23120, val loss: 0.23003, in 0.773s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22216, val loss: 0.22076, in 0.775s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22537, val loss: 0.22316, in 0.798s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22514, val loss: 0.22320, in 0.704s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23749, val loss: 0.23678, in 0.756s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22552, val loss: 0.22424, in 0.760s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23122, val loss: 0.22989, in 0.775s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23122, val loss: 0.23044, in 0.794s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22804, val loss: 0.22683, in 0.829s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21928, val loss: 0.21786, in 0.809s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22263, val loss: 0.22049, in 0.667s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22242, val loss: 0.22052, in 0.681s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23413, val loss: 0.23342, in 0.716s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22276, val loss: 0.22143, in 0.674s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22826, val loss: 0.22744, in 0.593s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22811, val loss: 0.22668, in 0.710s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22515, val loss: 0.22391, in 0.586s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21678, val loss: 0.21534, in 0.625s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21978, val loss: 0.21759, in 0.666s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23097, val loss: 0.23023, in 0.611s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21956, val loss: 0.21766, in 0.709s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21993, val loss: 0.21855, in 0.712s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22520, val loss: 0.22439, in 0.693s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22521, val loss: 0.22371, in 0.592s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22246, val loss: 0.22117, in 0.667s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21410, val loss: 0.21265, in 0.756s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21728, val loss: 0.21514, in 0.696s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22804, val loss: 0.22727, in 0.728s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21705, val loss: 0.21511, in 0.746s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21748, val loss: 0.21603, in 0.676s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22243, val loss: 0.22162, in 0.733s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22254, val loss: 0.22099, in 0.733s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21935, val loss: 0.21800, in 0.815s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21178, val loss: 0.21031, in 0.708s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21448, val loss: 0.21232, in 0.750s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21512, val loss: 0.21365, in 0.674s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22472, val loss: 0.22391, in 0.737s\n",
      "[42/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21437, val loss: 0.21239, in 0.743s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21971, val loss: 0.21811, in 0.868s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21940, val loss: 0.21853, in 0.885s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21688, val loss: 0.21547, in 0.695s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20967, val loss: 0.20824, in 0.678s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21225, val loss: 0.21010, in 0.743s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22199, val loss: 0.22116, in 0.764s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21214, val loss: 0.21015, in 0.734s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21252, val loss: 0.21100, in 0.848s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21691, val loss: 0.21606, in 0.670s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21715, val loss: 0.21549, in 0.706s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21402, val loss: 0.21255, in 0.809s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20695, val loss: 0.20550, in 0.842s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21003, val loss: 0.20798, in 0.727s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20996, val loss: 0.20793, in 0.677s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21911, val loss: 0.21828, in 0.762s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20989, val loss: 0.20832, in 0.818s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21452, val loss: 0.21364, in 0.754s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21436, val loss: 0.21266, in 0.831s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20493, val loss: 0.20353, in 0.630s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21180, val loss: 0.21030, in 0.683s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20757, val loss: 0.20544, in 0.870s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20783, val loss: 0.20575, in 0.827s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21666, val loss: 0.21581, in 0.822s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20773, val loss: 0.20611, in 0.733s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21190, val loss: 0.21104, in 0.763s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21207, val loss: 0.21033, in 0.720s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20295, val loss: 0.20154, in 0.778s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20926, val loss: 0.20775, in 0.802s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20554, val loss: 0.20343, in 0.635s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20541, val loss: 0.20325, in 0.732s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20576, val loss: 0.20405, in 0.741s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21398, val loss: 0.21312, in 0.795s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20108, val loss: 0.19970, in 0.604s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20971, val loss: 0.20881, in 0.783s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20956, val loss: 0.20773, in 0.764s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20710, val loss: 0.20555, in 0.731s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20358, val loss: 0.20146, in 0.742s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20355, val loss: 0.20139, in 0.758s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20380, val loss: 0.20210, in 0.718s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19924, val loss: 0.19784, in 0.675s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21169, val loss: 0.21081, in 0.770s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20727, val loss: 0.20638, in 0.855s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20745, val loss: 0.20556, in 0.818s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20507, val loss: 0.20352, in 0.777s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20166, val loss: 0.19941, in 0.639s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20159, val loss: 0.19943, in 0.809s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20188, val loss: 0.20018, in 0.699s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19701, val loss: 0.19562, in 0.837s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20948, val loss: 0.20862, in 0.798s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20314, val loss: 0.20155, in 0.775s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20529, val loss: 0.20440, in 0.811s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20541, val loss: 0.20352, in 0.819s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20009, val loss: 0.19839, in 0.614s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19935, val loss: 0.19714, in 0.794s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19942, val loss: 0.19716, in 0.812s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19493, val loss: 0.19357, in 0.705s\n",
      "[55/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20702, val loss: 0.20616, in 0.757s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20333, val loss: 0.20242, in 0.671s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20354, val loss: 0.20167, in 0.684s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20126, val loss: 0.19963, in 0.775s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19749, val loss: 0.19527, in 0.632s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19792, val loss: 0.19613, in 0.848s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19760, val loss: 0.19538, in 0.782s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19327, val loss: 0.19194, in 0.648s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20139, val loss: 0.20047, in 0.634s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20502, val loss: 0.20414, in 0.766s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20112, val loss: 0.19918, in 0.823s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19902, val loss: 0.19737, in 0.789s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19577, val loss: 0.19353, in 0.679s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19168, val loss: 0.19034, in 0.639s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19627, val loss: 0.19445, in 0.687s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19587, val loss: 0.19361, in 0.683s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20304, val loss: 0.20216, in 0.682s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19918, val loss: 0.19822, in 0.841s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19932, val loss: 0.19737, in 0.647s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19721, val loss: 0.19556, in 0.637s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19406, val loss: 0.19178, in 0.696s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19411, val loss: 0.19179, in 0.665s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18963, val loss: 0.18833, in 0.681s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19424, val loss: 0.19242, in 0.737s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19740, val loss: 0.19643, in 0.644s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20054, val loss: 0.19967, in 0.934s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19547, val loss: 0.19380, in 0.828s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19753, val loss: 0.19558, in 0.883s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19252, val loss: 0.19012, in 0.615s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19262, val loss: 0.19078, in 0.672s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19202, val loss: 0.18971, in 0.875s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18803, val loss: 0.18679, in 0.743s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19560, val loss: 0.19466, in 0.829s\n",
      "[55/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19385, val loss: 0.19217, in 0.702s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19870, val loss: 0.19784, in 0.867s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19092, val loss: 0.18849, in 0.819s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19575, val loss: 0.19377, in 0.869s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19061, val loss: 0.18881, in 0.727s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19044, val loss: 0.18809, in 0.726s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18618, val loss: 0.18500, in 0.755s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19362, val loss: 0.19273, in 0.822s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19692, val loss: 0.19605, in 0.668s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19189, val loss: 0.19024, in 0.764s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18483, val loss: 0.18363, in 0.674s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18877, val loss: 0.18697, in 0.773s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18853, val loss: 0.18619, in 0.773s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18898, val loss: 0.18654, in 0.807s\n",
      "[59/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19369, val loss: 0.19164, in 0.857s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19196, val loss: 0.19105, in 0.700s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19519, val loss: 0.19432, in 0.700s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19032, val loss: 0.18864, in 0.784s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18744, val loss: 0.18501, in 0.712s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18658, val loss: 0.18429, in 0.745s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18717, val loss: 0.18541, in 0.758s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19206, val loss: 0.19000, in 0.757s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18293, val loss: 0.18172, in 0.905s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19041, val loss: 0.18948, in 0.799s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19353, val loss: 0.19265, in 0.779s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18507, val loss: 0.18279, in 0.690s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18551, val loss: 0.18313, in 0.726s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18833, val loss: 0.18663, in 0.885s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18575, val loss: 0.18400, in 0.711s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19053, val loss: 0.18845, in 0.702s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18112, val loss: 0.17994, in 0.753s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19148, val loss: 0.19064, in 0.830s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18843, val loss: 0.18753, in 0.867s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18685, val loss: 0.18515, in 0.758s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18437, val loss: 0.18262, in 0.785s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18405, val loss: 0.18167, in 0.844s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17976, val loss: 0.17861, in 0.768s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18333, val loss: 0.18109, in 0.942s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18855, val loss: 0.18647, in 0.838s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18945, val loss: 0.18864, in 0.701s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18650, val loss: 0.18562, in 0.736s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18494, val loss: 0.18325, in 0.667s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18259, val loss: 0.18087, in 0.697s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18192, val loss: 0.17963, in 0.624s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18228, val loss: 0.17996, in 0.722s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17843, val loss: 0.17729, in 0.698s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18667, val loss: 0.18463, in 0.702s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18794, val loss: 0.18712, in 0.687s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18505, val loss: 0.18414, in 0.717s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18354, val loss: 0.18181, in 0.708s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18126, val loss: 0.17952, in 0.704s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18048, val loss: 0.17817, in 0.719s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18001, val loss: 0.17765, in 0.744s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17627, val loss: 0.17518, in 0.729s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18521, val loss: 0.18316, in 0.722s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18608, val loss: 0.18529, in 0.689s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18219, val loss: 0.18044, in 0.748s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18327, val loss: 0.18239, in 0.787s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17992, val loss: 0.17819, in 0.720s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17876, val loss: 0.17649, in 0.734s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17870, val loss: 0.17631, in 0.723s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17506, val loss: 0.17395, in 0.800s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18347, val loss: 0.18140, in 0.802s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18454, val loss: 0.18380, in 0.734s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18046, val loss: 0.17872, in 0.686s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18152, val loss: 0.18067, in 0.696s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17781, val loss: 0.17610, in 0.691s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17747, val loss: 0.17520, in 0.651s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17739, val loss: 0.17499, in 0.652s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17386, val loss: 0.17276, in 0.610s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18218, val loss: 0.18012, in 0.639s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18016, val loss: 0.17932, in 0.597s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18275, val loss: 0.18205, in 0.757s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17826, val loss: 0.17655, in 0.723s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17587, val loss: 0.17419, in 0.765s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17582, val loss: 0.17345, in 0.712s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17540, val loss: 0.17310, in 0.769s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18080, val loss: 0.17874, in 0.633s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17219, val loss: 0.17112, in 0.777s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18138, val loss: 0.18071, in 0.618s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17888, val loss: 0.17805, in 0.686s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17695, val loss: 0.17524, in 0.619s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17465, val loss: 0.17227, in 0.672s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17473, val loss: 0.17302, in 0.692s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17948, val loss: 0.17743, in 0.645s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17371, val loss: 0.17146, in 0.731s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17092, val loss: 0.16987, in 0.786s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17753, val loss: 0.17672, in 0.738s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17953, val loss: 0.17885, in 0.815s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17566, val loss: 0.17395, in 0.754s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17344, val loss: 0.17100, in 0.668s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17732, val loss: 0.17531, in 0.747s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17266, val loss: 0.17039, in 0.717s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17303, val loss: 0.17127, in 0.875s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16972, val loss: 0.16866, in 0.703s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17824, val loss: 0.17757, in 0.678s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17576, val loss: 0.17496, in 0.771s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17242, val loss: 0.16997, in 0.695s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17414, val loss: 0.17248, in 0.795s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17569, val loss: 0.17367, in 0.754s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17154, val loss: 0.16919, in 0.741s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17159, val loss: 0.16985, in 0.728s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16805, val loss: 0.16701, in 0.674s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17661, val loss: 0.17595, in 0.692s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17129, val loss: 0.16886, in 0.677s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17421, val loss: 0.17343, in 0.761s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17042, val loss: 0.16809, in 0.636s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17228, val loss: 0.17063, in 0.796s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17451, val loss: 0.17248, in 0.751s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17045, val loss: 0.16870, in 0.662s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16615, val loss: 0.16515, in 0.865s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17023, val loss: 0.16779, in 0.710s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17463, val loss: 0.17401, in 0.825s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17127, val loss: 0.16962, in 0.683s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17253, val loss: 0.17178, in 0.782s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16922, val loss: 0.16749, in 0.702s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16857, val loss: 0.16631, in 0.827s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17300, val loss: 0.17098, in 0.786s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16509, val loss: 0.16411, in 0.643s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16908, val loss: 0.16657, in 0.743s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17135, val loss: 0.17061, in 0.651s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17259, val loss: 0.17198, in 0.764s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16820, val loss: 0.16647, in 0.683s\n",
      "[73/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16965, val loss: 0.16799, in 0.854s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17185, val loss: 0.16984, in 0.711s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16677, val loss: 0.16447, in 0.805s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16370, val loss: 0.16273, in 0.726s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17141, val loss: 0.17082, in 0.643s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16721, val loss: 0.16476, in 0.811s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16945, val loss: 0.16876, in 0.817s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16852, val loss: 0.16684, in 0.686s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17061, val loss: 0.16858, in 0.662s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16666, val loss: 0.16497, in 0.768s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16588, val loss: 0.16353, in 0.642s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16267, val loss: 0.16170, in 0.612s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17027, val loss: 0.16968, in 0.688s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16837, val loss: 0.16769, in 0.624s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16541, val loss: 0.16293, in 0.767s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16708, val loss: 0.16543, in 0.692s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16525, val loss: 0.16357, in 0.690s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16443, val loss: 0.16214, in 0.675s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16163, val loss: 0.16066, in 0.704s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16900, val loss: 0.16693, in 0.800s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16905, val loss: 0.16850, in 0.665s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16689, val loss: 0.16625, in 0.646s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16436, val loss: 0.16185, in 0.628s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16434, val loss: 0.16269, in 0.645s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16565, val loss: 0.16401, in 0.665s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16304, val loss: 0.16076, in 0.671s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15987, val loss: 0.15894, in 0.638s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16716, val loss: 0.16514, in 0.813s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16575, val loss: 0.16511, in 0.770s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16347, val loss: 0.16094, in 0.707s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16745, val loss: 0.16693, in 0.888s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16329, val loss: 0.16164, in 0.746s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16206, val loss: 0.15976, in 0.716s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16271, in 0.759s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15851, val loss: 0.15765, in 0.776s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16568, val loss: 0.16366, in 0.755s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16458, val loss: 0.16397, in 0.713s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16196, val loss: 0.15949, in 0.748s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16606, val loss: 0.16558, in 0.787s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16229, val loss: 0.16066, in 0.735s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16331, val loss: 0.16170, in 0.755s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16082, val loss: 0.15853, in 0.769s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15749, val loss: 0.15667, in 0.777s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16454, val loss: 0.16250, in 0.730s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16315, val loss: 0.16261, in 0.707s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16060, val loss: 0.15811, in 0.666s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16464, val loss: 0.16419, in 0.726s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16237, val loss: 0.16076, in 0.691s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16103, val loss: 0.15939, in 0.743s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15665, val loss: 0.15584, in 0.679s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15978, val loss: 0.15755, in 0.792s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16311, val loss: 0.16105, in 0.767s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16189, val loss: 0.16138, in 0.696s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15957, val loss: 0.15710, in 0.775s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16351, val loss: 0.16305, in 0.658s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16014, val loss: 0.15851, in 0.711s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16067, val loss: 0.15909, in 0.724s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15902, val loss: 0.15674, in 0.660s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15530, val loss: 0.15452, in 0.700s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.15943, in 0.789s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16254, val loss: 0.16211, in 0.607s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15858, val loss: 0.15607, in 0.654s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16014, val loss: 0.15962, in 0.779s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15922, val loss: 0.15759, in 0.621s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15805, val loss: 0.15578, in 0.683s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15963, val loss: 0.15803, in 0.762s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15373, val loss: 0.15300, in 0.733s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16055, val loss: 0.15852, in 0.690s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16122, val loss: 0.16083, in 0.773s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15780, val loss: 0.15526, in 0.745s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15911, val loss: 0.15859, in 0.821s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15832, val loss: 0.15668, in 0.809s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15704, val loss: 0.15475, in 0.773s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15874, val loss: 0.15716, in 0.772s\n",
      "[80/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15281, val loss: 0.15208, in 0.875s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15921, val loss: 0.15720, in 0.724s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16040, val loss: 0.16001, in 0.697s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15781, val loss: 0.15736, in 0.763s\n",
      "[80/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15634, val loss: 0.15380, in 0.893s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15789, val loss: 0.15631, in 0.682s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15212, val loss: 0.15140, in 0.626s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15692, val loss: 0.15523, in 0.884s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15564, val loss: 0.15335, in 0.847s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15789, val loss: 0.15592, in 0.779s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15949, val loss: 0.15911, in 0.636s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15680, val loss: 0.15637, in 0.698s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15498, val loss: 0.15249, in 0.714s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15701, val loss: 0.15542, in 0.746s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15443, val loss: 0.15212, in 0.701s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15601, val loss: 0.15430, in 0.757s\n",
      "[84/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15082, val loss: 0.15008, in 0.903s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15696, val loss: 0.15498, in 0.675s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15850, val loss: 0.15815, in 0.718s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15587, val loss: 0.15544, in 0.616s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15417, val loss: 0.15170, in 0.589s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15617, val loss: 0.15457, in 0.526s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15321, val loss: 0.15086, in 0.595s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15475, val loss: 0.15304, in 0.578s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14999, val loss: 0.14922, in 0.548s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15611, val loss: 0.15413, in 0.531s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15758, val loss: 0.15724, in 0.498s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15334, val loss: 0.15085, in 0.499s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15507, val loss: 0.15465, in 0.510s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15254, val loss: 0.15015, in 0.464s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15480, val loss: 0.15319, in 0.686s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15399, val loss: 0.15228, in 0.531s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14880, val loss: 0.14805, in 0.624s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15497, val loss: 0.15299, in 0.640s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15620, val loss: 0.15586, in 0.770s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15418, val loss: 0.15376, in 0.645s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15182, val loss: 0.14938, in 0.749s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15404, val loss: 0.15242, in 0.636s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15141, val loss: 0.14906, in 0.751s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15280, val loss: 0.15111, in 0.699s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14762, val loss: 0.14694, in 0.716s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15377, val loss: 0.15184, in 0.758s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15491, val loss: 0.15454, in 0.688s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15336, val loss: 0.15297, in 0.656s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15093, val loss: 0.14846, in 0.694s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14814, in 0.632s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15284, val loss: 0.15129, in 0.704s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15202, val loss: 0.15034, in 0.675s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14692, val loss: 0.14625, in 0.594s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15256, val loss: 0.15066, in 0.570s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15395, val loss: 0.15358, in 0.545s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15246, val loss: 0.15204, in 0.569s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15013, val loss: 0.14762, in 0.464s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14980, val loss: 0.14748, in 0.496s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15199, val loss: 0.15046, in 0.546s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15082, val loss: 0.14917, in 0.531s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14619, val loss: 0.14554, in 0.467s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15171, val loss: 0.14981, in 0.472s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15320, val loss: 0.15286, in 0.459s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15128, val loss: 0.15089, in 0.504s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14893, val loss: 0.14640, in 0.512s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14867, val loss: 0.14638, in 0.521s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15075, val loss: 0.14924, in 0.495s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15002, val loss: 0.14834, in 0.513s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14548, val loss: 0.14482, in 0.473s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15077, val loss: 0.14886, in 0.520s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15238, val loss: 0.15206, in 0.513s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14982, val loss: 0.14947, in 0.546s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14795, val loss: 0.14543, in 0.583s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14790, val loss: 0.14558, in 0.502s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14882, val loss: 0.14718, in 0.507s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14963, val loss: 0.14815, in 0.546s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14404, in 0.514s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15008, val loss: 0.14819, in 0.518s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15155, val loss: 0.15122, in 0.628s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14892, val loss: 0.14859, in 0.594s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14728, val loss: 0.14474, in 0.553s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14707, val loss: 0.14473, in 0.616s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14893, val loss: 0.14745, in 0.603s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14787, val loss: 0.14626, in 0.671s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14385, val loss: 0.14322, in 0.661s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14896, val loss: 0.14707, in 0.623s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14813, val loss: 0.14776, in 0.618s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14648, val loss: 0.14393, in 0.624s\n",
      "[93/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15030, val loss: 0.14999, in 0.816s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14605, val loss: 0.14370, in 0.704s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14797, val loss: 0.14651, in 0.701s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14306, val loss: 0.14247, in 0.733s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14687, val loss: 0.14527, in 0.831s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14810, val loss: 0.14620, in 0.811s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14739, val loss: 0.14703, in 0.713s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14945, val loss: 0.14912, in 0.740s\n",
      "[89/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14561, val loss: 0.14309, in 0.852s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14727, val loss: 0.14582, in 0.724s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14497, val loss: 0.14260, in 0.828s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14740, val loss: 0.14552, in 0.686s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14191, val loss: 0.14134, in 0.913s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14604, val loss: 0.14443, in 0.833s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14829, val loss: 0.14796, in 0.771s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14611, val loss: 0.14575, in 0.994s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14656, val loss: 0.14505, in 0.723s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14213, in 0.870s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14417, val loss: 0.14180, in 0.835s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14086, val loss: 0.14029, in 0.815s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14308, in 0.882s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14616, val loss: 0.14424, in 0.963s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14741, val loss: 0.14710, in 0.748s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14572, val loss: 0.14419, in 0.665s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14515, val loss: 0.14480, in 0.750s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14400, val loss: 0.14143, in 0.731s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14323, val loss: 0.14090, in 0.842s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14024, val loss: 0.13971, in 0.807s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14403, val loss: 0.14243, in 0.865s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14503, val loss: 0.14314, in 0.914s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14676, val loss: 0.14644, in 0.846s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14511, val loss: 0.14357, in 0.866s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14405, val loss: 0.14372, in 0.914s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14296, val loss: 0.14042, in 0.889s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14194, val loss: 0.13966, in 0.903s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13961, val loss: 0.13912, in 0.760s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14347, val loss: 0.14189, in 0.727s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14591, val loss: 0.14560, in 0.792s\n",
      "[93/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14422, val loss: 0.14232, in 0.955s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14430, val loss: 0.14278, in 0.861s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14228, val loss: 0.13972, in 0.867s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14265, val loss: 0.14232, in 0.942s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14129, val loss: 0.13898, in 0.892s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14268, val loss: 0.14112, in 0.855s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13828, in 1.008s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14524, val loss: 0.14486, in 0.760s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14359, val loss: 0.14203, in 0.765s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14315, val loss: 0.14129, in 0.870s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14165, val loss: 0.13906, in 0.722s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14187, val loss: 0.14159, in 0.709s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14055, val loss: 0.13824, in 0.608s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13821, val loss: 0.13767, in 0.560s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14457, val loss: 0.14420, in 0.548s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14177, val loss: 0.14022, in 0.686s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14126, in 0.611s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14124, val loss: 0.14089, in 0.534s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14222, val loss: 0.14036, in 0.600s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14068, val loss: 0.13809, in 0.625s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13973, val loss: 0.13743, in 0.563s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14398, val loss: 0.14361, in 0.513s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13753, val loss: 0.13700, in 0.593s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14096, val loss: 0.13942, in 0.531s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14054, val loss: 0.14022, in 0.527s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14194, val loss: 0.14046, in 0.619s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14135, val loss: 0.13951, in 0.598s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13984, val loss: 0.13725, in 0.579s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13881, val loss: 0.13653, in 0.656s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14047, val loss: 0.13891, in 0.483s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14330, val loss: 0.14292, in 0.531s\n",
      "[97/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13667, val loss: 0.13617, in 0.637s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13971, val loss: 0.13942, in 0.446s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14061, val loss: 0.13872, in 0.422s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14112, val loss: 0.13966, in 0.467s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13904, val loss: 0.13642, in 0.474s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13986, val loss: 0.13831, in 0.431s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14209, val loss: 0.14173, in 0.480s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13801, val loss: 0.13572, in 0.555s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13611, val loss: 0.13562, in 0.515s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13905, val loss: 0.13878, in 0.582s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14051, val loss: 0.13907, in 0.578s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14000, val loss: 0.13811, in 0.645s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13847, val loss: 0.13585, in 0.627s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13927, val loss: 0.13768, in 0.650s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14115, val loss: 0.14075, in 0.717s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13705, val loss: 0.13474, in 0.682s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13536, val loss: 0.13486, in 0.588s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13846, val loss: 0.13820, in 0.647s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13946, val loss: 0.13804, in 0.640s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13693, in 0.750s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13759, val loss: 0.13498, in 0.770s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13846, val loss: 0.13682, in 0.832s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13635, val loss: 0.13406, in 0.784s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13480, val loss: 0.13434, in 0.789s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14034, val loss: 0.13995, in 0.823s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13780, val loss: 0.13752, in 0.767s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13803, val loss: 0.13623, in 0.712s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13874, val loss: 0.13731, in 0.930s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13671, val loss: 0.13411, in 0.709s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13755, val loss: 0.13592, in 0.755s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13578, val loss: 0.13349, in 0.677s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13986, val loss: 0.13949, in 0.667s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13403, val loss: 0.13358, in 0.690s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13693, val loss: 0.13666, in 0.735s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13756, val loss: 0.13573, in 0.707s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13820, val loss: 0.13674, in 0.667s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13626, val loss: 0.13364, in 0.646s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13521, val loss: 0.13291, in 0.716s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13656, val loss: 0.13496, in 0.826s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13914, val loss: 0.13878, in 0.831s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13313, val loss: 0.13269, in 0.902s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13594, val loss: 0.13569, in 0.873s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13684, val loss: 0.13500, in 0.782s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13765, val loss: 0.13618, in 0.835s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13558, val loss: 0.13297, in 0.930s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13430, val loss: 0.13200, in 0.691s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13269, val loss: 0.13226, in 0.712s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13827, val loss: 0.13793, in 0.805s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13410, in 0.930s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13437, in 0.729s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13519, val loss: 0.13497, in 0.878s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13503, val loss: 0.13240, in 0.699s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13565, val loss: 0.13417, in 0.921s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13376, val loss: 0.13146, in 0.771s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13213, val loss: 0.13164, in 0.605s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13758, val loss: 0.13725, in 0.737s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13497, val loss: 0.13344, in 0.723s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13570, val loss: 0.13383, in 0.668s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13475, val loss: 0.13451, in 0.585s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13426, val loss: 0.13166, in 0.722s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13310, val loss: 0.13081, in 0.631s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13481, val loss: 0.13334, in 0.751s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13119, val loss: 0.13071, in 0.791s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13703, val loss: 0.13664, in 0.749s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13292, in 0.725s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13518, val loss: 0.13329, in 0.772s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13381, val loss: 0.13360, in 0.877s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13360, val loss: 0.13097, in 0.758s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13232, val loss: 0.13007, in 0.818s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13421, val loss: 0.13274, in 0.837s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12993, in 0.689s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13640, val loss: 0.13603, in 0.601s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13398, val loss: 0.13239, in 0.740s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13266, in 0.633s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13326, val loss: 0.13307, in 0.682s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13306, val loss: 0.13043, in 0.701s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13189, val loss: 0.12962, in 0.746s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13536, in 0.745s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13195, in 0.845s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.12907, in 0.821s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13341, val loss: 0.13181, in 0.755s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13269, val loss: 0.13249, in 0.838s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13347, val loss: 0.13160, in 1.048s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13227, val loss: 0.12965, in 0.835s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13121, val loss: 0.12896, in 0.907s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12883, val loss: 0.12833, in 0.832s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13270, val loss: 0.13131, in 0.859s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13468, val loss: 0.13435, in 0.998s\n",
      "[108/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13275, val loss: 0.13116, in 0.887s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13294, val loss: 0.13102, in 0.703s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13162, val loss: 0.12902, in 0.795s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13196, val loss: 0.13177, in 0.858s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13068, val loss: 0.12843, in 0.715s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12799, val loss: 0.12752, in 0.643s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13218, val loss: 0.13079, in 0.751s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13413, val loss: 0.13380, in 0.736s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13205, val loss: 0.13048, in 0.775s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13109, val loss: 0.12850, in 0.603s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13139, val loss: 0.13120, in 0.601s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13217, val loss: 0.13024, in 0.805s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13029, val loss: 0.12802, in 0.556s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12751, val loss: 0.12704, in 0.633s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13353, val loss: 0.13320, in 0.510s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13147, val loss: 0.13008, in 0.590s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13165, val loss: 0.13008, in 0.469s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13098, val loss: 0.13078, in 0.483s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13049, val loss: 0.12790, in 0.567s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12945, val loss: 0.12720, in 0.515s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13129, val loss: 0.12939, in 0.642s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12680, val loss: 0.12637, in 0.600s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13105, val loss: 0.12964, in 0.533s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13119, val loss: 0.12959, in 0.558s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13053, val loss: 0.13032, in 0.515s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13271, val loss: 0.13240, in 0.707s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12864, val loss: 0.12640, in 0.512s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12992, val loss: 0.12731, in 0.609s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13075, val loss: 0.12883, in 0.524s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12615, val loss: 0.12571, in 0.571s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12880, in 0.579s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13002, val loss: 0.12976, in 0.465s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13213, val loss: 0.13180, in 0.466s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12887, in 0.561s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12940, val loss: 0.12678, in 0.481s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12795, val loss: 0.12574, in 0.533s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13035, val loss: 0.12841, in 0.471s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12539, val loss: 0.12496, in 0.530s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12938, val loss: 0.12915, in 0.499s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12982, val loss: 0.12841, in 0.514s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12971, val loss: 0.12813, in 0.535s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13138, val loss: 0.13103, in 0.570s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12875, val loss: 0.12612, in 0.605s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12983, val loss: 0.12784, in 0.563s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12721, val loss: 0.12503, in 0.617s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12896, val loss: 0.12758, in 0.452s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12470, val loss: 0.12426, in 0.491s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13098, val loss: 0.13063, in 0.442s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12878, val loss: 0.12723, in 0.534s\n",
      "[118/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12876, val loss: 0.12853, in 0.621s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12932, val loss: 0.12732, in 0.470s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12828, val loss: 0.12563, in 0.496s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12664, val loss: 0.12445, in 0.471s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12806, val loss: 0.12669, in 0.532s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12391, val loss: 0.12348, in 0.522s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12801, val loss: 0.12781, in 0.402s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13039, val loss: 0.13005, in 0.545s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12811, val loss: 0.12652, in 0.495s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12617, val loss: 0.12396, in 0.385s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12860, val loss: 0.12663, in 0.444s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12714, val loss: 0.12454, in 0.473s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12757, val loss: 0.12622, in 0.340s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12344, val loss: 0.12302, in 0.362s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12743, val loss: 0.12723, in 0.348s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12763, val loss: 0.12605, in 0.337s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12970, val loss: 0.12933, in 0.412s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12776, val loss: 0.12580, in 0.313s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12542, val loss: 0.12320, in 0.361s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12666, val loss: 0.12404, in 0.349s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12688, val loss: 0.12551, in 0.313s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12280, val loss: 0.12236, in 0.355s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12667, val loss: 0.12653, in 0.369s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12714, val loss: 0.12554, in 0.292s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12884, val loss: 0.12851, in 0.275s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12683, val loss: 0.12488, in 0.359s\n",
      "[118/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12488, val loss: 0.12265, in 0.349s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12598, val loss: 0.12339, in 0.332s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12246, val loss: 0.12200, in 0.293s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12512, val loss: 0.12374, in 0.377s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12807, val loss: 0.12775, in 0.273s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12650, val loss: 0.12494, in 0.316s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12580, in 0.321s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12563, val loss: 0.12304, in 0.218s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12211, in 0.288s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12184, val loss: 0.12137, in 0.234s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12608, val loss: 0.12414, in 0.353s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12560, val loss: 0.12544, in 0.235s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12753, val loss: 0.12720, in 0.252s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12444, val loss: 0.12308, in 0.290s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12567, val loss: 0.12413, in 0.250s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12398, val loss: 0.12175, in 0.222s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12493, val loss: 0.12238, in 0.297s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12573, val loss: 0.12376, in 0.221s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12108, val loss: 0.12065, in 0.238s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12532, val loss: 0.12377, in 0.208s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12378, val loss: 0.12244, in 0.238s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12504, val loss: 0.12488, in 0.251s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12570, val loss: 0.12538, in 0.281s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12325, val loss: 0.12103, in 0.192s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12445, val loss: 0.12188, in 0.187s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12057, val loss: 0.12016, in 0.221s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12482, val loss: 0.12287, in 0.239s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12423, in 0.200s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12465, val loss: 0.12312, in 0.240s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12534, val loss: 0.12502, in 0.203s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12322, val loss: 0.12187, in 0.250s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12258, val loss: 0.12040, in 0.234s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12395, val loss: 0.12135, in 0.225s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12442, val loss: 0.12245, in 0.176s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11994, val loss: 0.11957, in 0.197s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12387, val loss: 0.12374, in 0.171s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12400, val loss: 0.12247, in 0.181s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12257, val loss: 0.12122, in 0.170s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12463, val loss: 0.12432, in 0.188s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12213, val loss: 0.11993, in 0.165s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12306, val loss: 0.12047, in 0.211s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11925, val loss: 0.11889, in 0.203s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12360, val loss: 0.12168, in 0.218s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12324, val loss: 0.12172, in 0.187s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12318, val loss: 0.12311, in 0.212s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12393, val loss: 0.12368, in 0.204s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12209, val loss: 0.12072, in 0.217s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12157, val loss: 0.11943, in 0.202s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12234, val loss: 0.11977, in 0.175s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12292, val loss: 0.12098, in 0.176s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12102, in 0.187s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11869, val loss: 0.11831, in 0.205s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12222, in 0.197s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12174, val loss: 0.12038, in 0.170s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12303, val loss: 0.12277, in 0.203s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12091, val loss: 0.11878, in 0.165s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12165, val loss: 0.11910, in 0.164s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12215, val loss: 0.12023, in 0.185s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12201, val loss: 0.12048, in 0.187s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11811, val loss: 0.11772, in 0.203s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12178, val loss: 0.12169, in 0.215s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12113, val loss: 0.11979, in 0.221s\n",
      "[127/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12201, val loss: 0.12177, in 0.208s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12018, val loss: 0.11809, in 0.213s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12102, val loss: 0.11850, in 0.216s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.11993, in 0.179s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12148, val loss: 0.11957, in 0.217s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11772, val loss: 0.11731, in 0.194s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12126, val loss: 0.12120, in 0.177s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12052, val loss: 0.11920, in 0.203s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12157, val loss: 0.12133, in 0.188s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11958, val loss: 0.11753, in 0.205s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11985, val loss: 0.11728, in 0.206s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12087, val loss: 0.11934, in 0.191s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12066, val loss: 0.11877, in 0.197s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11728, val loss: 0.11688, in 0.183s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12062, val loss: 0.12057, in 0.211s\n",
      "[129/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11987, val loss: 0.11854, in 0.201s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11916, val loss: 0.11710, in 0.198s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12099, val loss: 0.12075, in 0.231s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11919, val loss: 0.11659, in 0.208s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11671, val loss: 0.11631, in 0.189s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12019, val loss: 0.11829, in 0.225s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11915, val loss: 0.11765, in 0.258s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11929, val loss: 0.11796, in 0.162s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11959, val loss: 0.11955, in 0.211s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11867, val loss: 0.11660, in 0.192s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12038, val loss: 0.12010, in 0.208s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11860, val loss: 0.11602, in 0.202s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11625, val loss: 0.11585, in 0.189s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11927, val loss: 0.11923, in 0.172s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11769, in 0.209s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11855, val loss: 0.11708, in 0.196s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11879, val loss: 0.11746, in 0.185s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11811, val loss: 0.11603, in 0.212s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11815, val loss: 0.11557, in 0.186s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11933, val loss: 0.11906, in 0.228s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11575, val loss: 0.11537, in 0.191s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11835, val loss: 0.11698, in 0.187s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11860, val loss: 0.11855, in 0.201s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11911, val loss: 0.11721, in 0.208s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11799, val loss: 0.11654, in 0.219s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11753, val loss: 0.11496, in 0.177s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11755, val loss: 0.11548, in 0.215s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11805, val loss: 0.11666, in 0.166s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11863, val loss: 0.11836, in 0.238s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11850, val loss: 0.11659, in 0.164s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11519, val loss: 0.11482, in 0.233s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11771, val loss: 0.11767, in 0.202s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11746, val loss: 0.11602, in 0.200s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11479, in 0.200s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11829, val loss: 0.11803, in 0.162s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11591, val loss: 0.11335, in 0.251s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11748, val loss: 0.11613, in 0.213s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11468, val loss: 0.11431, in 0.206s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11694, in 0.185s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11789, val loss: 0.11600, in 0.216s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11697, val loss: 0.11554, in 0.205s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11782, val loss: 0.11756, in 0.182s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11633, val loss: 0.11426, in 0.213s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11637, val loss: 0.11636, in 0.177s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11524, val loss: 0.11270, in 0.251s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11641, val loss: 0.11507, in 0.233s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11360, val loss: 0.11323, in 0.227s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11715, val loss: 0.11529, in 0.233s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11647, val loss: 0.11508, in 0.211s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11565, val loss: 0.11359, in 0.179s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11708, val loss: 0.11684, in 0.190s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11463, val loss: 0.11210, in 0.173s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11577, val loss: 0.11580, in 0.235s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11278, val loss: 0.11242, in 0.196s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11581, val loss: 0.11446, in 0.203s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11660, val loss: 0.11477, in 0.212s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11603, val loss: 0.11463, in 0.208s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11678, val loss: 0.11654, in 0.173s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11517, val loss: 0.11313, in 0.217s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11424, val loss: 0.11168, in 0.176s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11529, val loss: 0.11394, in 0.174s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11243, val loss: 0.11206, in 0.177s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11500, val loss: 0.11503, in 0.194s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11626, val loss: 0.11440, in 0.169s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11549, val loss: 0.11408, in 0.159s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11616, val loss: 0.11596, in 0.202s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11459, val loss: 0.11256, in 0.198s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11194, val loss: 0.11156, in 0.185s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11395, val loss: 0.11138, in 0.219s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11457, val loss: 0.11324, in 0.252s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11452, val loss: 0.11456, in 0.254s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11515, val loss: 0.11375, in 0.240s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11580, val loss: 0.11395, in 0.275s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11561, val loss: 0.11539, in 0.289s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11329, val loss: 0.11132, in 0.268s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11128, val loss: 0.11093, in 0.251s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11340, val loss: 0.11084, in 0.265s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11409, val loss: 0.11269, in 0.243s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11403, val loss: 0.11272, in 0.258s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11400, val loss: 0.11403, in 0.253s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11525, val loss: 0.11341, in 0.243s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11512, val loss: 0.11490, in 0.180s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11281, val loss: 0.11087, in 0.212s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11065, val loss: 0.11032, in 0.210s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11281, val loss: 0.11022, in 0.201s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11342, val loss: 0.11205, in 0.186s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11348, val loss: 0.11353, in 0.187s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11331, val loss: 0.11203, in 0.198s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11445, val loss: 0.11425, in 0.187s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11433, val loss: 0.11252, in 0.226s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11202, val loss: 0.11013, in 0.212s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11222, val loss: 0.10964, in 0.175s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10996, val loss: 0.10965, in 0.205s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11170, in 0.188s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11287, val loss: 0.11158, in 0.186s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11292, val loss: 0.11298, in 0.216s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11357, val loss: 0.11339, in 0.204s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11393, val loss: 0.11211, in 0.216s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11145, val loss: 0.10956, in 0.192s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11170, val loss: 0.10914, in 0.221s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11260, val loss: 0.11121, in 0.176s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10946, val loss: 0.10918, in 0.217s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11125, in 0.180s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11225, val loss: 0.11232, in 0.193s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11318, val loss: 0.11297, in 0.195s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11338, val loss: 0.11156, in 0.185s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11027, val loss: 0.10843, in 0.208s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10909, val loss: 0.10883, in 0.195s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11204, val loss: 0.11076, in 0.222s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11182, val loss: 0.11192, in 0.189s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.10768, in 0.277s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11106, val loss: 0.10970, in 0.268s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11289, val loss: 0.11268, in 0.207s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11290, val loss: 0.11110, in 0.223s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10965, val loss: 0.10782, in 0.191s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10844, val loss: 0.10818, in 0.217s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11141, val loss: 0.11154, in 0.203s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10969, val loss: 0.10716, in 0.191s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11154, val loss: 0.11027, in 0.225s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11055, val loss: 0.10922, in 0.238s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11219, val loss: 0.11198, in 0.212s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10913, val loss: 0.10731, in 0.174s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11241, val loss: 0.11058, in 0.239s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10796, val loss: 0.10770, in 0.188s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11110, val loss: 0.11124, in 0.198s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10919, val loss: 0.10668, in 0.233s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11059, val loss: 0.10933, in 0.241s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10997, val loss: 0.10864, in 0.211s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11173, val loss: 0.11155, in 0.214s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10864, val loss: 0.10682, in 0.199s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11197, val loss: 0.11010, in 0.196s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11072, val loss: 0.11084, in 0.173s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10738, val loss: 0.10713, in 0.217s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10884, val loss: 0.10633, in 0.195s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.10903, in 0.196s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10964, val loss: 0.10829, in 0.211s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11123, val loss: 0.11102, in 0.245s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10815, val loss: 0.10636, in 0.243s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11147, val loss: 0.10963, in 0.233s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11010, val loss: 0.11024, in 0.201s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10697, val loss: 0.10667, in 0.201s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10859, val loss: 0.10607, in 0.191s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10929, val loss: 0.10795, in 0.189s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10987, val loss: 0.10862, in 0.215s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11087, val loss: 0.11067, in 0.200s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10759, val loss: 0.10580, in 0.201s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10962, val loss: 0.10977, in 0.199s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11096, val loss: 0.10914, in 0.224s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10653, val loss: 0.10625, in 0.221s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10820, val loss: 0.10566, in 0.205s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10943, val loss: 0.10820, in 0.222s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10883, val loss: 0.10752, in 0.224s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11048, val loss: 0.11030, in 0.199s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10650, val loss: 0.10474, in 0.207s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.10850, in 0.210s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10893, val loss: 0.10908, in 0.230s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10535, in 0.198s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10608, val loss: 0.10582, in 0.231s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.11003, in 0.196s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10715, in 0.229s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10604, val loss: 0.10428, in 0.199s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10850, val loss: 0.10729, in 0.245s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.10881, in 0.182s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10982, val loss: 0.10802, in 0.243s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10562, val loss: 0.10533, in 0.234s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10485, in 0.241s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10968, val loss: 0.10953, in 0.206s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10781, val loss: 0.10661, in 0.237s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10555, val loss: 0.10382, in 0.243s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10577, in 0.266s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10814, val loss: 0.10832, in 0.215s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10900, val loss: 0.10722, in 0.236s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10522, val loss: 0.10492, in 0.208s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10605, val loss: 0.10351, in 0.276s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10857, val loss: 0.10843, in 0.260s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10486, val loss: 0.10312, in 0.215s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10733, val loss: 0.10614, in 0.223s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10765, val loss: 0.10786, in 0.232s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10650, val loss: 0.10522, in 0.244s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.10687, in 0.210s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10469, val loss: 0.10438, in 0.203s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10304, in 0.200s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10798, val loss: 0.10787, in 0.193s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10447, val loss: 0.10271, in 0.197s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10693, val loss: 0.10573, in 0.202s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10709, val loss: 0.10731, in 0.218s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10835, val loss: 0.10657, in 0.196s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10608, val loss: 0.10482, in 0.244s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10534, val loss: 0.10281, in 0.205s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10325, val loss: 0.10295, in 0.292s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10731, in 0.221s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10392, val loss: 0.10215, in 0.219s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10648, val loss: 0.10527, in 0.256s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10787, val loss: 0.10609, in 0.200s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10633, val loss: 0.10657, in 0.238s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10541, val loss: 0.10419, in 0.227s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10284, val loss: 0.10253, in 0.181s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10489, val loss: 0.10238, in 0.218s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10347, val loss: 0.10168, in 0.204s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10671, val loss: 0.10663, in 0.225s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10744, val loss: 0.10567, in 0.188s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10604, val loss: 0.10484, in 0.216s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10548, val loss: 0.10573, in 0.242s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10463, val loss: 0.10341, in 0.229s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10240, val loss: 0.10211, in 0.230s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10641, val loss: 0.10631, in 0.186s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10296, val loss: 0.10117, in 0.202s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10362, val loss: 0.10113, in 0.291s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10682, val loss: 0.10503, in 0.222s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10313, in 0.181s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10520, val loss: 0.10402, in 0.243s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10503, val loss: 0.10528, in 0.225s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10218, val loss: 0.10190, in 0.196s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10617, val loss: 0.10607, in 0.195s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10256, val loss: 0.10077, in 0.217s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10328, val loss: 0.10076, in 0.186s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10653, val loss: 0.10472, in 0.190s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10495, val loss: 0.10376, in 0.200s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10391, val loss: 0.10273, in 0.246s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10191, val loss: 0.10159, in 0.193s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10464, val loss: 0.10488, in 0.226s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10578, val loss: 0.10568, in 0.195s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10157, val loss: 0.09983, in 0.223s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10609, val loss: 0.10425, in 0.227s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10460, val loss: 0.10341, in 0.195s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10277, val loss: 0.10026, in 0.269s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10341, val loss: 0.10222, in 0.200s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10459, in 0.189s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10154, val loss: 0.10125, in 0.193s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10506, val loss: 0.10497, in 0.228s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10115, val loss: 0.09939, in 0.187s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10429, val loss: 0.10310, in 0.219s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10230, val loss: 0.09981, in 0.210s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10488, val loss: 0.10306, in 0.232s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10101, val loss: 0.10072, in 0.218s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10380, val loss: 0.10404, in 0.230s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10297, val loss: 0.10176, in 0.263s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10074, val loss: 0.09898, in 0.204s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10459, val loss: 0.10451, in 0.242s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10368, val loss: 0.10253, in 0.199s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10443, val loss: 0.10262, in 0.212s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10187, val loss: 0.09940, in 0.243s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10064, val loss: 0.10035, in 0.202s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10254, val loss: 0.10132, in 0.188s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10027, val loss: 0.09851, in 0.201s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10226, val loss: 0.10248, in 0.283s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10427, val loss: 0.10415, in 0.222s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10323, val loss: 0.10207, in 0.192s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10401, val loss: 0.10220, in 0.196s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10135, val loss: 0.09890, in 0.195s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10216, val loss: 0.10094, in 0.230s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09902, in 0.301s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10184, val loss: 0.10208, in 0.215s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10316, val loss: 0.10303, in 0.215s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09979, val loss: 0.09804, in 0.278s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10265, val loss: 0.10150, in 0.243s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10114, val loss: 0.09870, in 0.207s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10342, val loss: 0.10163, in 0.271s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10169, val loss: 0.10047, in 0.239s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10140, val loss: 0.10167, in 0.230s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09890, val loss: 0.09863, in 0.252s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10260, in 0.242s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09935, val loss: 0.09763, in 0.278s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10304, val loss: 0.10126, in 0.203s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10029, val loss: 0.09781, in 0.272s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10132, val loss: 0.10016, in 0.299s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10114, val loss: 0.10142, in 0.230s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10043, val loss: 0.09924, in 0.302s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09822, val loss: 0.09796, in 0.273s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09844, val loss: 0.09674, in 0.221s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10221, val loss: 0.10211, in 0.307s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09981, val loss: 0.09730, in 0.230s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10266, val loss: 0.10089, in 0.264s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10096, val loss: 0.09979, in 0.268s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10003, val loss: 0.09884, in 0.220s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10070, val loss: 0.10100, in 0.248s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09768, val loss: 0.09741, in 0.220s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09803, val loss: 0.09636, in 0.241s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10196, val loss: 0.10185, in 0.212s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10222, val loss: 0.10047, in 0.262s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10032, val loss: 0.09919, in 0.244s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09866, val loss: 0.09616, in 0.314s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09980, val loss: 0.09864, in 0.224s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09728, val loss: 0.09701, in 0.277s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10093, val loss: 0.10082, in 0.245s\n",
      "[163/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09739, val loss: 0.09576, in 0.275s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09928, val loss: 0.09955, in 0.350s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10165, val loss: 0.09991, in 0.235s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09993, val loss: 0.09879, in 0.224s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09826, val loss: 0.09577, in 0.231s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09943, val loss: 0.09827, in 0.229s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10051, val loss: 0.10041, in 0.234s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09889, val loss: 0.09918, in 0.202s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09690, val loss: 0.09526, in 0.246s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10055, val loss: 0.09883, in 0.235s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09608, val loss: 0.09580, in 0.307s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09790, val loss: 0.09538, in 0.240s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09869, val loss: 0.09754, in 0.295s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09864, val loss: 0.09749, in 0.267s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09839, val loss: 0.09870, in 0.230s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09656, val loss: 0.09491, in 0.217s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09571, val loss: 0.09543, in 0.239s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10017, val loss: 0.09845, in 0.250s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09941, in 0.317s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09751, val loss: 0.09502, in 0.262s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09834, val loss: 0.09721, in 0.245s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09829, val loss: 0.09716, in 0.279s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09457, in 0.220s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09805, val loss: 0.09836, in 0.256s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09916, val loss: 0.09913, in 0.213s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09533, val loss: 0.09509, in 0.238s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09788, in 0.250s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09722, val loss: 0.09472, in 0.237s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09774, val loss: 0.09661, in 0.256s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09781, val loss: 0.09811, in 0.230s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09718, val loss: 0.09608, in 0.330s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09582, val loss: 0.09417, in 0.276s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09865, val loss: 0.09861, in 0.254s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09922, val loss: 0.09749, in 0.243s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09499, val loss: 0.09474, in 0.276s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09626, val loss: 0.09381, in 0.318s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09736, val loss: 0.09622, in 0.280s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09746, val loss: 0.09775, in 0.249s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09691, val loss: 0.09579, in 0.232s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09544, val loss: 0.09380, in 0.245s\n",
      "[173/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09827, val loss: 0.09826, in 0.283s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09839, val loss: 0.09669, in 0.265s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09476, val loss: 0.09449, in 0.251s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09609, val loss: 0.09364, in 0.241s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09725, val loss: 0.09755, in 0.245s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09682, val loss: 0.09571, in 0.261s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09656, val loss: 0.09546, in 0.276s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09475, val loss: 0.09311, in 0.268s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09782, val loss: 0.09782, in 0.239s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09446, val loss: 0.09418, in 0.241s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09779, val loss: 0.09606, in 0.332s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09563, val loss: 0.09320, in 0.242s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09646, val loss: 0.09534, in 0.228s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09686, val loss: 0.09717, in 0.235s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09266, in 0.244s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09618, val loss: 0.09509, in 0.290s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09741, val loss: 0.09740, in 0.269s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09354, in 0.293s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09227, in 0.264s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09736, val loss: 0.09565, in 0.271s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09616, val loss: 0.09506, in 0.251s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09646, val loss: 0.09680, in 0.268s\n",
      "[173/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09401, val loss: 0.09237, in 0.241s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09317, in 0.213s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09586, val loss: 0.09477, in 0.277s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09689, val loss: 0.09690, in 0.251s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09425, val loss: 0.09189, in 0.230s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09695, val loss: 0.09527, in 0.239s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09576, val loss: 0.09468, in 0.224s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09349, val loss: 0.09186, in 0.236s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09550, val loss: 0.09441, in 0.216s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09515, val loss: 0.09546, in 0.321s\n",
      "[174/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09311, val loss: 0.09286, in 0.235s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09650, val loss: 0.09652, in 0.243s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09386, val loss: 0.09152, in 0.202s\n",
      "[176/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09470, in 0.222s\n",
      "[172/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09549, val loss: 0.09441, in 0.219s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09315, val loss: 0.09151, in 0.222s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09511, val loss: 0.09402, in 0.218s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09444, val loss: 0.09477, in 0.237s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09560, in 0.221s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09201, val loss: 0.09175, in 0.264s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09101, in 0.240s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09587, val loss: 0.09420, in 0.222s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09435, val loss: 0.09326, in 0.260s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09279, val loss: 0.09116, in 0.227s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09396, val loss: 0.09426, in 0.199s\n",
      "[176/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09182, val loss: 0.09158, in 0.178s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09297, in 0.248s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09514, val loss: 0.09518, in 0.224s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09307, val loss: 0.09074, in 0.185s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09554, val loss: 0.09386, in 0.184s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09407, val loss: 0.09299, in 0.181s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09197, val loss: 0.09038, in 0.195s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09130, val loss: 0.09108, in 0.187s\n",
      "[181/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09360, val loss: 0.09390, in 0.221s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09359, val loss: 0.09251, in 0.215s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09461, in 0.218s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09349, in 0.191s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09235, val loss: 0.09000, in 0.204s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09386, val loss: 0.09277, in 0.175s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09005, in 0.186s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09091, val loss: 0.09071, in 0.206s\n",
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09234, in 0.223s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09353, in 0.246s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09351, val loss: 0.09243, in 0.232s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09419, val loss: 0.09252, in 0.279s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09424, val loss: 0.09426, in 0.301s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09150, val loss: 0.08919, in 0.327s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09126, val loss: 0.08968, in 0.317s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09063, val loss: 0.09042, in 0.247s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09324, val loss: 0.09216, in 0.239s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09328, in 0.272s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09390, val loss: 0.09393, in 0.264s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09370, val loss: 0.09202, in 0.310s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09300, val loss: 0.09190, in 0.359s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09113, val loss: 0.08884, in 0.330s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09090, val loss: 0.08930, in 0.298s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09183, in 0.279s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09271, val loss: 0.09303, in 0.291s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08960, val loss: 0.08939, in 0.397s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09335, val loss: 0.09169, in 0.260s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09268, val loss: 0.09160, in 0.241s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09306, val loss: 0.09308, in 0.308s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09013, val loss: 0.08857, in 0.276s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.08849, in 0.328s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09190, val loss: 0.09086, in 0.368s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08907, in 0.320s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09151, val loss: 0.09181, in 0.354s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09269, val loss: 0.09271, in 0.260s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09261, val loss: 0.09097, in 0.298s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09054, in 0.357s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08975, val loss: 0.08821, in 0.280s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09037, val loss: 0.08810, in 0.268s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09172, val loss: 0.09070, in 0.251s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08905, val loss: 0.08886, in 0.263s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09192, val loss: 0.09197, in 0.298s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.09110, in 0.314s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09214, val loss: 0.09052, in 0.354s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09122, val loss: 0.09013, in 0.337s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08938, val loss: 0.08786, in 0.310s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09009, val loss: 0.08783, in 0.327s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09121, val loss: 0.09022, in 0.303s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.08855, in 0.333s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09054, val loss: 0.09089, in 0.288s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09133, val loss: 0.09139, in 0.322s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09177, val loss: 0.09017, in 0.291s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09074, val loss: 0.08967, in 0.273s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08977, val loss: 0.08751, in 0.256s\n",
      "[185/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08891, val loss: 0.08736, in 0.295s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.08979, in 0.264s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08822, val loss: 0.08804, in 0.267s\n",
      "[188/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09078, val loss: 0.09085, in 0.255s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08944, val loss: 0.08977, in 0.290s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09051, val loss: 0.08944, in 0.200s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09134, val loss: 0.08972, in 0.267s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08829, val loss: 0.08675, in 0.208s\n",
      "[188/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09054, val loss: 0.08953, in 0.194s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08880, val loss: 0.08655, in 0.270s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09049, val loss: 0.09056, in 0.204s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08790, val loss: 0.08772, in 0.226s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09020, val loss: 0.08913, in 0.193s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08884, val loss: 0.08919, in 0.206s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08798, val loss: 0.08645, in 0.192s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09044, val loss: 0.08883, in 0.210s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09023, val loss: 0.08924, in 0.193s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08848, val loss: 0.08624, in 0.226s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08999, val loss: 0.08895, in 0.185s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09011, val loss: 0.09021, in 0.216s\n",
      "[184/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08758, val loss: 0.08741, in 0.233s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08763, val loss: 0.08612, in 0.226s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09001, val loss: 0.08841, in 0.237s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08782, val loss: 0.08815, in 0.286s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08991, val loss: 0.08893, in 0.220s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08780, val loss: 0.08560, in 0.241s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08995, val loss: 0.09006, in 0.182s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08965, val loss: 0.08862, in 0.219s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08707, val loss: 0.08692, in 0.202s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08589, in 0.176s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08964, val loss: 0.08806, in 0.184s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08756, in 0.218s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08520, in 0.197s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08899, val loss: 0.08803, in 0.262s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08938, in 0.196s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08920, val loss: 0.08820, in 0.186s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08671, val loss: 0.08522, in 0.191s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08896, val loss: 0.08741, in 0.184s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08614, val loss: 0.08600, in 0.243s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08672, val loss: 0.08706, in 0.193s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08876, val loss: 0.08779, in 0.166s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08706, val loss: 0.08486, in 0.195s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.08886, in 0.210s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08888, val loss: 0.08789, in 0.213s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08637, val loss: 0.08488, in 0.193s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08865, val loss: 0.08710, in 0.189s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08593, val loss: 0.08580, in 0.225s\n",
      "[193/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08682, val loss: 0.08462, in 0.220s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08818, val loss: 0.08720, in 0.254s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08577, val loss: 0.08610, in 0.316s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08856, in 0.301s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08743, in 0.326s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08603, val loss: 0.08455, in 0.372s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08570, val loss: 0.08557, in 0.331s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08804, val loss: 0.08652, in 0.393s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08801, val loss: 0.08705, in 0.290s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08425, in 0.304s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08812, val loss: 0.08712, in 0.218s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08807, val loss: 0.08821, in 0.258s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08540, val loss: 0.08572, in 0.354s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08551, val loss: 0.08539, in 0.160s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08560, val loss: 0.08412, in 0.195s\n",
      "[195/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08772, val loss: 0.08619, in 0.168s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08614, val loss: 0.08396, in 0.153s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08757, val loss: 0.08660, in 0.162s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08793, val loss: 0.08693, in 0.152s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08525, val loss: 0.08513, in 0.154s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08765, val loss: 0.08777, in 0.205s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08506, val loss: 0.08539, in 0.189s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08594, val loss: 0.08374, in 0.162s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08729, val loss: 0.08577, in 0.190s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08375, in 0.208s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08727, val loss: 0.08631, in 0.206s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08740, val loss: 0.08643, in 0.198s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08491, val loss: 0.08524, in 0.175s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08730, in 0.200s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08648, val loss: 0.08496, in 0.204s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08439, val loss: 0.08426, in 0.263s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08457, val loss: 0.08314, in 0.208s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08562, val loss: 0.08344, in 0.224s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08682, val loss: 0.08587, in 0.189s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08725, val loss: 0.08630, in 0.209s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08440, val loss: 0.08474, in 0.253s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08654, in 0.259s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08429, val loss: 0.08287, in 0.232s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08396, val loss: 0.08383, in 0.248s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08585, val loss: 0.08436, in 0.264s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08529, val loss: 0.08313, in 0.257s\n",
      "[196/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08555, in 0.247s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08411, val loss: 0.08447, in 0.169s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08630, val loss: 0.08534, in 0.268s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08581, val loss: 0.08592, in 0.179s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08374, val loss: 0.08361, in 0.238s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08624, val loss: 0.08528, in 0.215s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08497, val loss: 0.08283, in 0.232s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08350, val loss: 0.08208, in 0.288s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08400, in 0.276s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08601, val loss: 0.08506, in 0.255s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08548, val loss: 0.08559, in 0.271s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08379, val loss: 0.08416, in 0.315s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08607, val loss: 0.08513, in 0.210s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08517, val loss: 0.08372, in 0.178s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08416, val loss: 0.08206, in 0.219s\n",
      "[198/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08308, val loss: 0.08164, in 0.197s\n",
      "[200/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08314, val loss: 0.08301, in 0.245s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08560, val loss: 0.08463, in 0.184s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08362, val loss: 0.08400, in 0.164s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08500, val loss: 0.08512, in 0.194s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08381, val loss: 0.08173, in 0.166s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08489, val loss: 0.08345, in 0.194s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08430, in 0.251s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08532, val loss: 0.08435, in 0.188s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08323, val loss: 0.08358, in 0.226s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08434, val loss: 0.08446, in 0.209s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08356, val loss: 0.08147, in 0.210s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08508, val loss: 0.08417, in 0.179s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08444, val loss: 0.08298, in 0.245s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08493, val loss: 0.08396, in 0.201s\n",
      "[199/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08277, val loss: 0.08311, in 0.187s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08392, val loss: 0.08405, in 0.193s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08424, val loss: 0.08278, in 0.163s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08477, val loss: 0.08380, in 0.156s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08357, val loss: 0.08371, in 0.193s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08238, val loss: 0.08271, in 0.240s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08349, val loss: 0.08204, in 0.329s\n",
      "[198/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08224, val loss: 0.08256, in 0.339s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08322, val loss: 0.08335, in 0.410s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08295, val loss: 0.08152, in 0.268s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08292, val loss: 0.08306, in 0.153s\n",
      "[200/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08246, val loss: 0.08105, in 0.201s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08296, val loss: 0.08284, in 0.171s\n",
      "Fit 200 trees in 133.375 s, (1569 total leaves)\n",
      "Time spent computing histograms: 72.125s\n",
      "Time spent finding best splits:  0.298s\n",
      "Time spent applying splits:      10.375s\n",
      "Time spent predicting:           1.274s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08273, val loss: 0.08131, in 0.205s\n",
      "Fit 200 trees in 133.391 s, (1570 total leaves)\n",
      "Time spent computing histograms: 71.064s\n",
      "Time spent finding best splits:  0.683s\n",
      "Time spent applying splits:      9.832s\n",
      "Time spent predicting:           1.358s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08456, val loss: 0.08363, in 0.187s\n",
      "Fit 200 trees in 133.881 s, (1566 total leaves)\n",
      "Time spent computing histograms: 71.383s\n",
      "Time spent finding best splits:  0.918s\n",
      "Time spent applying splits:      9.970s\n",
      "Time spent predicting:           1.302s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08282, val loss: 0.08077, in 0.251s\n",
      "Fit 200 trees in 133.869 s, (1576 total leaves)\n",
      "Time spent computing histograms: 71.924s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent finding best splits:  0.936s\n",
      "Time spent applying splits:      9.769s\n",
      "Time spent predicting:           0.946s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08458, val loss: 0.08362, in 0.336s\n",
      "Fit 200 trees in 134.208 s, (1574 total leaves)\n",
      "Time spent computing histograms: 70.919s\n",
      "Time spent finding best splits:  0.552s\n",
      "Time spent applying splits:      9.313s\n",
      "Time spent predicting:           1.361s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08194, val loss: 0.08227, in 0.184s\n",
      "Fit 200 trees in 134.388 s, (1570 total leaves)\n",
      "Time spent computing histograms: 70.380s\n",
      "Time spent finding best splits:  0.552s\n",
      "Time spent applying splits:      9.165s\n",
      "Time spent predicting:           1.510s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08253, val loss: 0.08265, in 0.195s\n",
      "Fit 200 trees in 134.752 s, (1569 total leaves)\n",
      "Time spent computing histograms: 70.096s\n",
      "Time spent finding best splits:  0.666s\n",
      "Time spent applying splits:      8.881s\n",
      "Time spent predicting:           1.077s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08222, val loss: 0.08082, in 0.188s\n",
      "Fit 200 trees in 134.776 s, (1573 total leaves)\n",
      "Time spent computing histograms: 70.171s\n",
      "Time spent finding best splits:  0.601s\n",
      "Time spent applying splits:      9.176s\n",
      "Time spent predicting:           1.323s\n",
      "Binning 0.111 GB of training data: 4.196 s\n",
      "Binning 0.012 GB of validation data: 4.410 s\n",
      "Binning 0.012 GB of validation data: 0.130 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.136 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65733, val loss: 0.65734, in 0.351s\n",
      "[2/200] 4.540 s\n",
      "Binning 0.012 GB of validation data: 4.599 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65911, in 0.394s\n",
      "[2/200] 0.184 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62489, val loss: 0.62486, in 0.307s\n",
      "[3/200] 4.656 s\n",
      "Binning 0.012 GB of validation data: 0.229 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62824, val loss: 0.62818, in 0.322s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65904, in 0.317s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59542, val loss: 0.59539, in 0.314s\n",
      "[4/200] 0.204 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65912, val loss: 0.65900, in 0.310s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60022, val loss: 0.60020, in 0.290s\n",
      "[4/200] 4.795 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.56852, val loss: 0.56845, in 0.281s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62823, val loss: 0.62806, in 0.297s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65911, val loss: 0.65914, in 0.332s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62829, val loss: 0.62810, in 0.423s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57464, val loss: 0.57454, in 0.425s\n",
      "[5/200] 0.309 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.54393, val loss: 0.54386, in 0.456s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60020, val loss: 0.59997, in 0.457s\n",
      "[4/200] 5.016 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62828, val loss: 0.62831, in 0.463s\n",
      "[3/200] 5.127 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.60029, val loss: 0.59997, in 0.410s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55125, val loss: 0.55118, in 0.409s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65910, in 0.416s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57461, val loss: 0.57425, in 0.400s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52135, val loss: 0.52125, in 0.405s\n",
      "[7/200] 0.295 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.252 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60027, val loss: 0.60031, in 0.402s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57473, val loss: 0.57434, in 0.385s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52976, val loss: 0.52965, in 0.400s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62822, val loss: 0.62823, in 0.405s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50059, val loss: 0.50044, in 0.408s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55123, val loss: 0.55075, in 0.417s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65910, val loss: 0.65907, in 0.440s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65908, val loss: 0.65906, in 0.416s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57471, val loss: 0.57473, in 0.400s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55136, val loss: 0.55085, in 0.421s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50999, val loss: 0.50981, in 0.412s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60018, val loss: 0.60017, in 0.412s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52974, val loss: 0.52916, in 0.396s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48146, val loss: 0.48127, in 0.403s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62826, val loss: 0.62825, in 0.390s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55133, val loss: 0.55136, in 0.388s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62820, val loss: 0.62820, in 0.398s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52989, val loss: 0.52927, in 0.375s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49177, val loss: 0.49153, in 0.393s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57458, val loss: 0.57456, in 0.401s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50995, val loss: 0.50933, in 0.380s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.46378, val loss: 0.46361, in 0.389s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60024, val loss: 0.60019, in 0.369s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60016, val loss: 0.60013, in 0.358s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52987, val loss: 0.52983, in 0.386s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51013, val loss: 0.50944, in 0.361s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47490, val loss: 0.47464, in 0.326s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55120, val loss: 0.55117, in 0.342s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49173, val loss: 0.49096, in 0.315s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44739, val loss: 0.44713, in 0.371s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51011, val loss: 0.51007, in 0.365s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57466, val loss: 0.57463, in 0.431s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57456, val loss: 0.57454, in 0.417s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49191, val loss: 0.49106, in 0.414s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45929, val loss: 0.45897, in 0.429s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52970, val loss: 0.52959, in 0.409s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47487, val loss: 0.47406, in 0.447s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43217, val loss: 0.43183, in 0.406s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49189, val loss: 0.49181, in 0.399s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55129, val loss: 0.55122, in 0.407s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55116, val loss: 0.55111, in 0.418s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47507, val loss: 0.47418, in 0.386s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50990, val loss: 0.50978, in 0.364s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44210, val loss: 0.44170, in 0.390s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45924, val loss: 0.45839, in 0.352s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41806, val loss: 0.41774, in 0.345s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47506, val loss: 0.47497, in 0.293s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52981, val loss: 0.52971, in 0.286s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52967, val loss: 0.52959, in 0.278s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45946, val loss: 0.45850, in 0.276s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49168, val loss: 0.49151, in 0.284s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42618, val loss: 0.42580, in 0.305s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44205, val loss: 0.44111, in 0.298s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40491, val loss: 0.40451, in 0.297s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45944, val loss: 0.45934, in 0.316s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50988, val loss: 0.50976, in 0.295s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51005, val loss: 0.50991, in 0.303s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44227, val loss: 0.44122, in 0.329s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47481, val loss: 0.47461, in 0.300s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41139, val loss: 0.41095, in 0.317s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42614, val loss: 0.42513, in 0.308s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39264, val loss: 0.39216, in 0.301s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44226, val loss: 0.44216, in 0.283s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49165, val loss: 0.49147, in 0.280s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49183, val loss: 0.49166, in 0.282s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42637, val loss: 0.42526, in 0.243s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45917, val loss: 0.45895, in 0.221s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39768, val loss: 0.39720, in 0.235s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38120, val loss: 0.38068, in 0.197s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41136, val loss: 0.41033, in 0.214s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47499, val loss: 0.47474, in 0.184s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47479, val loss: 0.47458, in 0.194s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42634, val loss: 0.42624, in 0.221s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41160, val loss: 0.41042, in 0.209s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44198, val loss: 0.44176, in 0.214s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37055, val loss: 0.36999, in 0.302s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38490, val loss: 0.38436, in 0.348s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39761, val loss: 0.39655, in 0.336s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45916, val loss: 0.45892, in 0.368s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45937, val loss: 0.45907, in 0.389s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41157, val loss: 0.41146, in 0.401s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42606, val loss: 0.42583, in 0.552s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39787, val loss: 0.39666, in 0.612s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36058, val loss: 0.36000, in 0.557s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37300, val loss: 0.37249, in 0.516s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38482, val loss: 0.38370, in 0.536s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44195, val loss: 0.44168, in 0.504s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44215, val loss: 0.44181, in 0.500s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39784, val loss: 0.39772, in 0.508s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41127, val loss: 0.41102, in 0.449s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38509, val loss: 0.38380, in 0.471s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35122, val loss: 0.35059, in 0.420s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36189, val loss: 0.36134, in 0.433s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37293, val loss: 0.37175, in 0.464s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42603, val loss: 0.42573, in 0.446s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42620, val loss: 0.42584, in 0.462s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38504, val loss: 0.38492, in 0.463s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39752, val loss: 0.39725, in 0.468s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37319, val loss: 0.37185, in 0.416s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34248, val loss: 0.34182, in 0.435s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35152, val loss: 0.35091, in 0.463s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41124, val loss: 0.41096, in 0.436s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36182, val loss: 0.36062, in 0.445s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41140, val loss: 0.41103, in 0.441s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37314, val loss: 0.37300, in 0.429s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38474, val loss: 0.38446, in 0.376s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36209, val loss: 0.36069, in 0.383s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33428, val loss: 0.33363, in 0.324s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34184, val loss: 0.34119, in 0.358s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39750, val loss: 0.39716, in 0.360s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35146, val loss: 0.35024, in 0.375s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39765, val loss: 0.39723, in 0.371s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36204, val loss: 0.36191, in 0.381s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37283, val loss: 0.37254, in 0.377s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35173, val loss: 0.35030, in 0.364s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32660, val loss: 0.32591, in 0.354s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33280, val loss: 0.33218, in 0.332s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38471, val loss: 0.38434, in 0.331s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34178, val loss: 0.34048, in 0.324s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38483, val loss: 0.38437, in 0.308s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35169, val loss: 0.35154, in 0.312s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36173, val loss: 0.36143, in 0.314s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31792, val loss: 0.31718, in 0.307s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34205, val loss: 0.34056, in 0.327s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32433, val loss: 0.32364, in 0.316s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37281, val loss: 0.37240, in 0.315s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33273, val loss: 0.33140, in 0.311s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37290, val loss: 0.37241, in 0.317s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34200, val loss: 0.34184, in 0.340s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35136, val loss: 0.35103, in 0.372s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30943, val loss: 0.30860, in 0.390s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33300, val loss: 0.33147, in 0.381s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31604, val loss: 0.31525, in 0.388s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36169, val loss: 0.36126, in 0.372s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32427, val loss: 0.32291, in 0.393s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36179, val loss: 0.36125, in 0.393s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33296, val loss: 0.33279, in 0.373s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30175, val loss: 0.30085, in 0.309s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34168, val loss: 0.34133, in 0.348s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32454, val loss: 0.32296, in 0.316s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35131, val loss: 0.35090, in 0.292s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30852, val loss: 0.30767, in 0.305s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31628, val loss: 0.31495, in 0.280s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35141, val loss: 0.35090, in 0.291s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32449, val loss: 0.32430, in 0.271s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29425, val loss: 0.29334, in 0.299s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33262, val loss: 0.33227, in 0.293s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31656, val loss: 0.31492, in 0.296s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34162, val loss: 0.34119, in 0.312s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30119, val loss: 0.30033, in 0.314s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30846, val loss: 0.30704, in 0.316s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34170, val loss: 0.34116, in 0.326s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31657, val loss: 0.31635, in 0.311s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32415, val loss: 0.32377, in 0.277s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28748, val loss: 0.28653, in 0.285s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30876, val loss: 0.30704, in 0.286s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33256, val loss: 0.33211, in 0.285s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29456, val loss: 0.29361, in 0.283s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30142, val loss: 0.29998, in 0.291s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33264, val loss: 0.33206, in 0.285s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30877, val loss: 0.30850, in 0.281s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31588, val loss: 0.31543, in 0.270s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28083, val loss: 0.27980, in 0.266s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30172, val loss: 0.29999, in 0.277s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32409, val loss: 0.32362, in 0.277s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28835, val loss: 0.28735, in 0.290s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29450, val loss: 0.29302, in 0.284s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32417, val loss: 0.32354, in 0.281s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30171, val loss: 0.30140, in 0.281s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30837, val loss: 0.30790, in 0.288s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27485, val loss: 0.27378, in 0.294s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29480, val loss: 0.29303, in 0.276s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31610, val loss: 0.31560, in 0.277s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28217, val loss: 0.28109, in 0.263s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28829, val loss: 0.28675, in 0.274s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31617, val loss: 0.31552, in 0.274s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29480, val loss: 0.29440, in 0.268s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26912, val loss: 0.26806, in 0.269s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30102, val loss: 0.30048, in 0.277s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28858, val loss: 0.28678, in 0.272s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30828, val loss: 0.30776, in 0.269s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27667, val loss: 0.27563, in 0.277s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28212, val loss: 0.28050, in 0.263s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28857, val loss: 0.28809, in 0.270s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30834, val loss: 0.30761, in 0.277s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26384, val loss: 0.26271, in 0.270s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29440, val loss: 0.29377, in 0.276s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28243, val loss: 0.28054, in 0.270s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30125, val loss: 0.30064, in 0.277s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27117, val loss: 0.27006, in 0.273s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27660, val loss: 0.27497, in 0.284s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30128, val loss: 0.30053, in 0.282s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28243, val loss: 0.28191, in 0.289s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25877, val loss: 0.25765, in 0.286s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28791, val loss: 0.28721, in 0.288s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27682, val loss: 0.27490, in 0.294s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26626, val loss: 0.26508, in 0.285s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29431, val loss: 0.29366, in 0.292s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27113, val loss: 0.26945, in 0.310s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29435, val loss: 0.29356, in 0.289s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27689, val loss: 0.27633, in 0.305s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25376, val loss: 0.25257, in 0.301s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28204, val loss: 0.28130, in 0.320s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27162, val loss: 0.26968, in 0.314s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26138, val loss: 0.26015, in 0.328s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28809, val loss: 0.28738, in 0.331s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26612, val loss: 0.26441, in 0.296s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27145, val loss: 0.27084, in 0.296s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28812, val loss: 0.28729, in 0.318s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24930, val loss: 0.24805, in 0.309s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26672, val loss: 0.26475, in 0.284s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27628, val loss: 0.27548, in 0.293s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25690, val loss: 0.25569, in 0.296s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28195, val loss: 0.28120, in 0.293s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26148, val loss: 0.25978, in 0.300s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26645, val loss: 0.26577, in 0.293s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28194, val loss: 0.28102, in 0.294s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26179, val loss: 0.25974, in 0.319s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24485, val loss: 0.24356, in 0.331s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27106, val loss: 0.27021, in 0.334s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27633, val loss: 0.27556, in 0.320s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25275, val loss: 0.25152, in 0.323s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25704, val loss: 0.25531, in 0.309s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26179, val loss: 0.26110, in 0.304s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27643, val loss: 0.27543, in 0.323s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25743, val loss: 0.25538, in 0.318s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26590, val loss: 0.26502, in 0.298s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24081, val loss: 0.23953, in 0.315s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24876, val loss: 0.24753, in 0.335s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27110, val loss: 0.27028, in 0.340s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25266, val loss: 0.25085, in 0.339s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25742, val loss: 0.25667, in 0.349s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27095, val loss: 0.26988, in 0.369s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26127, val loss: 0.26035, in 0.343s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23703, val loss: 0.23572, in 0.358s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25322, val loss: 0.25115, in 0.367s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24497, val loss: 0.24371, in 0.307s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26619, val loss: 0.26540, in 0.314s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24872, val loss: 0.24686, in 0.332s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25321, val loss: 0.25238, in 0.324s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26594, val loss: 0.26485, in 0.318s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23343, val loss: 0.23213, in 0.347s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24895, val loss: 0.24683, in 0.345s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25681, val loss: 0.25584, in 0.370s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24105, val loss: 0.23975, in 0.387s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26127, val loss: 0.26044, in 0.383s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24489, val loss: 0.24300, in 0.369s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24928, val loss: 0.24839, in 0.372s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26129, val loss: 0.26018, in 0.381s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24524, val loss: 0.24312, in 0.357s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22984, val loss: 0.22849, in 0.364s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25268, val loss: 0.25167, in 0.364s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23761, val loss: 0.23626, in 0.303s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25689, val loss: 0.25602, in 0.355s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24130, val loss: 0.23939, in 0.359s\n",
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24530, val loss: 0.24438, in 0.359s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25684, val loss: 0.25571, in 0.378s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24158, val loss: 0.23936, in 0.313s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22662, val loss: 0.22526, in 0.326s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23424, val loss: 0.23290, in 0.322s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24852, val loss: 0.24744, in 0.344s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23785, val loss: 0.23600, in 0.277s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25268, val loss: 0.25179, in 0.328s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24167, val loss: 0.24065, in 0.290s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25269, val loss: 0.25151, in 0.308s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23811, val loss: 0.23597, in 0.344s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24471, val loss: 0.24357, in 0.336s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23111, val loss: 0.22973, in 0.338s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22353, val loss: 0.22220, in 0.370s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23450, val loss: 0.23256, in 0.337s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23823, val loss: 0.23718, in 0.330s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24876, val loss: 0.24782, in 0.371s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24880, val loss: 0.24766, in 0.355s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23476, val loss: 0.23257, in 0.291s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22068, val loss: 0.21938, in 0.271s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24114, val loss: 0.23995, in 0.285s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22797, val loss: 0.22663, in 0.286s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23132, val loss: 0.22940, in 0.255s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.23466, val loss: 0.23354, in 0.287s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24496, val loss: 0.24400, in 0.279s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24465, val loss: 0.24344, in 0.284s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23160, val loss: 0.22947, in 0.269s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22506, val loss: 0.22370, in 0.259s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23771, val loss: 0.23647, in 0.280s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22799, val loss: 0.22604, in 0.291s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21778, val loss: 0.21649, in 0.308s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23155, val loss: 0.23034, in 0.263s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24111, val loss: 0.24008, in 0.317s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24108, val loss: 0.23981, in 0.293s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22237, val loss: 0.22098, in 0.261s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22829, val loss: 0.22610, in 0.288s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21523, val loss: 0.21399, in 0.236s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22514, val loss: 0.22320, in 0.261s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23435, val loss: 0.23306, in 0.278s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22837, val loss: 0.22711, in 0.289s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23766, val loss: 0.23658, in 0.237s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23765, val loss: 0.23635, in 0.250s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22537, val loss: 0.22316, in 0.260s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22242, val loss: 0.22052, in 0.236s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21953, val loss: 0.21816, in 0.278s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23122, val loss: 0.22989, in 0.252s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21226, val loss: 0.21101, in 0.286s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22552, val loss: 0.22424, in 0.247s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23432, val loss: 0.23321, in 0.292s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23401, val loss: 0.23269, in 0.295s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21696, val loss: 0.21560, in 0.265s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22263, val loss: 0.22049, in 0.281s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20994, val loss: 0.20871, in 0.266s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21956, val loss: 0.21766, in 0.309s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22811, val loss: 0.22668, in 0.299s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22276, val loss: 0.22143, in 0.260s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23120, val loss: 0.23003, in 0.281s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23088, val loss: 0.22951, in 0.280s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21407, val loss: 0.21267, in 0.304s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21978, val loss: 0.21759, in 0.314s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22521, val loss: 0.22371, in 0.281s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21705, val loss: 0.21511, in 0.297s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20746, val loss: 0.20624, in 0.326s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21993, val loss: 0.21855, in 0.315s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22804, val loss: 0.22683, in 0.305s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22769, val loss: 0.22632, in 0.299s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21728, val loss: 0.21514, in 0.239s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22254, val loss: 0.22099, in 0.248s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21172, val loss: 0.21035, in 0.283s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21748, val loss: 0.21603, in 0.241s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21437, val loss: 0.21239, in 0.289s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20538, val loss: 0.20420, in 0.273s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22515, val loss: 0.22391, in 0.245s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22485, val loss: 0.22344, in 0.250s\n",
      "[42/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21448, val loss: 0.21232, in 0.301s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21971, val loss: 0.21811, in 0.304s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21214, val loss: 0.21015, in 0.256s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20956, val loss: 0.20818, in 0.296s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20336, val loss: 0.20219, in 0.267s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21512, val loss: 0.21365, in 0.295s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22246, val loss: 0.22117, in 0.252s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22216, val loss: 0.22076, in 0.275s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21225, val loss: 0.21010, in 0.260s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20996, val loss: 0.20793, in 0.255s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21715, val loss: 0.21549, in 0.261s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20710, val loss: 0.20573, in 0.278s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20112, val loss: 0.19995, in 0.286s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21252, val loss: 0.21100, in 0.270s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21935, val loss: 0.21800, in 0.275s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21928, val loss: 0.21786, in 0.264s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21003, val loss: 0.20798, in 0.241s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20783, val loss: 0.20575, in 0.262s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20506, val loss: 0.20365, in 0.239s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19928, val loss: 0.19808, in 0.225s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21436, val loss: 0.21266, in 0.269s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20989, val loss: 0.20832, in 0.274s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21688, val loss: 0.21547, in 0.241s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21678, val loss: 0.21534, in 0.236s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20757, val loss: 0.20544, in 0.266s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19746, val loss: 0.19625, in 0.226s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21207, val loss: 0.21033, in 0.230s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20314, val loss: 0.20176, in 0.247s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20541, val loss: 0.20325, in 0.271s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20773, val loss: 0.20611, in 0.238s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21402, val loss: 0.21255, in 0.258s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20554, val loss: 0.20343, in 0.198s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21410, val loss: 0.21265, in 0.301s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20123, val loss: 0.19983, in 0.235s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19563, val loss: 0.19442, in 0.266s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20355, val loss: 0.20139, in 0.244s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20956, val loss: 0.20773, in 0.286s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20576, val loss: 0.20405, in 0.276s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21180, val loss: 0.21030, in 0.288s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20358, val loss: 0.20146, in 0.276s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21178, val loss: 0.21031, in 0.307s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20166, val loss: 0.19941, in 0.265s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19897, val loss: 0.19759, in 0.300s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20745, val loss: 0.20556, in 0.290s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19333, val loss: 0.19212, in 0.335s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20380, val loss: 0.20210, in 0.263s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20926, val loss: 0.20775, in 0.301s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20159, val loss: 0.19943, in 0.261s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20967, val loss: 0.20824, in 0.257s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20188, val loss: 0.20018, in 0.207s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19942, val loss: 0.19716, in 0.275s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19678, val loss: 0.19541, in 0.271s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20541, val loss: 0.20352, in 0.260s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19129, val loss: 0.19009, in 0.254s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20710, val loss: 0.20555, in 0.329s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19935, val loss: 0.19714, in 0.375s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19506, val loss: 0.19367, in 0.297s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20009, val loss: 0.19839, in 0.314s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20695, val loss: 0.20550, in 0.356s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18969, val loss: 0.18848, in 0.295s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19760, val loss: 0.19538, in 0.332s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20354, val loss: 0.20167, in 0.311s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20507, val loss: 0.20352, in 0.305s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19749, val loss: 0.19527, in 0.295s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19340, val loss: 0.19202, in 0.290s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20493, val loss: 0.20353, in 0.296s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19587, val loss: 0.19361, in 0.290s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18757, val loss: 0.18637, in 0.303s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19792, val loss: 0.19613, in 0.362s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20112, val loss: 0.19918, in 0.345s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20314, val loss: 0.20155, in 0.280s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19577, val loss: 0.19353, in 0.223s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19175, val loss: 0.19037, in 0.254s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19411, val loss: 0.19179, in 0.251s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18605, val loss: 0.18484, in 0.252s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20295, val loss: 0.20154, in 0.277s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19627, val loss: 0.19445, in 0.238s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19932, val loss: 0.19737, in 0.237s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20126, val loss: 0.19963, in 0.256s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19406, val loss: 0.19178, in 0.244s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19025, val loss: 0.18888, in 0.238s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19252, val loss: 0.19012, in 0.222s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20108, val loss: 0.19970, in 0.225s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19424, val loss: 0.19242, in 0.250s\n",
      "[56/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18419, val loss: 0.18300, in 0.287s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19753, val loss: 0.19558, in 0.256s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18826, val loss: 0.18690, in 0.234s\n",
      "[59/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19202, val loss: 0.18971, in 0.271s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19902, val loss: 0.19737, in 0.285s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19092, val loss: 0.18849, in 0.230s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19924, val loss: 0.19784, in 0.221s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19262, val loss: 0.19078, in 0.227s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18122, in 0.244s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19575, val loss: 0.19377, in 0.287s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19044, val loss: 0.18809, in 0.218s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19721, val loss: 0.19556, in 0.216s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18640, val loss: 0.18505, in 0.269s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18898, val loss: 0.18654, in 0.264s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19061, val loss: 0.18881, in 0.225s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19701, val loss: 0.19562, in 0.272s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18051, val loss: 0.17934, in 0.209s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19369, val loss: 0.19164, in 0.249s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19547, val loss: 0.19380, in 0.214s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18498, val loss: 0.18363, in 0.191s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18853, val loss: 0.18619, in 0.241s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18744, val loss: 0.18501, in 0.192s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18877, val loss: 0.18697, in 0.241s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19493, val loss: 0.19357, in 0.238s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17919, val loss: 0.17801, in 0.240s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19206, val loss: 0.19000, in 0.226s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19385, val loss: 0.19217, in 0.279s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18658, val loss: 0.18429, in 0.257s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18318, val loss: 0.18185, in 0.269s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18551, val loss: 0.18313, in 0.265s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17787, val loss: 0.17671, in 0.259s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19327, val loss: 0.19194, in 0.280s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18717, val loss: 0.18541, in 0.292s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19053, val loss: 0.18845, in 0.272s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18507, val loss: 0.18279, in 0.302s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18405, val loss: 0.18167, in 0.297s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19189, val loss: 0.19024, in 0.315s\n",
      "[57/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18135, val loss: 0.18003, in 0.343s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19168, val loss: 0.19034, in 0.278s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18575, val loss: 0.18400, in 0.278s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17607, val loss: 0.17489, in 0.305s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18855, val loss: 0.18647, in 0.309s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19032, val loss: 0.18864, in 0.263s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18333, val loss: 0.18109, in 0.295s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18228, val loss: 0.17996, in 0.300s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18437, val loss: 0.18262, in 0.257s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18963, val loss: 0.18833, in 0.271s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17929, val loss: 0.17800, in 0.321s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17449, val loss: 0.17335, in 0.282s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18667, val loss: 0.18463, in 0.264s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18192, val loss: 0.17963, in 0.261s\n",
      "[63/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18833, val loss: 0.18663, in 0.320s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18001, val loss: 0.17765, in 0.288s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18259, val loss: 0.18087, in 0.273s\n",
      "[63/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17799, val loss: 0.17670, in 0.254s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18803, val loss: 0.18679, in 0.302s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17242, val loss: 0.17127, in 0.286s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18521, val loss: 0.18316, in 0.270s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18048, val loss: 0.17817, in 0.267s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18685, val loss: 0.18515, in 0.242s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17870, val loss: 0.17631, in 0.246s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17669, val loss: 0.17542, in 0.227s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18126, val loss: 0.17952, in 0.268s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18618, val loss: 0.18500, in 0.278s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17118, val loss: 0.17000, in 0.273s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18347, val loss: 0.18140, in 0.257s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17876, val loss: 0.17649, in 0.246s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18494, val loss: 0.18325, in 0.244s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17739, val loss: 0.17499, in 0.246s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17992, val loss: 0.17819, in 0.212s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17507, val loss: 0.17380, in 0.251s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18483, val loss: 0.18363, in 0.206s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16917, val loss: 0.16802, in 0.247s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18218, val loss: 0.18012, in 0.221s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17747, val loss: 0.17520, in 0.232s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18354, val loss: 0.18181, in 0.264s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17339, val loss: 0.17216, in 0.238s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17582, val loss: 0.17345, in 0.269s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17781, val loss: 0.17610, in 0.279s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18080, val loss: 0.17874, in 0.271s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16792, val loss: 0.16677, in 0.293s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18293, val loss: 0.18172, in 0.348s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17465, val loss: 0.17227, in 0.301s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17540, val loss: 0.17310, in 0.365s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18219, val loss: 0.18044, in 0.331s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17233, val loss: 0.17111, in 0.334s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17587, val loss: 0.17419, in 0.351s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17948, val loss: 0.17743, in 0.302s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18112, val loss: 0.17994, in 0.308s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16638, val loss: 0.16525, in 0.339s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18046, val loss: 0.17872, in 0.287s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17120, val loss: 0.16998, in 0.287s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17371, val loss: 0.17146, in 0.301s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17344, val loss: 0.17100, in 0.321s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17473, val loss: 0.17302, in 0.313s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17976, val loss: 0.17861, in 0.259s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17732, val loss: 0.17531, in 0.300s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16526, val loss: 0.16407, in 0.275s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17242, val loss: 0.16997, in 0.281s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16977, val loss: 0.16857, in 0.299s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17266, val loss: 0.17039, in 0.321s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17826, val loss: 0.17655, in 0.335s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17843, val loss: 0.17729, in 0.318s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17569, val loss: 0.17367, in 0.311s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17303, val loss: 0.17127, in 0.345s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16374, val loss: 0.16257, in 0.295s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17129, val loss: 0.16886, in 0.249s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17154, val loss: 0.16919, in 0.220s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16866, val loss: 0.16747, in 0.284s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17695, val loss: 0.17524, in 0.271s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17451, val loss: 0.17248, in 0.245s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16276, val loss: 0.16164, in 0.252s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17159, val loss: 0.16985, in 0.257s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17627, val loss: 0.17518, in 0.287s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17023, val loss: 0.16779, in 0.255s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17042, val loss: 0.16809, in 0.279s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16721, val loss: 0.16611, in 0.243s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17566, val loss: 0.17395, in 0.274s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17045, val loss: 0.16870, in 0.275s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17300, val loss: 0.17098, in 0.316s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17506, val loss: 0.17395, in 0.292s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16127, val loss: 0.16016, in 0.362s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16908, val loss: 0.16657, in 0.295s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16857, val loss: 0.16631, in 0.311s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17414, val loss: 0.17248, in 0.267s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16533, val loss: 0.16420, in 0.317s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16922, val loss: 0.16749, in 0.260s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17185, val loss: 0.16984, in 0.261s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17386, val loss: 0.17276, in 0.262s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15953, val loss: 0.15843, in 0.308s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16721, val loss: 0.16476, in 0.307s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16420, val loss: 0.16308, in 0.268s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16677, val loss: 0.16447, in 0.302s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17228, val loss: 0.17063, in 0.297s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16820, val loss: 0.16647, in 0.254s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17061, val loss: 0.16858, in 0.244s\n",
      "[71/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17219, val loss: 0.17112, in 0.285s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15846, val loss: 0.15739, in 0.263s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16319, val loss: 0.16210, in 0.252s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17127, val loss: 0.16962, in 0.244s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16541, val loss: 0.16293, in 0.292s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16588, val loss: 0.16353, in 0.278s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16666, val loss: 0.16497, in 0.270s\n",
      "[74/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16900, val loss: 0.16693, in 0.316s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17092, val loss: 0.16987, in 0.311s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15757, val loss: 0.15655, in 0.266s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16187, val loss: 0.16084, in 0.314s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16436, val loss: 0.16185, in 0.292s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16443, val loss: 0.16214, in 0.285s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16965, val loss: 0.16799, in 0.332s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16525, val loss: 0.16357, in 0.304s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16972, val loss: 0.16866, in 0.262s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16716, val loss: 0.16514, in 0.337s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15660, val loss: 0.15553, in 0.278s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16347, val loss: 0.16094, in 0.249s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16083, val loss: 0.15979, in 0.268s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16304, val loss: 0.16076, in 0.270s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16434, val loss: 0.16269, in 0.246s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16852, val loss: 0.16684, in 0.267s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16805, val loss: 0.16701, in 0.308s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15529, val loss: 0.15423, in 0.285s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16568, val loss: 0.16366, in 0.304s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16196, val loss: 0.15949, in 0.309s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16206, val loss: 0.15976, in 0.302s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15915, val loss: 0.15810, in 0.327s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16708, val loss: 0.16543, in 0.342s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16329, val loss: 0.16164, in 0.371s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16454, val loss: 0.16250, in 0.318s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15399, val loss: 0.15297, in 0.357s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16615, val loss: 0.16515, in 0.384s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16060, val loss: 0.15811, in 0.355s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15833, val loss: 0.15730, in 0.334s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16082, val loss: 0.15853, in 0.349s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16229, val loss: 0.16066, in 0.291s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16565, val loss: 0.16401, in 0.320s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16311, val loss: 0.16105, in 0.303s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15312, val loss: 0.15214, in 0.271s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16509, val loss: 0.16411, in 0.288s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15728, val loss: 0.15628, in 0.247s\n",
      "[81/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15957, val loss: 0.15710, in 0.302s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15978, val loss: 0.15755, in 0.286s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16432, val loss: 0.16271, in 0.274s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16103, val loss: 0.15939, in 0.280s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15220, val loss: 0.15124, in 0.269s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16370, val loss: 0.16273, in 0.282s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16146, val loss: 0.15943, in 0.326s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15597, val loss: 0.15499, in 0.291s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15902, val loss: 0.15674, in 0.253s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15858, val loss: 0.15607, in 0.286s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16331, val loss: 0.16170, in 0.310s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16014, val loss: 0.15851, in 0.306s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16267, val loss: 0.16170, in 0.343s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15062, val loss: 0.14965, in 0.398s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16055, val loss: 0.15852, in 0.350s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15483, val loss: 0.15386, in 0.384s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15780, val loss: 0.15526, in 0.351s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15805, val loss: 0.15578, in 0.405s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16237, val loss: 0.16076, in 0.346s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15922, val loss: 0.15759, in 0.358s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14982, val loss: 0.14878, in 0.280s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16163, val loss: 0.16066, in 0.305s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15921, val loss: 0.15720, in 0.324s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15704, val loss: 0.15475, in 0.248s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15387, val loss: 0.15290, in 0.317s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16067, val loss: 0.15909, in 0.282s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15832, val loss: 0.15668, in 0.269s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15634, val loss: 0.15380, in 0.338s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15987, val loss: 0.15894, in 0.302s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14862, val loss: 0.14760, in 0.340s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15789, val loss: 0.15592, in 0.289s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15295, val loss: 0.15197, in 0.267s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15564, val loss: 0.15335, in 0.324s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15498, val loss: 0.15249, in 0.285s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15963, val loss: 0.15803, in 0.309s\n",
      "[79/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15692, val loss: 0.15523, in 0.315s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14795, val loss: 0.14699, in 0.226s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15851, val loss: 0.15765, in 0.284s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15696, val loss: 0.15498, in 0.290s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15179, val loss: 0.15084, in 0.287s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15417, val loss: 0.15170, in 0.261s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15443, val loss: 0.15212, in 0.301s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15874, val loss: 0.15716, in 0.286s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15601, val loss: 0.15430, in 0.296s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14672, val loss: 0.14579, in 0.284s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15611, val loss: 0.15413, in 0.262s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15749, val loss: 0.15667, in 0.320s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15103, val loss: 0.15012, in 0.252s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15334, val loss: 0.15085, in 0.261s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15321, val loss: 0.15086, in 0.276s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15789, val loss: 0.15631, in 0.265s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15475, val loss: 0.15304, in 0.277s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14590, val loss: 0.14497, in 0.280s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15665, val loss: 0.15584, in 0.278s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15497, val loss: 0.15299, in 0.292s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15015, val loss: 0.14924, in 0.293s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15254, val loss: 0.15015, in 0.276s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15182, val loss: 0.14938, in 0.322s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15701, val loss: 0.15542, in 0.289s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15399, val loss: 0.15228, in 0.271s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14394, in 0.341s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15530, val loss: 0.15452, in 0.289s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15377, val loss: 0.15184, in 0.300s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15617, val loss: 0.15457, in 0.240s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14929, val loss: 0.14836, in 0.301s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15093, val loss: 0.14846, in 0.250s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15141, val loss: 0.14906, in 0.275s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15280, val loss: 0.15111, in 0.249s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14415, val loss: 0.14326, in 0.258s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15373, val loss: 0.15300, in 0.298s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15256, val loss: 0.15066, in 0.297s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15013, val loss: 0.14762, in 0.272s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14814, in 0.260s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15202, val loss: 0.15034, in 0.274s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14842, val loss: 0.14751, in 0.313s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15480, val loss: 0.15319, in 0.349s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14338, val loss: 0.14251, in 0.234s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15171, val loss: 0.14981, in 0.241s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15281, val loss: 0.15208, in 0.279s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14980, val loss: 0.14748, in 0.234s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14774, val loss: 0.14686, in 0.223s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14893, val loss: 0.14640, in 0.260s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15082, val loss: 0.14917, in 0.258s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15404, val loss: 0.15242, in 0.217s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15077, val loss: 0.14886, in 0.223s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15212, val loss: 0.15140, in 0.196s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14271, val loss: 0.14189, in 0.295s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14867, val loss: 0.14638, in 0.235s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14693, val loss: 0.14604, in 0.257s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15002, val loss: 0.14834, in 0.243s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14795, val loss: 0.14543, in 0.276s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15284, val loss: 0.15129, in 0.301s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14206, val loss: 0.14124, in 0.212s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15008, val loss: 0.14819, in 0.280s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14728, val loss: 0.14474, in 0.247s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14790, val loss: 0.14558, in 0.314s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15082, val loss: 0.15008, in 0.358s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14882, val loss: 0.14718, in 0.287s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15199, val loss: 0.15046, in 0.235s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14569, val loss: 0.14481, in 0.336s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14117, val loss: 0.14039, in 0.234s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14896, val loss: 0.14707, in 0.223s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14707, val loss: 0.14473, in 0.214s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14648, val loss: 0.14393, in 0.226s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14999, val loss: 0.14922, in 0.224s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14787, val loss: 0.14626, in 0.228s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15075, val loss: 0.14924, in 0.221s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14490, val loss: 0.14401, in 0.235s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14006, val loss: 0.13928, in 0.267s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14810, val loss: 0.14620, in 0.249s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14605, val loss: 0.14370, in 0.249s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14880, val loss: 0.14805, in 0.249s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14561, val loss: 0.14309, in 0.268s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14963, val loss: 0.14815, in 0.259s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14687, val loss: 0.14527, in 0.282s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14405, val loss: 0.14321, in 0.230s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14740, val loss: 0.14552, in 0.239s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13906, val loss: 0.13829, in 0.323s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14497, val loss: 0.14260, in 0.297s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14762, val loss: 0.14694, in 0.312s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14893, val loss: 0.14745, in 0.272s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14213, in 0.322s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14318, val loss: 0.14234, in 0.294s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14604, val loss: 0.14443, in 0.317s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13852, val loss: 0.13778, in 0.226s\n",
      "[97/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14616, val loss: 0.14424, in 0.328s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14692, val loss: 0.14625, in 0.233s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14417, val loss: 0.14180, in 0.271s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14400, val loss: 0.14143, in 0.227s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14797, val loss: 0.14651, in 0.271s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14242, val loss: 0.14157, in 0.271s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14308, in 0.282s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13787, val loss: 0.13709, in 0.235s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14503, val loss: 0.14314, in 0.252s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14619, val loss: 0.14554, in 0.211s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14323, val loss: 0.14090, in 0.226s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14296, val loss: 0.14042, in 0.222s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14727, val loss: 0.14582, in 0.205s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14180, val loss: 0.14097, in 0.203s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14403, val loss: 0.14243, in 0.181s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13733, val loss: 0.13657, in 0.172s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14548, val loss: 0.14482, in 0.203s\n",
      "[92/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14422, val loss: 0.14232, in 0.239s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14656, val loss: 0.14505, in 0.197s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14228, val loss: 0.13972, in 0.223s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14119, val loss: 0.14036, in 0.200s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14194, val loss: 0.13966, in 0.246s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13670, val loss: 0.13595, in 0.223s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14347, val loss: 0.14189, in 0.245s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14467, val loss: 0.14404, in 0.381s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14315, val loss: 0.14129, in 0.364s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14165, val loss: 0.13906, in 0.417s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14572, val loss: 0.14419, in 0.441s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14129, val loss: 0.13898, in 0.447s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14049, val loss: 0.13965, in 0.454s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13609, val loss: 0.13538, in 0.441s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14268, val loss: 0.14112, in 0.444s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14385, val loss: 0.14322, in 0.376s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14511, val loss: 0.14357, in 0.287s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14222, val loss: 0.14036, in 0.407s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13975, val loss: 0.13892, in 0.275s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14055, val loss: 0.13824, in 0.291s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14068, val loss: 0.13809, in 0.338s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14177, val loss: 0.14022, in 0.325s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13506, val loss: 0.13434, in 0.337s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14430, val loss: 0.14278, in 0.430s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13927, val loss: 0.13845, in 0.438s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14306, val loss: 0.14247, in 0.483s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14135, val loss: 0.13951, in 0.463s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13984, val loss: 0.13725, in 0.454s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13973, val loss: 0.13743, in 0.455s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14096, val loss: 0.13942, in 0.419s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13415, val loss: 0.13343, in 0.469s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14359, val loss: 0.14203, in 0.253s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14061, val loss: 0.13872, in 0.248s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13856, val loss: 0.13775, in 0.283s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14047, val loss: 0.13891, in 0.228s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13904, val loss: 0.13642, in 0.286s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14191, val loss: 0.14134, in 0.316s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13881, val loss: 0.13653, in 0.316s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13266, in 0.282s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14279, val loss: 0.14126, in 0.284s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14000, val loss: 0.13811, in 0.260s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13800, val loss: 0.13717, in 0.259s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13986, val loss: 0.13831, in 0.268s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13847, val loss: 0.13585, in 0.275s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14086, val loss: 0.14029, in 0.295s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13801, val loss: 0.13572, in 0.300s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13270, val loss: 0.13199, in 0.285s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14194, val loss: 0.14046, in 0.281s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13747, val loss: 0.13663, in 0.259s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13927, val loss: 0.13768, in 0.252s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13693, in 0.308s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14024, val loss: 0.13971, in 0.251s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13759, val loss: 0.13498, in 0.286s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13222, val loss: 0.13153, in 0.212s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13705, val loss: 0.13474, in 0.270s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13678, val loss: 0.13599, in 0.238s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14112, val loss: 0.13966, in 0.290s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13803, val loss: 0.13623, in 0.239s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13846, val loss: 0.13682, in 0.283s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13671, val loss: 0.13411, in 0.231s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13961, val loss: 0.13912, in 0.237s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13146, val loss: 0.13077, in 0.232s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13635, val loss: 0.13406, in 0.242s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13612, val loss: 0.13535, in 0.194s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13756, val loss: 0.13573, in 0.171s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14051, val loss: 0.13907, in 0.183s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13626, val loss: 0.13364, in 0.155s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13755, val loss: 0.13592, in 0.187s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13828, in 0.189s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13578, val loss: 0.13349, in 0.158s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13059, val loss: 0.12991, in 0.187s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13546, val loss: 0.13469, in 0.155s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13684, val loss: 0.13500, in 0.180s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13946, val loss: 0.13804, in 0.191s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13821, val loss: 0.13767, in 0.178s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13558, val loss: 0.13297, in 0.214s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13656, val loss: 0.13496, in 0.194s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13521, val loss: 0.13291, in 0.175s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12988, val loss: 0.12921, in 0.232s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13437, in 0.265s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13393, val loss: 0.13318, in 0.325s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13874, val loss: 0.13731, in 0.330s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13503, val loss: 0.13240, in 0.293s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13753, val loss: 0.13700, in 0.321s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13430, val loss: 0.13200, in 0.310s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13410, in 0.358s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12898, val loss: 0.12831, in 0.366s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13570, val loss: 0.13383, in 0.273s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13348, val loss: 0.13273, in 0.252s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13820, val loss: 0.13674, in 0.266s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13426, val loss: 0.13166, in 0.287s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13376, val loss: 0.13146, in 0.263s\n",
      "[108/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13497, val loss: 0.13344, in 0.276s\n",
      "[108/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13667, val loss: 0.13617, in 0.349s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12854, val loss: 0.12790, in 0.239s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13518, val loss: 0.13329, in 0.241s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13283, val loss: 0.13208, in 0.288s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13765, val loss: 0.13618, in 0.247s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13360, val loss: 0.13097, in 0.245s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13310, val loss: 0.13081, in 0.260s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13292, in 0.252s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13611, val loss: 0.13562, in 0.243s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12791, val loss: 0.12730, in 0.247s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13450, val loss: 0.13266, in 0.251s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13197, val loss: 0.13124, in 0.256s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13306, val loss: 0.13043, in 0.264s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13232, val loss: 0.13007, in 0.292s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13398, val loss: 0.13239, in 0.273s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13565, val loss: 0.13417, in 0.371s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12722, val loss: 0.12661, in 0.268s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13536, val loss: 0.13486, in 0.312s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13136, val loss: 0.13063, in 0.263s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13347, val loss: 0.13160, in 0.345s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13227, val loss: 0.12965, in 0.256s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13189, val loss: 0.12962, in 0.236s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13341, val loss: 0.13181, in 0.242s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12655, val loss: 0.12592, in 0.255s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13481, val loss: 0.13334, in 0.301s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13480, val loss: 0.13434, in 0.257s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13067, val loss: 0.12993, in 0.268s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13294, val loss: 0.13102, in 0.259s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13162, val loss: 0.12902, in 0.261s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13121, val loss: 0.12896, in 0.281s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12535, in 0.246s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13275, val loss: 0.13116, in 0.309s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13421, val loss: 0.13274, in 0.270s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13403, val loss: 0.13358, in 0.269s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12989, val loss: 0.12920, in 0.245s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13109, val loss: 0.12850, in 0.243s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13217, val loss: 0.13024, in 0.275s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13068, val loss: 0.12843, in 0.241s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12555, val loss: 0.12499, in 0.222s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13205, val loss: 0.13048, in 0.242s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12947, val loss: 0.12877, in 0.181s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13195, in 0.245s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13313, val loss: 0.13269, in 0.250s\n",
      "[108/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13049, val loss: 0.12790, in 0.195s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13029, val loss: 0.12802, in 0.160s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13129, val loss: 0.12939, in 0.222s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13165, val loss: 0.13008, in 0.156s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12480, val loss: 0.12422, in 0.219s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12868, val loss: 0.12799, in 0.162s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13269, val loss: 0.13226, in 0.160s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13270, val loss: 0.13131, in 0.193s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12945, val loss: 0.12720, in 0.183s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12992, val loss: 0.12731, in 0.195s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13075, val loss: 0.12883, in 0.184s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13119, val loss: 0.12959, in 0.188s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12798, val loss: 0.12731, in 0.195s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13214, val loss: 0.13164, in 0.187s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12399, val loss: 0.12341, in 0.222s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13218, val loss: 0.13079, in 0.193s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12864, val loss: 0.12640, in 0.180s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12940, val loss: 0.12678, in 0.184s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13035, val loss: 0.12841, in 0.171s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12887, in 0.220s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13119, val loss: 0.13071, in 0.212s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12665, val loss: 0.12601, in 0.237s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12311, val loss: 0.12256, in 0.221s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13147, val loss: 0.13008, in 0.220s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12983, val loss: 0.12784, in 0.192s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12795, val loss: 0.12574, in 0.215s\n",
      "[117/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12875, val loss: 0.12612, in 0.229s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12971, val loss: 0.12813, in 0.171s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13043, val loss: 0.12993, in 0.170s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12242, val loss: 0.12190, in 0.165s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13105, val loss: 0.12964, in 0.173s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12573, val loss: 0.12512, in 0.205s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12932, val loss: 0.12732, in 0.189s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12828, val loss: 0.12563, in 0.199s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12721, val loss: 0.12503, in 0.222s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12878, val loss: 0.12723, in 0.214s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12955, val loss: 0.12907, in 0.210s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12517, val loss: 0.12457, in 0.219s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12047, val loss: 0.11992, in 0.290s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13020, val loss: 0.12880, in 0.271s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12860, val loss: 0.12663, in 0.245s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12664, val loss: 0.12445, in 0.227s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12714, val loss: 0.12454, in 0.266s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12811, val loss: 0.12652, in 0.283s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12883, val loss: 0.12833, in 0.271s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12982, val loss: 0.12841, in 0.212s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12422, val loss: 0.12365, in 0.262s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12617, val loss: 0.12396, in 0.203s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12776, val loss: 0.12580, in 0.223s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11983, val loss: 0.11932, in 0.249s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12666, val loss: 0.12404, in 0.195s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12763, val loss: 0.12605, in 0.189s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12799, val loss: 0.12752, in 0.181s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12896, val loss: 0.12758, in 0.172s\n",
      "[116/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12362, val loss: 0.12304, in 0.188s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11946, val loss: 0.11897, in 0.169s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12542, val loss: 0.12320, in 0.193s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12683, val loss: 0.12488, in 0.193s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12598, val loss: 0.12339, in 0.209s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12714, val loss: 0.12554, in 0.190s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12751, val loss: 0.12704, in 0.196s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11882, val loss: 0.11835, in 0.210s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12806, val loss: 0.12669, in 0.248s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12325, val loss: 0.12266, in 0.227s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12563, val loss: 0.12304, in 0.252s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12488, val loss: 0.12265, in 0.303s\n",
      "[122/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12608, val loss: 0.12414, in 0.336s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12650, val loss: 0.12494, in 0.293s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12680, val loss: 0.12637, in 0.300s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12757, val loss: 0.12622, in 0.261s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12199, in 0.288s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11772, val loss: 0.11724, in 0.314s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12573, val loss: 0.12376, in 0.237s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12493, val loss: 0.12238, in 0.291s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12211, in 0.288s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12567, val loss: 0.12413, in 0.304s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12688, val loss: 0.12551, in 0.485s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11735, val loss: 0.11690, in 0.446s\n",
      "[126/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12615, val loss: 0.12571, in 0.541s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12220, val loss: 0.12164, in 0.510s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12398, val loss: 0.12175, in 0.684s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12445, val loss: 0.12188, in 0.838s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12482, val loss: 0.12287, in 0.875s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12532, val loss: 0.12377, in 0.857s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11645, in 0.703s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12152, val loss: 0.12100, in 0.657s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12539, val loss: 0.12496, in 0.713s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12325, val loss: 0.12103, in 0.488s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12512, val loss: 0.12374, in 0.883s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12442, val loss: 0.12245, in 0.389s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12395, val loss: 0.12135, in 0.442s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12465, val loss: 0.12312, in 0.374s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12082, val loss: 0.12031, in 0.304s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12470, val loss: 0.12426, in 0.304s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11633, val loss: 0.11593, in 0.354s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12258, val loss: 0.12040, in 0.419s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12444, val loss: 0.12308, in 0.496s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12360, val loss: 0.12168, in 0.503s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12306, val loss: 0.12047, in 0.496s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12400, val loss: 0.12247, in 0.460s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11600, val loss: 0.11560, in 0.558s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12035, val loss: 0.11985, in 0.640s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12391, val loss: 0.12348, in 0.707s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12213, val loss: 0.11993, in 0.682s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12292, val loss: 0.12098, in 0.556s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12234, val loss: 0.11977, in 0.582s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12378, val loss: 0.12244, in 0.634s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12324, val loss: 0.12172, in 0.589s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11983, val loss: 0.11933, in 0.507s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12344, val loss: 0.12302, in 0.500s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11424, val loss: 0.11382, in 0.678s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12215, val loss: 0.12023, in 0.505s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12165, val loss: 0.11910, in 0.475s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12157, val loss: 0.11943, in 0.562s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12322, val loss: 0.12187, in 0.573s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12102, in 0.586s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12280, val loss: 0.12236, in 0.485s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11918, val loss: 0.11873, in 0.596s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11336, val loss: 0.11296, in 0.554s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12091, val loss: 0.11878, in 0.407s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12148, val loss: 0.11957, in 0.493s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12102, val loss: 0.11850, in 0.483s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12257, val loss: 0.12122, in 0.389s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12201, val loss: 0.12048, in 0.382s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11869, val loss: 0.11828, in 0.335s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12246, val loss: 0.12200, in 0.385s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11278, val loss: 0.11241, in 0.343s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12018, val loss: 0.11809, in 0.431s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12066, val loss: 0.11877, in 0.401s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.11993, in 0.386s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12209, val loss: 0.12072, in 0.416s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11985, val loss: 0.11728, in 0.445s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11807, val loss: 0.11769, in 0.338s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12184, val loss: 0.12137, in 0.381s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11217, val loss: 0.11178, in 0.485s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12087, val loss: 0.11934, in 0.349s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11958, val loss: 0.11753, in 0.419s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12174, val loss: 0.12038, in 0.347s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12019, val loss: 0.11829, in 0.404s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11919, val loss: 0.11659, in 0.364s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12108, val loss: 0.12065, in 0.399s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11634, val loss: 0.11596, in 0.558s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11118, val loss: 0.11079, in 0.385s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11916, val loss: 0.11710, in 0.383s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11769, in 0.538s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12113, val loss: 0.11979, in 0.563s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11860, val loss: 0.11602, in 0.547s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11915, val loss: 0.11765, in 0.601s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12057, val loss: 0.12016, in 0.492s\n",
      "[127/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11548, in 0.577s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11087, val loss: 0.11049, in 0.519s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11867, val loss: 0.11660, in 0.636s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11815, val loss: 0.11557, in 0.497s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12052, val loss: 0.11920, in 0.536s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11911, val loss: 0.11721, in 0.546s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11855, val loss: 0.11708, in 0.563s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11994, val loss: 0.11957, in 0.556s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11529, val loss: 0.11489, in 0.452s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10926, val loss: 0.10886, in 0.614s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11850, val loss: 0.11659, in 0.370s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11812, val loss: 0.11603, in 0.462s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11987, val loss: 0.11854, in 0.403s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11753, val loss: 0.11496, in 0.449s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11799, val loss: 0.11654, in 0.524s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11925, val loss: 0.11889, in 0.522s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11477, val loss: 0.11437, in 0.621s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10873, val loss: 0.10835, in 0.531s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11929, val loss: 0.11796, in 0.537s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11789, val loss: 0.11600, in 0.615s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11755, val loss: 0.11548, in 0.627s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11746, val loss: 0.11602, in 0.476s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11591, val loss: 0.11335, in 0.664s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11869, val loss: 0.11831, in 0.522s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11408, val loss: 0.11370, in 0.429s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11879, val loss: 0.11746, in 0.347s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10780, val loss: 0.10741, in 0.405s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11479, in 0.358s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11715, val loss: 0.11529, in 0.443s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11697, val loss: 0.11554, in 0.445s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11524, val loss: 0.11270, in 0.462s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11811, val loss: 0.11772, in 0.428s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11363, val loss: 0.11325, in 0.356s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10748, val loss: 0.10710, in 0.321s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11835, val loss: 0.11698, in 0.336s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11633, val loss: 0.11426, in 0.368s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11660, val loss: 0.11477, in 0.323s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11772, val loss: 0.11731, in 0.265s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11463, val loss: 0.11210, in 0.297s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11647, val loss: 0.11508, in 0.335s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10711, val loss: 0.10674, in 0.287s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11328, val loss: 0.11293, in 0.327s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11805, val loss: 0.11666, in 0.302s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11626, val loss: 0.11440, in 0.323s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11565, val loss: 0.11359, in 0.362s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11424, val loss: 0.11168, in 0.310s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11728, val loss: 0.11688, in 0.359s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11603, val loss: 0.11463, in 0.338s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11238, val loss: 0.11204, in 0.337s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11748, val loss: 0.11613, in 0.381s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10564, val loss: 0.10524, in 0.418s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11580, val loss: 0.11395, in 0.307s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11395, val loss: 0.11138, in 0.288s\n",
      "[140/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11517, val loss: 0.11313, in 0.361s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11671, val loss: 0.11631, in 0.286s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11549, val loss: 0.11408, in 0.296s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11196, val loss: 0.11159, in 0.328s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10515, val loss: 0.10478, in 0.305s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11641, val loss: 0.11507, in 0.335s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11525, val loss: 0.11341, in 0.446s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11459, val loss: 0.11256, in 0.376s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11340, val loss: 0.11084, in 0.412s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11515, val loss: 0.11375, in 0.368s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11625, val loss: 0.11585, in 0.412s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11139, val loss: 0.11106, in 0.347s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10460, val loss: 0.10426, in 0.421s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11581, val loss: 0.11446, in 0.435s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11329, val loss: 0.11132, in 0.363s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11281, val loss: 0.11022, in 0.371s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11433, val loss: 0.11252, in 0.413s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11409, val loss: 0.11269, in 0.392s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11575, val loss: 0.11537, in 0.452s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11079, val loss: 0.11046, in 0.420s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11529, val loss: 0.11394, in 0.362s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10322, val loss: 0.10286, in 0.509s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11281, val loss: 0.11087, in 0.411s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11222, val loss: 0.10964, in 0.384s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11342, val loss: 0.11205, in 0.377s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11047, val loss: 0.11013, in 0.352s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11393, val loss: 0.11211, in 0.463s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11519, val loss: 0.11482, in 0.402s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11457, val loss: 0.11324, in 0.384s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10295, val loss: 0.10260, in 0.301s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11170, in 0.302s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11202, val loss: 0.11013, in 0.326s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11338, val loss: 0.11156, in 0.242s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11170, val loss: 0.10914, in 0.359s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10985, val loss: 0.10951, in 0.303s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11468, val loss: 0.11431, in 0.333s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10267, val loss: 0.10234, in 0.266s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11403, val loss: 0.11272, in 0.351s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11260, val loss: 0.11121, in 0.305s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11145, val loss: 0.10956, in 0.364s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11290, val loss: 0.11110, in 0.367s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10939, val loss: 0.10908, in 0.333s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.10768, in 0.438s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11331, val loss: 0.11203, in 0.286s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11360, val loss: 0.11323, in 0.376s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10220, val loss: 0.10190, in 0.383s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.10860, in 0.254s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11027, val loss: 0.10843, in 0.304s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11106, val loss: 0.10970, in 0.380s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11241, val loss: 0.11058, in 0.322s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10969, val loss: 0.10716, in 0.254s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11287, val loss: 0.11158, in 0.279s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11278, val loss: 0.11242, in 0.317s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10173, val loss: 0.10146, in 0.258s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10965, val loss: 0.10782, in 0.300s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10859, val loss: 0.10831, in 0.316s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11197, val loss: 0.11010, in 0.329s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11055, val loss: 0.10922, in 0.362s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10919, val loss: 0.10668, in 0.367s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11254, val loss: 0.11125, in 0.290s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11243, val loss: 0.11206, in 0.290s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10125, val loss: 0.10097, in 0.337s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10913, val loss: 0.10731, in 0.239s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10997, val loss: 0.10864, in 0.274s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11147, val loss: 0.10963, in 0.298s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10678, in 0.363s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10884, val loss: 0.10633, in 0.277s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11194, val loss: 0.11156, in 0.277s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11204, val loss: 0.11076, in 0.333s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10075, val loss: 0.10050, in 0.306s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10864, val loss: 0.10682, in 0.294s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10964, val loss: 0.10829, in 0.305s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10859, val loss: 0.10607, in 0.288s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11096, val loss: 0.10914, in 0.345s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11128, val loss: 0.11093, in 0.320s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10632, in 0.397s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11154, val loss: 0.11027, in 0.379s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10815, val loss: 0.10636, in 0.388s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09949, val loss: 0.09922, in 0.460s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10929, val loss: 0.10795, in 0.353s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10820, val loss: 0.10566, in 0.338s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.10850, in 0.331s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10606, val loss: 0.10579, in 0.281s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11065, val loss: 0.11032, in 0.356s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11059, val loss: 0.10933, in 0.341s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10759, val loss: 0.10580, in 0.287s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09925, val loss: 0.09898, in 0.254s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10535, in 0.235s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10533, in 0.241s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10883, val loss: 0.10752, in 0.295s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10982, val loss: 0.10802, in 0.306s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10996, val loss: 0.10965, in 0.288s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11031, val loss: 0.10903, in 0.247s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10650, val loss: 0.10474, in 0.282s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09859, val loss: 0.09835, in 0.280s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10519, val loss: 0.10497, in 0.267s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10846, val loss: 0.10715, in 0.286s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10485, in 0.332s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10900, val loss: 0.10722, in 0.332s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10946, val loss: 0.10918, in 0.329s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10987, val loss: 0.10862, in 0.318s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10604, val loss: 0.10428, in 0.277s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10447, val loss: 0.10426, in 0.346s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09748, val loss: 0.09721, in 0.397s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.10687, in 0.260s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10577, in 0.366s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10605, val loss: 0.10351, in 0.377s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10909, val loss: 0.10883, in 0.276s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10943, val loss: 0.10820, in 0.331s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10555, val loss: 0.10382, in 0.335s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10421, val loss: 0.10399, in 0.249s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09713, val loss: 0.09685, in 0.260s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10835, val loss: 0.10657, in 0.257s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10304, in 0.225s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10844, val loss: 0.10818, in 0.224s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10650, val loss: 0.10522, in 0.301s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10850, val loss: 0.10729, in 0.225s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10486, val loss: 0.10312, in 0.216s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09689, val loss: 0.09662, in 0.197s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10334, val loss: 0.10312, in 0.236s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10787, val loss: 0.10609, in 0.199s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10534, val loss: 0.10281, in 0.198s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10796, val loss: 0.10770, in 0.194s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10608, val loss: 0.10482, in 0.210s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10447, val loss: 0.10271, in 0.165s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10781, val loss: 0.10661, in 0.184s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09655, val loss: 0.09626, in 0.144s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10744, val loss: 0.10567, in 0.138s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10284, val loss: 0.10263, in 0.150s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10489, val loss: 0.10238, in 0.178s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10738, val loss: 0.10713, in 0.189s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10541, val loss: 0.10419, in 0.174s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10733, val loss: 0.10614, in 0.167s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10392, val loss: 0.10215, in 0.173s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09574, val loss: 0.09543, in 0.175s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10682, val loss: 0.10503, in 0.174s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10215, val loss: 0.10195, in 0.171s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10697, val loss: 0.10667, in 0.130s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10362, val loss: 0.10113, in 0.199s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10693, val loss: 0.10573, in 0.137s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10463, val loss: 0.10341, in 0.155s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10347, val loss: 0.10168, in 0.147s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09532, val loss: 0.09505, in 0.142s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10653, val loss: 0.10472, in 0.128s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10150, val loss: 0.10133, in 0.162s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10653, val loss: 0.10625, in 0.159s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10328, val loss: 0.10076, in 0.136s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10313, in 0.128s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10296, val loss: 0.10117, in 0.133s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10648, val loss: 0.10527, in 0.162s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09438, in 0.147s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10609, val loss: 0.10425, in 0.166s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10127, val loss: 0.10109, in 0.128s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10608, val loss: 0.10582, in 0.159s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10256, val loss: 0.10077, in 0.154s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10391, val loss: 0.10273, in 0.169s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10277, val loss: 0.10026, in 0.187s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09427, val loss: 0.09402, in 0.132s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10604, val loss: 0.10484, in 0.165s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10488, val loss: 0.10306, in 0.142s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10100, val loss: 0.10082, in 0.140s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10562, val loss: 0.10533, in 0.165s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10157, val loss: 0.09983, in 0.147s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10230, val loss: 0.09981, in 0.145s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10341, val loss: 0.10222, in 0.155s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09392, val loss: 0.09367, in 0.146s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10520, val loss: 0.10402, in 0.152s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10036, val loss: 0.10018, in 0.154s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10443, val loss: 0.10262, in 0.154s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10115, val loss: 0.09939, in 0.135s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10522, val loss: 0.10492, in 0.146s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10187, val loss: 0.09940, in 0.160s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10495, val loss: 0.10376, in 0.133s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10297, val loss: 0.10176, in 0.157s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09318, val loss: 0.09292, in 0.159s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10401, val loss: 0.10220, in 0.138s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09995, val loss: 0.09979, in 0.144s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10074, val loss: 0.09898, in 0.142s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10469, val loss: 0.10438, in 0.161s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10135, val loss: 0.09890, in 0.152s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09291, val loss: 0.09266, in 0.142s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10460, val loss: 0.10341, in 0.161s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10254, val loss: 0.10132, in 0.155s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09934, in 0.158s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10342, val loss: 0.10163, in 0.164s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10027, val loss: 0.09851, in 0.150s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10114, val loss: 0.09870, in 0.142s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10216, val loss: 0.10094, in 0.153s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09224, val loss: 0.09200, in 0.163s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10429, val loss: 0.10310, in 0.158s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10325, val loss: 0.10295, in 0.205s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10304, val loss: 0.10126, in 0.149s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09885, val loss: 0.09874, in 0.179s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09979, val loss: 0.09804, in 0.198s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10029, val loss: 0.09781, in 0.178s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10369, val loss: 0.10253, in 0.153s\n",
      "[159/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09190, val loss: 0.09169, in 0.163s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10169, val loss: 0.10047, in 0.173s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10284, val loss: 0.10253, in 0.153s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10266, val loss: 0.10089, in 0.190s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09845, val loss: 0.09833, in 0.172s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10323, val loss: 0.10207, in 0.137s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09981, val loss: 0.09730, in 0.161s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09161, val loss: 0.09141, in 0.154s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09935, val loss: 0.09763, in 0.182s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10240, val loss: 0.10211, in 0.178s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10043, val loss: 0.09924, in 0.209s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10222, val loss: 0.10047, in 0.167s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09811, val loss: 0.09797, in 0.176s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09844, val loss: 0.09674, in 0.132s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10265, val loss: 0.10150, in 0.167s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09118, val loss: 0.09099, in 0.153s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10218, val loss: 0.10190, in 0.127s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10003, val loss: 0.09884, in 0.125s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09866, val loss: 0.09616, in 0.191s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10165, val loss: 0.09991, in 0.128s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09778, val loss: 0.09763, in 0.132s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10191, val loss: 0.10159, in 0.163s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09803, val loss: 0.09636, in 0.192s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09069, val loss: 0.09050, in 0.182s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09980, val loss: 0.09864, in 0.158s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09826, val loss: 0.09577, in 0.163s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10132, val loss: 0.10016, in 0.222s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10055, val loss: 0.09883, in 0.174s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09744, val loss: 0.09729, in 0.186s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10154, val loss: 0.10125, in 0.150s\n",
      "[162/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09033, val loss: 0.09014, in 0.164s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09943, val loss: 0.09827, in 0.150s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09739, val loss: 0.09576, in 0.170s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09790, val loss: 0.09538, in 0.168s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10017, val loss: 0.09845, in 0.158s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10096, val loss: 0.09979, in 0.173s\n",
      "[163/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09690, val loss: 0.09676, in 0.167s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10101, val loss: 0.10072, in 0.143s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08965, val loss: 0.08948, in 0.136s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09864, val loss: 0.09749, in 0.152s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09690, val loss: 0.09526, in 0.145s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09788, in 0.142s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09751, val loss: 0.09502, in 0.161s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10032, val loss: 0.09919, in 0.146s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09649, val loss: 0.09637, in 0.143s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10064, val loss: 0.10035, in 0.131s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08934, val loss: 0.08915, in 0.131s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09656, val loss: 0.09491, in 0.129s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09834, val loss: 0.09721, in 0.155s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09922, val loss: 0.09749, in 0.138s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09993, val loss: 0.09879, in 0.132s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09722, val loss: 0.09472, in 0.137s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09594, val loss: 0.09584, in 0.139s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08897, val loss: 0.08880, in 0.148s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09623, val loss: 0.09457, in 0.135s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09931, val loss: 0.09902, in 0.182s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09839, val loss: 0.09669, in 0.138s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09626, val loss: 0.09381, in 0.167s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09554, in 0.132s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09718, val loss: 0.09608, in 0.186s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09869, val loss: 0.09754, in 0.177s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08861, val loss: 0.08846, in 0.132s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09582, val loss: 0.09417, in 0.158s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09890, val loss: 0.09863, in 0.155s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09609, val loss: 0.09364, in 0.121s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09539, val loss: 0.09530, in 0.125s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09779, val loss: 0.09606, in 0.165s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09691, val loss: 0.09579, in 0.127s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09829, val loss: 0.09716, in 0.151s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08828, val loss: 0.08815, in 0.118s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09544, val loss: 0.09380, in 0.114s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09563, val loss: 0.09320, in 0.130s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09736, val loss: 0.09565, in 0.159s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09656, val loss: 0.09546, in 0.155s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09822, val loss: 0.09796, in 0.179s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09502, val loss: 0.09493, in 0.164s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09774, val loss: 0.09661, in 0.142s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08788, val loss: 0.08777, in 0.161s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09475, val loss: 0.09311, in 0.149s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09465, val loss: 0.09227, in 0.154s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09695, val loss: 0.09527, in 0.141s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09768, val loss: 0.09741, in 0.145s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09393, in 0.155s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09618, val loss: 0.09509, in 0.163s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09736, val loss: 0.09622, in 0.155s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08751, val loss: 0.08741, in 0.177s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09266, in 0.188s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09425, val loss: 0.09189, in 0.178s\n",
      "[175/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09470, in 0.173s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09728, val loss: 0.09701, in 0.185s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09682, val loss: 0.09571, in 0.170s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09586, val loss: 0.09477, in 0.183s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09361, val loss: 0.09352, in 0.191s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09401, val loss: 0.09237, in 0.134s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08717, val loss: 0.08707, in 0.165s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09386, val loss: 0.09152, in 0.130s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09587, val loss: 0.09420, in 0.149s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09646, val loss: 0.09534, in 0.149s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09550, val loss: 0.09441, in 0.142s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09280, val loss: 0.09273, in 0.196s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09349, val loss: 0.09186, in 0.179s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09608, val loss: 0.09580, in 0.232s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08667, val loss: 0.08659, in 0.179s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09334, val loss: 0.09101, in 0.209s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09554, val loss: 0.09386, in 0.180s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09616, val loss: 0.09506, in 0.173s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09511, val loss: 0.09402, in 0.189s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09238, val loss: 0.09232, in 0.145s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09571, val loss: 0.09543, in 0.138s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09315, val loss: 0.09151, in 0.160s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08566, val loss: 0.08557, in 0.197s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09307, val loss: 0.09074, in 0.139s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09576, val loss: 0.09468, in 0.140s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09349, in 0.167s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09183, val loss: 0.09178, in 0.175s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09533, val loss: 0.09509, in 0.171s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09297, in 0.204s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09279, val loss: 0.09116, in 0.197s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08494, val loss: 0.08488, in 0.177s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09235, val loss: 0.09000, in 0.177s\n",
      "[179/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09549, val loss: 0.09441, in 0.159s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09419, val loss: 0.09252, in 0.176s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09137, val loss: 0.09130, in 0.153s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09499, val loss: 0.09474, in 0.171s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09359, val loss: 0.09251, in 0.184s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09197, val loss: 0.09038, in 0.159s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09370, val loss: 0.09202, in 0.151s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08402, val loss: 0.08394, in 0.195s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09150, val loss: 0.08919, in 0.195s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09102, val loss: 0.09098, in 0.142s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09435, val loss: 0.09326, in 0.214s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09476, val loss: 0.09449, in 0.149s\n",
      "[174/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09234, in 0.161s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09005, in 0.163s\n",
      "[181/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09336, val loss: 0.09169, in 0.176s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08346, val loss: 0.08340, in 0.204s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09113, val loss: 0.08884, in 0.211s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09407, val loss: 0.09299, in 0.192s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09077, val loss: 0.09072, in 0.208s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09446, val loss: 0.09418, in 0.208s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09324, val loss: 0.09216, in 0.184s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09126, val loss: 0.08968, in 0.221s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09261, val loss: 0.09097, in 0.205s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09386, val loss: 0.09277, in 0.201s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09046, val loss: 0.09043, in 0.219s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08309, val loss: 0.08301, in 0.244s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.08849, in 0.235s\n",
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09183, in 0.181s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09380, val loss: 0.09354, in 0.221s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09090, val loss: 0.08930, in 0.169s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09214, val loss: 0.09052, in 0.172s\n",
      "[180/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09351, val loss: 0.09243, in 0.130s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09008, val loss: 0.09005, in 0.140s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09037, val loss: 0.08810, in 0.138s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09342, val loss: 0.09317, in 0.134s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08242, val loss: 0.08233, in 0.177s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09190, val loss: 0.09086, in 0.185s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09013, val loss: 0.08857, in 0.145s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09177, val loss: 0.09017, in 0.159s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09300, val loss: 0.09190, in 0.159s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08920, val loss: 0.08915, in 0.140s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09311, val loss: 0.09286, in 0.126s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09009, val loss: 0.08783, in 0.152s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09172, val loss: 0.09070, in 0.129s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08975, val loss: 0.08821, in 0.136s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08207, val loss: 0.08199, in 0.154s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09268, val loss: 0.09160, in 0.141s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09134, val loss: 0.08972, in 0.175s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08977, val loss: 0.08751, in 0.147s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08884, val loss: 0.08881, in 0.161s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09121, val loss: 0.09022, in 0.143s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08186, val loss: 0.08179, in 0.136s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09201, val loss: 0.09175, in 0.193s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08938, val loss: 0.08786, in 0.168s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09044, val loss: 0.08883, in 0.146s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09164, val loss: 0.09054, in 0.187s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.08979, in 0.152s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08840, val loss: 0.08836, in 0.177s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08153, val loss: 0.08147, in 0.150s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08880, val loss: 0.08655, in 0.182s\n",
      "[186/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09182, val loss: 0.09158, in 0.137s\n",
      "[180/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08891, val loss: 0.08736, in 0.157s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09001, val loss: 0.08841, in 0.155s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09122, val loss: 0.09013, in 0.175s\n",
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09054, val loss: 0.08953, in 0.160s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09130, val loss: 0.09108, in 0.165s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08779, val loss: 0.08774, in 0.175s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08102, val loss: 0.08099, in 0.175s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08848, val loss: 0.08624, in 0.177s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08829, val loss: 0.08675, in 0.150s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08964, val loss: 0.08806, in 0.153s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09023, val loss: 0.08924, in 0.146s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09074, val loss: 0.08967, in 0.152s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09092, val loss: 0.09071, in 0.142s\n",
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08798, val loss: 0.08645, in 0.150s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08739, in 0.171s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08042, val loss: 0.08037, in 0.184s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08780, val loss: 0.08560, in 0.186s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08896, val loss: 0.08741, in 0.161s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09051, val loss: 0.08944, in 0.147s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09063, val loss: 0.09042, in 0.155s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08991, val loss: 0.08893, in 0.170s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08763, val loss: 0.08612, in 0.161s\n",
      "[190/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08695, val loss: 0.08695, in 0.187s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08520, in 0.178s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07973, val loss: 0.07969, in 0.198s\n",
      "[191/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08865, val loss: 0.08710, in 0.165s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09020, val loss: 0.08913, in 0.177s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08589, in 0.164s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08706, val loss: 0.08486, in 0.156s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08960, val loss: 0.08939, in 0.240s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08899, val loss: 0.08803, in 0.243s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08661, val loss: 0.08660, in 0.184s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07936, val loss: 0.07931, in 0.173s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08999, val loss: 0.08895, in 0.131s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08804, val loss: 0.08652, in 0.168s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08671, val loss: 0.08522, in 0.163s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08876, val loss: 0.08779, in 0.140s\n",
      "[190/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08682, val loss: 0.08462, in 0.173s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07877, val loss: 0.07874, in 0.168s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08907, in 0.194s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08582, val loss: 0.08579, in 0.188s\n",
      "[194/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08772, val loss: 0.08619, in 0.160s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08965, val loss: 0.08862, in 0.178s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08637, val loss: 0.08488, in 0.152s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08818, val loss: 0.08720, in 0.136s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08425, in 0.128s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08905, val loss: 0.08886, in 0.163s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08547, val loss: 0.08545, in 0.183s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08920, val loss: 0.08820, in 0.215s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08729, val loss: 0.08577, in 0.233s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07850, val loss: 0.07846, in 0.298s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08801, val loss: 0.08705, in 0.240s\n",
      "[192/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08614, val loss: 0.08396, in 0.236s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08603, val loss: 0.08455, in 0.319s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.08855, in 0.274s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08500, val loss: 0.08499, in 0.267s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08648, val loss: 0.08496, in 0.247s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07829, val loss: 0.07824, in 0.219s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08888, val loss: 0.08789, in 0.264s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08594, val loss: 0.08374, in 0.215s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08757, val loss: 0.08660, in 0.231s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08560, val loss: 0.08412, in 0.191s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08469, val loss: 0.08469, in 0.179s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08822, val loss: 0.08804, in 0.226s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08585, val loss: 0.08436, in 0.180s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08743, in 0.199s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07799, val loss: 0.07796, in 0.225s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08727, val loss: 0.08631, in 0.219s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08562, val loss: 0.08344, in 0.229s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08446, val loss: 0.08446, in 0.187s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08375, in 0.256s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08790, val loss: 0.08772, in 0.231s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08400, in 0.216s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08812, val loss: 0.08712, in 0.205s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07745, val loss: 0.07740, in 0.236s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08682, val loss: 0.08587, in 0.233s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08529, val loss: 0.08313, in 0.263s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08421, in 0.232s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08457, val loss: 0.08314, in 0.234s\n",
      "[197/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08518, val loss: 0.08372, in 0.235s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08793, val loss: 0.08693, in 0.215s\n",
      "[192/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08758, val loss: 0.08741, in 0.249s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07718, val loss: 0.07716, in 0.208s\n",
      "[198/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08555, in 0.267s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08498, val loss: 0.08283, in 0.289s\n",
      "[197/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08429, val loss: 0.08287, in 0.319s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08388, val loss: 0.08391, in 0.362s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08489, val loss: 0.08345, in 0.357s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08707, val loss: 0.08692, in 0.352s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08740, val loss: 0.08643, in 0.383s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08624, val loss: 0.08528, in 0.254s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07653, val loss: 0.07650, in 0.372s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08416, val loss: 0.08206, in 0.246s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08350, val loss: 0.08208, in 0.226s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08607, val loss: 0.08513, in 0.166s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08725, val loss: 0.08630, in 0.179s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08444, val loss: 0.08298, in 0.220s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07638, val loss: 0.07636, in 0.172s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08614, val loss: 0.08600, in 0.257s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08381, val loss: 0.08173, in 0.188s\n",
      "[199/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08308, val loss: 0.08164, in 0.215s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08424, val loss: 0.08278, in 0.272s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08593, val loss: 0.08580, in 0.277s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08630, val loss: 0.08534, in 0.352s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08430, in 0.360s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08356, val loss: 0.08147, in 0.301s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08349, val loss: 0.08204, in 0.459s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08508, val loss: 0.08417, in 0.452s\n",
      "[200/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08601, val loss: 0.08506, in 0.464s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08570, val loss: 0.08557, in 0.501s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08295, val loss: 0.08152, in 0.312s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08551, val loss: 0.08539, in 0.232s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08560, val loss: 0.08463, in 0.248s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08532, val loss: 0.08435, in 0.153s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08525, val loss: 0.08513, in 0.159s\n",
      "[196/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08246, val loss: 0.08106, in 0.185s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08493, val loss: 0.08396, in 0.193s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08439, val loss: 0.08426, in 0.266s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08477, val loss: 0.08380, in 0.220s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08396, val loss: 0.08383, in 0.214s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08374, val loss: 0.08361, in 0.185s\n",
      "[199/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08314, val loss: 0.08301, in 0.193s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08358, val loss: 0.08360, in 0.205s\n",
      "Fit 200 trees in 61.977 s, (1568 total leaves)\n",
      "Time spent computing histograms: 36.401s\n",
      "Time spent finding best splits:  0.289s\n",
      "Time spent applying splits:      4.929s\n",
      "Time spent predicting:           0.557s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.07607, val loss: 0.07605, in 0.315s\n",
      "Fit 200 trees in 62.403 s, (1584 total leaves)\n",
      "Time spent computing histograms: 36.770s\n",
      "Time spent finding best splits:  0.393s\n",
      "Time spent applying splits:      5.030s\n",
      "Time spent predicting:           0.514s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08273, val loss: 0.08131, in 0.274s\n",
      "Fit 200 trees in 61.980 s, (1568 total leaves)\n",
      "Time spent computing histograms: 36.105s\n",
      "Time spent finding best splits:  0.341s\n",
      "Time spent applying splits:      5.084s\n",
      "Time spent predicting:           0.541s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08282, val loss: 0.08077, in 0.595s\n",
      "Fit 200 trees in 62.650 s, (1575 total leaves)\n",
      "Time spent computing histograms: 36.915s\n",
      "Time spent finding best splits:  0.360s\n",
      "Time spent applying splits:      5.130s\n",
      "Time spent predicting:           0.632s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08456, val loss: 0.08363, in 0.251s\n",
      "Fit 200 trees in 62.501 s, (1565 total leaves)\n",
      "Time spent computing histograms: 36.679s\n",
      "Time spent finding best splits:  0.252s\n",
      "Time spent applying splits:      5.269s\n",
      "Time spent predicting:           0.474s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08222, val loss: 0.08082, in 0.174s\n",
      "Fit 200 trees in 62.576 s, (1571 total leaves)\n",
      "Time spent computing histograms: 36.414s\n",
      "Time spent finding best splits:  0.262s\n",
      "Time spent applying splits:      4.986s\n",
      "Time spent predicting:           0.560s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08458, val loss: 0.08362, in 0.163s\n",
      "Fit 200 trees in 62.727 s, (1572 total leaves)\n",
      "Time spent computing histograms: 36.607s\n",
      "Time spent finding best splits:  0.281s\n",
      "Time spent applying splits:      4.826s\n",
      "Time spent predicting:           0.529s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08296, val loss: 0.08284, in 0.171s\n",
      "Fit 200 trees in 63.135 s, (1569 total leaves)\n",
      "Time spent computing histograms: 36.345s\n",
      "Time spent finding best splits:  0.245s\n",
      "Time spent applying splits:      5.274s\n",
      "Time spent predicting:           0.432s\n",
      "Binning 0.111 GB of training data: 6.729 s\n",
      "Binning 0.012 GB of validation data: 0.263 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 6.636 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.65910, val loss: 0.65906, in 0.330s\n",
      "[2/200] 0.238 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 6.309 s\n",
      "Binning 0.012 GB of validation data: 6.189 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62824, val loss: 0.62823, in 0.381s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65908, val loss: 0.65905, in 0.381s\n",
      "[2/200] 0.269 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.246 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60022, val loss: 0.60017, in 0.331s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62821, val loss: 0.62821, in 0.350s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65909, val loss: 0.65911, in 0.342s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.65733, val loss: 0.65734, in 0.349s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57464, val loss: 0.57460, in 0.322s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60017, val loss: 0.60016, in 0.317s\n",
      "[4/200] 5.753 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62824, val loss: 0.62818, in 0.360s\n",
      "[3/200] 5.728 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62489, val loss: 0.62486, in 0.342s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55125, val loss: 0.55117, in 0.329s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57458, val loss: 0.57459, in 0.339s\n",
      "[5/200] 0.259 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.60022, val loss: 0.60020, in 0.299s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.59542, val loss: 0.59539, in 0.315s\n",
      "[4/200] 5.520 s\n",
      "Binning 0.012 GB of validation data: 0.254 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52977, val loss: 0.52969, in 0.320s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55118, val loss: 0.55116, in 0.299s\n",
      "[6/200] 5.425 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.57464, val loss: 0.57454, in 0.299s\n",
      "[5/200] 0.171 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56852, val loss: 0.56845, in 0.295s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65060, in 0.427s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51000, val loss: 0.50989, in 0.273s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52968, val loss: 0.52971, in 0.293s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65068, val loss: 0.65051, in 0.438s\n",
      "[2/200] 0.180 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.55125, val loss: 0.55118, in 0.288s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.54393, val loss: 0.54386, in 0.270s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49177, val loss: 0.49161, in 0.281s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65078, val loss: 0.65071, in 0.403s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50991, val loss: 0.50991, in 0.267s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61225, val loss: 0.61198, in 0.432s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52976, val loss: 0.52965, in 0.283s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52135, val loss: 0.52125, in 0.300s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61226, val loss: 0.61198, in 0.420s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65062, in 0.432s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47493, val loss: 0.47473, in 0.299s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49167, val loss: 0.49164, in 0.301s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50999, val loss: 0.50981, in 0.305s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61245, val loss: 0.61226, in 0.505s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.50059, val loss: 0.50044, in 0.310s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57731, val loss: 0.57700, in 0.453s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45930, val loss: 0.45906, in 0.328s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57734, val loss: 0.57693, in 0.433s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47482, val loss: 0.47483, in 0.322s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61231, val loss: 0.61209, in 0.447s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.49177, val loss: 0.49153, in 0.271s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48146, val loss: 0.48127, in 0.248s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44208, val loss: 0.44182, in 0.265s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57753, val loss: 0.57729, in 0.370s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45919, val loss: 0.45911, in 0.243s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54535, val loss: 0.54490, in 0.378s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47490, val loss: 0.47464, in 0.291s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54545, val loss: 0.54498, in 0.398s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.46378, val loss: 0.46361, in 0.311s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57730, val loss: 0.57692, in 0.402s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42615, val loss: 0.42588, in 0.323s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44199, val loss: 0.44188, in 0.321s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54564, val loss: 0.54532, in 0.433s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45929, val loss: 0.45897, in 0.293s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51591, val loss: 0.51536, in 0.449s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44739, val loss: 0.44713, in 0.326s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51618, val loss: 0.51561, in 0.447s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41135, val loss: 0.41106, in 0.355s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54539, val loss: 0.54492, in 0.446s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42608, val loss: 0.42594, in 0.366s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44210, val loss: 0.44170, in 0.339s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.43217, val loss: 0.43183, in 0.307s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51626, val loss: 0.51583, in 0.435s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48877, val loss: 0.48810, in 0.425s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39759, val loss: 0.39734, in 0.324s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48902, val loss: 0.48834, in 0.401s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41129, val loss: 0.41112, in 0.303s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51612, val loss: 0.51553, in 0.406s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42618, val loss: 0.42580, in 0.300s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41806, val loss: 0.41774, in 0.289s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38478, val loss: 0.38453, in 0.297s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48916, val loss: 0.48868, in 0.415s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46359, val loss: 0.46286, in 0.455s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39754, val loss: 0.39740, in 0.362s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41139, val loss: 0.41095, in 0.347s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.40491, val loss: 0.40451, in 0.341s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46385, val loss: 0.46315, in 0.458s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48906, val loss: 0.48841, in 0.448s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37287, val loss: 0.37259, in 0.320s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38476, val loss: 0.38457, in 0.257s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39768, val loss: 0.39720, in 0.242s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46407, val loss: 0.46353, in 0.392s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39264, val loss: 0.39216, in 0.227s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44039, val loss: 0.43961, in 0.351s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44074, val loss: 0.43993, in 0.368s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36175, val loss: 0.36146, in 0.293s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46390, val loss: 0.46310, in 0.379s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37286, val loss: 0.37264, in 0.308s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38490, val loss: 0.38436, in 0.326s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38120, val loss: 0.38068, in 0.301s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44096, val loss: 0.44033, in 0.425s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41905, val loss: 0.41816, in 0.420s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35137, val loss: 0.35114, in 0.324s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41923, val loss: 0.41839, in 0.439s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36176, val loss: 0.36151, in 0.358s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37055, val loss: 0.36999, in 0.325s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44080, val loss: 0.43989, in 0.438s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37300, val loss: 0.37249, in 0.357s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41953, val loss: 0.41885, in 0.424s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34167, val loss: 0.34142, in 0.317s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39907, val loss: 0.39812, in 0.418s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36058, val loss: 0.36000, in 0.281s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35139, val loss: 0.35119, in 0.309s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36189, val loss: 0.36134, in 0.323s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39941, val loss: 0.39849, in 0.440s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41926, val loss: 0.41827, in 0.419s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33261, val loss: 0.33236, in 0.330s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35122, val loss: 0.35059, in 0.322s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34170, val loss: 0.34148, in 0.318s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39969, val loss: 0.39893, in 0.433s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.35152, val loss: 0.35091, in 0.312s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38045, val loss: 0.37939, in 0.439s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38080, val loss: 0.37982, in 0.401s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32413, val loss: 0.32386, in 0.288s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39944, val loss: 0.39832, in 0.408s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34248, val loss: 0.34182, in 0.267s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33266, val loss: 0.33241, in 0.281s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34184, val loss: 0.34119, in 0.305s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38109, val loss: 0.38027, in 0.430s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36309, val loss: 0.36202, in 0.444s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33428, val loss: 0.33363, in 0.361s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31615, val loss: 0.31585, in 0.407s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32418, val loss: 0.32392, in 0.416s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36348, val loss: 0.36246, in 0.515s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38084, val loss: 0.37965, in 0.515s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33280, val loss: 0.33218, in 0.407s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32660, val loss: 0.32591, in 0.336s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36383, val loss: 0.36293, in 0.497s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30832, val loss: 0.30800, in 0.349s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34703, val loss: 0.34585, in 0.475s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31619, val loss: 0.31586, in 0.342s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32433, val loss: 0.32364, in 0.348s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34723, val loss: 0.34623, in 0.460s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36354, val loss: 0.36225, in 0.444s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31792, val loss: 0.31718, in 0.338s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30129, val loss: 0.30090, in 0.345s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30874, val loss: 0.30843, in 0.317s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34761, val loss: 0.34669, in 0.463s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31604, val loss: 0.31525, in 0.347s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.33184, val loss: 0.33067, in 0.488s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33203, val loss: 0.33094, in 0.473s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30943, val loss: 0.30860, in 0.345s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34726, val loss: 0.34592, in 0.469s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29432, val loss: 0.29387, in 0.339s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30134, val loss: 0.30095, in 0.345s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30852, val loss: 0.30767, in 0.305s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33232, val loss: 0.33132, in 0.401s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31760, val loss: 0.31638, in 0.393s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30175, val loss: 0.30085, in 0.274s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28810, val loss: 0.28766, in 0.292s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29471, val loss: 0.29428, in 0.277s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31793, val loss: 0.31681, in 0.398s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.33214, val loss: 0.33070, in 0.440s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.30119, val loss: 0.30033, in 0.346s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31819, val loss: 0.31715, in 0.425s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29425, val loss: 0.29334, in 0.336s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28192, val loss: 0.28143, in 0.343s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30403, val loss: 0.30268, in 0.479s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28817, val loss: 0.28767, in 0.374s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29456, val loss: 0.29361, in 0.342s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30460, val loss: 0.30343, in 0.480s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.31801, val loss: 0.31650, in 0.459s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28748, val loss: 0.28653, in 0.404s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27639, val loss: 0.27588, in 0.385s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28219, val loss: 0.28170, in 0.347s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.30474, val loss: 0.30367, in 0.504s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28835, val loss: 0.28735, in 0.326s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29126, val loss: 0.28989, in 0.448s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29208, val loss: 0.29090, in 0.454s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28083, val loss: 0.27980, in 0.329s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27091, val loss: 0.27035, in 0.333s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30471, val loss: 0.30312, in 0.456s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27665, val loss: 0.27612, in 0.342s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28217, val loss: 0.28109, in 0.358s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29217, val loss: 0.29108, in 0.435s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27943, val loss: 0.27806, in 0.460s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27485, val loss: 0.27378, in 0.345s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26589, val loss: 0.26534, in 0.335s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27146, val loss: 0.27088, in 0.347s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27998, val loss: 0.27873, in 0.461s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27667, val loss: 0.27563, in 0.345s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29197, val loss: 0.29034, in 0.472s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26912, val loss: 0.26806, in 0.355s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26124, val loss: 0.26066, in 0.339s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.28004, val loss: 0.27892, in 0.506s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26625, val loss: 0.26560, in 0.335s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26818, val loss: 0.26678, in 0.519s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27117, val loss: 0.27006, in 0.345s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26898, val loss: 0.26775, in 0.484s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28003, val loss: 0.27834, in 0.477s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26384, val loss: 0.26271, in 0.326s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25679, val loss: 0.25621, in 0.344s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26150, val loss: 0.26087, in 0.328s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26876, val loss: 0.26762, in 0.442s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26626, val loss: 0.26508, in 0.307s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25773, val loss: 0.25636, in 0.418s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25877, val loss: 0.25765, in 0.307s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25817, val loss: 0.25690, in 0.403s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25263, val loss: 0.25203, in 0.300s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25713, val loss: 0.25645, in 0.309s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26878, val loss: 0.26699, in 0.405s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26138, val loss: 0.26015, in 0.297s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25798, val loss: 0.25683, in 0.414s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24800, val loss: 0.24655, in 0.400s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25376, val loss: 0.25257, in 0.289s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24836, val loss: 0.24771, in 0.296s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25292, val loss: 0.25226, in 0.304s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24795, val loss: 0.24661, in 0.392s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25690, val loss: 0.25569, in 0.289s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25833, val loss: 0.25649, in 0.404s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24930, val loss: 0.24805, in 0.298s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24453, val loss: 0.24388, in 0.295s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24822, val loss: 0.24694, in 0.391s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24864, val loss: 0.24794, in 0.288s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23829, val loss: 0.23675, in 0.408s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25275, val loss: 0.25152, in 0.299s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23852, val loss: 0.23709, in 0.404s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24848, val loss: 0.24653, in 0.406s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24485, val loss: 0.24356, in 0.291s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24094, val loss: 0.24026, in 0.285s\n",
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24489, val loss: 0.24418, in 0.281s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24876, val loss: 0.24753, in 0.274s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23891, val loss: 0.23760, in 0.405s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22944, val loss: 0.22787, in 0.394s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23749, val loss: 0.23678, in 0.251s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24081, val loss: 0.23953, in 0.285s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22953, val loss: 0.22804, in 0.402s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24121, val loss: 0.24051, in 0.291s\n",
      "[37/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.24497, val loss: 0.24371, in 0.283s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23882, val loss: 0.23675, in 0.397s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23031, val loss: 0.22892, in 0.400s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23413, val loss: 0.23342, in 0.299s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23703, val loss: 0.23572, in 0.308s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22081, val loss: 0.21919, in 0.407s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23776, val loss: 0.23700, in 0.268s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24105, val loss: 0.23975, in 0.293s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22144, val loss: 0.21991, in 0.398s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23015, val loss: 0.22805, in 0.394s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23097, val loss: 0.23023, in 0.239s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23343, val loss: 0.23213, in 0.262s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23441, val loss: 0.23367, in 0.277s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23761, val loss: 0.23626, in 0.240s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22184, val loss: 0.22046, in 0.381s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21308, val loss: 0.21139, in 0.386s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22804, val loss: 0.22727, in 0.245s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21360, val loss: 0.21198, in 0.363s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23122, val loss: 0.23044, in 0.248s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22984, val loss: 0.22849, in 0.285s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22154, val loss: 0.21943, in 0.434s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23424, val loss: 0.23290, in 0.301s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21393, val loss: 0.21253, in 0.426s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22472, val loss: 0.22391, in 0.327s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22826, val loss: 0.22744, in 0.284s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20549, val loss: 0.20375, in 0.431s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22662, val loss: 0.22526, in 0.336s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23111, val loss: 0.22973, in 0.290s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20593, val loss: 0.20431, in 0.463s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22199, val loss: 0.22116, in 0.248s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21346, val loss: 0.21135, in 0.417s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22520, val loss: 0.22439, in 0.280s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20645, val loss: 0.20501, in 0.388s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22353, val loss: 0.22220, in 0.271s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22797, val loss: 0.22663, in 0.261s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19845, val loss: 0.19664, in 0.392s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21911, val loss: 0.21828, in 0.296s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19887, val loss: 0.19721, in 0.399s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22243, val loss: 0.22162, in 0.274s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22068, val loss: 0.21938, in 0.267s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22506, val loss: 0.22370, in 0.270s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20605, val loss: 0.20390, in 0.412s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19969, val loss: 0.19821, in 0.411s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21666, val loss: 0.21581, in 0.248s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19143, val loss: 0.18961, in 0.412s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21940, val loss: 0.21853, in 0.266s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22237, val loss: 0.22098, in 0.244s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21778, val loss: 0.21649, in 0.279s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19238, val loss: 0.19067, in 0.400s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19892, val loss: 0.19671, in 0.375s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21398, val loss: 0.21312, in 0.256s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21691, val loss: 0.21606, in 0.235s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21523, val loss: 0.21399, in 0.207s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19290, val loss: 0.19141, in 0.387s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21953, val loss: 0.21816, in 0.261s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18501, val loss: 0.18321, in 0.382s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21169, val loss: 0.21081, in 0.248s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21452, val loss: 0.21364, in 0.253s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18597, val loss: 0.18423, in 0.380s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21226, val loss: 0.21101, in 0.299s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19199, val loss: 0.18979, in 0.387s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21696, val loss: 0.21560, in 0.278s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20948, val loss: 0.20862, in 0.258s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18621, val loss: 0.18469, in 0.419s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21190, val loss: 0.21104, in 0.273s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17881, val loss: 0.17696, in 0.410s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20994, val loss: 0.20871, in 0.256s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21407, val loss: 0.21267, in 0.302s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17973, val loss: 0.17792, in 0.411s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20702, val loss: 0.20616, in 0.295s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18547, val loss: 0.18328, in 0.427s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20971, val loss: 0.20881, in 0.271s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20746, val loss: 0.20624, in 0.304s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21172, val loss: 0.21035, in 0.268s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17983, val loss: 0.17832, in 0.439s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17306, val loss: 0.17116, in 0.432s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20502, val loss: 0.20414, in 0.291s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17385, val loss: 0.17197, in 0.434s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20727, val loss: 0.20638, in 0.324s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20538, val loss: 0.20420, in 0.291s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20956, val loss: 0.20818, in 0.280s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17922, val loss: 0.17707, in 0.458s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20304, val loss: 0.20216, in 0.215s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20529, val loss: 0.20440, in 0.226s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17394, val loss: 0.17246, in 0.427s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16733, val loss: 0.16543, in 0.428s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20336, val loss: 0.20219, in 0.246s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20710, val loss: 0.20573, in 0.312s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16815, val loss: 0.16625, in 0.427s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20054, val loss: 0.19967, in 0.292s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20333, val loss: 0.20242, in 0.304s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17339, val loss: 0.17128, in 0.484s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20112, val loss: 0.19995, in 0.355s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20506, val loss: 0.20365, in 0.291s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16843, val loss: 0.16693, in 0.508s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19870, val loss: 0.19784, in 0.334s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16213, val loss: 0.16023, in 0.486s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20139, val loss: 0.20047, in 0.251s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16286, val loss: 0.16097, in 0.444s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19928, val loss: 0.19808, in 0.240s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20314, val loss: 0.20176, in 0.260s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19692, val loss: 0.19605, in 0.209s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16762, val loss: 0.16547, in 0.401s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19918, val loss: 0.19822, in 0.267s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19746, val loss: 0.19625, in 0.202s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16303, val loss: 0.16147, in 0.365s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20123, val loss: 0.19983, in 0.204s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15715, val loss: 0.15521, in 0.377s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19519, val loss: 0.19432, in 0.213s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15779, val loss: 0.15589, in 0.378s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19740, val loss: 0.19643, in 0.209s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19563, val loss: 0.19442, in 0.242s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16221, val loss: 0.16002, in 0.369s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19353, val loss: 0.19265, in 0.211s\n",
      "[56/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19897, val loss: 0.19759, in 0.271s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19560, val loss: 0.19466, in 0.239s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15806, val loss: 0.15646, in 0.395s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15224, val loss: 0.15027, in 0.401s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19333, val loss: 0.19212, in 0.273s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15291, val loss: 0.15102, in 0.397s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19148, val loss: 0.19064, in 0.251s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19678, val loss: 0.19541, in 0.241s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19362, val loss: 0.19273, in 0.266s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15724, val loss: 0.15504, in 0.439s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19129, val loss: 0.19009, in 0.300s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19506, val loss: 0.19367, in 0.266s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18945, val loss: 0.18864, in 0.293s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15303, val loss: 0.15143, in 0.469s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19196, val loss: 0.19105, in 0.309s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14752, val loss: 0.14556, in 0.581s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14827, val loss: 0.14639, in 0.523s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18969, val loss: 0.18848, in 0.273s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19340, val loss: 0.19202, in 0.279s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18794, val loss: 0.18712, in 0.260s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15243, val loss: 0.15021, in 0.505s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19041, val loss: 0.18948, in 0.250s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14854, val loss: 0.14692, in 0.501s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18757, val loss: 0.18637, in 0.290s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19175, val loss: 0.19037, in 0.290s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18608, val loss: 0.18529, in 0.289s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14321, val loss: 0.14120, in 0.433s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18843, val loss: 0.18753, in 0.293s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14387, val loss: 0.14198, in 0.519s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19025, val loss: 0.18888, in 0.378s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18605, val loss: 0.18484, in 0.391s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18454, val loss: 0.18380, in 0.395s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14778, val loss: 0.14548, in 0.597s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18650, val loss: 0.18562, in 0.390s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14412, val loss: 0.14244, in 0.611s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18826, val loss: 0.18690, in 0.271s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13911, val loss: 0.13711, in 0.605s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18275, val loss: 0.18205, in 0.284s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18419, val loss: 0.18300, in 0.329s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13954, val loss: 0.13767, in 0.548s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18505, val loss: 0.18414, in 0.299s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14354, val loss: 0.14124, in 0.484s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18138, val loss: 0.18071, in 0.232s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18640, val loss: 0.18505, in 0.279s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18122, in 0.257s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13988, val loss: 0.13817, in 0.421s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18327, val loss: 0.18239, in 0.232s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13489, val loss: 0.13288, in 0.454s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18498, val loss: 0.18363, in 0.234s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13544, val loss: 0.13353, in 0.459s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17953, val loss: 0.17885, in 0.292s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18051, val loss: 0.17934, in 0.262s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18152, val loss: 0.18067, in 0.263s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13897, val loss: 0.13668, in 0.506s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18318, val loss: 0.18185, in 0.333s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17824, val loss: 0.17757, in 0.326s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17919, val loss: 0.17801, in 0.324s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13548, val loss: 0.13379, in 0.566s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18016, val loss: 0.17932, in 0.277s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13097, val loss: 0.12898, in 0.534s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13161, val loss: 0.12968, in 0.530s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18135, val loss: 0.18003, in 0.305s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17787, val loss: 0.17671, in 0.255s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17661, val loss: 0.17595, in 0.279s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17888, val loss: 0.17805, in 0.263s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13478, val loss: 0.13244, in 0.506s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13154, val loss: 0.12978, in 0.520s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17463, val loss: 0.17401, in 0.344s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17753, val loss: 0.17672, in 0.373s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17929, val loss: 0.17800, in 0.466s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17607, val loss: 0.17489, in 0.468s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12719, val loss: 0.12518, in 0.681s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12781, val loss: 0.12589, in 0.774s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13095, val loss: 0.12861, in 0.887s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17799, val loss: 0.17670, in 0.529s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17259, val loss: 0.17198, in 0.653s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17449, val loss: 0.17335, in 0.548s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17576, val loss: 0.17496, in 0.675s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12782, val loss: 0.12610, in 0.934s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17669, val loss: 0.17542, in 0.345s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17141, val loss: 0.17082, in 0.338s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12362, val loss: 0.12160, in 0.829s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12409, val loss: 0.12218, in 0.760s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17242, val loss: 0.17127, in 0.436s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17421, val loss: 0.17343, in 0.422s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12715, val loss: 0.12483, in 0.733s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17027, val loss: 0.16968, in 0.409s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17507, val loss: 0.17380, in 0.421s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17118, val loss: 0.17000, in 0.356s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12424, val loss: 0.12257, in 0.618s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17253, val loss: 0.17178, in 0.336s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11993, val loss: 0.11796, in 0.684s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17339, val loss: 0.17216, in 0.330s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12050, val loss: 0.11862, in 0.647s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16905, val loss: 0.16850, in 0.340s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16917, val loss: 0.16802, in 0.337s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17135, val loss: 0.17061, in 0.316s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12364, val loss: 0.12126, in 0.499s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17233, val loss: 0.17111, in 0.265s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12071, val loss: 0.11902, in 0.569s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16792, val loss: 0.16677, in 0.268s\n",
      "[69/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16745, val loss: 0.16693, in 0.335s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16945, val loss: 0.16876, in 0.289s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11631, val loss: 0.11440, in 0.447s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11686, val loss: 0.11503, in 0.474s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17120, val loss: 0.16998, in 0.244s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16638, val loss: 0.16525, in 0.230s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16606, val loss: 0.16558, in 0.221s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16837, val loss: 0.16769, in 0.202s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12011, val loss: 0.11771, in 0.447s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16977, val loss: 0.16857, in 0.194s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11720, val loss: 0.11551, in 0.383s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16526, val loss: 0.16407, in 0.193s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16689, val loss: 0.16625, in 0.196s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16464, val loss: 0.16419, in 0.206s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11318, val loss: 0.11130, in 0.380s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11359, val loss: 0.11179, in 0.390s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16866, val loss: 0.16747, in 0.198s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11677, val loss: 0.11439, in 0.364s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16351, val loss: 0.16305, in 0.191s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16374, val loss: 0.16257, in 0.208s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16575, val loss: 0.16511, in 0.206s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11395, val loss: 0.11220, in 0.371s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16721, val loss: 0.16611, in 0.206s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16254, val loss: 0.16211, in 0.194s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16458, val loss: 0.16397, in 0.197s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16276, val loss: 0.16164, in 0.207s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11004, val loss: 0.10818, in 0.389s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11044, val loss: 0.10870, in 0.366s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11346, val loss: 0.11106, in 0.384s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16533, val loss: 0.16420, in 0.228s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16122, val loss: 0.16083, in 0.210s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16315, val loss: 0.16261, in 0.207s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16127, val loss: 0.16016, in 0.256s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11069, val loss: 0.10897, in 0.370s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16420, val loss: 0.16308, in 0.200s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16040, val loss: 0.16001, in 0.176s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10697, val loss: 0.10518, in 0.383s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16189, val loss: 0.16138, in 0.216s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10741, val loss: 0.10568, in 0.385s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15953, val loss: 0.15843, in 0.232s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11031, val loss: 0.10793, in 0.394s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16319, val loss: 0.16210, in 0.208s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15949, val loss: 0.15911, in 0.210s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16014, val loss: 0.15962, in 0.215s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10764, val loss: 0.10588, in 0.397s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15846, val loss: 0.15739, in 0.201s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16187, val loss: 0.16084, in 0.196s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10394, val loss: 0.10217, in 0.379s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15850, val loss: 0.15815, in 0.211s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15911, val loss: 0.15859, in 0.208s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10425, val loss: 0.10259, in 0.407s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15757, val loss: 0.15655, in 0.194s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10738, val loss: 0.10504, in 0.383s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15758, val loss: 0.15724, in 0.200s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16083, val loss: 0.15979, in 0.222s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10484, val loss: 0.10305, in 0.364s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15781, val loss: 0.15736, in 0.215s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15660, val loss: 0.15553, in 0.202s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10120, val loss: 0.09947, in 0.396s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15915, val loss: 0.15810, in 0.241s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10124, val loss: 0.09964, in 0.400s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15620, val loss: 0.15586, in 0.277s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15680, val loss: 0.15637, in 0.236s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15529, val loss: 0.15423, in 0.220s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10468, val loss: 0.10232, in 0.386s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15833, val loss: 0.15730, in 0.191s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10172, val loss: 0.09997, in 0.392s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15491, val loss: 0.15454, in 0.202s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15587, val loss: 0.15544, in 0.194s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15399, val loss: 0.15297, in 0.224s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09820, val loss: 0.09651, in 0.424s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15728, val loss: 0.15628, in 0.191s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09826, val loss: 0.09668, in 0.389s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15395, val loss: 0.15358, in 0.216s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10187, val loss: 0.09953, in 0.395s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15507, val loss: 0.15465, in 0.224s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15312, val loss: 0.15214, in 0.203s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15597, val loss: 0.15499, in 0.227s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09884, val loss: 0.09709, in 0.424s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15320, val loss: 0.15286, in 0.201s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15418, val loss: 0.15376, in 0.197s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15220, val loss: 0.15124, in 0.209s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09543, val loss: 0.09371, in 0.410s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15483, val loss: 0.15386, in 0.236s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09553, val loss: 0.09400, in 0.440s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15336, val loss: 0.15297, in 0.207s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15238, val loss: 0.15206, in 0.261s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09899, val loss: 0.09672, in 0.441s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15062, val loss: 0.14965, in 0.289s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09608, val loss: 0.09434, in 0.475s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15387, val loss: 0.15290, in 0.329s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15155, val loss: 0.15122, in 0.277s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15246, val loss: 0.15204, in 0.335s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14982, val loss: 0.14878, in 0.311s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09321, val loss: 0.09150, in 0.551s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09290, val loss: 0.09140, in 0.628s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09625, val loss: 0.09401, in 0.603s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15295, val loss: 0.15197, in 0.345s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15128, val loss: 0.15089, in 0.326s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15030, val loss: 0.14999, in 0.388s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14862, val loss: 0.14760, in 0.326s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09378, val loss: 0.09210, in 0.563s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15179, val loss: 0.15084, in 0.236s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09057, val loss: 0.08889, in 0.472s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14945, val loss: 0.14912, in 0.292s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14982, val loss: 0.14947, in 0.363s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14795, val loss: 0.14699, in 0.292s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09052, val loss: 0.08902, in 0.595s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09365, val loss: 0.09140, in 0.621s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15103, val loss: 0.15012, in 0.411s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14829, val loss: 0.14796, in 0.378s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14892, val loss: 0.14859, in 0.349s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14672, val loss: 0.14579, in 0.344s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09102, val loss: 0.08937, in 0.654s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15015, val loss: 0.14924, in 0.259s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08829, val loss: 0.08663, in 0.652s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14813, val loss: 0.14776, in 0.234s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14741, val loss: 0.14710, in 0.254s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14590, val loss: 0.14497, in 0.277s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08799, val loss: 0.08654, in 0.543s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09140, val loss: 0.08920, in 0.526s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14929, val loss: 0.14836, in 0.316s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14676, val loss: 0.14644, in 0.245s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14739, val loss: 0.14703, in 0.279s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08865, val loss: 0.08705, in 0.467s\n",
      "[55/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14486, val loss: 0.14394, in 0.329s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08585, val loss: 0.08420, in 0.526s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14591, val loss: 0.14560, in 0.252s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14842, val loss: 0.14751, in 0.309s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14611, val loss: 0.14575, in 0.352s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14415, val loss: 0.14326, in 0.261s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08572, val loss: 0.08428, in 0.530s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08903, val loss: 0.08686, in 0.506s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14524, val loss: 0.14486, in 0.275s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14774, val loss: 0.14686, in 0.265s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08648, val loss: 0.08478, in 0.586s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14515, val loss: 0.14480, in 0.306s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14338, val loss: 0.14251, in 0.298s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08371, val loss: 0.08206, in 0.645s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14457, val loss: 0.14420, in 0.370s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14693, val loss: 0.14604, in 0.384s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14271, val loss: 0.14189, in 0.314s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14405, val loss: 0.14372, in 0.399s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08368, val loss: 0.08228, in 0.706s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08664, val loss: 0.08451, in 0.706s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14398, val loss: 0.14361, in 0.284s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08430, val loss: 0.08265, in 0.657s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14206, val loss: 0.14124, in 0.335s\n",
      "[93/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14569, val loss: 0.14481, in 0.414s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14265, val loss: 0.14232, in 0.347s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14330, val loss: 0.14292, in 0.308s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08156, val loss: 0.07990, in 0.633s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14117, val loss: 0.14039, in 0.279s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14490, val loss: 0.14401, in 0.294s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14187, val loss: 0.14159, in 0.256s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08138, val loss: 0.08002, in 0.583s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08426, val loss: 0.08211, in 0.568s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14209, val loss: 0.14173, in 0.281s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08211, val loss: 0.08051, in 0.569s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14405, val loss: 0.14321, in 0.271s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14006, val loss: 0.13928, in 0.329s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14124, val loss: 0.14089, in 0.266s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07951, val loss: 0.07792, in 0.514s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14115, val loss: 0.14075, in 0.303s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14054, val loss: 0.14022, in 0.256s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14318, val loss: 0.14234, in 0.300s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07956, val loss: 0.07820, in 0.554s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08214, val loss: 0.08008, in 0.578s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13906, val loss: 0.13829, in 0.348s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14034, val loss: 0.13995, in 0.324s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08013, val loss: 0.07857, in 0.585s\n",
      "[59/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13971, val loss: 0.13942, in 0.338s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13852, val loss: 0.13778, in 0.285s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14242, val loss: 0.14157, in 0.388s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07762, val loss: 0.07603, in 0.631s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13986, val loss: 0.13949, in 0.331s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13905, val loss: 0.13878, in 0.357s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13787, val loss: 0.13709, in 0.341s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07744, val loss: 0.07613, in 0.694s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14180, val loss: 0.14097, in 0.317s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08008, val loss: 0.07805, in 0.680s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13914, val loss: 0.13878, in 0.305s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07810, val loss: 0.07657, in 0.637s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13846, val loss: 0.13820, in 0.262s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13733, val loss: 0.13657, in 0.251s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14119, val loss: 0.14036, in 0.290s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07563, val loss: 0.07407, in 0.593s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13827, val loss: 0.13793, in 0.342s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13780, val loss: 0.13752, in 0.305s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13670, val loss: 0.13595, in 0.307s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07575, val loss: 0.07447, in 0.568s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14049, val loss: 0.13965, in 0.290s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07814, val loss: 0.07613, in 0.589s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13758, val loss: 0.13725, in 0.247s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07617, val loss: 0.07461, in 0.616s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13609, val loss: 0.13538, in 0.283s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13693, val loss: 0.13666, in 0.316s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13975, val loss: 0.13892, in 0.291s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07401, val loss: 0.07246, in 0.583s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13703, val loss: 0.13664, in 0.298s\n",
      "[105/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13927, val loss: 0.13845, in 0.235s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07394, val loss: 0.07268, in 0.572s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13506, val loss: 0.13434, in 0.351s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13594, val loss: 0.13569, in 0.331s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07617, val loss: 0.07420, in 0.598s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13640, val loss: 0.13603, in 0.255s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07432, val loss: 0.07278, in 0.565s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13856, val loss: 0.13775, in 0.441s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07217, val loss: 0.07064, in 0.694s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13569, val loss: 0.13536, in 0.566s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13415, val loss: 0.13343, in 0.631s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13519, val loss: 0.13497, in 0.632s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07230, val loss: 0.07103, in 1.051s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13800, val loss: 0.13717, in 0.654s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13475, val loss: 0.13451, in 0.552s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07418, val loss: 0.07226, in 1.195s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13339, val loss: 0.13266, in 0.682s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13468, val loss: 0.13435, in 0.724s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07256, val loss: 0.07104, in 1.219s\n",
      "[63/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13747, val loss: 0.13663, in 0.408s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07060, val loss: 0.06912, in 1.118s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13381, val loss: 0.13360, in 0.352s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13270, val loss: 0.13199, in 0.330s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13413, val loss: 0.13380, in 0.327s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13678, val loss: 0.13599, in 0.318s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07040, val loss: 0.06916, in 0.795s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13326, val loss: 0.13307, in 0.331s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07236, val loss: 0.07048, in 0.703s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13222, val loss: 0.13153, in 0.311s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13353, val loss: 0.13320, in 0.306s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07087, val loss: 0.06939, in 0.642s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13612, val loss: 0.13535, in 0.312s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06895, val loss: 0.06750, in 0.610s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13269, val loss: 0.13249, in 0.306s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13146, val loss: 0.13077, in 0.271s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13271, val loss: 0.13240, in 0.373s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13546, val loss: 0.13469, in 0.295s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06863, val loss: 0.06743, in 0.611s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13196, val loss: 0.13177, in 0.339s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07068, val loss: 0.06880, in 0.597s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13059, val loss: 0.12991, in 0.321s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06920, val loss: 0.06772, in 0.622s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13213, val loss: 0.13180, in 0.329s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06751, val loss: 0.06605, in 0.597s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13393, val loss: 0.13318, in 0.373s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13139, val loss: 0.13120, in 0.294s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12988, val loss: 0.12921, in 0.355s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06716, val loss: 0.06597, in 0.552s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13348, val loss: 0.13273, in 0.242s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13138, val loss: 0.13103, in 0.295s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13098, val loss: 0.13078, in 0.273s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06900, val loss: 0.06721, in 0.599s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06779, val loss: 0.06638, in 0.529s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13098, val loss: 0.13063, in 0.253s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12898, val loss: 0.12831, in 0.337s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06589, val loss: 0.06444, in 0.562s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13283, val loss: 0.13208, in 0.320s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13053, val loss: 0.13032, in 0.253s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12854, val loss: 0.12790, in 0.277s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13039, val loss: 0.13005, in 0.338s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13197, val loss: 0.13124, in 0.288s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06560, val loss: 0.06444, in 0.616s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13002, val loss: 0.12976, in 0.302s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06750, val loss: 0.06571, in 0.604s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06609, val loss: 0.06472, in 0.618s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12791, val loss: 0.12730, in 0.305s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13136, val loss: 0.13063, in 0.296s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06431, val loss: 0.06286, in 0.599s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12938, val loss: 0.12915, in 0.268s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12970, val loss: 0.12933, in 0.343s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12722, val loss: 0.12661, in 0.267s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06400, val loss: 0.06286, in 0.612s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12884, val loss: 0.12851, in 0.285s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13067, val loss: 0.12993, in 0.335s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12876, val loss: 0.12853, in 0.360s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06584, val loss: 0.06411, in 0.609s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06455, val loss: 0.06319, in 0.593s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12655, val loss: 0.12592, in 0.317s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06292, val loss: 0.06148, in 0.586s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12807, val loss: 0.12775, in 0.299s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12989, val loss: 0.12920, in 0.311s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12801, val loss: 0.12781, in 0.322s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12535, in 0.329s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12947, val loss: 0.12877, in 0.264s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12753, val loss: 0.12720, in 0.313s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06259, val loss: 0.06145, in 0.635s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12743, val loss: 0.12723, in 0.307s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06263, in 0.651s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12555, val loss: 0.12499, in 0.268s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06298, val loss: 0.06171, in 0.669s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12868, val loss: 0.12799, in 0.285s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06139, val loss: 0.05998, in 0.618s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12570, val loss: 0.12538, in 0.387s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12667, val loss: 0.12653, in 0.315s\n",
      "[119/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12480, val loss: 0.12422, in 0.362s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12798, val loss: 0.12731, in 0.300s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06118, val loss: 0.06006, in 0.590s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12534, val loss: 0.12502, in 0.279s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12580, in 0.335s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06290, val loss: 0.06124, in 0.589s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06174, val loss: 0.06046, in 0.575s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05997, val loss: 0.05859, in 0.592s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12399, val loss: 0.12341, in 0.371s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12463, val loss: 0.12432, in 0.266s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12665, val loss: 0.12601, in 0.370s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12560, val loss: 0.12544, in 0.254s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05990, val loss: 0.05879, in 0.572s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12311, val loss: 0.12256, in 0.319s\n",
      "[119/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12573, val loss: 0.12512, in 0.303s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12393, val loss: 0.12368, in 0.327s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12504, val loss: 0.12488, in 0.316s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06166, val loss: 0.06003, in 0.552s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06029, val loss: 0.05909, in 0.608s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05869, val loss: 0.05732, in 0.611s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12242, val loss: 0.12190, in 0.282s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12517, val loss: 0.12457, in 0.327s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12436, val loss: 0.12423, in 0.307s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12303, val loss: 0.12277, in 0.361s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05862, val loss: 0.05754, in 0.637s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12387, val loss: 0.12374, in 0.318s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12422, val loss: 0.12365, in 0.374s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12047, val loss: 0.11992, in 0.455s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06021, val loss: 0.05866, in 0.683s\n",
      "[71/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12201, val loss: 0.12177, in 0.390s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05903, val loss: 0.05785, in 0.666s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05758, val loss: 0.05624, in 0.667s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12318, val loss: 0.12311, in 0.359s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12362, val loss: 0.12304, in 0.348s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12157, val loss: 0.12133, in 0.318s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11983, val loss: 0.11932, in 0.385s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05733, val loss: 0.05623, in 0.677s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12325, val loss: 0.12266, in 0.304s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12222, in 0.337s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11946, val loss: 0.11897, in 0.266s\n",
      "[123/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12099, val loss: 0.12075, in 0.328s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05891, val loss: 0.05739, in 0.689s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05768, val loss: 0.05655, in 0.633s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05626, val loss: 0.05494, in 0.658s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11882, val loss: 0.11835, in 0.293s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12199, in 0.332s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12178, val loss: 0.12169, in 0.362s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12038, val loss: 0.12010, in 0.369s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05607, val loss: 0.05502, in 0.632s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12220, val loss: 0.12164, in 0.302s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11772, val loss: 0.11724, in 0.368s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12126, val loss: 0.12120, in 0.318s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05662, val loss: 0.05553, in 0.607s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05766, val loss: 0.05616, in 0.616s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11933, val loss: 0.11906, in 0.383s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05504, val loss: 0.05376, in 0.637s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12152, val loss: 0.12100, in 0.328s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11735, val loss: 0.11690, in 0.354s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12062, val loss: 0.12057, in 0.432s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05485, val loss: 0.05381, in 0.697s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11863, val loss: 0.11836, in 0.431s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12082, val loss: 0.12031, in 0.345s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11689, val loss: 0.11645, in 0.320s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05541, val loss: 0.05434, in 0.676s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05647, val loss: 0.05501, in 0.680s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11959, val loss: 0.11955, in 0.342s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05251, in 0.671s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11829, val loss: 0.11803, in 0.282s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12035, val loss: 0.11985, in 0.305s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11633, val loss: 0.11593, in 0.299s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11927, val loss: 0.11923, in 0.286s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11782, val loss: 0.11756, in 0.268s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05377, val loss: 0.05272, in 0.618s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11983, val loss: 0.11933, in 0.271s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11600, val loss: 0.11560, in 0.267s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05422, val loss: 0.05321, in 0.603s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05524, val loss: 0.05383, in 0.610s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11860, val loss: 0.11855, in 0.308s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11708, val loss: 0.11684, in 0.309s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05266, val loss: 0.05141, in 0.643s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11918, val loss: 0.11873, in 0.421s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11424, val loss: 0.11382, in 0.491s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11678, val loss: 0.11654, in 0.348s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11771, val loss: 0.11767, in 0.434s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05273, val loss: 0.05170, in 0.711s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11869, val loss: 0.11828, in 0.311s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05409, val loss: 0.05272, in 0.687s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05313, val loss: 0.05216, in 0.725s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11336, val loss: 0.11296, in 0.345s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11616, val loss: 0.11596, in 0.328s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05157, val loss: 0.05034, in 0.632s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11694, in 0.296s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11807, val loss: 0.11769, in 0.278s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11278, val loss: 0.11241, in 0.329s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11637, val loss: 0.11636, in 0.363s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11561, val loss: 0.11539, in 0.396s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05169, val loss: 0.05067, in 0.651s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11634, val loss: 0.11596, in 0.439s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05201, val loss: 0.05105, in 0.658s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05310, val loss: 0.05175, in 0.683s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05059, val loss: 0.04937, in 0.611s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11217, val loss: 0.11178, in 0.343s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11512, val loss: 0.11490, in 0.267s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11577, val loss: 0.11580, in 0.301s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11548, in 0.335s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11445, val loss: 0.11425, in 0.259s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05067, val loss: 0.04968, in 0.511s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11118, val loss: 0.11079, in 0.288s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11500, val loss: 0.11503, in 0.291s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05174, val loss: 0.05042, in 0.539s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05105, val loss: 0.05011, in 0.569s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04960, val loss: 0.04838, in 0.558s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11529, val loss: 0.11489, in 0.312s\n",
      "[136/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11357, val loss: 0.11339, in 0.311s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11034, val loss: 0.10995, in 0.291s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11452, val loss: 0.11456, in 0.298s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11477, val loss: 0.11437, in 0.261s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04957, val loss: 0.04861, in 0.542s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10996, val loss: 0.10957, in 0.250s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11318, val loss: 0.11297, in 0.256s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11400, val loss: 0.11403, in 0.329s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05075, val loss: 0.04944, in 0.602s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04869, val loss: 0.04749, in 0.628s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05003, val loss: 0.04910, in 0.653s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10957, val loss: 0.10919, in 0.340s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11289, val loss: 0.11268, in 0.340s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11408, val loss: 0.11370, in 0.388s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11348, val loss: 0.11353, in 0.329s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10925, val loss: 0.10887, in 0.308s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04860, val loss: 0.04764, in 0.674s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11219, val loss: 0.11198, in 0.353s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11363, val loss: 0.11325, in 0.353s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11292, val loss: 0.11298, in 0.334s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04982, val loss: 0.04854, in 0.625s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04770, val loss: 0.04650, in 0.623s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10867, val loss: 0.10832, in 0.331s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04902, val loss: 0.04812, in 0.664s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11328, val loss: 0.11293, in 0.291s\n",
      "[140/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11173, val loss: 0.11155, in 0.329s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11225, val loss: 0.11232, in 0.303s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04771, val loss: 0.04675, in 0.882s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11123, val loss: 0.11102, in 0.576s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11182, val loss: 0.11192, in 0.525s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11238, val loss: 0.11204, in 0.603s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10710, val loss: 0.10672, in 0.641s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04871, val loss: 0.04744, in 0.863s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04661, val loss: 0.04545, in 0.826s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04815, val loss: 0.04726, in 0.800s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10658, val loss: 0.10623, in 0.230s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11087, val loss: 0.11067, in 0.271s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11196, val loss: 0.11159, in 0.266s\n",
      "[142/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11141, val loss: 0.11154, in 0.280s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04682, val loss: 0.04588, in 0.542s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11110, val loss: 0.11124, in 0.280s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11139, val loss: 0.11106, in 0.317s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11048, val loss: 0.11030, in 0.329s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10511, val loss: 0.10474, in 0.476s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04783, val loss: 0.04657, in 0.647s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04574, val loss: 0.04457, in 0.821s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04723, val loss: 0.04634, in 0.900s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11021, val loss: 0.11003, in 0.538s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11072, val loss: 0.11084, in 0.579s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11079, val loss: 0.11046, in 0.562s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10462, val loss: 0.10428, in 0.508s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04586, val loss: 0.04497, in 1.012s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11047, val loss: 0.11013, in 0.353s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10968, val loss: 0.10953, in 0.405s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11010, val loss: 0.11024, in 0.408s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04680, val loss: 0.04555, in 0.898s\n",
      "[83/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10415, val loss: 0.10381, in 0.447s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04454, val loss: 0.04340, in 0.712s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04637, val loss: 0.04547, in 0.712s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10962, val loss: 0.10977, in 0.252s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10985, val loss: 0.10951, in 0.301s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10857, val loss: 0.10843, in 0.348s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10387, val loss: 0.10356, in 0.241s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04505, val loss: 0.04419, in 0.540s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10939, val loss: 0.10908, in 0.293s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10893, val loss: 0.10908, in 0.330s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10798, val loss: 0.10787, in 0.300s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04602, val loss: 0.04479, in 0.567s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10310, val loss: 0.10281, in 0.325s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04365, val loss: 0.04255, in 0.563s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04559, val loss: 0.04470, in 0.552s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10865, val loss: 0.10881, in 0.228s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10889, val loss: 0.10860, in 0.259s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10731, in 0.246s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04413, val loss: 0.04329, in 0.461s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10175, val loss: 0.10143, in 0.360s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10859, val loss: 0.10831, in 0.247s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10814, val loss: 0.10832, in 0.282s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10671, val loss: 0.10663, in 0.300s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04272, val loss: 0.04164, in 0.499s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04506, val loss: 0.04384, in 0.543s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04486, val loss: 0.04397, in 0.493s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10128, val loss: 0.10098, in 0.258s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10765, val loss: 0.10786, in 0.317s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04326, val loss: 0.04244, in 0.460s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10706, val loss: 0.10678, in 0.371s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10641, val loss: 0.10631, in 0.247s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10081, val loss: 0.10055, in 0.287s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10709, val loss: 0.10731, in 0.253s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10617, val loss: 0.10607, in 0.245s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04390, val loss: 0.04272, in 0.459s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10660, val loss: 0.10632, in 0.300s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04370, val loss: 0.04285, in 0.460s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04197, val loss: 0.04091, in 0.545s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10036, val loss: 0.10011, in 0.271s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04252, val loss: 0.04171, in 0.501s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10578, val loss: 0.10568, in 0.253s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10633, val loss: 0.10657, in 0.301s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10606, val loss: 0.10579, in 0.259s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10002, val loss: 0.09977, in 0.263s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04173, in 0.455s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04091, val loss: 0.03986, in 0.496s\n",
      "[89/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10557, val loss: 0.10533, in 0.271s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10506, val loss: 0.10497, in 0.336s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04203, in 0.561s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10548, val loss: 0.10573, in 0.354s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04176, val loss: 0.04098, in 0.483s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09967, val loss: 0.09942, in 0.289s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10519, val loss: 0.10497, in 0.244s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10459, val loss: 0.10451, in 0.340s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10503, val loss: 0.10528, in 0.357s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04030, val loss: 0.03925, in 0.576s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04206, val loss: 0.04095, in 0.710s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09913, val loss: 0.09888, in 0.491s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10447, val loss: 0.10426, in 0.505s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10427, val loss: 0.10415, in 0.432s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04105, val loss: 0.04029, in 0.745s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04191, val loss: 0.04109, in 0.838s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10464, val loss: 0.10488, in 0.519s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09863, val loss: 0.09840, in 0.450s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10421, val loss: 0.10399, in 0.365s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10316, val loss: 0.10303, in 0.469s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10435, val loss: 0.10459, in 0.400s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03949, val loss: 0.03847, in 0.821s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04129, val loss: 0.04018, in 0.834s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09827, val loss: 0.09805, in 0.430s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04030, val loss: 0.03956, in 0.740s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10334, val loss: 0.10312, in 0.564s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10260, in 0.447s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10380, val loss: 0.10404, in 0.402s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04114, val loss: 0.04032, in 0.847s\n",
      "[90/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09758, val loss: 0.09737, in 0.374s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10284, val loss: 0.10263, in 0.270s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03854, val loss: 0.03752, in 0.559s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04061, val loss: 0.03953, in 0.602s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10221, val loss: 0.10211, in 0.369s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10226, val loss: 0.10248, in 0.363s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03930, val loss: 0.03855, in 0.481s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09727, val loss: 0.09707, in 0.247s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04011, val loss: 0.03933, in 0.460s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10215, val loss: 0.10195, in 0.284s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10196, val loss: 0.10185, in 0.243s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10184, val loss: 0.10208, in 0.259s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03789, val loss: 0.03691, in 0.501s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09694, val loss: 0.09671, in 0.308s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03971, val loss: 0.03866, in 0.528s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10150, val loss: 0.10133, in 0.403s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.03769, in 0.540s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10093, val loss: 0.10082, in 0.389s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10140, val loss: 0.10167, in 0.418s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09648, val loss: 0.09627, in 0.355s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03938, val loss: 0.03861, in 0.632s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10127, val loss: 0.10109, in 0.269s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03701, val loss: 0.03604, in 0.516s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10051, val loss: 0.10041, in 0.288s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10114, val loss: 0.10142, in 0.248s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09580, val loss: 0.09560, in 0.292s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03895, val loss: 0.03791, in 0.585s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10100, val loss: 0.10082, in 0.258s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03774, val loss: 0.03704, in 0.552s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03844, val loss: 0.03769, in 0.504s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09941, in 0.359s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10070, val loss: 0.10100, in 0.341s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09518, val loss: 0.09498, in 0.361s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10036, val loss: 0.10018, in 0.333s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03618, val loss: 0.03523, in 0.597s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09916, val loss: 0.09913, in 0.252s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03713, val loss: 0.03646, in 0.467s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09928, val loss: 0.09955, in 0.343s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03818, val loss: 0.03715, in 0.560s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09439, val loss: 0.09418, in 0.265s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09995, val loss: 0.09979, in 0.246s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03743, val loss: 0.03671, in 0.536s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09865, val loss: 0.09861, in 0.333s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09889, val loss: 0.09918, in 0.279s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09414, val loss: 0.09395, in 0.272s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09934, in 0.329s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03555, val loss: 0.03464, in 0.559s\n",
      "[96/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09827, val loss: 0.09826, in 0.304s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03750, val loss: 0.03648, in 0.548s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09839, val loss: 0.09870, in 0.285s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.03625, val loss: 0.03561, in 0.625s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03657, val loss: 0.03588, in 0.461s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09296, val loss: 0.09275, in 0.365s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09885, val loss: 0.09874, in 0.309s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09782, val loss: 0.09782, in 0.231s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09805, val loss: 0.09836, in 0.280s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03492, val loss: 0.03401, in 0.472s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09255, val loss: 0.09236, in 0.257s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09845, val loss: 0.09833, in 0.293s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03668, val loss: 0.03568, in 0.502s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09741, val loss: 0.09740, in 0.305s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03559, val loss: 0.03495, in 0.487s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09781, val loss: 0.09811, in 0.279s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03599, val loss: 0.03532, in 0.556s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09194, val loss: 0.09174, in 0.372s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09811, val loss: 0.09797, in 0.408s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09689, val loss: 0.09690, in 0.383s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09746, val loss: 0.09775, in 0.374s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09171, val loss: 0.09151, in 0.314s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03413, val loss: 0.03325, in 0.725s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09778, val loss: 0.09763, in 0.307s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03476, val loss: 0.03413, in 0.658s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03609, val loss: 0.03513, in 0.742s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09650, val loss: 0.09652, in 0.406s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09725, val loss: 0.09755, in 0.357s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03525, val loss: 0.03460, in 0.700s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09744, val loss: 0.09729, in 0.364s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09061, val loss: 0.09040, in 0.448s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09686, val loss: 0.09717, in 0.232s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09558, val loss: 0.09560, in 0.318s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03334, val loss: 0.03249, in 0.608s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03419, val loss: 0.03355, in 0.624s\n",
      "[99/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09690, val loss: 0.09676, in 0.322s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09004, val loss: 0.08984, in 0.312s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03546, val loss: 0.03451, in 0.582s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03438, val loss: 0.03374, in 0.518s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09646, val loss: 0.09680, in 0.346s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09514, val loss: 0.09518, in 0.310s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08984, val loss: 0.08965, in 0.224s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09649, val loss: 0.09637, in 0.269s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09515, val loss: 0.09546, in 0.319s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03273, val loss: 0.03188, in 0.545s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09458, val loss: 0.09461, in 0.314s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03366, val loss: 0.03302, in 0.451s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03493, val loss: 0.03401, in 0.465s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08947, val loss: 0.08929, in 0.284s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09594, val loss: 0.09584, in 0.263s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03362, val loss: 0.03302, in 0.509s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09444, val loss: 0.09477, in 0.304s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09424, val loss: 0.09426, in 0.298s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08921, val loss: 0.08904, in 0.258s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09562, val loss: 0.09554, in 0.259s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03217, val loss: 0.03134, in 0.447s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03318, val loss: 0.03256, in 0.428s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09396, val loss: 0.09426, in 0.251s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03427, val loss: 0.03337, in 0.471s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09390, val loss: 0.09393, in 0.242s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08893, val loss: 0.08876, in 0.245s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09539, val loss: 0.09530, in 0.247s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03298, val loss: 0.03243, in 0.570s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09306, val loss: 0.09308, in 0.349s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09360, val loss: 0.09390, in 0.440s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03275, val loss: 0.03214, in 0.531s\n",
      "[102/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09502, val loss: 0.09493, in 0.376s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08838, val loss: 0.08822, in 0.405s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03070, in 0.634s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09269, val loss: 0.09271, in 0.295s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03350, val loss: 0.03263, in 0.703s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09322, val loss: 0.09353, in 0.305s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03179, in 0.612s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09393, in 0.326s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08739, val loss: 0.08722, in 0.608s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09192, val loss: 0.09197, in 0.496s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09328, in 0.461s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03220, val loss: 0.03160, in 0.793s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09361, val loss: 0.09352, in 0.516s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.03014, in 0.796s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08702, val loss: 0.08689, in 0.266s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03187, val loss: 0.03135, in 0.667s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09133, val loss: 0.09139, in 0.351s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09271, val loss: 0.09303, in 0.327s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03283, val loss: 0.03199, in 0.868s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09280, val loss: 0.09273, in 0.387s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08666, val loss: 0.08654, in 0.389s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03165, val loss: 0.03106, in 0.550s\n",
      "[104/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09078, val loss: 0.09085, in 0.394s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03025, val loss: 0.02948, in 0.638s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09238, val loss: 0.09232, in 0.358s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09151, val loss: 0.09181, in 0.531s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08628, val loss: 0.08617, in 0.412s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03127, val loss: 0.03078, in 0.724s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03210, val loss: 0.03128, in 0.656s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09049, val loss: 0.09056, in 0.383s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09183, val loss: 0.09178, in 0.322s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09078, val loss: 0.09110, in 0.359s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08593, val loss: 0.08583, in 0.363s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03119, val loss: 0.03060, in 0.719s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09011, val loss: 0.09021, in 0.304s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.02912, in 0.625s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09054, val loss: 0.09089, in 0.271s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09137, val loss: 0.09130, in 0.312s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03070, val loss: 0.03021, in 0.571s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08574, val loss: 0.08565, in 0.257s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03169, val loss: 0.03087, in 0.553s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08995, val loss: 0.09006, in 0.270s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09102, val loss: 0.09098, in 0.270s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08944, val loss: 0.08977, in 0.379s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03056, val loss: 0.02999, in 0.600s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08483, val loss: 0.08472, in 0.409s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08926, val loss: 0.08938, in 0.327s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02831, in 0.670s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09077, val loss: 0.09072, in 0.313s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03020, val loss: 0.02971, in 0.602s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03109, val loss: 0.03029, in 0.578s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08884, val loss: 0.08919, in 0.334s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08413, val loss: 0.08404, in 0.276s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08873, val loss: 0.08886, in 0.294s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09046, val loss: 0.09043, in 0.329s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03008, val loss: 0.02953, in 0.489s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08782, val loss: 0.08815, in 0.376s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08842, val loss: 0.08856, in 0.297s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.02922, in 0.460s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02780, in 0.562s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08337, val loss: 0.08326, in 0.397s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09008, val loss: 0.09005, in 0.308s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03052, val loss: 0.02975, in 0.584s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.02914, in 0.471s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08756, in 0.342s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08807, val loss: 0.08821, in 0.370s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08289, val loss: 0.08281, in 0.358s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08920, val loss: 0.08915, in 0.323s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02801, val loss: 0.02728, in 0.614s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02909, val loss: 0.02865, in 0.649s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08672, val loss: 0.08706, in 0.349s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08765, val loss: 0.08777, in 0.372s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08256, val loss: 0.08250, in 0.342s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08884, val loss: 0.08881, in 0.355s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02925, val loss: 0.02871, in 0.561s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02988, val loss: 0.02913, in 0.703s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08720, val loss: 0.08730, in 0.349s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08193, val loss: 0.08188, in 0.342s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08577, val loss: 0.08610, in 0.460s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08840, val loss: 0.08836, in 0.405s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02750, val loss: 0.02678, in 0.622s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02841, val loss: 0.02799, in 0.615s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08654, in 0.277s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08139, val loss: 0.08134, in 0.255s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02868, val loss: 0.02816, in 0.575s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02914, val loss: 0.02841, in 0.562s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08540, val loss: 0.08572, in 0.344s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08779, val loss: 0.08774, in 0.284s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08581, val loss: 0.08592, in 0.248s\n",
      "[193/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08086, val loss: 0.08081, in 0.284s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02782, val loss: 0.02741, in 0.414s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08741, val loss: 0.08739, in 0.231s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08506, val loss: 0.08539, in 0.259s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02683, val loss: 0.02613, in 0.469s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08548, val loss: 0.08559, in 0.224s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02849, val loss: 0.02778, in 0.433s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02829, val loss: 0.02778, in 0.443s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08050, val loss: 0.08048, in 0.254s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08491, val loss: 0.08524, in 0.242s\n",
      "[192/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08695, val loss: 0.08695, in 0.307s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08500, val loss: 0.08512, in 0.310s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02736, val loss: 0.02698, in 0.509s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08440, val loss: 0.08474, in 0.297s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07971, val loss: 0.07967, in 0.385s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02638, val loss: 0.02568, in 0.547s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02792, val loss: 0.02723, in 0.465s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08661, val loss: 0.08660, in 0.316s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02791, val loss: 0.02741, in 0.485s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08434, val loss: 0.08446, in 0.279s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07955, val loss: 0.07951, in 0.226s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08411, val loss: 0.08447, in 0.232s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08582, val loss: 0.08579, in 0.278s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08392, val loss: 0.08405, in 0.265s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02612, val loss: 0.02542, in 0.427s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02684, val loss: 0.02648, in 0.535s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07887, val loss: 0.07883, in 0.297s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08379, val loss: 0.08416, in 0.309s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08547, val loss: 0.08545, in 0.238s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02737, val loss: 0.02670, in 0.540s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02739, val loss: 0.02692, in 0.513s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08357, val loss: 0.08371, in 0.236s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08363, val loss: 0.08400, in 0.247s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07847, val loss: 0.07843, in 0.273s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08500, val loss: 0.08499, in 0.299s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02568, val loss: 0.02500, in 0.469s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02617, val loss: 0.02582, in 0.508s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08322, val loss: 0.08335, in 0.328s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07821, val loss: 0.07818, in 0.262s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02678, val loss: 0.02613, in 0.486s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08323, val loss: 0.08358, in 0.316s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08469, val loss: 0.08469, in 0.252s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02671, val loss: 0.02624, in 0.567s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08292, val loss: 0.08306, in 0.235s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07799, val loss: 0.07797, in 0.235s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02525, val loss: 0.02459, in 0.430s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08446, val loss: 0.08446, in 0.222s\n",
      "[198/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08277, val loss: 0.08311, in 0.252s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02560, val loss: 0.02527, in 0.476s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02640, val loss: 0.02578, in 0.499s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07750, val loss: 0.07750, in 0.279s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08421, in 0.256s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08238, val loss: 0.08271, in 0.283s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02617, val loss: 0.02571, in 0.529s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02416, in 0.497s\n",
      "[115/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08224, val loss: 0.08256, in 0.211s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08388, val loss: 0.08391, in 0.262s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07693, val loss: 0.07691, in 0.296s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02481, in 0.487s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02577, val loss: 0.02518, in 0.452s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02561, val loss: 0.02516, in 0.380s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07645, val loss: 0.07643, in 0.225s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02434, val loss: 0.02372, in 0.403s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02450, in 0.420s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07611, val loss: 0.07608, in 0.272s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02476, in 0.412s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02525, val loss: 0.02469, in 0.469s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02399, val loss: 0.02339, in 0.401s\n",
      "[117/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07565, val loss: 0.07561, in 0.273s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02431, val loss: 0.02403, in 0.430s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02472, val loss: 0.02428, in 0.391s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02485, val loss: 0.02432, in 0.447s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02338, val loss: 0.02279, in 0.479s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02380, val loss: 0.02355, in 0.477s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02432, val loss: 0.02389, in 0.512s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.02439, val loss: 0.02387, in 0.523s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02297, val loss: 0.02240, in 0.489s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02342, val loss: 0.02316, in 0.466s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02396, val loss: 0.02344, in 0.433s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02371, val loss: 0.02329, in 0.528s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02240, val loss: 0.02184, in 0.479s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02301, val loss: 0.02275, in 0.503s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02342, val loss: 0.02293, in 0.450s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02323, val loss: 0.02283, in 0.508s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02196, val loss: 0.02141, in 0.402s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02248, val loss: 0.02224, in 0.451s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02246, in 0.453s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02287, val loss: 0.02247, in 0.499s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02145, val loss: 0.02092, in 0.511s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02214, val loss: 0.02190, in 0.467s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02244, val loss: 0.02198, in 0.535s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02207, in 0.449s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02117, val loss: 0.02064, in 0.463s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02179, val loss: 0.02156, in 0.477s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02205, val loss: 0.02167, in 0.456s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02204, val loss: 0.02160, in 0.534s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02075, val loss: 0.02025, in 0.460s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02146, val loss: 0.02124, in 0.466s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02116, in 0.493s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02116, in 0.588s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.01987, in 0.501s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02105, val loss: 0.02083, in 0.611s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02123, val loss: 0.02086, in 0.681s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02120, val loss: 0.02079, in 0.742s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02008, val loss: 0.01960, in 0.698s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02073, val loss: 0.02053, in 0.676s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08253, val loss: 0.08265, in 0.257s\n",
      "Fit 200 trees in 71.294 s, (1569 total leaves)\n",
      "Time spent computing histograms: 40.177s\n",
      "Time spent finding best splits:  0.394s\n",
      "Time spent applying splits:      5.566s\n",
      "Time spent predicting:           0.525s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02052, in 0.624s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02087, val loss: 0.02045, in 0.623s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.01920, in 0.676s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02045, val loss: 0.02024, in 0.623s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02026, in 0.574s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08194, val loss: 0.08227, in 0.256s\n",
      "Fit 200 trees in 71.583 s, (1570 total leaves)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time spent computing histograms: 40.447s\n",
      "Time spent finding best splits:  0.338s\n",
      "Time spent applying splits:      5.466s\n",
      "Time spent predicting:           0.466s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.08358, val loss: 0.08360, in 0.251s\n",
      "Fit 200 trees in 71.107 s, (1568 total leaves)\n",
      "Time spent computing histograms: 40.475s\n",
      "Time spent finding best splits:  0.267s\n",
      "Time spent applying splits:      5.401s\n",
      "Time spent predicting:           0.564s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02045, val loss: 0.02005, in 0.646s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01928, val loss: 0.01883, in 0.676s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02004, val loss: 0.01984, in 0.613s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01994, in 0.646s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02001, val loss: 0.01964, in 0.660s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01892, val loss: 0.01848, in 0.622s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01967, val loss: 0.01949, in 0.782s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07545, val loss: 0.07541, in 0.226s\n",
      "Fit 200 trees in 71.678 s, (1583 total leaves)\n",
      "Time spent computing histograms: 40.231s\n",
      "Time spent finding best splits:  0.227s\n",
      "Time spent applying splits:      6.006s\n",
      "Time spent predicting:           0.580s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01995, val loss: 0.01961, in 0.741s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.01928, in 0.749s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01858, val loss: 0.01816, in 0.715s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01914, in 0.623s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01962, val loss: 0.01929, in 0.566s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01825, val loss: 0.01784, in 0.529s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01925, val loss: 0.01890, in 0.620s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01905, val loss: 0.01887, in 0.525s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01901, in 0.513s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01788, val loss: 0.01749, in 0.539s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01896, val loss: 0.01863, in 0.569s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01869, val loss: 0.01853, in 0.539s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01898, val loss: 0.01869, in 0.650s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01724, in 0.591s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.01829, in 0.583s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01822, in 0.566s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01865, val loss: 0.01837, in 0.644s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01694, in 0.654s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01794, in 0.596s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01810, val loss: 0.01796, in 0.602s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01833, val loss: 0.01804, in 0.499s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01664, in 0.583s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01791, val loss: 0.01762, in 0.632s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01770, in 0.567s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01811, val loss: 0.01783, in 0.544s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01675, val loss: 0.01642, in 0.595s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01733, in 0.566s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01751, val loss: 0.01737, in 0.719s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01793, val loss: 0.01766, in 0.578s\n",
      "[137/200] 6.282 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01642, val loss: 0.01610, in 0.651s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01732, val loss: 0.01704, in 0.667s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01712, in 0.532s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01740, in 0.482s\n",
      "[138/200] 0.213 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 6.108 s\n",
      "Binning 0.012 GB of validation data: 6.174 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01686, in 0.497s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01672, in 0.568s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01613, val loss: 0.01582, in 0.631s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01739, val loss: 0.01714, in 0.527s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65068, val loss: 0.65055, in 0.570s\n",
      "[2/200] 0.218 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 0.223 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01681, val loss: 0.01668, in 0.520s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01585, val loss: 0.01554, in 0.504s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01668, val loss: 0.01642, in 0.600s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01713, val loss: 0.01688, in 0.597s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61223, val loss: 0.61202, in 0.557s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65076, val loss: 0.65069, in 0.554s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65067, val loss: 0.65063, in 0.549s\n",
      "[2/200] 6.003 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01534, in 0.570s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01654, val loss: 0.01642, in 0.621s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01642, val loss: 0.01616, in 0.586s\n",
      "[137/200] 0.283 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01679, val loss: 0.01656, in 0.659s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57719, val loss: 0.57685, in 0.658s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61233, val loss: 0.61221, in 0.672s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61224, val loss: 0.61216, in 0.696s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01517, in 0.533s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01598, in 0.510s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01616, in 0.693s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65064, in 0.607s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54524, val loss: 0.54482, in 0.637s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57744, val loss: 0.57721, in 0.629s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01631, in 0.721s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57734, val loss: 0.57721, in 0.640s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01597, val loss: 0.01572, in 0.610s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01495, in 0.709s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01598, in 0.605s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51600, val loss: 0.51550, in 0.588s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61223, val loss: 0.61208, in 0.672s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54557, val loss: 0.54531, in 0.594s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01625, val loss: 0.01603, in 0.554s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54541, val loss: 0.54526, in 0.592s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01587, val loss: 0.01576, in 0.585s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01499, val loss: 0.01472, in 0.727s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01570, val loss: 0.01546, in 0.788s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48886, val loss: 0.48824, in 0.648s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51624, val loss: 0.51596, in 0.646s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57733, val loss: 0.57715, in 0.671s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01576, in 0.659s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51609, val loss: 0.51589, in 0.654s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01564, val loss: 0.01554, in 0.648s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01482, val loss: 0.01455, in 0.636s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01520, in 0.660s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48915, val loss: 0.48884, in 0.620s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54540, val loss: 0.54521, in 0.614s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46372, val loss: 0.46303, in 0.644s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48900, val loss: 0.48878, in 0.611s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01545, in 0.692s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01458, val loss: 0.01432, in 0.537s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01527, in 0.672s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01518, val loss: 0.01497, in 0.591s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51586, val loss: 0.51562, in 0.604s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44063, val loss: 0.43988, in 0.624s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46398, val loss: 0.46361, in 0.680s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01517, in 0.684s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46382, val loss: 0.46359, in 0.718s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01436, val loss: 0.01412, in 0.716s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01507, in 0.632s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01475, in 0.695s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48889, val loss: 0.48860, in 0.720s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41914, val loss: 0.41830, in 0.717s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44074, val loss: 0.44031, in 0.706s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01493, in 0.709s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44057, val loss: 0.44033, in 0.704s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01389, in 0.695s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01492, val loss: 0.01483, in 0.743s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01475, val loss: 0.01456, in 0.785s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46373, val loss: 0.46340, in 0.689s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39924, val loss: 0.39832, in 0.686s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41919, val loss: 0.41873, in 0.667s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41909, val loss: 0.41883, in 0.609s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01481, val loss: 0.01465, in 0.678s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01393, val loss: 0.01369, in 0.605s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01459, in 0.708s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44051, val loss: 0.44009, in 0.584s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01433, in 0.679s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38071, val loss: 0.37971, in 0.611s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39930, val loss: 0.39878, in 0.603s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39921, val loss: 0.39891, in 0.589s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01459, val loss: 0.01443, in 0.644s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01353, in 0.558s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01449, val loss: 0.01442, in 0.582s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01416, in 0.491s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41900, val loss: 0.41856, in 0.564s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38064, val loss: 0.38008, in 0.567s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36340, val loss: 0.36234, in 0.592s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38068, val loss: 0.38031, in 0.568s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01435, val loss: 0.01418, in 0.645s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01338, in 0.549s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01426, in 0.521s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01414, val loss: 0.01398, in 0.686s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39912, val loss: 0.39863, in 0.646s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36334, val loss: 0.36268, in 0.630s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34714, val loss: 0.34599, in 0.630s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36342, val loss: 0.36303, in 0.639s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01395, in 0.614s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01412, in 0.506s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01337, val loss: 0.01315, in 0.736s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01394, val loss: 0.01378, in 0.536s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38043, val loss: 0.37994, in 0.600s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34718, val loss: 0.34646, in 0.582s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33178, val loss: 0.33057, in 0.588s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34716, val loss: 0.34673, in 0.580s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01392, val loss: 0.01379, in 0.587s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01389, in 0.741s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01297, in 0.681s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01358, in 0.679s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36310, val loss: 0.36264, in 0.612s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33193, val loss: 0.33118, in 0.604s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31751, val loss: 0.31625, in 0.619s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.33175, val loss: 0.33137, in 0.620s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01362, in 0.513s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01374, val loss: 0.01369, in 0.574s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01279, in 0.583s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01357, val loss: 0.01340, in 0.528s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34694, val loss: 0.34642, in 0.579s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.31754, val loss: 0.31678, in 0.593s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30407, val loss: 0.30272, in 0.607s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31743, val loss: 0.31704, in 0.588s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01339, in 0.569s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01265, in 0.508s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01357, val loss: 0.01352, in 0.624s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01323, in 0.549s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33181, val loss: 0.33122, in 0.571s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29149, val loss: 0.29007, in 0.554s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30392, val loss: 0.30311, in 0.608s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30402, val loss: 0.30360, in 0.571s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01332, val loss: 0.01321, in 0.643s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01267, val loss: 0.01248, in 0.557s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01312, in 0.456s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01336, val loss: 0.01332, in 0.555s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31756, val loss: 0.31699, in 0.566s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29127, val loss: 0.29043, in 0.558s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27972, val loss: 0.27824, in 0.577s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.29140, val loss: 0.29104, in 0.570s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01307, in 0.522s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01245, val loss: 0.01228, in 0.594s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01316, in 0.497s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01307, val loss: 0.01293, in 0.637s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30413, val loss: 0.30360, in 0.571s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27912, val loss: 0.27823, in 0.565s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.26817, val loss: 0.26670, in 0.568s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27950, val loss: 0.27913, in 0.542s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01286, in 0.543s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01212, in 0.515s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01292, val loss: 0.01277, in 0.490s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01301, val loss: 0.01299, in 0.647s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29149, val loss: 0.29098, in 0.556s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26800, val loss: 0.26705, in 0.582s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25764, val loss: 0.25612, in 0.567s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.26806, val loss: 0.26764, in 0.594s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01265, in 0.635s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01260, in 0.568s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01194, in 0.691s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01281, val loss: 0.01279, in 0.658s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27942, val loss: 0.27888, in 0.610s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25735, val loss: 0.25638, in 0.596s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24747, val loss: 0.24589, in 0.604s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25756, val loss: 0.25712, in 0.600s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01249, in 0.532s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01193, val loss: 0.01175, in 0.467s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01241, in 0.634s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01262, in 0.460s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26818, val loss: 0.26759, in 0.544s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23825, val loss: 0.23659, in 0.534s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24748, val loss: 0.24641, in 0.546s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01240, val loss: 0.01231, in 0.518s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24730, val loss: 0.24681, in 0.567s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01228, in 0.528s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01158, in 0.668s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01243, in 0.671s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25777, val loss: 0.25713, in 0.586s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23805, val loss: 0.23695, in 0.583s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22939, val loss: 0.22769, in 0.598s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23815, val loss: 0.23762, in 0.553s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01217, in 0.567s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01228, val loss: 0.01216, in 0.475s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01145, in 0.504s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24763, val loss: 0.24698, in 0.529s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01229, val loss: 0.01228, in 0.579s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22122, val loss: 0.21948, in 0.519s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22927, val loss: 0.22807, in 0.550s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22934, val loss: 0.22876, in 0.548s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01205, val loss: 0.01199, in 0.591s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01200, in 0.514s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01133, in 0.444s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01210, val loss: 0.01210, in 0.525s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23804, val loss: 0.23733, in 0.561s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21329, val loss: 0.21148, in 0.567s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22112, val loss: 0.21986, in 0.562s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01182, in 0.487s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22106, val loss: 0.22046, in 0.555s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01135, val loss: 0.01118, in 0.459s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01187, in 0.558s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01196, val loss: 0.01196, in 0.480s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22929, val loss: 0.22856, in 0.548s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01176, val loss: 0.01168, in 0.473s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20565, val loss: 0.20379, in 0.518s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21317, val loss: 0.21189, in 0.536s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21302, val loss: 0.21238, in 0.512s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01103, in 0.556s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01184, val loss: 0.01173, in 0.516s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01177, val loss: 0.01178, in 0.569s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22082, val loss: 0.22010, in 0.497s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01151, in 0.516s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20581, val loss: 0.20447, in 0.498s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20559, val loss: 0.20492, in 0.502s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19831, val loss: 0.19649, in 0.535s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01104, val loss: 0.01087, in 0.548s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01168, val loss: 0.01159, in 0.544s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01142, val loss: 0.01135, in 0.510s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21268, val loss: 0.21196, in 0.562s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19140, val loss: 0.18956, in 0.533s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01160, val loss: 0.01161, in 0.639s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19854, val loss: 0.19789, in 0.539s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19852, val loss: 0.19722, in 0.571s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01072, in 0.508s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01150, val loss: 0.01141, in 0.510s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01128, val loss: 0.01121, in 0.442s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20549, val loss: 0.20472, in 0.483s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01144, val loss: 0.01146, in 0.455s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18498, val loss: 0.18315, in 0.499s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19203, val loss: 0.19136, in 0.513s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19209, val loss: 0.19072, in 0.486s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01075, val loss: 0.01059, in 0.410s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01127, in 0.464s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01137, in 0.539s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01108, in 0.669s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19834, val loss: 0.19759, in 0.713s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17867, val loss: 0.17685, in 0.703s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18550, val loss: 0.18484, in 0.709s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01126, val loss: 0.01118, in 0.612s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18554, val loss: 0.18419, in 0.762s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01057, val loss: 0.01042, in 0.847s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01119, val loss: 0.01122, in 0.602s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01099, val loss: 0.01095, in 0.636s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19156, val loss: 0.19079, in 0.576s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17272, val loss: 0.17090, in 0.569s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17907, val loss: 0.17771, in 0.526s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17924, val loss: 0.17856, in 0.599s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01107, val loss: 0.01101, in 0.619s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01027, in 0.548s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01083, in 0.439s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01106, in 0.562s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18518, val loss: 0.18441, in 0.549s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16704, val loss: 0.16516, in 0.551s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01097, val loss: 0.01091, in 0.482s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17328, val loss: 0.17259, in 0.524s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17318, val loss: 0.17183, in 0.551s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01015, in 0.548s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01070, val loss: 0.01067, in 0.491s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01091, in 0.522s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17875, val loss: 0.17801, in 0.498s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01082, val loss: 0.01076, in 0.443s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16165, val loss: 0.15976, in 0.474s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16765, val loss: 0.16628, in 0.452s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16755, val loss: 0.16686, in 0.476s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01004, in 0.382s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01055, in 0.416s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01078, in 0.390s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01063, in 0.417s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17279, val loss: 0.17206, in 0.460s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.00991, in 0.395s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16239, val loss: 0.16099, in 0.468s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15665, val loss: 0.15475, in 0.486s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16232, val loss: 0.16165, in 0.464s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01061, val loss: 0.01064, in 0.422s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01040, val loss: 0.01039, in 0.484s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16738, val loss: 0.16666, in 0.492s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00982, in 0.454s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15745, val loss: 0.15679, in 0.470s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15749, val loss: 0.15610, in 0.502s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01053, val loss: 0.01047, in 0.585s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15155, val loss: 0.14969, in 0.515s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01030, val loss: 0.01028, in 0.391s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01051, val loss: 0.01054, in 0.433s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16202, val loss: 0.16136, in 0.484s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01036, in 0.444s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15267, val loss: 0.15203, in 0.485s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00980, val loss: 0.00967, in 0.551s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15269, val loss: 0.15130, in 0.494s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14692, val loss: 0.14503, in 0.501s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01017, in 0.490s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01035, val loss: 0.01039, in 0.537s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15688, val loss: 0.15622, in 0.483s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00956, in 0.420s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14820, val loss: 0.14759, in 0.500s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14798, val loss: 0.14664, in 0.505s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14272, val loss: 0.14088, in 0.485s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01021, in 0.562s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01006, val loss: 0.01007, in 0.439s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01023, val loss: 0.01027, in 0.460s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00960, val loss: 0.00947, in 0.377s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15218, val loss: 0.15153, in 0.458s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01017, val loss: 0.01013, in 0.364s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14353, val loss: 0.14297, in 0.449s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13842, val loss: 0.13657, in 0.443s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14373, val loss: 0.14241, in 0.458s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01013, val loss: 0.01018, in 0.379s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00991, val loss: 0.00992, in 0.538s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00945, val loss: 0.00933, in 0.444s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14776, val loss: 0.14710, in 0.461s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01006, val loss: 0.01002, in 0.438s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13919, val loss: 0.13866, in 0.484s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13941, val loss: 0.13808, in 0.449s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13421, val loss: 0.13240, in 0.493s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00999, val loss: 0.01004, in 0.512s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00980, val loss: 0.00981, in 0.455s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.00921, in 0.456s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00992, val loss: 0.00989, in 0.412s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14331, val loss: 0.14263, in 0.449s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13508, val loss: 0.13455, in 0.453s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13539, val loss: 0.13405, in 0.456s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13029, val loss: 0.12841, in 0.454s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00971, in 0.432s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00986, val loss: 0.00992, in 0.530s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00912, in 0.572s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13899, val loss: 0.13828, in 0.591s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.00974, in 0.636s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13125, val loss: 0.13072, in 0.575s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13143, val loss: 0.13009, in 0.604s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12650, val loss: 0.12461, in 0.611s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00954, val loss: 0.00956, in 0.550s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00973, val loss: 0.00979, in 0.486s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00901, in 0.500s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13486, val loss: 0.13418, in 0.564s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12731, val loss: 0.12682, in 0.567s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12769, val loss: 0.12636, in 0.555s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.00961, in 0.658s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00947, in 0.531s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12279, val loss: 0.12092, in 0.553s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00967, in 0.537s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00906, val loss: 0.00896, in 0.412s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12386, val loss: 0.12336, in 0.442s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13080, val loss: 0.13015, in 0.532s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00952, val loss: 0.00950, in 0.489s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.00938, in 0.474s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12404, val loss: 0.12275, in 0.507s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00957, in 0.451s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11911, val loss: 0.11729, in 0.514s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00886, in 0.441s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00929, in 0.416s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12707, val loss: 0.12641, in 0.504s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12020, val loss: 0.11976, in 0.557s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00888, val loss: 0.00879, in 0.387s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12069, val loss: 0.11942, in 0.484s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00938, val loss: 0.00937, in 0.526s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00939, val loss: 0.00948, in 0.508s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11578, val loss: 0.11399, in 0.490s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00917, val loss: 0.00922, in 0.461s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12346, val loss: 0.12283, in 0.506s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00871, in 0.491s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11693, val loss: 0.11650, in 0.505s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11711, val loss: 0.11588, in 0.516s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00928, in 0.507s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00937, in 0.513s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11245, val loss: 0.11071, in 0.521s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00917, in 0.354s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00923, in 0.348s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11992, val loss: 0.11931, in 0.456s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11358, val loss: 0.11319, in 0.458s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00866, val loss: 0.00858, in 0.475s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11373, val loss: 0.11255, in 0.469s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00918, val loss: 0.00928, in 0.468s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10934, val loss: 0.10762, in 0.455s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00902, val loss: 0.00907, in 0.379s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00854, val loss: 0.00846, in 0.364s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00911, in 0.440s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11670, val loss: 0.11612, in 0.438s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00920, in 0.363s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11042, val loss: 0.11005, in 0.439s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11063, val loss: 0.10947, in 0.452s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10634, val loss: 0.10462, in 0.466s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00893, val loss: 0.00899, in 0.442s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00898, val loss: 0.00909, in 0.395s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00901, in 0.460s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11338, val loss: 0.11285, in 0.468s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00842, val loss: 0.00834, in 0.532s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10749, val loss: 0.10711, in 0.467s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10762, val loss: 0.10646, in 0.441s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10366, val loss: 0.10194, in 0.443s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00884, val loss: 0.00889, in 0.404s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00891, in 0.377s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00891, val loss: 0.00902, in 0.389s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11019, val loss: 0.10968, in 0.428s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00822, in 0.419s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10448, val loss: 0.10412, in 0.449s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10468, val loss: 0.10353, in 0.439s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10066, val loss: 0.09895, in 0.417s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00880, in 0.389s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00891, in 0.408s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00824, val loss: 0.00816, in 0.337s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00880, in 0.463s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10706, val loss: 0.10661, in 0.443s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10142, val loss: 0.10114, in 0.435s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10189, val loss: 0.10078, in 0.431s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00865, val loss: 0.00871, in 0.397s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09815, val loss: 0.09643, in 0.429s\n",
      "[51/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.00876, val loss: 0.00887, in 0.310s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00876, in 0.327s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00805, in 0.418s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00864, in 0.357s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10417, val loss: 0.10372, in 0.442s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09854, val loss: 0.09828, in 0.473s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09897, val loss: 0.09789, in 0.468s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00876, in 0.370s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09552, val loss: 0.09384, in 0.475s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00863, val loss: 0.00865, in 0.459s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00794, in 0.401s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00847, val loss: 0.00854, in 0.463s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10105, val loss: 0.10065, in 0.451s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00869, in 0.390s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09583, val loss: 0.09560, in 0.446s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09610, val loss: 0.09507, in 0.454s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09297, val loss: 0.09131, in 0.424s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00793, val loss: 0.00786, in 0.381s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00855, in 0.421s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00837, val loss: 0.00844, in 0.403s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09820, val loss: 0.09783, in 0.447s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00859, in 0.421s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09324, val loss: 0.09304, in 0.450s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09343, val loss: 0.09246, in 0.431s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09073, val loss: 0.08909, in 0.432s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00774, in 0.390s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00844, val loss: 0.00847, in 0.368s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00829, val loss: 0.00836, in 0.377s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00833, val loss: 0.00848, in 0.408s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09535, val loss: 0.09498, in 0.464s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09108, val loss: 0.09004, in 0.437s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09076, val loss: 0.09058, in 0.463s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08838, val loss: 0.08678, in 0.470s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00838, in 0.382s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00765, in 0.470s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00821, val loss: 0.00827, in 0.358s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00840, in 0.421s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09274, val loss: 0.09237, in 0.458s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08832, val loss: 0.08811, in 0.432s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00824, val loss: 0.00827, in 0.423s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08854, val loss: 0.08756, in 0.476s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08600, val loss: 0.08440, in 0.462s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00810, val loss: 0.00817, in 0.393s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00755, in 0.451s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00835, in 0.357s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00816, val loss: 0.00819, in 0.367s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09007, val loss: 0.08968, in 0.447s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00755, val loss: 0.00749, in 0.311s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08611, val loss: 0.08515, in 0.437s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08601, val loss: 0.08579, in 0.455s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08380, val loss: 0.08224, in 0.454s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00808, in 0.450s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00827, in 0.372s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00811, in 0.399s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00742, in 0.394s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08768, val loss: 0.08730, in 0.445s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08370, val loss: 0.08346, in 0.446s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08394, val loss: 0.08303, in 0.459s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08160, val loss: 0.08002, in 0.444s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00791, val loss: 0.00799, in 0.435s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00820, in 0.385s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00801, in 0.396s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00736, in 0.376s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08535, val loss: 0.08500, in 0.418s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08166, val loss: 0.08145, in 0.414s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08182, val loss: 0.08095, in 0.410s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00785, val loss: 0.00793, in 0.347s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07971, val loss: 0.07808, in 0.430s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00794, val loss: 0.00810, in 0.405s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00788, val loss: 0.00792, in 0.360s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00734, val loss: 0.00729, in 0.662s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08307, val loss: 0.08272, in 1.507s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07969, val loss: 0.07878, in 1.495s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07971, val loss: 0.07953, in 1.515s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00806, in 1.531s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07778, val loss: 0.07620, in 1.592s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00773, val loss: 0.00781, in 1.649s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00786, in 1.516s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00724, in 1.237s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08121, val loss: 0.08089, in 0.726s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07798, val loss: 0.07782, in 0.683s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07778, val loss: 0.07692, in 0.728s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07581, val loss: 0.07430, in 0.591s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00799, in 0.616s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00772, val loss: 0.00777, in 0.612s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00773, val loss: 0.00790, in 0.453s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07902, val loss: 0.07871, in 0.560s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07597, val loss: 0.07581, in 0.548s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07603, val loss: 0.07519, in 0.542s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07400, val loss: 0.07252, in 0.565s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00763, val loss: 0.00768, in 0.567s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07716, val loss: 0.07686, in 0.519s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07409, val loss: 0.07324, in 0.507s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00755, val loss: 0.00760, in 0.379s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07413, val loss: 0.07396, in 0.543s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07214, val loss: 0.07072, in 0.510s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00745, val loss: 0.00751, in 0.371s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07527, val loss: 0.07495, in 0.432s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07251, val loss: 0.07168, in 0.414s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07232, val loss: 0.07216, in 0.411s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07040, val loss: 0.06904, in 0.425s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07353, val loss: 0.07323, in 0.421s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07067, val loss: 0.06987, in 0.429s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07076, val loss: 0.07060, in 0.431s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06879, val loss: 0.06748, in 0.415s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07174, val loss: 0.07144, in 0.462s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06930, val loss: 0.06917, in 0.456s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06897, val loss: 0.06819, in 0.463s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06740, val loss: 0.06608, in 0.456s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07006, val loss: 0.06979, in 0.442s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06756, val loss: 0.06745, in 0.457s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06731, val loss: 0.06656, in 0.469s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06576, val loss: 0.06448, in 0.449s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06847, val loss: 0.06822, in 0.440s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06590, val loss: 0.06582, in 0.428s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06566, val loss: 0.06493, in 0.424s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06305, in 0.424s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06693, val loss: 0.06669, in 0.415s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06276, val loss: 0.06152, in 0.439s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06426, in 0.454s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06400, val loss: 0.06331, in 0.483s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06532, val loss: 0.06512, in 0.398s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06157, val loss: 0.06039, in 0.409s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06304, val loss: 0.06303, in 0.416s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06258, val loss: 0.06190, in 0.428s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06378, val loss: 0.06359, in 0.434s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06005, val loss: 0.05892, in 0.420s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06158, val loss: 0.06158, in 0.420s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06101, val loss: 0.06038, in 0.392s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06231, val loss: 0.06216, in 0.431s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05878, val loss: 0.05766, in 0.440s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06020, val loss: 0.06023, in 0.449s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05974, val loss: 0.05912, in 0.436s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06110, val loss: 0.06097, in 0.432s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05753, val loss: 0.05644, in 0.458s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05894, val loss: 0.05897, in 0.463s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05841, val loss: 0.05781, in 0.475s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05974, val loss: 0.05964, in 0.764s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05620, val loss: 0.05514, in 0.773s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05757, val loss: 0.05757, in 0.775s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05697, val loss: 0.05642, in 0.767s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05844, val loss: 0.05833, in 0.812s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05509, val loss: 0.05404, in 0.781s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05615, val loss: 0.05621, in 0.872s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05587, val loss: 0.05534, in 0.888s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05710, val loss: 0.05701, in 0.797s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05394, val loss: 0.05289, in 0.796s\n",
      "[76/200] 1 tree, 27 leaves, max depth = 10, train loss: 0.00724, val loss: 0.00720, in 0.463s\n",
      "Fit 200 trees in 116.258 s, (6196 total leaves)\n",
      "Time spent computing histograms: 67.619s\n",
      "Time spent finding best splits:  1.964s\n",
      "Time spent applying splits:      13.196s\n",
      "Time spent predicting:           0.995s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05464, val loss: 0.05412, in 0.692s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05513, val loss: 0.05521, in 0.767s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00767, val loss: 0.00775, in 0.544s\n",
      "Fit 200 trees in 115.455 s, (6200 total leaves)\n",
      "Time spent computing histograms: 69.041s\n",
      "Time spent finding best splits:  2.133s\n",
      "Time spent applying splits:      13.274s\n",
      "Time spent predicting:           0.852s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05599, val loss: 0.05591, in 0.921s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05270, val loss: 0.05172, in 0.953s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05341, val loss: 0.05293, in 1.016s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05385, val loss: 0.05398, in 0.989s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05472, val loss: 0.05469, in 0.651s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05158, val loss: 0.05063, in 0.665s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05226, val loss: 0.05179, in 0.619s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05284, val loss: 0.05301, in 0.654s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05348, val loss: 0.05352, in 0.547s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00769, val loss: 0.00786, in 0.422s\n",
      "Fit 200 trees in 116.138 s, (6199 total leaves)\n",
      "Time spent computing histograms: 68.620s\n",
      "Time spent finding best splits:  2.176s\n",
      "Time spent applying splits:      14.437s\n",
      "Time spent predicting:           0.772s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 9, train loss: 0.05066, val loss: 0.04971, in 0.511s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05122, val loss: 0.05077, in 0.466s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05187, val loss: 0.05209, in 0.567s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00743, in 0.376s\n",
      "Fit 200 trees in 115.891 s, (6200 total leaves)\n",
      "Time spent computing histograms: 69.327s\n",
      "Time spent finding best splits:  1.950s\n",
      "Time spent applying splits:      13.673s\n",
      "Time spent predicting:           0.720s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05237, val loss: 0.05238, in 0.579s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05023, val loss: 0.04978, in 0.598s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04965, val loss: 0.04872, in 0.634s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05087, val loss: 0.05109, in 0.585s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05132, val loss: 0.05133, in 0.755s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04930, val loss: 0.04883, in 0.692s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04872, val loss: 0.04780, in 0.707s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04987, val loss: 0.05010, in 0.689s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05024, val loss: 0.05024, in 0.577s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04785, val loss: 0.04695, in 0.517s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04841, val loss: 0.04796, in 0.560s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04894, val loss: 0.04915, in 0.540s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04930, val loss: 0.04930, in 0.583s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04681, val loss: 0.04590, in 0.584s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04740, val loss: 0.04697, in 0.596s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04808, val loss: 0.04831, in 0.557s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04597, val loss: 0.04509, in 0.556s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04831, val loss: 0.04836, in 0.578s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04647, val loss: 0.04604, in 0.552s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04718, val loss: 0.04738, in 0.565s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04568, val loss: 0.04523, in 0.578s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04502, val loss: 0.04415, in 0.624s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04742, val loss: 0.04748, in 0.619s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04615, val loss: 0.04634, in 0.568s\n",
      "[84/200] 5.847 s\n",
      "Binning 0.012 GB of validation data: 0.271 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04469, val loss: 0.04426, in 0.539s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04420, val loss: 0.04334, in 0.515s\n",
      "[86/200] 5.990 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04648, val loss: 0.04655, in 0.556s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04538, val loss: 0.04557, in 0.534s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85/200] 0.289 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65033, val loss: 0.65031, in 0.489s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04382, val loss: 0.04338, in 0.532s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04334, val loss: 0.04252, in 0.581s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04425, val loss: 0.04446, in 0.520s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04570, val loss: 0.04579, in 0.550s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65071, val loss: 0.65064, in 0.557s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61156, val loss: 0.61153, in 0.594s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04348, val loss: 0.04371, in 0.569s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04227, val loss: 0.04147, in 0.587s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04227, in 0.662s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04471, val loss: 0.04481, in 0.653s\n",
      "[85/200] 5.707 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.61229, val loss: 0.61217, in 0.579s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57628, val loss: 0.57626, in 0.537s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04160, val loss: 0.04080, in 0.553s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04288, in 0.591s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04196, val loss: 0.04157, in 0.575s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04386, val loss: 0.04400, in 0.523s\n",
      "[86/200] 0.287 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57737, val loss: 0.57712, in 0.534s\n",
      "[4/200] 5.782 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.54383, val loss: 0.54380, in 0.529s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04084, val loss: 0.04007, in 0.507s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04181, val loss: 0.04205, in 0.531s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04099, val loss: 0.04061, in 0.575s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04301, val loss: 0.04315, in 0.614s\n",
      "[87/200] 0.247 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65060, in 0.544s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54546, val loss: 0.54517, in 0.551s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51440, val loss: 0.51438, in 0.538s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04071, val loss: 0.04097, in 0.518s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04011, val loss: 0.03935, in 0.598s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03995, val loss: 0.03959, in 0.536s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04226, val loss: 0.04240, in 0.510s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65068, val loss: 0.65051, in 0.518s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61225, val loss: 0.61198, in 0.548s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51610, val loss: 0.51572, in 0.563s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48701, val loss: 0.48697, in 0.566s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04005, val loss: 0.04029, in 0.563s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03939, val loss: 0.03864, in 0.597s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04116, val loss: 0.04131, in 0.573s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03897, val loss: 0.03863, in 0.647s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61226, val loss: 0.61198, in 0.648s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57731, val loss: 0.57700, in 0.570s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48904, val loss: 0.48857, in 0.558s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46154, val loss: 0.46152, in 0.595s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03903, val loss: 0.03928, in 0.548s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03774, in 0.567s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03805, val loss: 0.03773, in 0.595s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04047, val loss: 0.04064, in 0.666s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57734, val loss: 0.57693, in 0.559s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54535, val loss: 0.54490, in 0.564s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46390, val loss: 0.46341, in 0.548s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43825, val loss: 0.43823, in 0.528s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03838, val loss: 0.03863, in 0.564s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03748, val loss: 0.03674, in 0.592s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03953, val loss: 0.03972, in 0.525s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51591, val loss: 0.51536, in 0.538s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03731, val loss: 0.03700, in 0.588s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54545, val loss: 0.54498, in 0.567s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44072, val loss: 0.44019, in 0.546s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41652, val loss: 0.41643, in 0.547s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03745, val loss: 0.03771, in 0.601s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03665, val loss: 0.03592, in 0.503s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03862, val loss: 0.03884, in 0.588s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48877, val loss: 0.48810, in 0.560s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51618, val loss: 0.51561, in 0.552s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03667, val loss: 0.03638, in 0.579s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41923, val loss: 0.41865, in 0.557s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39649, val loss: 0.39636, in 0.598s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03510, in 0.655s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03659, val loss: 0.03687, in 0.669s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46359, val loss: 0.46286, in 0.605s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03777, val loss: 0.03802, in 0.639s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48902, val loss: 0.48834, in 0.644s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03603, val loss: 0.03575, in 0.632s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39931, val loss: 0.39866, in 0.633s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37766, val loss: 0.37748, in 0.606s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03579, val loss: 0.03608, in 0.565s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03425, in 0.671s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46385, val loss: 0.46315, in 0.565s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44039, val loss: 0.43961, in 0.614s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03715, val loss: 0.03739, in 0.616s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03538, val loss: 0.03508, in 0.614s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38077, val loss: 0.38007, in 0.585s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36009, val loss: 0.35988, in 0.590s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03501, val loss: 0.03531, in 0.654s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41905, val loss: 0.41816, in 0.587s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44074, val loss: 0.43993, in 0.605s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03649, val loss: 0.03675, in 0.556s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03416, val loss: 0.03347, in 0.665s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03472, val loss: 0.03442, in 0.652s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36355, val loss: 0.36283, in 0.571s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34358, val loss: 0.34333, in 0.570s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03437, val loss: 0.03466, in 0.596s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39907, val loss: 0.39812, in 0.532s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03333, val loss: 0.03264, in 0.524s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41923, val loss: 0.41839, in 0.528s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03607, in 0.530s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34729, val loss: 0.34652, in 0.531s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03392, val loss: 0.03363, in 0.581s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.32813, val loss: 0.32788, in 0.536s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03388, val loss: 0.03416, in 0.540s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03266, val loss: 0.03199, in 0.519s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39941, val loss: 0.39849, in 0.518s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38045, val loss: 0.37939, in 0.535s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03499, val loss: 0.03531, in 0.592s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33198, val loss: 0.33124, in 0.511s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.31386, val loss: 0.31354, in 0.531s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03316, val loss: 0.03290, in 0.611s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36309, val loss: 0.36202, in 0.617s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03311, val loss: 0.03340, in 0.661s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38080, val loss: 0.37982, in 0.643s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03213, val loss: 0.03146, in 0.652s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03448, val loss: 0.03481, in 0.605s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31775, val loss: 0.31697, in 0.680s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30062, val loss: 0.30026, in 0.632s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03253, val loss: 0.03228, in 0.699s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34703, val loss: 0.34585, in 0.596s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36348, val loss: 0.36246, in 0.616s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03240, val loss: 0.03272, in 0.684s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03150, val loss: 0.03084, in 0.681s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03377, val loss: 0.03412, in 0.654s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.28808, val loss: 0.28766, in 0.557s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30429, val loss: 0.30354, in 0.594s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03208, val loss: 0.03185, in 0.534s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.33184, val loss: 0.33067, in 0.569s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34723, val loss: 0.34623, in 0.551s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03323, val loss: 0.03359, in 0.544s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03103, val loss: 0.03038, in 0.549s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03177, val loss: 0.03209, in 0.606s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27614, val loss: 0.27571, in 0.567s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29139, val loss: 0.29068, in 0.579s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03141, val loss: 0.03119, in 0.575s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31760, val loss: 0.31638, in 0.694s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33203, val loss: 0.33094, in 0.727s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03064, val loss: 0.03000, in 0.672s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03136, val loss: 0.03170, in 0.647s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03268, in 0.706s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26520, val loss: 0.26475, in 0.676s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27968, val loss: 0.27887, in 0.683s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03082, val loss: 0.03060, in 0.696s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30403, val loss: 0.30268, in 0.601s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31793, val loss: 0.31681, in 0.570s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03021, val loss: 0.02958, in 0.592s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03067, val loss: 0.03102, in 0.618s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03160, val loss: 0.03198, in 0.629s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25466, val loss: 0.25420, in 0.601s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26843, val loss: 0.26762, in 0.605s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03000, val loss: 0.02979, in 0.664s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29126, val loss: 0.28989, in 0.614s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02961, val loss: 0.02900, in 0.566s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30460, val loss: 0.30343, in 0.621s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24476, val loss: 0.24426, in 0.611s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03105, val loss: 0.03145, in 0.630s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25793, val loss: 0.25711, in 0.618s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03002, val loss: 0.03036, in 0.676s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02954, val loss: 0.02933, in 0.644s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27943, val loss: 0.27806, in 0.648s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02845, in 0.680s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29208, val loss: 0.29090, in 0.661s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23534, val loss: 0.23487, in 0.638s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02954, val loss: 0.02989, in 0.630s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24770, val loss: 0.24686, in 0.648s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03023, val loss: 0.03064, in 0.679s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02879, val loss: 0.02857, in 0.592s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26818, val loss: 0.26678, in 0.477s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27998, val loss: 0.27873, in 0.466s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02842, val loss: 0.02785, in 0.494s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22642, val loss: 0.22590, in 0.474s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02915, val loss: 0.02952, in 0.498s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02964, val loss: 0.03006, in 0.501s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23858, val loss: 0.23769, in 0.520s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02826, val loss: 0.02805, in 0.628s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25773, val loss: 0.25636, in 0.676s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02793, val loss: 0.02737, in 0.666s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26898, val loss: 0.26775, in 0.741s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21827, val loss: 0.21772, in 0.757s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02923, val loss: 0.02967, in 0.797s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22955, val loss: 0.22859, in 0.802s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02859, val loss: 0.02896, in 0.861s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02781, val loss: 0.02761, in 0.863s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24800, val loss: 0.24655, in 0.734s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02756, val loss: 0.02700, in 0.765s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25817, val loss: 0.25690, in 0.787s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21037, val loss: 0.20980, in 0.799s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02870, val loss: 0.02915, in 0.740s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22131, val loss: 0.22030, in 0.811s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02800, val loss: 0.02837, in 0.812s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02724, val loss: 0.02706, in 0.880s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23829, val loss: 0.23675, in 0.793s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02701, val loss: 0.02648, in 0.848s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24795, val loss: 0.24661, in 0.786s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20291, val loss: 0.20232, in 0.737s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02764, val loss: 0.02803, in 0.580s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02815, val loss: 0.02860, in 0.759s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21299, val loss: 0.21199, in 0.726s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02664, val loss: 0.02646, in 0.492s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02667, val loss: 0.02614, in 0.404s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22944, val loss: 0.22787, in 0.553s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23852, val loss: 0.23709, in 0.480s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19563, val loss: 0.19508, in 0.459s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02715, val loss: 0.02755, in 0.479s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20552, val loss: 0.20450, in 0.411s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02813, in 0.475s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02615, val loss: 0.02595, in 0.376s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02568, in 0.398s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22081, val loss: 0.21919, in 0.452s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22953, val loss: 0.22804, in 0.440s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18884, val loss: 0.18827, in 0.462s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02670, val loss: 0.02711, in 0.479s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02731, val loss: 0.02777, in 0.469s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19838, val loss: 0.19735, in 0.486s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02564, val loss: 0.02548, in 0.539s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02565, val loss: 0.02517, in 0.510s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21308, val loss: 0.21139, in 0.532s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22144, val loss: 0.21991, in 0.553s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18230, val loss: 0.18173, in 0.543s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02619, val loss: 0.02658, in 0.614s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19147, val loss: 0.19048, in 0.579s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02647, val loss: 0.02694, in 0.598s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02503, in 0.469s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02526, val loss: 0.02479, in 0.533s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20549, val loss: 0.20375, in 0.494s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21360, val loss: 0.21198, in 0.529s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17634, val loss: 0.17576, in 0.522s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02579, val loss: 0.02618, in 0.486s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02488, val loss: 0.02473, in 0.453s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18506, val loss: 0.18404, in 0.538s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02597, val loss: 0.02644, in 0.568s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02495, val loss: 0.02450, in 0.525s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19845, val loss: 0.19664, in 0.528s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20593, val loss: 0.20431, in 0.512s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17035, val loss: 0.16976, in 0.517s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02439, in 0.430s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02532, val loss: 0.02574, in 0.512s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17877, val loss: 0.17777, in 0.452s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02542, val loss: 0.02589, in 0.498s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02436, val loss: 0.02393, in 0.492s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19143, val loss: 0.18961, in 0.499s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19887, val loss: 0.19721, in 0.475s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16472, val loss: 0.16418, in 0.478s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02407, val loss: 0.02393, in 0.459s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17301, val loss: 0.17206, in 0.490s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02534, in 0.484s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02467, val loss: 0.02509, in 0.595s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02405, val loss: 0.02364, in 0.403s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18501, val loss: 0.18321, in 0.495s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19238, val loss: 0.19067, in 0.493s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02375, val loss: 0.02363, in 0.472s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15913, val loss: 0.15863, in 0.528s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16741, val loss: 0.16647, in 0.494s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02369, val loss: 0.02330, in 0.439s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02444, val loss: 0.02490, in 0.520s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02425, val loss: 0.02468, in 0.522s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17881, val loss: 0.17696, in 0.499s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02330, val loss: 0.02317, in 0.443s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18597, val loss: 0.18423, in 0.505s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15403, val loss: 0.15356, in 0.463s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16220, val loss: 0.16128, in 0.478s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02326, val loss: 0.02288, in 0.488s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02386, val loss: 0.02430, in 0.537s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02377, val loss: 0.02424, in 0.601s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17306, val loss: 0.17116, in 0.494s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02292, val loss: 0.02281, in 0.448s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17973, val loss: 0.17792, in 0.481s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14930, val loss: 0.14889, in 0.487s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15702, val loss: 0.15612, in 0.475s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02282, val loss: 0.02244, in 0.495s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02378, in 0.393s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02386, in 0.496s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02259, val loss: 0.02249, in 0.438s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16733, val loss: 0.16543, in 0.466s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17385, val loss: 0.17197, in 0.440s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14481, val loss: 0.14440, in 0.455s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15218, val loss: 0.15124, in 0.478s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02231, val loss: 0.02195, in 0.458s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02298, val loss: 0.02340, in 0.438s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02343, in 0.389s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16213, val loss: 0.16023, in 0.467s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02218, val loss: 0.02208, in 0.526s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16815, val loss: 0.16625, in 0.497s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14033, val loss: 0.13994, in 0.488s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14766, val loss: 0.14672, in 0.485s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02251, val loss: 0.02292, in 0.427s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02202, val loss: 0.02166, in 0.453s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02251, val loss: 0.02299, in 0.518s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15715, val loss: 0.15521, in 0.476s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02186, val loss: 0.02176, in 0.432s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16286, val loss: 0.16097, in 0.487s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13623, val loss: 0.13584, in 0.472s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14311, val loss: 0.14219, in 0.457s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02213, val loss: 0.02254, in 0.463s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02169, val loss: 0.02134, in 0.504s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02150, in 0.434s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02211, val loss: 0.02259, in 0.524s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15224, val loss: 0.15027, in 0.494s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15779, val loss: 0.15589, in 0.472s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13226, val loss: 0.13188, in 0.462s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13884, val loss: 0.13791, in 0.466s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02132, val loss: 0.02097, in 0.421s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02176, val loss: 0.02217, in 0.503s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02218, in 0.438s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02118, val loss: 0.02110, in 0.468s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14752, val loss: 0.14556, in 0.538s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15291, val loss: 0.15102, in 0.542s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12851, val loss: 0.12815, in 0.509s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02098, val loss: 0.02062, in 0.463s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02172, in 0.454s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13470, val loss: 0.13379, in 0.539s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02084, val loss: 0.02077, in 0.451s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02121, val loss: 0.02168, in 0.500s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14321, val loss: 0.14120, in 0.473s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14827, val loss: 0.14639, in 0.481s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12450, val loss: 0.12413, in 0.497s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02027, in 0.441s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02140, in 0.446s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13084, val loss: 0.12995, in 0.448s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02057, val loss: 0.02052, in 0.444s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02085, val loss: 0.02130, in 0.411s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13911, val loss: 0.13711, in 0.461s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02099, in 0.433s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14387, val loss: 0.14198, in 0.485s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12113, val loss: 0.12075, in 0.500s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02026, val loss: 0.01993, in 0.542s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12700, val loss: 0.12613, in 0.520s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02023, val loss: 0.02017, in 0.513s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.02081, in 0.524s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13489, val loss: 0.13288, in 0.498s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02028, val loss: 0.02069, in 0.479s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13954, val loss: 0.13767, in 0.476s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11806, val loss: 0.11769, in 0.460s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.01972, in 0.437s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12323, val loss: 0.12240, in 0.448s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01994, val loss: 0.01989, in 0.413s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02041, in 0.467s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13097, val loss: 0.12898, in 0.465s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01997, val loss: 0.02038, in 0.414s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13544, val loss: 0.13353, in 0.466s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11492, val loss: 0.11456, in 0.454s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01969, val loss: 0.01939, in 0.464s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11962, val loss: 0.11884, in 0.472s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01962, val loss: 0.02007, in 0.370s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.01963, in 0.451s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12719, val loss: 0.12518, in 0.481s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01967, val loss: 0.02007, in 0.507s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13161, val loss: 0.12968, in 0.489s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01938, val loss: 0.01908, in 0.445s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11181, val loss: 0.11148, in 0.502s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11628, val loss: 0.11553, in 0.511s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.01978, in 0.463s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01937, val loss: 0.01934, in 0.476s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01949, val loss: 0.01991, in 0.432s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12362, val loss: 0.12160, in 0.522s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12781, val loss: 0.12589, in 0.487s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10882, val loss: 0.10850, in 0.491s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01898, val loss: 0.01869, in 0.505s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11295, val loss: 0.11224, in 0.514s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01906, val loss: 0.01903, in 0.498s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01904, val loss: 0.01950, in 0.523s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01915, val loss: 0.01956, in 0.515s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11993, val loss: 0.11796, in 0.544s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01864, val loss: 0.01835, in 0.517s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12409, val loss: 0.12218, in 0.563s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10596, val loss: 0.10569, in 0.558s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01879, val loss: 0.01876, in 0.473s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01869, val loss: 0.01916, in 0.473s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10980, val loss: 0.10912, in 0.551s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01882, val loss: 0.01924, in 0.495s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11631, val loss: 0.11440, in 0.468s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.01811, in 0.443s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01864, val loss: 0.01862, in 0.366s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10317, val loss: 0.10293, in 0.464s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12050, val loss: 0.11862, in 0.508s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01840, val loss: 0.01885, in 0.506s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10679, val loss: 0.10612, in 0.476s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01847, val loss: 0.01887, in 0.396s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01784, in 0.420s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11318, val loss: 0.11130, in 0.455s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01841, val loss: 0.01840, in 0.459s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10064, val loss: 0.10039, in 0.444s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11686, val loss: 0.11503, in 0.467s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01809, val loss: 0.01855, in 0.486s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10387, val loss: 0.10329, in 0.492s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01820, val loss: 0.01861, in 0.463s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01761, in 0.464s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01822, in 0.389s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11004, val loss: 0.10818, in 0.559s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09831, val loss: 0.09808, in 0.520s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11359, val loss: 0.11179, in 0.522s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01822, in 0.431s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01788, val loss: 0.01828, in 0.416s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10086, val loss: 0.10031, in 0.526s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01789, in 0.413s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01726, in 0.519s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10697, val loss: 0.10518, in 0.525s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09573, val loss: 0.09553, in 0.546s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01745, val loss: 0.01790, in 0.488s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11044, val loss: 0.10870, in 0.521s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01763, val loss: 0.01803, in 0.467s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09795, val loss: 0.09741, in 0.553s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01768, val loss: 0.01768, in 0.465s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01728, val loss: 0.01701, in 0.407s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10394, val loss: 0.10217, in 0.472s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09346, val loss: 0.09326, in 0.446s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01715, val loss: 0.01761, in 0.439s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10741, val loss: 0.10568, in 0.492s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01735, val loss: 0.01775, in 0.465s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01743, val loss: 0.01743, in 0.402s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01674, in 0.418s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09528, val loss: 0.09474, in 0.480s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10120, val loss: 0.09947, in 0.448s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01691, val loss: 0.01739, in 0.410s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01724, val loss: 0.01765, in 0.324s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09093, val loss: 0.09075, in 0.451s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10425, val loss: 0.10259, in 0.461s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01651, in 0.369s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01712, val loss: 0.01713, in 0.458s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09258, val loss: 0.09204, in 0.442s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01655, val loss: 0.01703, in 0.423s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01741, in 0.416s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09820, val loss: 0.09651, in 0.468s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08852, val loss: 0.08837, in 0.452s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01686, val loss: 0.01686, in 0.377s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01627, in 0.451s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10124, val loss: 0.09964, in 0.498s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09014, val loss: 0.08957, in 0.496s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01711, in 0.394s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01629, val loss: 0.01676, in 0.436s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08634, val loss: 0.08621, in 0.464s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09543, val loss: 0.09371, in 0.513s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01658, val loss: 0.01660, in 0.482s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01623, val loss: 0.01597, in 0.444s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09826, val loss: 0.09668, in 0.444s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08781, val loss: 0.08721, in 0.431s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01644, val loss: 0.01683, in 0.399s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01606, val loss: 0.01653, in 0.428s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08414, val loss: 0.08399, in 0.492s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09321, val loss: 0.09150, in 0.463s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01639, val loss: 0.01642, in 0.410s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01574, in 0.446s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09553, val loss: 0.09400, in 0.479s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08553, val loss: 0.08492, in 0.474s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01617, val loss: 0.01656, in 0.471s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01622, in 0.420s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01618, val loss: 0.01620, in 0.401s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08203, val loss: 0.08186, in 0.457s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09057, val loss: 0.08889, in 0.461s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01550, in 0.421s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09290, val loss: 0.09140, in 0.474s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08335, val loss: 0.08274, in 0.462s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01634, in 0.409s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01599, in 0.513s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08829, val loss: 0.08663, in 0.493s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07973, val loss: 0.07959, in 0.517s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01589, val loss: 0.01591, in 0.583s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01549, val loss: 0.01526, in 0.538s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09052, val loss: 0.08902, in 0.508s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01568, val loss: 0.01608, in 0.459s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08121, val loss: 0.08061, in 0.485s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01572, in 0.613s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01509, in 0.487s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01567, in 0.545s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08585, val loss: 0.08420, in 0.591s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07751, val loss: 0.07742, in 0.580s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08799, val loss: 0.08654, in 0.572s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01541, val loss: 0.01580, in 0.580s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07912, val loss: 0.07850, in 0.600s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01549, in 0.497s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01489, in 0.409s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01544, in 0.366s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08371, val loss: 0.08206, in 0.471s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07541, val loss: 0.07532, in 0.480s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08572, val loss: 0.08428, in 0.496s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01557, in 0.514s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07707, val loss: 0.07644, in 0.500s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01526, in 0.368s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01495, val loss: 0.01473, in 0.373s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01520, val loss: 0.01521, in 0.421s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08156, val loss: 0.07990, in 0.463s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07344, val loss: 0.07337, in 0.497s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08368, val loss: 0.08228, in 0.471s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01499, val loss: 0.01540, in 0.414s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01463, val loss: 0.01509, in 0.381s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01474, val loss: 0.01454, in 0.399s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07511, val loss: 0.07450, in 0.464s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01494, val loss: 0.01496, in 0.459s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07951, val loss: 0.07792, in 0.513s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07156, val loss: 0.07148, in 0.494s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01443, val loss: 0.01487, in 0.403s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01434, in 0.423s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08138, val loss: 0.08002, in 0.494s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01521, in 0.484s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01476, val loss: 0.01480, in 0.412s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07352, val loss: 0.07293, in 0.496s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01511, in 0.356s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07762, val loss: 0.07603, in 0.480s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06999, val loss: 0.06994, in 0.495s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01420, val loss: 0.01464, in 0.476s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07956, val loss: 0.07820, in 0.492s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01411, in 0.521s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01450, in 0.482s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07151, val loss: 0.07098, in 0.528s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01448, val loss: 0.01488, in 0.385s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01442, in 0.384s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07563, val loss: 0.07407, in 0.482s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06822, val loss: 0.06818, in 0.485s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07744, val loss: 0.07613, in 0.481s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01390, in 0.475s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01428, in 0.481s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06966, val loss: 0.06913, in 0.485s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01387, val loss: 0.01432, in 0.403s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01467, in 0.451s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07401, val loss: 0.07246, in 0.481s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01378, in 0.363s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06652, val loss: 0.06648, in 0.519s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07575, val loss: 0.07447, in 0.476s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01404, val loss: 0.01441, in 0.325s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01367, val loss: 0.01411, in 0.356s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01405, in 0.513s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06816, val loss: 0.06764, in 0.464s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01380, val loss: 0.01360, in 0.336s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07217, val loss: 0.07064, in 0.467s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06498, val loss: 0.06492, in 0.475s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07394, val loss: 0.07268, in 0.485s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01385, val loss: 0.01423, in 0.436s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01346, val loss: 0.01390, in 0.422s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01381, in 0.430s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06653, val loss: 0.06606, in 0.443s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01359, val loss: 0.01340, in 0.478s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07060, val loss: 0.06912, in 0.508s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06364, val loss: 0.06356, in 0.472s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07230, val loss: 0.07103, in 0.454s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01372, in 0.415s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01362, val loss: 0.01400, in 0.488s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01364, in 0.460s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06521, val loss: 0.06472, in 0.475s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01339, val loss: 0.01321, in 0.412s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06895, val loss: 0.06750, in 0.446s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01314, val loss: 0.01356, in 0.371s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06213, val loss: 0.06204, in 0.442s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01346, in 0.396s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07040, val loss: 0.06916, in 0.473s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01342, val loss: 0.01380, in 0.466s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06372, val loss: 0.06321, in 0.456s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01323, val loss: 0.01305, in 0.443s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06751, val loss: 0.06605, in 0.480s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01339, in 0.481s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01323, in 0.421s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06050, val loss: 0.06046, in 0.517s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01357, in 0.411s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06863, val loss: 0.06743, in 0.482s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06219, val loss: 0.06176, in 0.488s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01306, val loss: 0.01290, in 0.437s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01271, val loss: 0.01313, in 0.402s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06589, val loss: 0.06444, in 0.433s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01300, val loss: 0.01337, in 0.352s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01302, in 0.451s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05920, val loss: 0.05919, in 0.424s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06716, val loss: 0.06597, in 0.411s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01292, val loss: 0.01277, in 0.338s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06068, val loss: 0.06026, in 0.430s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01289, val loss: 0.01327, in 0.382s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01295, in 0.505s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06431, val loss: 0.06286, in 0.507s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01280, val loss: 0.01288, in 0.448s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05789, val loss: 0.05788, in 0.512s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06560, val loss: 0.06444, in 0.515s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01258, in 0.506s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05941, val loss: 0.05899, in 0.478s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01271, val loss: 0.01308, in 0.390s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01281, in 0.343s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01232, val loss: 0.01274, in 0.417s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06292, val loss: 0.06148, in 0.450s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05652, val loss: 0.05652, in 0.471s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06400, val loss: 0.06286, in 0.482s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01241, in 0.448s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05803, val loss: 0.05768, in 0.546s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01251, val loss: 0.01288, in 0.462s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01258, in 0.439s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01252, val loss: 0.01260, in 0.542s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06139, val loss: 0.05998, in 0.529s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01239, val loss: 0.01226, in 0.431s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06259, val loss: 0.06145, in 0.508s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05517, val loss: 0.05517, in 0.536s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05673, val loss: 0.05640, in 0.514s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01202, val loss: 0.01242, in 0.401s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01233, val loss: 0.01270, in 0.518s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01234, val loss: 0.01242, in 0.407s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05997, val loss: 0.05859, in 0.408s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01222, val loss: 0.01209, in 0.393s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06118, val loss: 0.06006, in 0.459s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05400, val loss: 0.05399, in 0.461s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01220, val loss: 0.01257, in 0.377s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01224, in 0.404s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01230, in 0.362s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05545, val loss: 0.05517, in 0.429s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05869, val loss: 0.05732, in 0.451s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01191, in 0.483s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05990, val loss: 0.05879, in 0.475s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05271, val loss: 0.05266, in 0.496s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01166, val loss: 0.01208, in 0.444s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01206, val loss: 0.01215, in 0.444s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01202, val loss: 0.01239, in 0.506s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05441, val loss: 0.05413, in 0.518s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01190, val loss: 0.01178, in 0.449s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05758, val loss: 0.05624, in 0.537s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01152, val loss: 0.01192, in 0.401s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01187, val loss: 0.01195, in 0.388s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05173, val loss: 0.05167, in 0.457s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05862, val loss: 0.05754, in 0.489s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01191, val loss: 0.01229, in 0.365s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01181, val loss: 0.01169, in 0.301s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05321, val loss: 0.05293, in 0.467s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05626, val loss: 0.05494, in 0.417s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01212, in 0.339s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01177, in 0.373s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01174, val loss: 0.01183, in 0.376s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05064, val loss: 0.05059, in 0.424s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05733, val loss: 0.05623, in 0.424s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01166, val loss: 0.01155, in 0.368s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05214, val loss: 0.05187, in 0.430s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05504, val loss: 0.05376, in 0.477s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01161, val loss: 0.01197, in 0.424s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01121, val loss: 0.01162, in 0.418s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01167, in 0.447s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05607, val loss: 0.05502, in 0.475s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04959, val loss: 0.04954, in 0.484s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01149, val loss: 0.01138, in 0.488s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05104, val loss: 0.05080, in 0.516s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01145, val loss: 0.01180, in 0.402s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01149, in 0.458s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05378, val loss: 0.05251, in 0.564s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01147, in 0.544s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01127, in 0.505s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05485, val loss: 0.05381, in 0.595s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04847, val loss: 0.04845, in 0.595s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05006, val loss: 0.04984, in 0.496s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01096, val loss: 0.01136, in 0.380s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01130, val loss: 0.01166, in 0.448s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01127, val loss: 0.01136, in 0.361s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05266, val loss: 0.05141, in 0.434s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01115, in 0.358s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04746, val loss: 0.04743, in 0.422s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05377, val loss: 0.05272, in 0.430s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04915, val loss: 0.04898, in 0.439s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01114, val loss: 0.01124, in 0.331s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01120, in 0.441s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01150, in 0.456s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05157, val loss: 0.05034, in 0.415s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01111, val loss: 0.01101, in 0.385s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04653, val loss: 0.04650, in 0.442s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05273, val loss: 0.05170, in 0.467s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01106, in 0.366s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01099, val loss: 0.01134, in 0.353s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04822, val loss: 0.04805, in 0.447s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01097, val loss: 0.01109, in 0.467s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05059, val loss: 0.04937, in 0.412s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01094, val loss: 0.01085, in 0.464s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04549, val loss: 0.04549, in 0.385s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01086, val loss: 0.01122, in 0.362s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05169, val loss: 0.05067, in 0.420s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01055, val loss: 0.01094, in 0.409s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04731, val loss: 0.04713, in 0.428s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01094, in 0.451s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04960, val loss: 0.04838, in 0.440s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01078, val loss: 0.01070, in 0.402s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04463, val loss: 0.04464, in 0.371s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01075, val loss: 0.01109, in 0.338s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05067, val loss: 0.04968, in 0.350s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01079, in 0.397s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04645, val loss: 0.04628, in 0.371s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01071, val loss: 0.01084, in 0.320s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04869, val loss: 0.04749, in 0.378s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04386, val loss: 0.04389, in 0.363s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01056, in 0.416s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01059, val loss: 0.01095, in 0.449s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01069, in 0.355s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04957, val loss: 0.04861, in 0.437s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04541, val loss: 0.04527, in 0.446s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01056, val loss: 0.01069, in 0.441s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01048, in 0.294s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04770, val loss: 0.04650, in 0.407s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04308, val loss: 0.04313, in 0.389s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01020, val loss: 0.01057, in 0.303s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01049, val loss: 0.01084, in 0.346s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04860, val loss: 0.04764, in 0.413s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04441, val loss: 0.04428, in 0.398s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01055, in 0.426s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01044, val loss: 0.01036, in 0.345s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04232, val loss: 0.04239, in 0.339s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01043, in 0.339s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04661, val loss: 0.04545, in 0.408s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01077, in 0.324s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04771, val loss: 0.04675, in 0.420s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04354, val loss: 0.04343, in 0.393s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01041, in 0.407s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04145, val loss: 0.04154, in 0.348s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01024, in 0.407s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01061, in 0.329s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01033, in 0.397s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04574, val loss: 0.04457, in 0.414s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04682, val loss: 0.04588, in 0.405s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01019, val loss: 0.01034, in 0.307s\n",
      "[176/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01019, in 0.310s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04275, val loss: 0.04264, in 0.409s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04078, val loss: 0.04089, in 0.363s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01014, val loss: 0.01049, in 0.352s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.01021, in 0.394s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04454, val loss: 0.04340, in 0.392s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01009, in 0.355s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01006, val loss: 0.01022, in 0.384s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04586, val loss: 0.04497, in 0.420s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03999, val loss: 0.04012, in 0.350s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00999, val loss: 0.01036, in 0.392s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04203, val loss: 0.04192, in 0.415s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04365, val loss: 0.04255, in 0.383s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.01008, in 0.416s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00996, val loss: 0.01013, in 0.323s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01002, val loss: 0.00997, in 0.361s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04505, val loss: 0.04419, in 0.400s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03928, val loss: 0.03942, in 0.408s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04121, val loss: 0.04113, in 0.401s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00986, val loss: 0.01022, in 0.457s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00958, val loss: 0.00997, in 0.363s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04272, val loss: 0.04164, in 0.414s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00990, in 0.332s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.00999, in 0.426s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04413, val loss: 0.04329, in 0.352s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03862, val loss: 0.03876, in 0.372s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04038, val loss: 0.04034, in 0.334s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00974, val loss: 0.01009, in 0.316s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04197, val loss: 0.04091, in 0.402s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00982, in 0.441s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00983, val loss: 0.00978, in 0.333s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04326, val loss: 0.04244, in 0.376s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00965, val loss: 0.00982, in 0.409s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03760, val loss: 0.03775, in 0.387s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03963, val loss: 0.03959, in 0.413s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00962, val loss: 0.00998, in 0.413s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.00972, in 0.329s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00971, val loss: 0.00966, in 0.362s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04091, val loss: 0.03986, in 0.389s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04252, val loss: 0.04171, in 0.360s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00971, in 0.368s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03700, val loss: 0.03715, in 0.346s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03894, val loss: 0.03894, in 0.350s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00985, in 0.413s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00965, val loss: 0.00960, in 0.317s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00962, in 0.379s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04030, val loss: 0.03925, in 0.341s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00948, val loss: 0.00966, in 0.312s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04176, val loss: 0.04098, in 0.361s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03616, val loss: 0.03631, in 0.336s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03815, val loss: 0.03816, in 0.320s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00936, val loss: 0.00972, in 0.371s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00949, in 0.358s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03949, val loss: 0.03847, in 0.364s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00913, val loss: 0.00952, in 0.410s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00939, val loss: 0.00958, in 0.414s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04105, val loss: 0.04029, in 0.450s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03745, val loss: 0.03746, in 0.450s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03510, in 0.504s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00963, in 0.368s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03854, val loss: 0.03752, in 0.395s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00938, in 0.453s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00942, in 0.405s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00945, in 0.400s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04030, val loss: 0.03956, in 0.350s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03668, val loss: 0.03671, in 0.408s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03438, val loss: 0.03453, in 0.403s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00914, val loss: 0.00951, in 0.400s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00930, val loss: 0.00926, in 0.379s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03789, val loss: 0.03691, in 0.417s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00933, in 0.409s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03930, val loss: 0.03855, in 0.413s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00916, val loss: 0.00935, in 0.435s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03602, val loss: 0.03607, in 0.388s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00903, val loss: 0.00940, in 0.399s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03701, val loss: 0.03604, in 0.335s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03327, val loss: 0.03342, in 0.448s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00919, val loss: 0.00916, in 0.375s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00882, val loss: 0.00920, in 0.345s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03842, val loss: 0.03769, in 0.326s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00923, in 0.352s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03511, val loss: 0.03517, in 0.340s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00894, val loss: 0.00932, in 0.319s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00909, val loss: 0.00906, in 0.326s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00908, in 0.328s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03618, val loss: 0.03523, in 0.374s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03223, val loss: 0.03239, in 0.376s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03774, val loss: 0.03704, in 0.390s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00910, in 0.368s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03425, val loss: 0.03432, in 0.352s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00895, in 0.375s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00901, in 0.372s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00883, val loss: 0.00920, in 0.443s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03555, val loss: 0.03464, in 0.433s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03171, in 0.447s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03713, val loss: 0.03646, in 0.359s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00898, in 0.455s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03368, val loss: 0.03375, in 0.421s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00889, in 0.344s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00909, in 0.350s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00892, in 0.445s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03492, val loss: 0.03401, in 0.394s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03074, in 0.466s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.03625, val loss: 0.03561, in 0.470s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00867, val loss: 0.00887, in 0.409s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00877, val loss: 0.00876, in 0.396s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03293, val loss: 0.03302, in 0.431s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00894, in 0.404s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00882, in 0.350s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03413, val loss: 0.03325, in 0.418s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02996, val loss: 0.03016, in 0.375s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03559, val loss: 0.03495, in 0.391s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00867, val loss: 0.00866, in 0.321s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00884, in 0.368s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00875, in 0.430s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03240, in 0.415s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00875, in 0.385s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03334, val loss: 0.03249, in 0.404s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02916, val loss: 0.02938, in 0.439s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00859, val loss: 0.00859, in 0.349s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03476, val loss: 0.03413, in 0.368s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00833, val loss: 0.00868, in 0.305s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00874, in 0.360s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03158, val loss: 0.03171, in 0.342s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00848, val loss: 0.00868, in 0.356s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03273, val loss: 0.03188, in 0.422s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00853, in 0.380s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02876, in 0.428s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00862, in 0.330s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03419, val loss: 0.03355, in 0.408s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00860, in 0.381s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03109, val loss: 0.03122, in 0.393s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00864, in 0.448s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03217, val loss: 0.03134, in 0.369s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00854, in 0.403s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03366, val loss: 0.03302, in 0.400s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02780, val loss: 0.02805, in 0.444s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00832, val loss: 0.00852, in 0.373s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00841, val loss: 0.00843, in 0.473s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03067, in 0.389s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00815, val loss: 0.00853, in 0.397s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03070, in 0.498s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00849, in 0.411s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00846, in 0.384s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03318, val loss: 0.03256, in 0.429s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02712, val loss: 0.02738, in 0.483s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00832, in 0.493s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00845, in 0.423s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02993, val loss: 0.03007, in 0.496s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.03014, in 0.430s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03275, val loss: 0.03214, in 0.356s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00837, in 0.389s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00828, in 0.313s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00816, val loss: 0.00837, in 0.461s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02671, val loss: 0.02697, in 0.390s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00797, val loss: 0.00837, in 0.358s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02940, val loss: 0.02956, in 0.404s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03025, val loss: 0.02948, in 0.402s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00820, in 0.385s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00792, val loss: 0.00829, in 0.446s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03220, val loss: 0.03160, in 0.459s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00830, in 0.397s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00829, in 0.439s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02892, val loss: 0.02908, in 0.403s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02643, in 0.486s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00812, in 0.396s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.02912, in 0.436s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00785, val loss: 0.00821, in 0.416s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03165, val loss: 0.03106, in 0.416s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00820, in 0.371s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02576, val loss: 0.02601, in 0.410s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00817, in 0.500s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.02861, in 0.473s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00812, in 0.392s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02831, in 0.491s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03119, val loss: 0.03060, in 0.477s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00812, in 0.480s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02538, in 0.493s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02798, val loss: 0.02815, in 0.460s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00784, val loss: 0.00805, in 0.531s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00770, val loss: 0.00806, in 0.419s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00802, in 0.484s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03056, val loss: 0.02999, in 0.489s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02780, in 0.548s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02468, val loss: 0.02495, in 0.474s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02746, val loss: 0.02763, in 0.503s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00775, val loss: 0.00797, in 0.456s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00796, in 0.503s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03008, val loss: 0.02953, in 0.402s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02801, val loss: 0.02728, in 0.466s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02470, in 0.406s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02661, val loss: 0.02679, in 0.523s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00765, val loss: 0.00786, in 0.523s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00789, in 0.391s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.02914, in 0.393s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02750, val loss: 0.02678, in 0.444s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02397, val loss: 0.02423, in 0.490s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00779, in 0.482s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02925, val loss: 0.02871, in 0.454s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02610, val loss: 0.02628, in 0.570s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02683, val loss: 0.02613, in 0.727s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02347, val loss: 0.02372, in 0.687s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02868, val loss: 0.02816, in 0.650s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02532, val loss: 0.02550, in 0.688s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02320, val loss: 0.02346, in 0.430s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02638, val loss: 0.02568, in 0.513s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02829, val loss: 0.02778, in 0.470s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02494, val loss: 0.02513, in 0.491s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02280, val loss: 0.02307, in 0.444s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02612, val loss: 0.02542, in 0.420s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02791, val loss: 0.02741, in 0.451s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02447, val loss: 0.02468, in 0.485s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02568, val loss: 0.02500, in 0.430s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02230, val loss: 0.02256, in 0.505s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02739, val loss: 0.02692, in 0.488s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02424, val loss: 0.02446, in 0.398s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02525, val loss: 0.02459, in 0.400s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02191, val loss: 0.02218, in 0.453s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02671, val loss: 0.02624, in 0.523s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02354, val loss: 0.02376, in 0.528s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02416, in 0.507s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02147, val loss: 0.02171, in 0.419s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02307, val loss: 0.02328, in 0.426s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02617, val loss: 0.02571, in 0.546s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02434, val loss: 0.02372, in 0.463s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02104, val loss: 0.02128, in 0.583s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02561, val loss: 0.02516, in 0.391s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02268, val loss: 0.02291, in 0.495s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02399, val loss: 0.02339, in 0.406s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02063, val loss: 0.02086, in 0.363s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02225, val loss: 0.02246, in 0.399s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02476, in 0.423s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02338, val loss: 0.02279, in 0.458s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.02054, in 0.398s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02472, val loss: 0.02428, in 0.408s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02183, val loss: 0.02205, in 0.441s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02297, val loss: 0.02240, in 0.524s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01993, val loss: 0.02015, in 0.549s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02123, val loss: 0.02146, in 0.489s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02432, val loss: 0.02389, in 0.522s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02240, val loss: 0.02184, in 0.432s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01956, val loss: 0.01976, in 0.427s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02111, in 0.480s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02196, val loss: 0.02141, in 0.439s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02371, val loss: 0.02329, in 0.545s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01944, in 0.435s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02050, val loss: 0.02073, in 0.506s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02145, val loss: 0.02092, in 0.521s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.01913, in 0.460s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00798, val loss: 0.00802, in 0.537s\n",
      "Fit 200 trees in 109.079 s, (6199 total leaves)\n",
      "Time spent computing histograms: 64.394s\n",
      "Time spent finding best splits:  2.071s\n",
      "Time spent applying splits:      13.030s\n",
      "Time spent predicting:           0.818s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02323, val loss: 0.02283, in 0.538s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02013, val loss: 0.02034, in 0.441s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01865, val loss: 0.01889, in 0.460s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02117, val loss: 0.02064, in 0.493s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02287, val loss: 0.02247, in 0.524s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01980, val loss: 0.02003, in 0.463s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02075, val loss: 0.02025, in 0.414s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01838, val loss: 0.01862, in 0.457s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02207, in 0.371s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00794, in 0.483s\n",
      "Fit 200 trees in 109.360 s, (6200 total leaves)\n",
      "Time spent computing histograms: 65.405s\n",
      "Time spent finding best splits:  1.941s\n",
      "Time spent applying splits:      12.834s\n",
      "Time spent predicting:           0.784s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01944, val loss: 0.01967, in 0.403s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01830, in 0.454s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.01987, in 0.468s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02205, val loss: 0.02167, in 0.456s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01936, in 0.466s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00778, in 0.574s\n",
      "Fit 200 trees in 110.135 s, (6200 total leaves)\n",
      "Time spent computing histograms: 65.917s\n",
      "Time spent finding best splits:  2.015s\n",
      "Time spent applying splits:      13.205s\n",
      "Time spent predicting:           0.785s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02008, val loss: 0.01960, in 0.535s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01779, val loss: 0.01804, in 0.565s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02152, val loss: 0.02116, in 0.668s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01882, val loss: 0.01905, in 0.616s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00735, val loss: 0.00771, in 0.641s\n",
      "Fit 200 trees in 109.551 s, (6200 total leaves)\n",
      "Time spent computing histograms: 65.224s\n",
      "Time spent finding best splits:  1.842s\n",
      "Time spent applying splits:      12.727s\n",
      "Time spent predicting:           1.006s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01760, val loss: 0.01785, in 0.466s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.01920, in 0.553s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02123, val loss: 0.02086, in 0.497s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01735, val loss: 0.01760, in 0.464s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01873, in 0.580s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01928, val loss: 0.01883, in 0.508s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02052, in 0.477s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01734, in 0.480s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01813, val loss: 0.01837, in 0.505s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01892, val loss: 0.01848, in 0.473s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02026, in 0.499s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01786, val loss: 0.01810, in 0.430s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01682, val loss: 0.01709, in 0.490s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01858, val loss: 0.01816, in 0.530s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01994, in 0.483s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01785, in 0.608s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01680, in 0.582s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01825, val loss: 0.01784, in 0.496s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01995, val loss: 0.01961, in 0.580s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01627, val loss: 0.01654, in 0.476s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01755, in 0.547s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01788, val loss: 0.01749, in 0.508s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01962, val loss: 0.01929, in 0.446s\n",
      "[131/200] 5.289 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01602, val loss: 0.01630, in 0.483s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01724, in 0.491s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01731, in 0.562s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01901, in 0.502s\n",
      "[132/200] 0.232 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01577, val loss: 0.01605, in 0.503s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01676, val loss: 0.01702, in 0.461s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01694, in 0.554s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65078, val loss: 0.65071, in 0.447s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01898, val loss: 0.01869, in 0.532s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01555, val loss: 0.01583, in 0.499s\n",
      "[139/200] 5.346 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01682, in 0.470s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01664, in 0.503s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61245, val loss: 0.61226, in 0.565s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01865, val loss: 0.01837, in 0.610s\n",
      "[134/200] 0.213 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01565, in 0.491s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01654, in 0.520s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01675, val loss: 0.01642, in 0.493s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01833, val loss: 0.01804, in 0.434s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57753, val loss: 0.57729, in 0.504s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65062, in 0.471s\n",
      "[2/200] 5.388 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01539, in 0.484s\n",
      "[141/200] 0.210 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 5.197 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01604, val loss: 0.01631, in 0.603s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01811, val loss: 0.01783, in 0.501s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01642, val loss: 0.01610, in 0.591s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54564, val loss: 0.54532, in 0.495s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61231, val loss: 0.61209, in 0.541s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01488, val loss: 0.01516, in 0.445s\n",
      "[142/200] 0.216 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65068, val loss: 0.65055, in 0.460s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01577, val loss: 0.01602, in 0.405s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01793, val loss: 0.01766, in 0.428s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51626, val loss: 0.51583, in 0.462s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01613, val loss: 0.01582, in 0.538s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57730, val loss: 0.57692, in 0.501s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01468, val loss: 0.01495, in 0.448s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65076, val loss: 0.65069, in 0.511s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01551, val loss: 0.01577, in 0.488s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61223, val loss: 0.61202, in 0.547s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01765, val loss: 0.01740, in 0.441s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48916, val loss: 0.48868, in 0.502s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01585, val loss: 0.01554, in 0.457s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54539, val loss: 0.54492, in 0.469s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01439, val loss: 0.01467, in 0.507s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61233, val loss: 0.61221, in 0.492s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01558, in 0.438s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01739, val loss: 0.01714, in 0.444s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57719, val loss: 0.57685, in 0.482s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01563, val loss: 0.01534, in 0.428s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46407, val loss: 0.46353, in 0.469s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51612, val loss: 0.51553, in 0.456s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01417, val loss: 0.01445, in 0.510s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57744, val loss: 0.57721, in 0.439s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01505, val loss: 0.01531, in 0.496s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54524, val loss: 0.54482, in 0.491s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01517, in 0.429s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01713, val loss: 0.01688, in 0.542s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44096, val loss: 0.44033, in 0.476s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48906, val loss: 0.48841, in 0.509s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01424, in 0.518s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54557, val loss: 0.54531, in 0.488s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51600, val loss: 0.51550, in 0.460s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01679, val loss: 0.01656, in 0.476s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01513, in 0.549s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01495, in 0.496s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41953, val loss: 0.41885, in 0.468s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46390, val loss: 0.46310, in 0.450s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01402, in 0.445s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51624, val loss: 0.51596, in 0.450s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01469, val loss: 0.01496, in 0.433s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48886, val loss: 0.48824, in 0.481s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01631, in 0.560s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39969, val loss: 0.39893, in 0.508s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01499, val loss: 0.01472, in 0.574s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44080, val loss: 0.43989, in 0.483s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01361, val loss: 0.01390, in 0.453s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48915, val loss: 0.48884, in 0.481s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01474, in 0.427s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46372, val loss: 0.46303, in 0.444s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01625, val loss: 0.01603, in 0.395s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38109, val loss: 0.38027, in 0.448s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01482, val loss: 0.01455, in 0.437s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41926, val loss: 0.41827, in 0.437s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01335, val loss: 0.01364, in 0.449s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46398, val loss: 0.46361, in 0.438s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44063, val loss: 0.43988, in 0.493s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01427, val loss: 0.01456, in 0.539s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01598, val loss: 0.01576, in 0.482s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01458, val loss: 0.01432, in 0.435s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36383, val loss: 0.36293, in 0.486s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39944, val loss: 0.39832, in 0.467s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01344, in 0.403s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44074, val loss: 0.44031, in 0.459s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01435, in 0.394s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41914, val loss: 0.41830, in 0.440s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01436, val loss: 0.01412, in 0.458s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34761, val loss: 0.34669, in 0.430s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01545, in 0.505s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38084, val loss: 0.37965, in 0.441s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01294, val loss: 0.01322, in 0.509s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41919, val loss: 0.41873, in 0.476s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01390, val loss: 0.01418, in 0.473s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39924, val loss: 0.39832, in 0.498s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01413, val loss: 0.01389, in 0.433s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01517, in 0.464s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33232, val loss: 0.33132, in 0.515s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36354, val loss: 0.36225, in 0.501s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01298, in 0.520s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39930, val loss: 0.39878, in 0.496s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38071, val loss: 0.37971, in 0.491s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01393, val loss: 0.01369, in 0.471s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01398, in 0.558s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01493, in 0.486s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31819, val loss: 0.31715, in 0.474s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34726, val loss: 0.34592, in 0.492s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01254, val loss: 0.01283, in 0.503s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38064, val loss: 0.38008, in 0.525s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36340, val loss: 0.36234, in 0.518s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01376, val loss: 0.01353, in 0.520s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01352, val loss: 0.01381, in 0.513s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01481, val loss: 0.01465, in 0.556s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.30474, val loss: 0.30367, in 0.528s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.33214, val loss: 0.33070, in 0.521s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01271, in 0.466s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36334, val loss: 0.36268, in 0.528s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01338, in 0.467s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34714, val loss: 0.34599, in 0.487s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01330, val loss: 0.01360, in 0.556s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29217, val loss: 0.29108, in 0.510s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01459, val loss: 0.01443, in 0.555s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.31801, val loss: 0.31650, in 0.509s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01253, in 0.507s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34718, val loss: 0.34646, in 0.485s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33178, val loss: 0.33057, in 0.539s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01312, val loss: 0.01340, in 0.478s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01337, val loss: 0.01315, in 0.637s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.28004, val loss: 0.27892, in 0.535s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01209, val loss: 0.01236, in 0.449s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30471, val loss: 0.30312, in 0.543s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01435, val loss: 0.01418, in 0.578s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33193, val loss: 0.33118, in 0.489s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01326, in 0.451s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31751, val loss: 0.31625, in 0.483s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01318, val loss: 0.01297, in 0.524s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26876, val loss: 0.26762, in 0.508s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29197, val loss: 0.29034, in 0.498s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01188, val loss: 0.01216, in 0.555s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01395, in 0.521s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.31754, val loss: 0.31678, in 0.509s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01278, val loss: 0.01308, in 0.491s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30407, val loss: 0.30272, in 0.503s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01279, in 0.492s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25798, val loss: 0.25683, in 0.515s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.28003, val loss: 0.27834, in 0.476s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01203, in 0.437s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01392, val loss: 0.01379, in 0.461s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30392, val loss: 0.30311, in 0.496s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29149, val loss: 0.29007, in 0.490s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01256, val loss: 0.01287, in 0.534s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01265, in 0.474s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01362, in 0.417s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01191, in 0.457s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24822, val loss: 0.24694, in 0.476s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26878, val loss: 0.26699, in 0.511s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29127, val loss: 0.29043, in 0.448s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01267, in 0.474s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27972, val loss: 0.27824, in 0.495s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01267, val loss: 0.01248, in 0.475s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01339, in 0.497s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23891, val loss: 0.23760, in 0.492s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25833, val loss: 0.25649, in 0.475s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01150, val loss: 0.01178, in 0.525s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27912, val loss: 0.27823, in 0.483s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01251, in 0.471s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.26817, val loss: 0.26670, in 0.591s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01163, in 0.521s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01245, val loss: 0.01228, in 0.639s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24848, val loss: 0.24653, in 0.583s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23031, val loss: 0.22892, in 0.604s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01332, val loss: 0.01321, in 0.640s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26800, val loss: 0.26705, in 0.575s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01210, val loss: 0.01240, in 0.470s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25764, val loss: 0.25612, in 0.443s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01230, val loss: 0.01212, in 0.358s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01147, in 0.383s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01307, in 0.375s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22184, val loss: 0.22046, in 0.436s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23882, val loss: 0.23675, in 0.440s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25735, val loss: 0.25638, in 0.418s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01219, in 0.393s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01108, val loss: 0.01134, in 0.337s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24747, val loss: 0.24589, in 0.409s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01194, in 0.447s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01286, in 0.373s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21393, val loss: 0.21253, in 0.375s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23015, val loss: 0.22805, in 0.383s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24748, val loss: 0.24641, in 0.381s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01173, val loss: 0.01204, in 0.437s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23825, val loss: 0.23659, in 0.398s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01193, val loss: 0.01175, in 0.372s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01115, in 0.479s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01273, val loss: 0.01265, in 0.415s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20645, val loss: 0.20501, in 0.409s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22154, val loss: 0.21943, in 0.428s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23805, val loss: 0.23695, in 0.373s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01188, in 0.305s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22939, val loss: 0.22769, in 0.354s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01100, in 0.354s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01158, in 0.378s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01257, val loss: 0.01249, in 0.325s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19969, val loss: 0.19821, in 0.323s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21346, val loss: 0.21135, in 0.326s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22927, val loss: 0.22807, in 0.364s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01139, val loss: 0.01169, in 0.343s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22122, val loss: 0.21948, in 0.358s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01145, in 0.343s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01240, val loss: 0.01231, in 0.363s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01059, val loss: 0.01087, in 0.376s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19290, val loss: 0.19141, in 0.404s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20605, val loss: 0.20390, in 0.373s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22112, val loss: 0.21986, in 0.364s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01154, in 0.372s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21329, val loss: 0.21148, in 0.354s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01133, in 0.298s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01217, in 0.342s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01069, in 0.343s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19892, val loss: 0.19671, in 0.338s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18621, val loss: 0.18469, in 0.349s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21317, val loss: 0.21189, in 0.334s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01141, in 0.349s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01135, val loss: 0.01118, in 0.267s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20565, val loss: 0.20379, in 0.320s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01059, in 0.307s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01205, val loss: 0.01199, in 0.344s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19199, val loss: 0.18979, in 0.319s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17983, val loss: 0.17832, in 0.327s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20581, val loss: 0.20447, in 0.297s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01095, val loss: 0.01124, in 0.285s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01103, in 0.302s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19831, val loss: 0.19649, in 0.315s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01182, in 0.263s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01019, val loss: 0.01047, in 0.314s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18547, val loss: 0.18328, in 0.310s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17394, val loss: 0.17246, in 0.335s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19852, val loss: 0.19722, in 0.368s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01078, val loss: 0.01107, in 0.402s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01104, val loss: 0.01087, in 0.383s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19140, val loss: 0.18956, in 0.350s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01032, in 0.311s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01176, val loss: 0.01168, in 0.331s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17922, val loss: 0.17707, in 0.369s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16843, val loss: 0.16693, in 0.341s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.19209, val loss: 0.19072, in 0.320s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01063, val loss: 0.01092, in 0.281s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01072, in 0.287s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01019, in 0.267s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18498, val loss: 0.18315, in 0.303s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01151, in 0.322s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16303, val loss: 0.16147, in 0.334s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17339, val loss: 0.17128, in 0.350s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01075, val loss: 0.01059, in 0.304s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18554, val loss: 0.18419, in 0.372s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01049, val loss: 0.01078, in 0.403s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01007, in 0.363s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17867, val loss: 0.17685, in 0.377s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01142, val loss: 0.01135, in 0.336s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15806, val loss: 0.15646, in 0.344s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16762, val loss: 0.16547, in 0.354s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17907, val loss: 0.17771, in 0.330s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01038, val loss: 0.01066, in 0.324s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01057, val loss: 0.01042, in 0.399s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01128, val loss: 0.01121, in 0.285s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.00994, in 0.337s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17272, val loss: 0.17090, in 0.325s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15303, val loss: 0.15143, in 0.335s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16221, val loss: 0.16002, in 0.330s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01053, in 0.285s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17318, val loss: 0.17183, in 0.335s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01113, val loss: 0.01108, in 0.357s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01027, in 0.375s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00979, in 0.363s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16704, val loss: 0.16516, in 0.351s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14854, val loss: 0.14692, in 0.335s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15724, val loss: 0.15504, in 0.329s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01012, val loss: 0.01039, in 0.317s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16765, val loss: 0.16628, in 0.321s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00971, in 0.289s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01015, in 0.324s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01099, val loss: 0.01095, in 0.341s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16165, val loss: 0.15976, in 0.321s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14412, val loss: 0.14244, in 0.352s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15243, val loss: 0.15021, in 0.357s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01001, val loss: 0.01028, in 0.349s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16239, val loss: 0.16099, in 0.352s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01083, in 0.289s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01004, in 0.296s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00932, val loss: 0.00958, in 0.357s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15665, val loss: 0.15475, in 0.346s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14778, val loss: 0.14548, in 0.298s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13988, val loss: 0.13817, in 0.309s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00989, val loss: 0.01016, in 0.290s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15749, val loss: 0.15610, in 0.300s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.00991, in 0.260s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01070, val loss: 0.01067, in 0.307s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00919, val loss: 0.00946, in 0.325s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15155, val loss: 0.14969, in 0.344s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.01004, in 0.301s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14354, val loss: 0.14124, in 0.370s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00982, in 0.328s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13548, val loss: 0.13379, in 0.375s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15269, val loss: 0.15130, in 0.375s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01055, in 0.333s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00908, val loss: 0.00934, in 0.366s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14692, val loss: 0.14503, in 0.349s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00972, val loss: 0.00998, in 0.276s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13897, val loss: 0.13668, in 0.326s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13154, val loss: 0.12978, in 0.343s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14798, val loss: 0.14664, in 0.328s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01040, val loss: 0.01039, in 0.324s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00980, val loss: 0.00967, in 0.374s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.00989, in 0.269s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14272, val loss: 0.14088, in 0.320s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00894, val loss: 0.00920, in 0.375s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01030, val loss: 0.01028, in 0.297s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13478, val loss: 0.13244, in 0.364s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00956, in 0.311s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12782, val loss: 0.12610, in 0.349s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14373, val loss: 0.14241, in 0.363s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00978, in 0.305s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00882, val loss: 0.00908, in 0.279s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13842, val loss: 0.13657, in 0.333s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00960, val loss: 0.00947, in 0.232s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01018, val loss: 0.01017, in 0.286s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13095, val loss: 0.12861, in 0.277s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12424, val loss: 0.12257, in 0.300s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13941, val loss: 0.13808, in 0.287s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00967, in 0.278s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.00898, in 0.272s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13421, val loss: 0.13240, in 0.295s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00945, val loss: 0.00933, in 0.368s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01006, val loss: 0.01007, in 0.379s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12715, val loss: 0.12483, in 0.410s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00937, val loss: 0.00962, in 0.331s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12071, val loss: 0.11902, in 0.419s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13539, val loss: 0.13405, in 0.402s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00863, val loss: 0.00890, in 0.376s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13029, val loss: 0.12841, in 0.444s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.00921, in 0.401s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12364, val loss: 0.12126, in 0.376s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00921, val loss: 0.00946, in 0.361s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00991, val loss: 0.00992, in 0.429s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11720, val loss: 0.11551, in 0.380s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00850, val loss: 0.00878, in 0.351s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13143, val loss: 0.13009, in 0.379s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12650, val loss: 0.12461, in 0.357s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00912, in 0.346s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00911, val loss: 0.00936, in 0.329s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12011, val loss: 0.11771, in 0.375s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00843, val loss: 0.00870, in 0.340s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00980, val loss: 0.00981, in 0.387s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11395, val loss: 0.11220, in 0.379s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12769, val loss: 0.12636, in 0.373s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12279, val loss: 0.12092, in 0.366s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00901, in 0.298s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00971, in 0.270s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00899, val loss: 0.00924, in 0.343s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11677, val loss: 0.11439, in 0.337s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00832, val loss: 0.00859, in 0.354s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11069, val loss: 0.10897, in 0.338s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12404, val loss: 0.12275, in 0.335s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00906, val loss: 0.00896, in 0.283s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11911, val loss: 0.11729, in 0.367s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00915, in 0.340s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00954, val loss: 0.00956, in 0.359s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11346, val loss: 0.11106, in 0.366s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12069, val loss: 0.11942, in 0.336s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00822, val loss: 0.00849, in 0.363s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10764, val loss: 0.10588, in 0.363s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00886, in 0.285s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11578, val loss: 0.11399, in 0.324s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00947, in 0.289s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00903, in 0.334s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11031, val loss: 0.10793, in 0.355s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00888, val loss: 0.00879, in 0.291s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11711, val loss: 0.11588, in 0.367s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10484, val loss: 0.10305, in 0.353s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00837, in 0.385s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11245, val loss: 0.11071, in 0.349s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.00938, in 0.347s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00867, val loss: 0.00891, in 0.380s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00833, in 0.250s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00871, in 0.316s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10738, val loss: 0.10504, in 0.357s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11373, val loss: 0.11255, in 0.343s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10172, val loss: 0.09997, in 0.354s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10934, val loss: 0.10762, in 0.337s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00929, in 0.264s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00797, val loss: 0.00825, in 0.312s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00883, in 0.318s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00866, val loss: 0.00858, in 0.346s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10468, val loss: 0.10232, in 0.335s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11063, val loss: 0.10947, in 0.331s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09884, val loss: 0.09709, in 0.342s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00917, val loss: 0.00922, in 0.334s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10634, val loss: 0.10462, in 0.394s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00786, val loss: 0.00814, in 0.370s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00854, val loss: 0.00846, in 0.333s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00849, val loss: 0.00873, in 0.391s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10187, val loss: 0.09953, in 0.393s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10762, val loss: 0.10646, in 0.388s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00917, in 0.269s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09608, val loss: 0.09434, in 0.399s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10366, val loss: 0.10194, in 0.334s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00779, val loss: 0.00808, in 0.308s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00840, val loss: 0.00864, in 0.347s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00842, val loss: 0.00834, in 0.395s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00902, val loss: 0.00907, in 0.324s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10468, val loss: 0.10353, in 0.341s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09899, val loss: 0.09672, in 0.360s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09378, val loss: 0.09210, in 0.358s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00777, val loss: 0.00805, in 0.278s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10066, val loss: 0.09895, in 0.383s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00849, in 0.353s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00822, in 0.366s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00893, val loss: 0.00899, in 0.366s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10189, val loss: 0.10078, in 0.411s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09625, val loss: 0.09401, in 0.432s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09102, val loss: 0.08937, in 0.403s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00768, val loss: 0.00797, in 0.327s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09815, val loss: 0.09643, in 0.361s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00824, val loss: 0.00816, in 0.302s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00814, val loss: 0.00838, in 0.387s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00884, val loss: 0.00889, in 0.329s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00759, val loss: 0.00786, in 0.301s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09897, val loss: 0.09789, in 0.373s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09365, val loss: 0.09140, in 0.359s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08865, val loss: 0.08705, in 0.360s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09552, val loss: 0.09384, in 0.369s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00805, in 0.345s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00829, in 0.315s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00880, in 0.340s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00749, val loss: 0.00776, in 0.341s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09140, val loss: 0.08920, in 0.342s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09610, val loss: 0.09507, in 0.353s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08648, val loss: 0.08478, in 0.340s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09297, val loss: 0.09131, in 0.336s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00824, in 0.247s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00794, in 0.293s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00865, val loss: 0.00871, in 0.268s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00770, in 0.251s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09343, val loss: 0.09246, in 0.311s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08903, val loss: 0.08686, in 0.321s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08430, val loss: 0.08265, in 0.322s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00789, val loss: 0.00812, in 0.299s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00864, in 0.255s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09073, val loss: 0.08909, in 0.326s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00793, val loss: 0.00786, in 0.288s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00733, val loss: 0.00760, in 0.386s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09108, val loss: 0.09004, in 0.366s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08664, val loss: 0.08451, in 0.392s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08211, val loss: 0.08051, in 0.375s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00779, val loss: 0.00803, in 0.369s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00774, in 0.350s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08838, val loss: 0.08678, in 0.371s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00847, val loss: 0.00854, in 0.380s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00754, in 0.255s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08854, val loss: 0.08756, in 0.354s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00793, in 0.295s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08013, val loss: 0.07857, in 0.364s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08426, val loss: 0.08211, in 0.375s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00765, in 0.374s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00837, val loss: 0.00844, in 0.361s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08600, val loss: 0.08440, in 0.387s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00747, in 0.336s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08611, val loss: 0.08515, in 0.369s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00829, val loss: 0.00836, in 0.303s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00760, val loss: 0.00782, in 0.414s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07810, val loss: 0.07657, in 0.382s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08214, val loss: 0.08008, in 0.383s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00755, in 0.367s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08380, val loss: 0.08224, in 0.374s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00737, in 0.345s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00755, val loss: 0.00778, in 0.287s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00821, val loss: 0.00827, in 0.299s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08394, val loss: 0.08303, in 0.391s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00749, in 0.293s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08008, val loss: 0.07805, in 0.376s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07617, val loss: 0.07461, in 0.399s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08160, val loss: 0.08002, in 0.395s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00810, val loss: 0.00817, in 0.306s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00742, in 0.283s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00768, in 0.372s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08182, val loss: 0.08095, in 0.331s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07432, val loss: 0.07278, in 0.340s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07814, val loss: 0.07613, in 0.362s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07971, val loss: 0.07808, in 0.350s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00741, val loss: 0.00736, in 0.366s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00808, in 0.405s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00761, in 0.368s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07969, val loss: 0.07878, in 0.399s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07617, val loss: 0.07420, in 0.413s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07256, val loss: 0.07104, in 0.417s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07778, val loss: 0.07620, in 0.413s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00734, val loss: 0.00729, in 0.341s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00791, val loss: 0.00799, in 0.427s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07778, val loss: 0.07692, in 0.442s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07418, val loss: 0.07226, in 0.469s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07087, val loss: 0.06939, in 0.470s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00724, in 0.353s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07581, val loss: 0.07430, in 0.459s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00785, val loss: 0.00793, in 0.375s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07603, val loss: 0.07519, in 0.426s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07236, val loss: 0.07048, in 0.411s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06920, val loss: 0.06772, in 0.421s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07400, val loss: 0.07252, in 0.404s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00773, val loss: 0.00781, in 0.454s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07409, val loss: 0.07324, in 0.415s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06779, val loss: 0.06638, in 0.417s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07068, val loss: 0.06880, in 0.498s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07214, val loss: 0.07072, in 0.487s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07251, val loss: 0.07168, in 0.489s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06609, val loss: 0.06472, in 0.480s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06900, val loss: 0.06721, in 0.437s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07040, val loss: 0.06904, in 0.443s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07067, val loss: 0.06987, in 0.453s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06455, val loss: 0.06319, in 0.432s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06750, val loss: 0.06571, in 0.423s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06879, val loss: 0.06748, in 0.434s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06897, val loss: 0.06819, in 0.433s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06298, val loss: 0.06171, in 0.498s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06584, val loss: 0.06411, in 0.493s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06740, val loss: 0.06608, in 0.459s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06731, val loss: 0.06656, in 0.517s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06174, val loss: 0.06046, in 0.477s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06263, in 0.503s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06576, val loss: 0.06448, in 0.480s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06566, val loss: 0.06493, in 0.358s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06029, val loss: 0.05909, in 0.352s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06290, val loss: 0.06124, in 0.322s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06305, in 0.339s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06400, val loss: 0.06331, in 0.377s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06166, val loss: 0.06003, in 0.350s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05903, val loss: 0.05785, in 0.370s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06276, val loss: 0.06152, in 0.367s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06258, val loss: 0.06190, in 0.372s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06021, val loss: 0.05866, in 0.419s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05768, val loss: 0.05655, in 0.412s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06157, val loss: 0.06039, in 0.406s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06101, val loss: 0.06038, in 0.404s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.05662, val loss: 0.05553, in 0.333s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05891, val loss: 0.05739, in 0.361s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06005, val loss: 0.05892, in 0.355s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05974, val loss: 0.05912, in 0.340s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05541, val loss: 0.05434, in 0.376s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05766, val loss: 0.05616, in 0.382s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05878, val loss: 0.05766, in 0.371s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00702, val loss: 0.00730, in 0.359s\n",
      "Fit 200 trees in 99.494 s, (6200 total leaves)\n",
      "Time spent computing histograms: 58.395s\n",
      "Time spent finding best splits:  1.749s\n",
      "Time spent applying splits:      11.974s\n",
      "Time spent predicting:           0.751s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05841, val loss: 0.05781, in 0.379s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05422, val loss: 0.05321, in 0.352s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05647, val loss: 0.05501, in 0.341s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05753, val loss: 0.05644, in 0.355s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05697, val loss: 0.05642, in 0.335s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05313, val loss: 0.05216, in 0.373s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05524, val loss: 0.05383, in 0.372s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05620, val loss: 0.05514, in 0.353s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05587, val loss: 0.05534, in 0.383s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05201, val loss: 0.05105, in 0.397s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05409, val loss: 0.05272, in 0.389s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05509, val loss: 0.05404, in 0.394s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00752, in 0.325s\n",
      "Fit 200 trees in 100.362 s, (6200 total leaves)\n",
      "Time spent computing histograms: 59.466s\n",
      "Time spent finding best splits:  1.742s\n",
      "Time spent applying splits:      11.324s\n",
      "Time spent predicting:           0.671s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05464, val loss: 0.05412, in 0.465s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05310, val loss: 0.05175, in 0.503s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05394, val loss: 0.05289, in 0.502s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05105, val loss: 0.05011, in 0.525s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05341, val loss: 0.05293, in 0.569s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05174, val loss: 0.05042, in 0.554s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05270, val loss: 0.05172, in 0.551s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05003, val loss: 0.04910, in 0.555s\n",
      "[80/200] 1 tree, 27 leaves, max depth = 10, train loss: 0.00724, val loss: 0.00720, in 0.289s\n",
      "Fit 200 trees in 99.676 s, (6196 total leaves)\n",
      "Time spent computing histograms: 58.210s\n",
      "Time spent finding best splits:  1.667s\n",
      "Time spent applying splits:      11.793s\n",
      "Time spent predicting:           0.861s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05226, val loss: 0.05179, in 0.527s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00767, val loss: 0.00775, in 0.410s\n",
      "Fit 200 trees in 98.586 s, (6200 total leaves)\n",
      "Time spent computing histograms: 58.896s\n",
      "Time spent finding best splits:  1.623s\n",
      "Time spent applying splits:      11.518s\n",
      "Time spent predicting:           0.732s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05075, val loss: 0.04944, in 0.498s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04902, val loss: 0.04812, in 0.499s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05158, val loss: 0.05063, in 0.512s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05122, val loss: 0.05077, in 0.424s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04982, val loss: 0.04854, in 0.414s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04815, val loss: 0.04726, in 0.409s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05066, val loss: 0.04971, in 0.447s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05023, val loss: 0.04978, in 0.446s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04871, val loss: 0.04744, in 0.458s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04723, val loss: 0.04634, in 0.472s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04965, val loss: 0.04872, in 0.468s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04930, val loss: 0.04883, in 0.427s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04783, val loss: 0.04657, in 0.410s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04637, val loss: 0.04547, in 0.443s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04872, val loss: 0.04780, in 0.414s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04841, val loss: 0.04796, in 0.446s\n",
      "[81/200] 4.166 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04680, val loss: 0.04555, in 0.445s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04559, val loss: 0.04470, in 0.414s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04785, val loss: 0.04695, in 0.406s\n",
      "[82/200] 0.135 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04740, val loss: 0.04697, in 0.379s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04602, val loss: 0.04479, in 0.429s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04486, val loss: 0.04397, in 0.411s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04681, val loss: 0.04590, in 0.436s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65067, val loss: 0.65063, in 0.406s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04647, val loss: 0.04604, in 0.473s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04370, val loss: 0.04285, in 0.366s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04506, val loss: 0.04384, in 0.451s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04597, val loss: 0.04509, in 0.424s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61224, val loss: 0.61216, in 0.382s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04568, val loss: 0.04523, in 0.390s\n",
      "[84/200] 4.330 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04203, in 0.429s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04390, val loss: 0.04272, in 0.363s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04502, val loss: 0.04415, in 0.448s\n",
      "[85/200] 0.172 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57734, val loss: 0.57721, in 0.375s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04469, val loss: 0.04426, in 0.401s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04173, in 0.336s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04191, val loss: 0.04109, in 0.394s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04420, val loss: 0.04334, in 0.372s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65070, val loss: 0.65064, in 0.364s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54541, val loss: 0.54526, in 0.361s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04382, val loss: 0.04338, in 0.412s\n",
      "[86/200] 4.178 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04206, val loss: 0.04095, in 0.426s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04114, val loss: 0.04032, in 0.441s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51609, val loss: 0.51589, in 0.354s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.61223, val loss: 0.61208, in 0.377s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04334, val loss: 0.04252, in 0.410s\n",
      "[87/200] 3.957 s\n",
      "Binning 0.012 GB of validation data: 0.146 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04227, in 0.373s\n",
      "[87/200] 0.154 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04011, val loss: 0.03933, in 0.424s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04129, val loss: 0.04018, in 0.493s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48900, val loss: 0.48878, in 0.441s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57733, val loss: 0.57715, in 0.442s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04227, val loss: 0.04147, in 0.450s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65071, val loss: 0.65064, in 0.480s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04196, val loss: 0.04157, in 0.511s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.65033, val loss: 0.65031, in 0.392s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04061, val loss: 0.03953, in 0.453s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54540, val loss: 0.54521, in 0.404s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03938, val loss: 0.03861, in 0.484s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46382, val loss: 0.46359, in 0.449s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04160, val loss: 0.04080, in 0.418s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61229, val loss: 0.61217, in 0.419s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04099, val loss: 0.04061, in 0.392s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61156, val loss: 0.61153, in 0.396s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03971, val loss: 0.03866, in 0.343s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.44057, val loss: 0.44033, in 0.357s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03844, val loss: 0.03769, in 0.360s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.51586, val loss: 0.51562, in 0.387s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04084, val loss: 0.04007, in 0.357s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.57737, val loss: 0.57712, in 0.324s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03995, val loss: 0.03959, in 0.393s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.57628, val loss: 0.57626, in 0.442s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41909, val loss: 0.41883, in 0.463s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48889, val loss: 0.48860, in 0.455s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03743, val loss: 0.03671, in 0.470s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03895, val loss: 0.03791, in 0.512s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04011, val loss: 0.03935, in 0.532s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54546, val loss: 0.54517, in 0.505s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03897, val loss: 0.03863, in 0.574s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54383, val loss: 0.54380, in 0.527s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39921, val loss: 0.39891, in 0.538s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03657, val loss: 0.03588, in 0.538s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.46373, val loss: 0.46340, in 0.562s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03939, val loss: 0.03864, in 0.509s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03818, val loss: 0.03715, in 0.603s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51610, val loss: 0.51572, in 0.540s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03805, val loss: 0.03773, in 0.545s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.51440, val loss: 0.51438, in 0.489s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44051, val loss: 0.44009, in 0.470s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03599, val loss: 0.03532, in 0.540s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38068, val loss: 0.38031, in 0.552s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03774, in 0.522s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03750, val loss: 0.03648, in 0.510s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48904, val loss: 0.48857, in 0.496s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48701, val loss: 0.48697, in 0.489s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03731, val loss: 0.03700, in 0.524s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.41900, val loss: 0.41856, in 0.497s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03525, val loss: 0.03460, in 0.468s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36342, val loss: 0.36303, in 0.476s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46390, val loss: 0.46341, in 0.449s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03668, val loss: 0.03568, in 0.482s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03748, val loss: 0.03674, in 0.508s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.46154, val loss: 0.46152, in 0.441s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03667, val loss: 0.03638, in 0.525s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39912, val loss: 0.39863, in 0.474s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03438, val loss: 0.03374, in 0.462s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34716, val loss: 0.34673, in 0.456s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03665, val loss: 0.03592, in 0.422s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.44072, val loss: 0.44019, in 0.444s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03609, val loss: 0.03513, in 0.487s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43825, val loss: 0.43823, in 0.392s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03603, val loss: 0.03575, in 0.360s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.38043, val loss: 0.37994, in 0.391s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.33175, val loss: 0.33137, in 0.407s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41923, val loss: 0.41865, in 0.389s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03362, val loss: 0.03302, in 0.435s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03510, in 0.415s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03546, val loss: 0.03451, in 0.392s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.41652, val loss: 0.41643, in 0.383s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03538, val loss: 0.03508, in 0.448s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36310, val loss: 0.36264, in 0.399s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31743, val loss: 0.31704, in 0.386s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39931, val loss: 0.39866, in 0.389s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03425, in 0.420s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03298, val loss: 0.03243, in 0.435s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03493, val loss: 0.03401, in 0.417s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39649, val loss: 0.39636, in 0.379s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34694, val loss: 0.34642, in 0.422s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03472, val loss: 0.03442, in 0.474s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30402, val loss: 0.30360, in 0.449s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.38077, val loss: 0.38007, in 0.450s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03179, in 0.445s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03427, val loss: 0.03337, in 0.443s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03416, val loss: 0.03347, in 0.542s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.37766, val loss: 0.37748, in 0.468s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33181, val loss: 0.33122, in 0.451s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.29140, val loss: 0.29104, in 0.469s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36355, val loss: 0.36283, in 0.472s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03392, val loss: 0.03363, in 0.526s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03187, val loss: 0.03135, in 0.507s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03350, val loss: 0.03263, in 0.552s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03333, val loss: 0.03264, in 0.503s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.36009, val loss: 0.35988, in 0.522s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31756, val loss: 0.31699, in 0.495s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27950, val loss: 0.27913, in 0.464s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.34729, val loss: 0.34652, in 0.472s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03316, val loss: 0.03290, in 0.500s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03266, val loss: 0.03199, in 0.392s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03127, val loss: 0.03078, in 0.475s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03283, val loss: 0.03199, in 0.478s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.34358, val loss: 0.34333, in 0.431s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30413, val loss: 0.30360, in 0.448s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.26806, val loss: 0.26764, in 0.438s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.33198, val loss: 0.33124, in 0.441s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03070, val loss: 0.03021, in 0.410s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03253, val loss: 0.03228, in 0.485s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03213, val loss: 0.03146, in 0.463s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03210, val loss: 0.03128, in 0.471s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.32813, val loss: 0.32788, in 0.410s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.29149, val loss: 0.29098, in 0.386s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25756, val loss: 0.25712, in 0.391s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.31775, val loss: 0.31697, in 0.395s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03208, val loss: 0.03185, in 0.351s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03020, val loss: 0.02971, in 0.412s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03150, val loss: 0.03084, in 0.403s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03169, val loss: 0.03087, in 0.339s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.31386, val loss: 0.31354, in 0.387s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27942, val loss: 0.27888, in 0.428s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.24730, val loss: 0.24681, in 0.441s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.02922, in 0.369s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30429, val loss: 0.30354, in 0.450s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03141, val loss: 0.03119, in 0.499s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03103, val loss: 0.03038, in 0.468s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03109, val loss: 0.03029, in 0.489s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30062, val loss: 0.30026, in 0.493s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.26818, val loss: 0.26759, in 0.466s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23815, val loss: 0.23762, in 0.457s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.29139, val loss: 0.29068, in 0.437s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02909, val loss: 0.02865, in 0.486s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03082, val loss: 0.03060, in 0.409s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03064, val loss: 0.03000, in 0.389s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.28808, val loss: 0.28766, in 0.371s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03052, val loss: 0.02975, in 0.446s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25777, val loss: 0.25713, in 0.362s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22934, val loss: 0.22876, in 0.362s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27968, val loss: 0.27887, in 0.346s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02841, val loss: 0.02799, in 0.362s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03021, val loss: 0.02958, in 0.342s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03000, val loss: 0.02979, in 0.394s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27614, val loss: 0.27571, in 0.345s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02988, val loss: 0.02913, in 0.398s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.24763, val loss: 0.24698, in 0.330s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26843, val loss: 0.26762, in 0.320s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22106, val loss: 0.22046, in 0.327s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02782, val loss: 0.02741, in 0.331s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02961, val loss: 0.02900, in 0.308s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02954, val loss: 0.02933, in 0.349s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.26520, val loss: 0.26475, in 0.331s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02914, val loss: 0.02841, in 0.329s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23804, val loss: 0.23733, in 0.360s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25793, val loss: 0.25711, in 0.347s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21302, val loss: 0.21238, in 0.354s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02736, val loss: 0.02698, in 0.313s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02904, val loss: 0.02845, in 0.361s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25466, val loss: 0.25420, in 0.335s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02879, val loss: 0.02857, in 0.367s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02849, val loss: 0.02778, in 0.322s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22929, val loss: 0.22856, in 0.344s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24770, val loss: 0.24686, in 0.350s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20559, val loss: 0.20492, in 0.348s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02684, val loss: 0.02648, in 0.370s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02842, val loss: 0.02785, in 0.372s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.24476, val loss: 0.24426, in 0.357s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02792, val loss: 0.02723, in 0.344s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02826, val loss: 0.02805, in 0.399s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.22082, val loss: 0.22010, in 0.405s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23858, val loss: 0.23769, in 0.405s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19854, val loss: 0.19789, in 0.421s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02793, val loss: 0.02737, in 0.396s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02617, val loss: 0.02582, in 0.476s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23534, val loss: 0.23487, in 0.411s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02781, val loss: 0.02761, in 0.414s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02737, val loss: 0.02670, in 0.441s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21268, val loss: 0.21196, in 0.385s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22955, val loss: 0.22859, in 0.366s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19203, val loss: 0.19136, in 0.357s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02756, val loss: 0.02700, in 0.335s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02560, val loss: 0.02527, in 0.330s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22642, val loss: 0.22590, in 0.359s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02678, val loss: 0.02613, in 0.344s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02724, val loss: 0.02706, in 0.406s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20549, val loss: 0.20472, in 0.366s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.22131, val loss: 0.22030, in 0.373s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18550, val loss: 0.18484, in 0.380s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02701, val loss: 0.02648, in 0.387s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02481, in 0.400s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21827, val loss: 0.21772, in 0.346s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02640, val loss: 0.02578, in 0.378s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02664, val loss: 0.02646, in 0.335s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19834, val loss: 0.19759, in 0.372s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21299, val loss: 0.21199, in 0.376s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17924, val loss: 0.17856, in 0.388s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02667, val loss: 0.02614, in 0.332s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02480, val loss: 0.02450, in 0.364s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21037, val loss: 0.20980, in 0.360s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02615, val loss: 0.02595, in 0.337s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02577, val loss: 0.02518, in 0.395s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19156, val loss: 0.19079, in 0.383s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02568, in 0.349s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20552, val loss: 0.20450, in 0.396s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17328, val loss: 0.17259, in 0.372s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02431, val loss: 0.02403, in 0.367s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20291, val loss: 0.20232, in 0.374s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02564, val loss: 0.02548, in 0.350s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02525, val loss: 0.02469, in 0.360s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18518, val loss: 0.18441, in 0.327s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02565, val loss: 0.02517, in 0.324s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19838, val loss: 0.19735, in 0.327s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16755, val loss: 0.16686, in 0.328s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02380, val loss: 0.02355, in 0.309s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19563, val loss: 0.19508, in 0.303s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02520, val loss: 0.02503, in 0.275s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02485, val loss: 0.02432, in 0.293s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17875, val loss: 0.17801, in 0.327s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02526, val loss: 0.02479, in 0.328s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.19147, val loss: 0.19048, in 0.328s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16232, val loss: 0.16165, in 0.322s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02488, val loss: 0.02473, in 0.277s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02342, val loss: 0.02316, in 0.336s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18884, val loss: 0.18827, in 0.342s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.02439, val loss: 0.02387, in 0.382s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17279, val loss: 0.17206, in 0.334s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02495, val loss: 0.02450, in 0.343s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15745, val loss: 0.15679, in 0.341s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02452, val loss: 0.02439, in 0.319s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18506, val loss: 0.18404, in 0.369s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18230, val loss: 0.18173, in 0.333s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02301, val loss: 0.02275, in 0.383s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02396, val loss: 0.02344, in 0.288s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16738, val loss: 0.16666, in 0.351s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02436, val loss: 0.02393, in 0.359s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02407, val loss: 0.02393, in 0.348s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17877, val loss: 0.17777, in 0.355s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15267, val loss: 0.15203, in 0.379s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17634, val loss: 0.17576, in 0.366s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02248, val loss: 0.02224, in 0.363s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02342, val loss: 0.02293, in 0.364s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02405, val loss: 0.02364, in 0.294s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16202, val loss: 0.16136, in 0.359s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02375, val loss: 0.02363, in 0.320s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14820, val loss: 0.14759, in 0.323s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17301, val loss: 0.17206, in 0.326s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02214, val loss: 0.02190, in 0.323s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17035, val loss: 0.16976, in 0.382s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02246, in 0.334s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02369, val loss: 0.02330, in 0.334s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02330, val loss: 0.02317, in 0.314s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15688, val loss: 0.15622, in 0.353s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16741, val loss: 0.16647, in 0.351s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14353, val loss: 0.14297, in 0.381s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02179, val loss: 0.02156, in 0.329s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16472, val loss: 0.16418, in 0.316s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02244, val loss: 0.02198, in 0.351s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02326, val loss: 0.02288, in 0.327s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02292, val loss: 0.02281, in 0.301s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15218, val loss: 0.15153, in 0.401s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16220, val loss: 0.16128, in 0.383s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13919, val loss: 0.13866, in 0.406s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02146, val loss: 0.02124, in 0.396s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15913, val loss: 0.15863, in 0.412s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02204, val loss: 0.02160, in 0.422s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02259, val loss: 0.02249, in 0.376s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02282, val loss: 0.02244, in 0.394s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14776, val loss: 0.14710, in 0.329s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15702, val loss: 0.15612, in 0.344s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13508, val loss: 0.13455, in 0.337s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02105, val loss: 0.02083, in 0.330s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15403, val loss: 0.15356, in 0.327s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02116, in 0.328s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02218, val loss: 0.02208, in 0.367s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02231, val loss: 0.02195, in 0.359s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14331, val loss: 0.14263, in 0.374s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15218, val loss: 0.15124, in 0.367s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13125, val loss: 0.13072, in 0.349s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02073, val loss: 0.02053, in 0.341s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14930, val loss: 0.14889, in 0.359s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02120, val loss: 0.02079, in 0.410s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02202, val loss: 0.02166, in 0.334s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02186, val loss: 0.02176, in 0.353s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13899, val loss: 0.13828, in 0.354s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14766, val loss: 0.14672, in 0.365s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02045, val loss: 0.02024, in 0.336s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12731, val loss: 0.12682, in 0.409s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14481, val loss: 0.14440, in 0.383s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02087, val loss: 0.02045, in 0.340s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02150, in 0.341s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02169, val loss: 0.02134, in 0.404s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02004, val loss: 0.01984, in 0.347s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13486, val loss: 0.13418, in 0.388s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14311, val loss: 0.14219, in 0.374s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12386, val loss: 0.12336, in 0.347s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14033, val loss: 0.13994, in 0.356s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02045, val loss: 0.02005, in 0.333s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02118, val loss: 0.02110, in 0.322s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02132, val loss: 0.02097, in 0.314s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13080, val loss: 0.13015, in 0.382s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13884, val loss: 0.13791, in 0.370s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01967, val loss: 0.01949, in 0.413s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12020, val loss: 0.11976, in 0.425s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13623, val loss: 0.13584, in 0.387s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02084, val loss: 0.02077, in 0.370s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02001, val loss: 0.01964, in 0.393s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02098, val loss: 0.02062, in 0.365s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01931, val loss: 0.01914, in 0.383s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12707, val loss: 0.12641, in 0.423s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13470, val loss: 0.13379, in 0.423s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13226, val loss: 0.13188, in 0.409s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11693, val loss: 0.11650, in 0.417s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02057, val loss: 0.02052, in 0.412s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02027, in 0.416s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01964, val loss: 0.01928, in 0.480s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01905, val loss: 0.01887, in 0.385s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12346, val loss: 0.12283, in 0.409s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13084, val loss: 0.12995, in 0.428s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12851, val loss: 0.12815, in 0.393s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11358, val loss: 0.11319, in 0.408s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02023, val loss: 0.02017, in 0.376s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01925, val loss: 0.01890, in 0.360s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02026, val loss: 0.01993, in 0.394s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01869, val loss: 0.01853, in 0.371s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11992, val loss: 0.11931, in 0.392s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12700, val loss: 0.12613, in 0.370s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12450, val loss: 0.12413, in 0.385s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01994, val loss: 0.01989, in 0.352s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11042, val loss: 0.11005, in 0.397s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02003, val loss: 0.01972, in 0.331s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01896, val loss: 0.01863, in 0.380s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01822, in 0.317s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11670, val loss: 0.11612, in 0.375s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12323, val loss: 0.12240, in 0.386s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12113, val loss: 0.12075, in 0.345s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01966, val loss: 0.01963, in 0.377s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10749, val loss: 0.10711, in 0.376s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01969, val loss: 0.01939, in 0.385s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.01829, in 0.351s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01810, val loss: 0.01796, in 0.388s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11338, val loss: 0.11285, in 0.380s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11962, val loss: 0.11884, in 0.374s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11806, val loss: 0.11769, in 0.371s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01937, val loss: 0.01934, in 0.350s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01938, val loss: 0.01908, in 0.321s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10448, val loss: 0.10412, in 0.443s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01794, in 0.425s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01784, val loss: 0.01770, in 0.396s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11628, val loss: 0.11553, in 0.411s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11019, val loss: 0.10968, in 0.445s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01906, val loss: 0.01903, in 0.375s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.11492, val loss: 0.11456, in 0.421s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01898, val loss: 0.01869, in 0.406s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10142, val loss: 0.10114, in 0.373s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01791, val loss: 0.01762, in 0.389s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01751, val loss: 0.01737, in 0.381s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01879, val loss: 0.01876, in 0.324s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11295, val loss: 0.11224, in 0.361s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10706, val loss: 0.10661, in 0.356s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11181, val loss: 0.11148, in 0.351s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01864, val loss: 0.01835, in 0.360s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01733, in 0.314s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09854, val loss: 0.09828, in 0.394s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01725, val loss: 0.01712, in 0.325s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01864, val loss: 0.01862, in 0.297s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10980, val loss: 0.10912, in 0.382s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10882, val loss: 0.10850, in 0.367s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10417, val loss: 0.10372, in 0.386s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01839, val loss: 0.01811, in 0.355s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01732, val loss: 0.01704, in 0.404s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01686, in 0.338s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09583, val loss: 0.09560, in 0.403s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01841, val loss: 0.01840, in 0.375s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01812, val loss: 0.01784, in 0.332s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10596, val loss: 0.10569, in 0.389s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10679, val loss: 0.10612, in 0.403s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10105, val loss: 0.10065, in 0.409s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01681, val loss: 0.01668, in 0.333s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01699, val loss: 0.01672, in 0.372s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01822, in 0.288s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09324, val loss: 0.09304, in 0.405s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01761, in 0.334s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.10317, val loss: 0.10293, in 0.387s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10387, val loss: 0.10329, in 0.388s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09820, val loss: 0.09783, in 0.386s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01654, val loss: 0.01642, in 0.340s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01789, in 0.320s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01668, val loss: 0.01642, in 0.372s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09076, val loss: 0.09058, in 0.394s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01753, val loss: 0.01726, in 0.400s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10064, val loss: 0.10039, in 0.394s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10086, val loss: 0.10031, in 0.414s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01768, val loss: 0.01768, in 0.339s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01642, val loss: 0.01616, in 0.331s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01616, in 0.409s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09535, val loss: 0.09498, in 0.435s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08832, val loss: 0.08811, in 0.384s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01728, val loss: 0.01701, in 0.289s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01622, val loss: 0.01598, in 0.287s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01743, val loss: 0.01743, in 0.328s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09831, val loss: 0.09808, in 0.379s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01609, val loss: 0.01598, in 0.322s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09795, val loss: 0.09741, in 0.377s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09274, val loss: 0.09237, in 0.387s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08601, val loss: 0.08579, in 0.388s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01700, val loss: 0.01674, in 0.369s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01597, val loss: 0.01572, in 0.373s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01587, val loss: 0.01576, in 0.365s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01712, val loss: 0.01713, in 0.450s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09573, val loss: 0.09553, in 0.461s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09528, val loss: 0.09474, in 0.452s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09007, val loss: 0.08968, in 0.433s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01677, val loss: 0.01651, in 0.388s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08370, val loss: 0.08346, in 0.452s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01564, val loss: 0.01554, in 0.386s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01686, val loss: 0.01686, in 0.336s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01570, val loss: 0.01546, in 0.462s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09346, val loss: 0.09326, in 0.396s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09258, val loss: 0.09204, in 0.435s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08768, val loss: 0.08730, in 0.420s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01627, in 0.364s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08166, val loss: 0.08145, in 0.398s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01520, in 0.378s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01527, in 0.409s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01658, val loss: 0.01660, in 0.409s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09093, val loss: 0.09075, in 0.410s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09014, val loss: 0.08957, in 0.403s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08535, val loss: 0.08500, in 0.430s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01623, val loss: 0.01597, in 0.444s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07971, val loss: 0.07953, in 0.424s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01517, val loss: 0.01507, in 0.329s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01518, val loss: 0.01497, in 0.364s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01639, val loss: 0.01642, in 0.345s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08852, val loss: 0.08837, in 0.393s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08781, val loss: 0.08721, in 0.408s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01599, val loss: 0.01574, in 0.376s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08307, val loss: 0.08272, in 0.439s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01492, val loss: 0.01483, in 0.389s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07798, val loss: 0.07782, in 0.460s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01496, val loss: 0.01475, in 0.401s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01618, val loss: 0.01620, in 0.401s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08634, val loss: 0.08621, in 0.456s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01550, in 0.392s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08553, val loss: 0.08492, in 0.471s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08121, val loss: 0.08089, in 0.433s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01475, val loss: 0.01456, in 0.398s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01466, val loss: 0.01459, in 0.448s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07597, val loss: 0.07581, in 0.439s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01589, val loss: 0.01591, in 0.484s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08414, val loss: 0.08399, in 0.442s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08335, val loss: 0.08274, in 0.420s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01549, val loss: 0.01526, in 0.453s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07902, val loss: 0.07871, in 0.432s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01449, val loss: 0.01442, in 0.408s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07413, val loss: 0.07396, in 0.430s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01451, val loss: 0.01433, in 0.459s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01565, val loss: 0.01567, in 0.412s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08203, val loss: 0.08186, in 0.423s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01509, in 0.362s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08121, val loss: 0.08061, in 0.452s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01426, in 0.368s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07716, val loss: 0.07686, in 0.464s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01416, in 0.365s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01542, val loss: 0.01544, in 0.373s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07232, val loss: 0.07216, in 0.476s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01489, in 0.375s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07973, val loss: 0.07959, in 0.443s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01418, val loss: 0.01412, in 0.317s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07912, val loss: 0.07850, in 0.432s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01520, val loss: 0.01521, in 0.366s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07527, val loss: 0.07495, in 0.446s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01414, val loss: 0.01398, in 0.430s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07076, val loss: 0.07060, in 0.432s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01495, val loss: 0.01473, in 0.343s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07751, val loss: 0.07742, in 0.454s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01389, in 0.458s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07707, val loss: 0.07644, in 0.422s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01394, val loss: 0.01378, in 0.353s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01494, val loss: 0.01496, in 0.427s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07353, val loss: 0.07323, in 0.417s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01474, val loss: 0.01454, in 0.348s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06930, val loss: 0.06917, in 0.389s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01374, val loss: 0.01369, in 0.348s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07541, val loss: 0.07532, in 0.415s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01358, in 0.401s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01476, val loss: 0.01480, in 0.343s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07511, val loss: 0.07450, in 0.423s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01454, val loss: 0.01434, in 0.340s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07174, val loss: 0.07144, in 0.416s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06756, val loss: 0.06745, in 0.409s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01357, val loss: 0.01352, in 0.422s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01357, val loss: 0.01340, in 0.346s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07344, val loss: 0.07337, in 0.449s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01450, in 0.409s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07352, val loss: 0.07293, in 0.433s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07006, val loss: 0.06979, in 0.414s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01411, in 0.466s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06590, val loss: 0.06582, in 0.409s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01336, val loss: 0.01332, in 0.362s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01323, in 0.349s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07156, val loss: 0.07148, in 0.407s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01428, in 0.411s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07151, val loss: 0.07098, in 0.436s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06847, val loss: 0.06822, in 0.439s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01409, val loss: 0.01390, in 0.417s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06430, val loss: 0.06426, in 0.434s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01312, in 0.326s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01320, val loss: 0.01316, in 0.347s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06999, val loss: 0.06994, in 0.433s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01378, in 0.307s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01400, val loss: 0.01405, in 0.484s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06966, val loss: 0.06913, in 0.435s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06693, val loss: 0.06669, in 0.417s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06304, val loss: 0.06303, in 0.422s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01307, val loss: 0.01293, in 0.432s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01301, val loss: 0.01299, in 0.431s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01380, val loss: 0.01360, in 0.337s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06822, val loss: 0.06818, in 0.449s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01375, val loss: 0.01381, in 0.410s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06816, val loss: 0.06764, in 0.437s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06532, val loss: 0.06512, in 0.436s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01292, val loss: 0.01277, in 0.390s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06158, val loss: 0.06158, in 0.478s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01281, val loss: 0.01279, in 0.488s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01359, val loss: 0.01340, in 0.461s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01364, in 0.422s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06652, val loss: 0.06648, in 0.462s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06653, val loss: 0.06606, in 0.451s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01260, in 0.359s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06378, val loss: 0.06359, in 0.456s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01265, val loss: 0.01262, in 0.333s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06020, val loss: 0.06023, in 0.405s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01339, val loss: 0.01321, in 0.356s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01338, val loss: 0.01346, in 0.375s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06498, val loss: 0.06492, in 0.408s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06521, val loss: 0.06472, in 0.396s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01241, in 0.428s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06231, val loss: 0.06216, in 0.406s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01244, val loss: 0.01243, in 0.416s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05894, val loss: 0.05897, in 0.428s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01323, val loss: 0.01305, in 0.416s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01323, in 0.376s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01228, in 0.340s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06364, val loss: 0.06356, in 0.447s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06372, val loss: 0.06321, in 0.446s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06110, val loss: 0.06097, in 0.443s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01229, val loss: 0.01228, in 0.443s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05757, val loss: 0.05757, in 0.453s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01306, val loss: 0.01290, in 0.428s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01295, val loss: 0.01302, in 0.456s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01228, val loss: 0.01216, in 0.379s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06213, val loss: 0.06204, in 0.440s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06219, val loss: 0.06176, in 0.446s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01210, val loss: 0.01210, in 0.361s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05974, val loss: 0.05964, in 0.431s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01292, val loss: 0.01277, in 0.316s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05615, val loss: 0.05621, in 0.411s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01280, val loss: 0.01288, in 0.411s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01212, val loss: 0.01200, in 0.400s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01196, val loss: 0.01196, in 0.461s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06050, val loss: 0.06046, in 0.537s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06068, val loss: 0.06026, in 0.523s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05844, val loss: 0.05833, in 0.558s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01258, in 0.546s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05513, val loss: 0.05521, in 0.547s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01281, in 0.398s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01187, in 0.474s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01177, val loss: 0.01178, in 0.472s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05920, val loss: 0.05919, in 0.479s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05941, val loss: 0.05899, in 0.472s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01255, val loss: 0.01241, in 0.430s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05710, val loss: 0.05701, in 0.470s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01184, val loss: 0.01173, in 0.415s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05385, val loss: 0.05398, in 0.501s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01252, val loss: 0.01260, in 0.512s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01160, val loss: 0.01161, in 0.558s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01239, val loss: 0.01226, in 0.459s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05789, val loss: 0.05788, in 0.548s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05803, val loss: 0.05768, in 0.554s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05599, val loss: 0.05591, in 0.512s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01234, val loss: 0.01242, in 0.434s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01168, val loss: 0.01159, in 0.479s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05284, val loss: 0.05301, in 0.519s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01144, val loss: 0.01146, in 0.379s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01222, val loss: 0.01209, in 0.382s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05652, val loss: 0.05652, in 0.450s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01230, in 0.368s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05673, val loss: 0.05640, in 0.447s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05472, val loss: 0.05469, in 0.427s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01150, val loss: 0.01141, in 0.392s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05187, val loss: 0.05209, in 0.455s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01137, in 0.309s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01203, val loss: 0.01191, in 0.469s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01205, val loss: 0.01215, in 0.394s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01127, in 0.395s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05545, val loss: 0.05517, in 0.447s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05517, val loss: 0.05517, in 0.461s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05348, val loss: 0.05352, in 0.454s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05087, val loss: 0.05109, in 0.439s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01119, val loss: 0.01122, in 0.387s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01190, val loss: 0.01178, in 0.367s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01126, val loss: 0.01118, in 0.332s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01190, val loss: 0.01200, in 0.431s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05441, val loss: 0.05413, in 0.447s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05400, val loss: 0.05399, in 0.449s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05237, val loss: 0.05238, in 0.437s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04987, val loss: 0.05010, in 0.399s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01106, in 0.403s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01181, val loss: 0.01169, in 0.306s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01176, val loss: 0.01187, in 0.338s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01107, val loss: 0.01101, in 0.415s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05132, val loss: 0.05133, in 0.424s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05321, val loss: 0.05293, in 0.427s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05271, val loss: 0.05266, in 0.447s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04894, val loss: 0.04915, in 0.401s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01166, val loss: 0.01155, in 0.354s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01088, val loss: 0.01091, in 0.435s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01097, val loss: 0.01091, in 0.345s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01170, in 0.452s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05024, val loss: 0.05024, in 0.414s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05173, val loss: 0.05167, in 0.415s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05214, val loss: 0.05187, in 0.440s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01078, in 0.334s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04808, val loss: 0.04831, in 0.411s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01149, val loss: 0.01138, in 0.432s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01082, val loss: 0.01076, in 0.392s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01142, val loss: 0.01153, in 0.324s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01061, val loss: 0.01064, in 0.365s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04930, val loss: 0.04930, in 0.445s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05104, val loss: 0.05080, in 0.424s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05064, val loss: 0.05059, in 0.438s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01137, val loss: 0.01127, in 0.388s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.04718, val loss: 0.04738, in 0.436s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01063, in 0.339s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01131, val loss: 0.01142, in 0.375s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01051, val loss: 0.01054, in 0.348s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01115, in 0.360s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04831, val loss: 0.04836, in 0.414s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05006, val loss: 0.04984, in 0.410s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04959, val loss: 0.04954, in 0.436s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04615, val loss: 0.04634, in 0.426s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01053, val loss: 0.01047, in 0.466s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01114, val loss: 0.01126, in 0.433s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01035, val loss: 0.01039, in 0.460s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01111, val loss: 0.01101, in 0.408s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04742, val loss: 0.04748, in 0.482s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04915, val loss: 0.04898, in 0.501s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04538, val loss: 0.04557, in 0.462s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01036, in 0.410s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04847, val loss: 0.04845, in 0.495s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01095, val loss: 0.01106, in 0.436s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01023, val loss: 0.01027, in 0.462s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01094, val loss: 0.01085, in 0.557s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04425, val loss: 0.04446, in 0.484s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04648, val loss: 0.04655, in 0.539s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04822, val loss: 0.04805, in 0.557s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04746, val loss: 0.04743, in 0.538s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01021, in 0.571s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01078, val loss: 0.01090, in 0.554s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01013, val loss: 0.01018, in 0.419s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04348, val loss: 0.04371, in 0.428s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01078, val loss: 0.01070, in 0.493s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01017, val loss: 0.01013, in 0.352s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04570, val loss: 0.04579, in 0.459s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04731, val loss: 0.04713, in 0.449s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04653, val loss: 0.04650, in 0.463s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01065, val loss: 0.01078, in 0.433s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00999, val loss: 0.01004, in 0.465s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01006, val loss: 0.01002, in 0.367s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04288, in 0.413s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01056, in 0.422s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04471, val loss: 0.04481, in 0.410s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04645, val loss: 0.04628, in 0.410s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01053, val loss: 0.01067, in 0.354s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04549, val loss: 0.04549, in 0.430s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00986, val loss: 0.00992, in 0.442s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01048, in 0.349s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00992, val loss: 0.00989, in 0.446s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04181, val loss: 0.04205, in 0.434s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01056, in 0.416s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04386, val loss: 0.04400, in 0.455s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04463, val loss: 0.04464, in 0.424s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04541, val loss: 0.04527, in 0.526s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00973, val loss: 0.00979, in 0.366s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01044, val loss: 0.01036, in 0.375s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04071, val loss: 0.04097, in 0.366s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01041, in 0.335s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00977, val loss: 0.00974, in 0.424s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04386, val loss: 0.04389, in 0.352s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04301, val loss: 0.04315, in 0.419s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04441, val loss: 0.04428, in 0.414s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00967, in 0.365s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04005, val loss: 0.04029, in 0.339s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01024, in 0.396s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04226, val loss: 0.04240, in 0.336s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01012, val loss: 0.01025, in 0.434s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04308, val loss: 0.04313, in 0.372s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.00961, in 0.447s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00957, in 0.334s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04354, val loss: 0.04343, in 0.363s\n",
      "[86/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01019, in 0.295s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03903, val loss: 0.03928, in 0.348s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04232, val loss: 0.04239, in 0.329s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04116, val loss: 0.04131, in 0.345s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00998, val loss: 0.01011, in 0.378s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00952, val loss: 0.00950, in 0.345s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00939, val loss: 0.00948, in 0.367s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01009, in 0.316s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04275, val loss: 0.04264, in 0.388s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03838, val loss: 0.03863, in 0.373s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04145, val loss: 0.04154, in 0.334s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04047, val loss: 0.04064, in 0.372s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00984, val loss: 0.00998, in 0.403s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00938, val loss: 0.00937, in 0.423s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00937, in 0.408s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01002, val loss: 0.00997, in 0.388s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04203, val loss: 0.04192, in 0.439s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03745, val loss: 0.03771, in 0.395s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04078, val loss: 0.04089, in 0.389s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03953, val loss: 0.03972, in 0.383s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00968, val loss: 0.00981, in 0.391s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00990, in 0.323s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00928, in 0.410s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00918, val loss: 0.00928, in 0.384s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04121, val loss: 0.04113, in 0.342s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03659, val loss: 0.03687, in 0.377s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03999, val loss: 0.04012, in 0.318s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03862, val loss: 0.03884, in 0.394s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00923, in 0.368s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00983, val loss: 0.00978, in 0.392s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00972, in 0.424s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00920, in 0.394s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04038, val loss: 0.04034, in 0.419s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03579, val loss: 0.03608, in 0.413s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03928, val loss: 0.03942, in 0.460s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03777, val loss: 0.03802, in 0.425s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00971, val loss: 0.00966, in 0.336s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00911, in 0.369s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00898, val loss: 0.00909, in 0.318s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.00961, in 0.401s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03963, val loss: 0.03959, in 0.345s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03501, val loss: 0.03531, in 0.391s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03862, val loss: 0.03876, in 0.355s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00965, val loss: 0.00960, in 0.303s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03715, val loss: 0.03739, in 0.354s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00891, val loss: 0.00902, in 0.310s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00936, val loss: 0.00951, in 0.326s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00901, in 0.383s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03894, val loss: 0.03894, in 0.325s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03437, val loss: 0.03466, in 0.349s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03760, val loss: 0.03775, in 0.343s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00949, in 0.360s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03649, val loss: 0.03675, in 0.338s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00891, in 0.373s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00891, in 0.333s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03815, val loss: 0.03816, in 0.327s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00921, val loss: 0.00935, in 0.420s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03700, val loss: 0.03715, in 0.327s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03388, val loss: 0.03416, in 0.363s\n",
      "[99/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.00876, val loss: 0.00887, in 0.280s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03607, in 0.362s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00938, in 0.385s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03745, val loss: 0.03746, in 0.349s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00880, in 0.400s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00911, val loss: 0.00925, in 0.332s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03616, val loss: 0.03631, in 0.329s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00876, in 0.290s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03311, val loss: 0.03340, in 0.365s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00930, val loss: 0.00926, in 0.306s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00876, in 0.288s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03499, val loss: 0.03531, in 0.401s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03668, val loss: 0.03671, in 0.432s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00899, val loss: 0.00914, in 0.421s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00869, in 0.397s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03495, val loss: 0.03510, in 0.442s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00919, val loss: 0.00916, in 0.366s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03240, val loss: 0.03272, in 0.436s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03448, val loss: 0.03481, in 0.355s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00863, val loss: 0.00865, in 0.425s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00893, val loss: 0.00908, in 0.292s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03602, val loss: 0.03607, in 0.317s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00859, in 0.341s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00909, val loss: 0.00906, in 0.326s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03438, val loss: 0.03453, in 0.348s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03177, val loss: 0.03209, in 0.370s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03377, val loss: 0.03412, in 0.348s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00885, val loss: 0.00900, in 0.323s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03511, val loss: 0.03517, in 0.326s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00855, in 0.357s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00833, val loss: 0.00848, in 0.330s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00895, in 0.334s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03136, val loss: 0.03170, in 0.314s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03327, val loss: 0.03342, in 0.395s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03323, val loss: 0.03359, in 0.317s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00844, val loss: 0.00847, in 0.285s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03425, val loss: 0.03432, in 0.341s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00874, val loss: 0.00890, in 0.384s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00889, in 0.302s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00840, in 0.344s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00838, in 0.302s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03067, val loss: 0.03102, in 0.366s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03223, val loss: 0.03239, in 0.370s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03232, val loss: 0.03268, in 0.363s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00866, val loss: 0.00882, in 0.316s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03368, val loss: 0.03375, in 0.347s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00835, in 0.302s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00877, val loss: 0.00876, in 0.357s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00824, val loss: 0.00827, in 0.368s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03160, val loss: 0.03198, in 0.376s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03171, in 0.397s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03002, val loss: 0.03036, in 0.406s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00873, in 0.384s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03293, val loss: 0.03302, in 0.399s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00827, in 0.313s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00867, val loss: 0.00866, in 0.293s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00816, val loss: 0.00819, in 0.297s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02954, val loss: 0.02989, in 0.318s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03105, val loss: 0.03145, in 0.353s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03074, in 0.387s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00859, val loss: 0.00859, in 0.289s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00820, in 0.319s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00863, in 0.371s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03228, val loss: 0.03240, in 0.369s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00811, in 0.330s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02915, val loss: 0.02952, in 0.527s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02996, val loss: 0.03016, in 0.655s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03158, val loss: 0.03171, in 0.605s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03023, val loss: 0.03064, in 0.713s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00853, in 0.641s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00853, in 0.680s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00794, val loss: 0.00810, in 0.670s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00801, in 0.612s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02859, val loss: 0.02896, in 0.434s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00806, in 0.240s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00828, val loss: 0.00847, in 0.287s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03109, val loss: 0.03122, in 0.331s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02964, val loss: 0.03006, in 0.337s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02916, val loss: 0.02938, in 0.358s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00841, val loss: 0.00843, in 0.363s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00788, val loss: 0.00792, in 0.284s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02800, val loss: 0.02837, in 0.325s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00836, in 0.296s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02923, val loss: 0.02967, in 0.267s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00799, in 0.337s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03054, val loss: 0.03067, in 0.308s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00786, in 0.264s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02853, val loss: 0.02876, in 0.354s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00832, in 0.356s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02764, val loss: 0.02803, in 0.289s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02870, val loss: 0.02915, in 0.327s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00773, val loss: 0.00790, in 0.313s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00827, in 0.374s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02993, val loss: 0.03007, in 0.383s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00825, val loss: 0.00828, in 0.277s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00772, val loss: 0.00777, in 0.375s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02780, val loss: 0.02805, in 0.395s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02715, val loss: 0.02755, in 0.370s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02815, val loss: 0.02860, in 0.355s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00820, in 0.263s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00816, in 0.347s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02940, val loss: 0.02956, in 0.305s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00763, val loss: 0.00768, in 0.297s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02712, val loss: 0.02738, in 0.305s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02670, val loss: 0.02711, in 0.276s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00812, in 0.268s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00755, val loss: 0.00760, in 0.249s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02813, in 0.321s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02892, val loss: 0.02908, in 0.288s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00786, val loss: 0.00806, in 0.297s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02671, val loss: 0.02697, in 0.277s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02619, val loss: 0.02658, in 0.336s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00775, val loss: 0.00795, in 0.276s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00745, val loss: 0.00751, in 0.290s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02731, val loss: 0.02777, in 0.298s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02845, val loss: 0.02861, in 0.325s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02618, val loss: 0.02643, in 0.346s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02579, val loss: 0.02618, in 0.277s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00768, val loss: 0.00788, in 0.273s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02798, val loss: 0.02815, in 0.292s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02647, val loss: 0.02694, in 0.325s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02576, val loss: 0.02601, in 0.272s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02532, val loss: 0.02574, in 0.310s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00780, in 0.262s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02746, val loss: 0.02763, in 0.320s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02597, val loss: 0.02644, in 0.317s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02512, val loss: 0.02538, in 0.309s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02467, val loss: 0.02509, in 0.365s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02542, val loss: 0.02589, in 0.348s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02661, val loss: 0.02679, in 0.353s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02468, val loss: 0.02495, in 0.329s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02425, val loss: 0.02468, in 0.336s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02534, in 0.283s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02442, val loss: 0.02470, in 0.256s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02610, val loss: 0.02628, in 0.313s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02386, val loss: 0.02430, in 0.291s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02444, val loss: 0.02490, in 0.301s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02397, val loss: 0.02423, in 0.303s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02532, val loss: 0.02550, in 0.321s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02378, in 0.247s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02347, val loss: 0.02372, in 0.306s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02377, val loss: 0.02424, in 0.335s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02494, val loss: 0.02513, in 0.310s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02298, val loss: 0.02340, in 0.289s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02320, val loss: 0.02346, in 0.254s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02336, val loss: 0.02386, in 0.313s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02447, val loss: 0.02468, in 0.298s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02251, val loss: 0.02292, in 0.234s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02280, val loss: 0.02307, in 0.275s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02295, val loss: 0.02343, in 0.256s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02424, val loss: 0.02446, in 0.250s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02213, val loss: 0.02254, in 0.286s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02230, val loss: 0.02256, in 0.313s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02251, val loss: 0.02299, in 0.317s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02354, val loss: 0.02376, in 0.333s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02176, val loss: 0.02217, in 0.324s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02191, val loss: 0.02218, in 0.314s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02307, val loss: 0.02328, in 0.292s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02211, val loss: 0.02259, in 0.340s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02133, val loss: 0.02172, in 0.281s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02147, val loss: 0.02171, in 0.262s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02268, val loss: 0.02291, in 0.303s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02218, in 0.288s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02101, val loss: 0.02140, in 0.286s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02104, val loss: 0.02128, in 0.326s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02225, val loss: 0.02246, in 0.246s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02121, val loss: 0.02168, in 0.265s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02060, val loss: 0.02099, in 0.256s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02063, val loss: 0.02086, in 0.242s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02183, val loss: 0.02205, in 0.268s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02085, val loss: 0.02130, in 0.291s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02028, val loss: 0.02069, in 0.302s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00769, val loss: 0.00786, in 0.261s\n",
      "Fit 200 trees in 86.623 s, (6199 total leaves)\n",
      "Time spent computing histograms: 50.588s\n",
      "Time spent finding best splits:  1.517s\n",
      "Time spent applying splits:      10.590s\n",
      "Time spent predicting:           0.604s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.02054, in 0.276s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02123, val loss: 0.02146, in 0.339s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01997, val loss: 0.02038, in 0.310s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02035, val loss: 0.02081, in 0.368s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01993, val loss: 0.02015, in 0.422s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02111, in 0.387s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01967, val loss: 0.02007, in 0.377s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02041, in 0.351s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01956, val loss: 0.01976, in 0.263s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01949, val loss: 0.01991, in 0.275s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00798, val loss: 0.00802, in 0.344s\n",
      "Fit 200 trees in 85.584 s, (6199 total leaves)\n",
      "Time spent computing histograms: 50.297s\n",
      "Time spent finding best splits:  1.551s\n",
      "Time spent applying splits:      9.996s\n",
      "Time spent predicting:           0.550s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.02050, val loss: 0.02073, in 0.378s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01962, val loss: 0.02007, in 0.370s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01944, in 0.416s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01925, val loss: 0.01967, in 0.345s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02013, val loss: 0.02034, in 0.302s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.01978, in 0.335s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.01913, in 0.284s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01889, val loss: 0.01929, in 0.239s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00743, in 0.268s\n",
      "Fit 200 trees in 86.630 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.073s\n",
      "Time spent finding best splits:  1.554s\n",
      "Time spent applying splits:      10.378s\n",
      "Time spent predicting:           0.591s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01980, val loss: 0.02003, in 0.310s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01904, val loss: 0.01950, in 0.350s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01865, val loss: 0.01889, in 0.314s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01944, val loss: 0.01967, in 0.288s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01862, val loss: 0.01901, in 0.420s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01869, val loss: 0.01916, in 0.489s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01838, val loss: 0.01862, in 0.433s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01913, val loss: 0.01936, in 0.397s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01830, val loss: 0.01870, in 0.384s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00750, val loss: 0.00771, in 0.350s\n",
      "Fit 200 trees in 86.018 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.815s\n",
      "Time spent finding best splits:  1.528s\n",
      "Time spent applying splits:      10.078s\n",
      "Time spent predicting:           0.635s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01840, val loss: 0.01885, in 0.407s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01795, val loss: 0.01834, in 0.425s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01808, val loss: 0.01830, in 0.497s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01882, val loss: 0.01905, in 0.487s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01809, val loss: 0.01855, in 0.359s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01779, val loss: 0.01804, in 0.305s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01770, val loss: 0.01809, in 0.324s\n",
      "[136/200] 3.112 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01849, val loss: 0.01873, in 0.368s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01822, in 0.288s\n",
      "[132/200] 0.111 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01760, val loss: 0.01785, in 0.262s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01739, val loss: 0.01778, in 0.277s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01813, val loss: 0.01837, in 0.289s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62678, val loss: 0.62667, in 0.192s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01745, val loss: 0.01790, in 0.309s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01735, val loss: 0.01760, in 0.273s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01709, val loss: 0.01749, in 0.331s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57229, val loss: 0.57192, in 0.204s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01786, val loss: 0.01810, in 0.267s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01715, val loss: 0.01761, in 0.263s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01708, val loss: 0.01734, in 0.278s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52708, val loss: 0.52648, in 0.193s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01685, val loss: 0.01726, in 0.278s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01761, val loss: 0.01785, in 0.310s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48886, val loss: 0.48808, in 0.201s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01691, val loss: 0.01739, in 0.291s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01682, val loss: 0.01709, in 0.306s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45631, val loss: 0.45545, in 0.186s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01661, val loss: 0.01702, in 0.326s\n",
      "[140/200] 3.323 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.01731, val loss: 0.01755, in 0.329s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01655, val loss: 0.01703, in 0.289s\n",
      "[136/200] 0.120 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01680, in 0.290s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42314, val loss: 0.42211, in 0.205s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01643, val loss: 0.01686, in 0.239s\n",
      "[141/200] 3.008 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.62683, val loss: 0.62658, in 0.201s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01706, val loss: 0.01731, in 0.314s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39469, val loss: 0.39361, in 0.213s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01629, val loss: 0.01676, in 0.280s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01627, val loss: 0.01654, in 0.275s\n",
      "[136/200] 0.121 s\n",
      "Fitting gradient boosted rounds:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01616, val loss: 0.01656, in 0.255s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57241, val loss: 0.57201, in 0.207s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37005, val loss: 0.36890, in 0.215s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01676, val loss: 0.01702, in 0.289s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62682, val loss: 0.62687, in 0.206s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01606, val loss: 0.01653, in 0.309s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01602, val loss: 0.01630, in 0.295s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01602, val loss: 0.01643, in 0.279s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52723, val loss: 0.52659, in 0.201s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34862, val loss: 0.34741, in 0.314s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57238, val loss: 0.57241, in 0.331s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48905, val loss: 0.48818, in 0.388s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01682, in 0.516s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01575, val loss: 0.01622, in 0.497s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52719, val loss: 0.52720, in 0.303s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33004, val loss: 0.32872, in 0.361s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01577, val loss: 0.01605, in 0.556s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01576, val loss: 0.01617, in 0.577s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45654, val loss: 0.45558, in 0.258s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01654, in 0.374s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48902, val loss: 0.48892, in 0.252s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31369, val loss: 0.31243, in 0.262s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01599, in 0.420s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01555, val loss: 0.01583, in 0.381s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01592, in 0.350s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42336, val loss: 0.42221, in 0.291s\n",
      "[7/200] 3.750 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.45654, val loss: 0.45644, in 0.253s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29867, val loss: 0.29724, in 0.275s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39491, val loss: 0.39365, in 0.282s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01604, val loss: 0.01631, in 0.449s\n",
      "[139/200] 0.150 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01536, val loss: 0.01565, in 0.477s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01526, val loss: 0.01572, in 0.550s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42334, val loss: 0.42324, in 0.399s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01527, val loss: 0.01568, in 0.519s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28596, val loss: 0.28450, in 0.386s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37031, val loss: 0.36895, in 0.334s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62677, val loss: 0.62679, in 0.321s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01577, val loss: 0.01602, in 0.424s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39488, val loss: 0.39478, in 0.284s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27419, val loss: 0.27264, in 0.282s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01511, val loss: 0.01539, in 0.349s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01503, val loss: 0.01542, in 0.347s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34892, val loss: 0.34750, in 0.330s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01502, val loss: 0.01549, in 0.496s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57227, val loss: 0.57225, in 0.302s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26421, val loss: 0.26260, in 0.322s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01551, val loss: 0.01577, in 0.420s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37026, val loss: 0.37012, in 0.357s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01488, val loss: 0.01516, in 0.488s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33034, val loss: 0.32881, in 0.344s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52704, val loss: 0.52698, in 0.331s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01526, in 0.392s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01480, val loss: 0.01519, in 0.558s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25471, val loss: 0.25303, in 0.326s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34888, val loss: 0.34872, in 0.330s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01558, in 0.382s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48880, val loss: 0.48859, in 0.250s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31410, val loss: 0.31250, in 0.277s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01468, val loss: 0.01495, in 0.326s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01463, val loss: 0.01509, in 0.343s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33027, val loss: 0.33007, in 0.262s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24677, val loss: 0.24509, in 0.289s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01460, val loss: 0.01500, in 0.367s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45624, val loss: 0.45603, in 0.247s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29910, val loss: 0.29733, in 0.277s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01505, val loss: 0.01531, in 0.381s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23944, val loss: 0.23771, in 0.276s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01439, val loss: 0.01467, in 0.402s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31403, val loss: 0.31378, in 0.294s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01443, val loss: 0.01487, in 0.342s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42305, val loss: 0.42283, in 0.272s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28631, val loss: 0.28448, in 0.273s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01436, val loss: 0.01477, in 0.432s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23278, val loss: 0.23116, in 0.232s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29905, val loss: 0.29862, in 0.262s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01486, val loss: 0.01513, in 0.422s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39457, val loss: 0.39431, in 0.268s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27456, val loss: 0.27258, in 0.266s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01417, val loss: 0.01445, in 0.389s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01420, val loss: 0.01464, in 0.409s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22598, val loss: 0.22424, in 0.259s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28630, val loss: 0.28578, in 0.287s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01412, val loss: 0.01454, in 0.375s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36992, val loss: 0.36963, in 0.263s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01469, val loss: 0.01496, in 0.312s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26451, val loss: 0.26252, in 0.265s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22038, val loss: 0.21869, in 0.236s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01424, in 0.418s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01397, val loss: 0.01442, in 0.367s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27441, val loss: 0.27381, in 0.300s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34850, val loss: 0.34815, in 0.333s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25537, val loss: 0.25332, in 0.311s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01382, val loss: 0.01423, in 0.445s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01447, val loss: 0.01474, in 0.402s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21464, val loss: 0.21277, in 0.334s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32948, in 0.337s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26442, val loss: 0.26380, in 0.417s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24745, val loss: 0.24535, in 0.378s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20991, val loss: 0.20799, in 0.421s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01387, val loss: 0.01432, in 0.734s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01373, val loss: 0.01402, in 0.766s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25507, val loss: 0.25438, in 0.395s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31362, val loss: 0.31320, in 0.450s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20569, val loss: 0.20391, in 0.278s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24013, val loss: 0.23798, in 0.431s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01353, val loss: 0.01394, in 0.752s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01427, val loss: 0.01456, in 0.781s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01367, val loss: 0.01411, in 0.332s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01361, val loss: 0.01390, in 0.313s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24698, val loss: 0.24614, in 0.282s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29864, val loss: 0.29808, in 0.256s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23350, val loss: 0.23150, in 0.267s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20105, val loss: 0.19911, in 0.298s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01374, in 0.368s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01435, in 0.357s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23971, val loss: 0.23875, in 0.291s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19730, val loss: 0.19519, in 0.202s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01346, val loss: 0.01390, in 0.395s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22669, val loss: 0.22459, in 0.265s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01335, val loss: 0.01364, in 0.400s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28588, val loss: 0.28528, in 0.320s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19390, val loss: 0.19180, in 0.223s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23308, val loss: 0.23206, in 0.269s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01390, val loss: 0.01418, in 0.408s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22103, val loss: 0.21889, in 0.297s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01356, in 0.460s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27403, val loss: 0.27328, in 0.322s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01316, val loss: 0.01344, in 0.395s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01329, val loss: 0.01372, in 0.417s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19065, val loss: 0.18847, in 0.284s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22674, val loss: 0.22562, in 0.321s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21615, val loss: 0.21415, in 0.292s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26400, val loss: 0.26314, in 0.340s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01342, in 0.434s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18738, val loss: 0.18511, in 0.288s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01370, val loss: 0.01398, in 0.501s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01314, val loss: 0.01356, in 0.396s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22118, val loss: 0.21991, in 0.290s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01294, val loss: 0.01322, in 0.485s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21062, val loss: 0.20841, in 0.306s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25495, val loss: 0.25399, in 0.305s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18143, in 0.238s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21523, val loss: 0.21386, in 0.293s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20644, val loss: 0.20423, in 0.264s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01316, in 0.438s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01352, val loss: 0.01381, in 0.421s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18099, val loss: 0.17882, in 0.216s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01339, in 0.454s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24642, val loss: 0.24532, in 0.301s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01298, in 0.439s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21053, val loss: 0.20907, in 0.263s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20255, val loss: 0.20028, in 0.235s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17734, val loss: 0.17512, in 0.331s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01264, val loss: 0.01305, in 0.383s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23917, val loss: 0.23800, in 0.337s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01330, val loss: 0.01360, in 0.524s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20640, val loss: 0.20484, in 0.347s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01271, val loss: 0.01313, in 0.511s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19810, val loss: 0.19572, in 0.391s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17296, val loss: 0.17068, in 0.301s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01254, val loss: 0.01283, in 0.549s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23258, val loss: 0.23132, in 0.331s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19446, val loss: 0.19205, in 0.229s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01245, val loss: 0.01287, in 0.453s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20169, val loss: 0.20004, in 0.298s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17058, val loss: 0.16825, in 0.235s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01312, val loss: 0.01340, in 0.394s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01295, in 0.454s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22614, val loss: 0.22475, in 0.282s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01242, val loss: 0.01271, in 0.363s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19118, val loss: 0.18868, in 0.226s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16833, val loss: 0.16594, in 0.219s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19789, val loss: 0.19617, in 0.273s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01227, val loss: 0.01269, in 0.497s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18734, val loss: 0.18488, in 0.290s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22054, val loss: 0.21904, in 0.307s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01326, in 0.453s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19433, val loss: 0.19266, in 0.267s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16616, val loss: 0.16364, in 0.279s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01253, in 0.468s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01232, val loss: 0.01274, in 0.500s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18123, in 0.228s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19123, val loss: 0.18952, in 0.230s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21503, val loss: 0.21335, in 0.331s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16342, val loss: 0.16090, in 0.321s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01209, val loss: 0.01249, in 0.416s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01278, val loss: 0.01308, in 0.503s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18070, val loss: 0.17836, in 0.392s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18749, val loss: 0.18581, in 0.375s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01209, val loss: 0.01236, in 0.511s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16130, val loss: 0.15871, in 0.312s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21041, val loss: 0.20865, in 0.355s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01258, in 0.541s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01197, val loss: 0.01238, in 0.537s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17823, val loss: 0.17579, in 0.318s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18374, val loss: 0.18213, in 0.308s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15956, val loss: 0.15692, in 0.301s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20621, val loss: 0.20433, in 0.354s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01256, val loss: 0.01287, in 0.613s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01202, val loss: 0.01242, in 0.467s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17574, val loss: 0.17330, in 0.287s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01188, val loss: 0.01216, in 0.553s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15778, val loss: 0.15509, in 0.269s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18110, val loss: 0.17944, in 0.306s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20118, val loss: 0.19916, in 0.310s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01181, val loss: 0.01222, in 0.518s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17868, val loss: 0.17698, in 0.237s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17197, val loss: 0.16965, in 0.283s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15576, val loss: 0.15308, in 0.268s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01238, val loss: 0.01267, in 0.387s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19759, val loss: 0.19555, in 0.249s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01175, val loss: 0.01203, in 0.375s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01224, in 0.452s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17624, val loss: 0.17455, in 0.223s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15393, val loss: 0.15123, in 0.255s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16869, val loss: 0.16638, in 0.303s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19404, val loss: 0.19198, in 0.234s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01165, val loss: 0.01207, in 0.447s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01251, in 0.401s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15259, val loss: 0.14987, in 0.207s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01191, in 0.399s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17275, val loss: 0.17096, in 0.297s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01166, val loss: 0.01208, in 0.402s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16639, val loss: 0.16401, in 0.246s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19017, val loss: 0.18819, in 0.271s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16433, val loss: 0.16194, in 0.203s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14773, in 0.280s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01149, val loss: 0.01190, in 0.402s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16900, val loss: 0.16726, in 0.284s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01210, val loss: 0.01240, in 0.384s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18635, val loss: 0.18435, in 0.245s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01152, val loss: 0.01192, in 0.404s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01150, val loss: 0.01178, in 0.455s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16242, val loss: 0.16001, in 0.225s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14886, val loss: 0.14614, in 0.270s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16533, val loss: 0.16364, in 0.265s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18356, val loss: 0.18159, in 0.231s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16041, val loss: 0.15801, in 0.258s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01127, val loss: 0.01168, in 0.446s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14752, val loss: 0.14478, in 0.220s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01189, val loss: 0.01219, in 0.428s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16350, val loss: 0.16185, in 0.223s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01177, in 0.373s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01136, val loss: 0.01163, in 0.366s\n",
      "[161/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18088, val loss: 0.17890, in 0.249s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14492, val loss: 0.14228, in 0.236s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15702, val loss: 0.15457, in 0.260s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16137, val loss: 0.15974, in 0.234s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17824, val loss: 0.17619, in 0.243s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01173, val loss: 0.01204, in 0.455s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01120, val loss: 0.01147, in 0.383s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01151, in 0.481s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01121, val loss: 0.01162, in 0.407s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14261, val loss: 0.13995, in 0.258s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15512, val loss: 0.15259, in 0.246s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15951, val loss: 0.15787, in 0.251s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17571, val loss: 0.17370, in 0.234s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14164, val loss: 0.13894, in 0.263s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15244, val loss: 0.14999, in 0.307s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15717, val loss: 0.15552, in 0.292s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01158, val loss: 0.01188, in 0.407s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01108, val loss: 0.01134, in 0.407s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17225, val loss: 0.17013, in 0.328s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01149, in 0.426s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01094, val loss: 0.01135, in 0.504s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14015, val loss: 0.13742, in 0.277s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15065, val loss: 0.14819, in 0.288s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15451, val loss: 0.15296, in 0.289s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17005, val loss: 0.16792, in 0.286s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13861, val loss: 0.13584, in 0.273s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01139, val loss: 0.01169, in 0.464s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01096, val loss: 0.01136, in 0.434s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14829, val loss: 0.14582, in 0.260s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15267, val loss: 0.15109, in 0.290s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01075, val loss: 0.01116, in 0.433s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01089, val loss: 0.01115, in 0.574s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16630, val loss: 0.16426, in 0.276s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13753, val loss: 0.13474, in 0.234s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14663, val loss: 0.14421, in 0.257s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15098, val loss: 0.14935, in 0.258s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16444, val loss: 0.16241, in 0.285s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13297, in 0.257s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01154, in 0.483s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01081, val loss: 0.01120, in 0.519s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01059, val loss: 0.01100, in 0.468s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14490, val loss: 0.14252, in 0.278s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01100, in 0.485s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14850, val loss: 0.14693, in 0.296s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16224, val loss: 0.16020, in 0.247s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13420, val loss: 0.13150, in 0.270s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14313, val loss: 0.14073, in 0.297s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14684, val loss: 0.14528, in 0.304s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15986, val loss: 0.15785, in 0.342s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13326, val loss: 0.13058, in 0.306s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01141, in 0.565s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01068, val loss: 0.01106, in 0.533s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01047, val loss: 0.01088, in 0.563s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01059, val loss: 0.01087, in 0.545s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14160, val loss: 0.13922, in 0.319s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14536, val loss: 0.14381, in 0.280s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15776, val loss: 0.15582, in 0.274s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13218, val loss: 0.12946, in 0.246s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01095, val loss: 0.01124, in 0.399s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14356, val loss: 0.14207, in 0.254s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01055, val loss: 0.01094, in 0.449s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15640, val loss: 0.15445, in 0.271s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13759, val loss: 0.13523, in 0.368s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01072, in 0.521s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13029, val loss: 0.12766, in 0.348s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01042, val loss: 0.01069, in 0.532s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14238, val loss: 0.14079, in 0.329s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15449, val loss: 0.15254, in 0.317s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13567, val loss: 0.13337, in 0.336s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12781, val loss: 0.12528, in 0.318s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01078, val loss: 0.01107, in 0.612s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14037, val loss: 0.13881, in 0.278s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15276, val loss: 0.15076, in 0.259s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01015, val loss: 0.01056, in 0.483s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01079, in 0.612s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01059, in 0.460s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13447, val loss: 0.13208, in 0.274s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12638, val loss: 0.12387, in 0.241s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13723, in 0.277s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15129, val loss: 0.14925, in 0.254s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13230, val loss: 0.12994, in 0.324s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01063, val loss: 0.01092, in 0.483s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12405, val loss: 0.12157, in 0.345s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01031, val loss: 0.01069, in 0.436s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13724, val loss: 0.13579, in 0.298s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01019, val loss: 0.01047, in 0.509s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14920, val loss: 0.14709, in 0.307s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01000, val loss: 0.01040, in 0.564s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13072, val loss: 0.12843, in 0.278s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12010, in 0.219s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13588, val loss: 0.13443, in 0.251s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14681, val loss: 0.14478, in 0.249s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01020, val loss: 0.01057, in 0.367s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.12717, in 0.217s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12121, val loss: 0.11884, in 0.252s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01032, in 0.379s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01049, val loss: 0.01078, in 0.497s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00989, val loss: 0.01029, in 0.389s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13475, val loss: 0.13330, in 0.232s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14551, val loss: 0.14351, in 0.237s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12844, val loss: 0.12608, in 0.226s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12021, val loss: 0.11780, in 0.249s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01043, in 0.395s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13384, val loss: 0.13228, in 0.225s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14423, val loss: 0.14225, in 0.214s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01019, in 0.374s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12698, val loss: 0.12470, in 0.246s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00983, val loss: 0.01023, in 0.371s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01038, val loss: 0.01066, in 0.420s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11935, val loss: 0.11689, in 0.198s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13273, val loss: 0.13109, in 0.220s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14260, val loss: 0.14063, in 0.242s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12598, val loss: 0.12371, in 0.233s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11768, val loss: 0.11518, in 0.338s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00994, val loss: 0.01033, in 0.497s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13127, val loss: 0.12961, in 0.289s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01053, in 0.470s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14116, val loss: 0.13929, in 0.320s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00972, val loss: 0.01012, in 0.504s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.01003, in 0.579s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11618, val loss: 0.11362, in 0.255s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12455, val loss: 0.12228, in 0.407s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12998, val loss: 0.12841, in 0.283s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13997, val loss: 0.13807, in 0.214s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12339, val loss: 0.12108, in 0.225s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11504, val loss: 0.11253, in 0.253s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.01021, in 0.499s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01012, val loss: 0.01039, in 0.431s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12905, val loss: 0.12743, in 0.225s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00956, val loss: 0.00995, in 0.422s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00966, val loss: 0.00992, in 0.397s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13812, val loss: 0.13619, in 0.240s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12219, val loss: 0.11990, in 0.242s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11406, val loss: 0.11157, in 0.240s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13712, val loss: 0.13515, in 0.210s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12754, val loss: 0.12591, in 0.259s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00950, val loss: 0.00990, in 0.360s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.11916, in 0.213s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11290, val loss: 0.11044, in 0.220s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.01008, in 0.459s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01001, val loss: 0.01028, in 0.422s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00951, val loss: 0.00977, in 0.437s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12438, in 0.223s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13550, val loss: 0.13357, in 0.298s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11174, val loss: 0.10930, in 0.251s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11968, val loss: 0.11745, in 0.305s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12421, val loss: 0.12269, in 0.294s\n",
      "[62/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13399, val loss: 0.13201, in 0.273s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00981, in 0.464s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00958, val loss: 0.00997, in 0.437s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00989, val loss: 0.01016, in 0.469s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11084, val loss: 0.10841, in 0.281s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11846, val loss: 0.11629, in 0.265s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00965, in 0.536s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13293, val loss: 0.13097, in 0.265s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12216, val loss: 0.12067, in 0.306s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11001, val loss: 0.10753, in 0.260s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11697, val loss: 0.11480, in 0.255s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.01004, in 0.427s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13144, val loss: 0.12946, in 0.259s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00928, val loss: 0.00967, in 0.530s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12046, val loss: 0.11902, in 0.282s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00982, in 0.561s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00931, val loss: 0.00957, in 0.450s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11559, val loss: 0.11345, in 0.253s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10888, val loss: 0.10634, in 0.278s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11816, in 0.235s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12924, val loss: 0.12731, in 0.272s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00972, val loss: 0.00998, in 0.392s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11455, val loss: 0.11247, in 0.231s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10764, val loss: 0.10513, in 0.281s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00934, val loss: 0.00972, in 0.368s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00915, val loss: 0.00953, in 0.423s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12836, val loss: 0.12651, in 0.232s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11821, val loss: 0.11679, in 0.284s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11347, val loss: 0.11150, in 0.268s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00917, val loss: 0.00942, in 0.547s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10655, val loss: 0.10405, in 0.259s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12759, val loss: 0.12571, in 0.224s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.00989, in 0.375s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11676, val loss: 0.11530, in 0.250s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10600, val loss: 0.10354, in 0.212s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11142, val loss: 0.10937, in 0.257s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00923, val loss: 0.00962, in 0.458s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00902, val loss: 0.00941, in 0.460s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12663, val loss: 0.12464, in 0.223s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11617, val loss: 0.11467, in 0.219s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00905, val loss: 0.00931, in 0.385s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10504, val loss: 0.10260, in 0.225s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00953, val loss: 0.00978, in 0.402s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12540, val loss: 0.12340, in 0.215s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10918, val loss: 0.10722, in 0.284s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11477, val loss: 0.11337, in 0.254s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00892, val loss: 0.00930, in 0.380s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10404, val loss: 0.10164, in 0.199s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00913, val loss: 0.00952, in 0.454s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00920, in 0.350s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12362, val loss: 0.12166, in 0.245s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10788, val loss: 0.10593, in 0.231s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11275, in 0.222s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10269, val loss: 0.10031, in 0.242s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00941, val loss: 0.00967, in 0.434s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12255, val loss: 0.12060, in 0.213s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10667, val loss: 0.10473, in 0.239s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00884, val loss: 0.00922, in 0.405s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11177, in 0.248s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00904, val loss: 0.00942, in 0.388s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10221, val loss: 0.09979, in 0.211s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10594, val loss: 0.10398, in 0.185s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00882, val loss: 0.00907, in 0.458s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12084, val loss: 0.11896, in 0.249s\n",
      "[66/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.00937, val loss: 0.00962, in 0.315s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11187, val loss: 0.11059, in 0.224s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09723, in 0.336s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10536, val loss: 0.10345, in 0.285s\n",
      "[74/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11969, val loss: 0.11777, in 0.287s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00933, in 0.414s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.00910, in 0.490s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00873, val loss: 0.00898, in 0.433s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11050, val loss: 0.10927, in 0.305s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00921, val loss: 0.00946, in 0.440s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09851, val loss: 0.09622, in 0.247s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10467, val loss: 0.10276, in 0.235s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11846, val loss: 0.11658, in 0.302s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10956, val loss: 0.10841, in 0.265s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00882, val loss: 0.00920, in 0.467s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09776, val loss: 0.09549, in 0.274s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00861, val loss: 0.00899, in 0.457s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10296, val loss: 0.10102, in 0.297s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11510, in 0.229s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10882, val loss: 0.10763, in 0.226s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00911, val loss: 0.00936, in 0.447s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09723, val loss: 0.09495, in 0.197s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00860, val loss: 0.00886, in 0.570s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10198, val loss: 0.10001, in 0.270s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11618, val loss: 0.11430, in 0.268s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10617, in 0.293s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00908, in 0.454s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00849, val loss: 0.00887, in 0.445s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09648, val loss: 0.09421, in 0.310s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11363, val loss: 0.11179, in 0.297s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09752, in 0.343s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00881, in 0.440s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10647, val loss: 0.10531, in 0.233s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00899, val loss: 0.00924, in 0.525s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09578, val loss: 0.09345, in 0.262s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11123, in 0.213s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09854, val loss: 0.09660, in 0.234s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00864, val loss: 0.00901, in 0.431s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10545, val loss: 0.10430, in 0.238s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09535, val loss: 0.09307, in 0.222s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00836, val loss: 0.00874, in 0.556s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00848, val loss: 0.00873, in 0.407s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00890, val loss: 0.00915, in 0.397s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09791, val loss: 0.09594, in 0.209s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11199, val loss: 0.11010, in 0.250s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10257, val loss: 0.10148, in 0.295s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09432, val loss: 0.09206, in 0.262s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09693, val loss: 0.09498, in 0.215s\n",
      "[81/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11106, val loss: 0.10917, in 0.218s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00855, val loss: 0.00892, in 0.449s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00831, val loss: 0.00869, in 0.361s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10184, val loss: 0.10071, in 0.258s\n",
      "[80/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09371, val loss: 0.09144, in 0.227s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00903, in 0.457s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11011, val loss: 0.10824, in 0.244s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09571, val loss: 0.09380, in 0.256s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00861, in 0.493s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10099, val loss: 0.09986, in 0.221s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00882, in 0.380s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00858, in 0.392s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10911, val loss: 0.10728, in 0.238s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09154, val loss: 0.08930, in 0.317s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09488, val loss: 0.09302, in 0.275s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10001, val loss: 0.09892, in 0.209s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00828, val loss: 0.00853, in 0.347s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09087, val loss: 0.08865, in 0.222s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00867, val loss: 0.00891, in 0.488s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10609, in 0.236s\n",
      "[77/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09363, val loss: 0.09185, in 0.248s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09951, val loss: 0.09850, in 0.226s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00875, in 0.417s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00851, in 0.435s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09045, val loss: 0.08822, in 0.214s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10705, val loss: 0.10528, in 0.255s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09319, val loss: 0.09142, in 0.219s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09903, val loss: 0.09800, in 0.198s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00844, in 0.421s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00883, in 0.410s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00833, val loss: 0.00868, in 0.323s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10654, val loss: 0.10476, in 0.203s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08748, in 0.260s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09832, val loss: 0.09728, in 0.232s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09211, val loss: 0.09030, in 0.253s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00840, in 0.407s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00834, in 0.417s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08915, val loss: 0.08694, in 0.250s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10358, val loss: 0.10186, in 0.291s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09740, val loss: 0.09631, in 0.260s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.08975, in 0.259s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00862, in 0.360s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00849, val loss: 0.00873, in 0.459s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08883, val loss: 0.08663, in 0.273s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00830, in 0.438s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10280, val loss: 0.10108, in 0.292s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09677, val loss: 0.09570, in 0.271s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09100, val loss: 0.08925, in 0.285s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00804, val loss: 0.00830, in 0.437s\n",
      "[189/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08796, val loss: 0.08573, in 0.226s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09530, in 0.213s\n",
      "[88/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09051, val loss: 0.08877, in 0.202s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00818, val loss: 0.00854, in 0.481s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10111, val loss: 0.09944, in 0.269s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00840, val loss: 0.00864, in 0.506s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00820, in 0.642s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09003, val loss: 0.08825, in 0.414s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09537, val loss: 0.09435, in 0.464s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08612, val loss: 0.08391, in 0.518s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00822, in 0.611s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10019, val loss: 0.09858, in 0.471s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00812, val loss: 0.00849, in 0.568s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08859, val loss: 0.08688, in 0.259s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08556, val loss: 0.08337, in 0.214s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00849, in 0.630s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09906, val loss: 0.09742, in 0.241s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09296, val loss: 0.09200, in 0.307s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00789, val loss: 0.00816, in 0.662s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00769, val loss: 0.00810, in 0.783s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08487, val loss: 0.08269, in 0.534s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00800, val loss: 0.00837, in 0.679s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08663, val loss: 0.08493, in 0.583s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09151, val loss: 0.09055, in 0.520s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09840, val loss: 0.09676, in 0.532s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00814, val loss: 0.00838, in 0.740s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08306, val loss: 0.08096, in 0.276s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08536, val loss: 0.08374, in 0.238s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09761, val loss: 0.09601, in 0.259s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00782, val loss: 0.00809, in 0.402s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08946, val loss: 0.08854, in 0.304s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00801, in 0.424s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00792, val loss: 0.00829, in 0.473s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08468, val loss: 0.08311, in 0.267s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08220, val loss: 0.08013, in 0.316s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09668, val loss: 0.09509, in 0.283s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08832, val loss: 0.08737, in 0.312s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00829, in 0.500s\n",
      "[192/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.08173, val loss: 0.07967, in 0.341s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08402, val loss: 0.08250, in 0.389s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00754, val loss: 0.00795, in 0.558s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09583, val loss: 0.09421, in 0.337s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00772, val loss: 0.00799, in 0.635s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08750, val loss: 0.08660, in 0.376s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00785, val loss: 0.00821, in 0.614s\n",
      "[195/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09544, val loss: 0.09381, in 0.282s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08036, val loss: 0.07830, in 0.328s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08332, val loss: 0.08183, in 0.328s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00801, val loss: 0.00824, in 0.548s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08557, in 0.321s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00747, val loss: 0.00787, in 0.467s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00763, val loss: 0.00789, in 0.490s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08202, val loss: 0.08063, in 0.287s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09266, in 0.326s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00776, val loss: 0.00812, in 0.445s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07938, val loss: 0.07735, in 0.330s\n",
      "[105/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08541, val loss: 0.08454, in 0.316s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00789, val loss: 0.00812, in 0.527s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09367, val loss: 0.09204, in 0.278s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08089, val loss: 0.07950, in 0.299s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07894, val loss: 0.07692, in 0.279s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00780, in 0.512s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08458, val loss: 0.08370, in 0.291s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00736, val loss: 0.00775, in 0.600s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00770, val loss: 0.00806, in 0.495s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07861, val loss: 0.07659, in 0.243s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08017, val loss: 0.07874, in 0.282s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09128, in 0.299s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08327, in 0.250s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00779, val loss: 0.00803, in 0.516s\n",
      "[195/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07988, val loss: 0.07846, in 0.243s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09166, val loss: 0.09009, in 0.268s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07770, val loss: 0.07570, in 0.300s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00769, in 0.504s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08370, val loss: 0.08278, in 0.254s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00796, in 0.504s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07892, val loss: 0.07754, in 0.244s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09125, val loss: 0.08966, in 0.231s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07741, val loss: 0.07540, in 0.238s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08342, val loss: 0.08255, in 0.217s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00793, in 0.429s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07784, val loss: 0.07654, in 0.297s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09016, val loss: 0.08862, in 0.284s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07649, val loss: 0.07447, in 0.314s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08212, val loss: 0.08127, in 0.276s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00733, val loss: 0.00759, in 0.512s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00753, val loss: 0.00789, in 0.433s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08950, val loss: 0.08799, in 0.283s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07728, val loss: 0.07599, in 0.300s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07576, val loss: 0.07375, in 0.293s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08146, val loss: 0.08066, in 0.327s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00760, val loss: 0.00782, in 0.601s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08894, val loss: 0.08741, in 0.314s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07632, val loss: 0.07505, in 0.302s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08093, val loss: 0.08017, in 0.246s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00724, val loss: 0.00750, in 0.563s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00779, in 0.568s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07529, val loss: 0.07329, in 0.338s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00755, val loss: 0.00778, in 0.515s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08832, val loss: 0.08681, in 0.388s\n",
      "[98/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08065, val loss: 0.07990, in 0.378s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07545, val loss: 0.07419, in 0.425s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07492, val loss: 0.07293, in 0.356s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00742, in 0.573s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08753, val loss: 0.08598, in 0.308s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07417, val loss: 0.07216, in 0.289s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07493, val loss: 0.07369, in 0.324s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07902, val loss: 0.07831, in 0.348s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00746, val loss: 0.00768, in 0.658s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08653, val loss: 0.08501, in 0.371s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07465, val loss: 0.07341, in 0.320s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07798, val loss: 0.07727, in 0.325s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07305, val loss: 0.07105, in 0.370s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00705, val loss: 0.00732, in 0.622s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08591, val loss: 0.08443, in 0.188s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07413, val loss: 0.07288, in 0.241s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07258, val loss: 0.07056, in 0.232s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07664, val loss: 0.07592, in 0.247s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00761, in 0.393s\n",
      "[200/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08399, in 0.250s\n",
      "[102/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07235, val loss: 0.07032, in 0.195s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07585, val loss: 0.07512, in 0.260s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07286, val loss: 0.07167, in 0.292s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07151, val loss: 0.06950, in 0.243s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08339, val loss: 0.08197, in 0.289s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07519, val loss: 0.07451, in 0.228s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07196, val loss: 0.07082, in 0.233s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07110, val loss: 0.06912, in 0.252s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08233, val loss: 0.08092, in 0.239s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07414, val loss: 0.07348, in 0.245s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07116, val loss: 0.07003, in 0.238s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07053, val loss: 0.06858, in 0.228s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07385, val loss: 0.07319, in 0.224s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07044, val loss: 0.06933, in 0.268s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08057, val loss: 0.07920, in 0.336s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06954, val loss: 0.06758, in 0.281s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07358, val loss: 0.07291, in 0.256s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08008, val loss: 0.07872, in 0.233s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06975, val loss: 0.06865, in 0.275s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07308, val loss: 0.07245, in 0.267s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06908, val loss: 0.06715, in 0.307s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07974, val loss: 0.07841, in 0.247s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06891, val loss: 0.06787, in 0.241s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06874, val loss: 0.06682, in 0.186s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07204, val loss: 0.07142, in 0.214s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06838, val loss: 0.06733, in 0.193s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07895, val loss: 0.07762, in 0.241s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06812, val loss: 0.06620, in 0.209s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07110, val loss: 0.07048, in 0.222s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07838, val loss: 0.07708, in 0.238s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06735, val loss: 0.06635, in 0.282s\n",
      "[116/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06770, val loss: 0.06581, in 0.188s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07062, val loss: 0.07006, in 0.222s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07798, val loss: 0.07670, in 0.196s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06666, val loss: 0.06569, in 0.216s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06667, val loss: 0.06487, in 0.215s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06998, val loss: 0.06947, in 0.195s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07774, val loss: 0.07648, in 0.185s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06625, val loss: 0.06531, in 0.226s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06621, val loss: 0.06441, in 0.195s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06926, val loss: 0.06873, in 0.242s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07675, val loss: 0.07552, in 0.295s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06599, val loss: 0.06505, in 0.245s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06871, val loss: 0.06820, in 0.208s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06548, val loss: 0.06372, in 0.297s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07628, val loss: 0.07504, in 0.223s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06518, val loss: 0.06426, in 0.233s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06464, val loss: 0.06289, in 0.265s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06814, val loss: 0.06760, in 0.276s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07559, val loss: 0.07435, in 0.238s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06450, val loss: 0.06363, in 0.223s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06436, val loss: 0.06261, in 0.190s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06767, val loss: 0.06713, in 0.238s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06426, val loss: 0.06339, in 0.181s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07442, val loss: 0.07315, in 0.284s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06396, val loss: 0.06225, in 0.248s\n",
      "[131/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06696, val loss: 0.06642, in 0.258s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06376, val loss: 0.06286, in 0.254s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07330, val loss: 0.07207, in 0.250s\n",
      "[116/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06332, val loss: 0.06162, in 0.266s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06654, val loss: 0.06603, in 0.257s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06313, val loss: 0.06224, in 0.265s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07274, val loss: 0.07151, in 0.280s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06309, val loss: 0.06139, in 0.225s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06582, val loss: 0.06530, in 0.236s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06161, in 0.267s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07247, val loss: 0.07128, in 0.245s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06239, val loss: 0.06075, in 0.259s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06182, val loss: 0.06096, in 0.236s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06483, val loss: 0.06433, in 0.297s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07210, val loss: 0.07092, in 0.232s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06166, val loss: 0.06001, in 0.310s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06441, val loss: 0.06392, in 0.252s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06140, val loss: 0.06058, in 0.273s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07136, val loss: 0.07021, in 0.236s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06128, val loss: 0.05961, in 0.179s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06117, val loss: 0.06035, in 0.193s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06395, val loss: 0.06346, in 0.230s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07028, val loss: 0.06915, in 0.234s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06074, val loss: 0.05905, in 0.236s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06349, val loss: 0.06299, in 0.203s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06082, val loss: 0.06001, in 0.258s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06979, val loss: 0.06866, in 0.213s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06023, val loss: 0.05856, in 0.194s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06329, val loss: 0.06278, in 0.172s\n",
      "[129/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06065, val loss: 0.05984, in 0.155s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05988, val loss: 0.05821, in 0.185s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06846, val loss: 0.06737, in 0.265s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06295, val loss: 0.06243, in 0.184s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06013, val loss: 0.05934, in 0.181s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05969, val loss: 0.05801, in 0.190s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06226, val loss: 0.06176, in 0.242s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06777, val loss: 0.06670, in 0.266s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05963, val loss: 0.05885, in 0.247s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00768, in 0.489s\n",
      "Fit 200 trees in 86.882 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.410s\n",
      "Time spent finding best splits:  1.619s\n",
      "Time spent applying splits:      10.676s\n",
      "Time spent predicting:           0.624s\n",
      "Binning 0.111 GB of training data: 1 tree, 6 leaves, max depth = 3, train loss: 0.05937, val loss: 0.05771, in 0.197s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06711, val loss: 0.06604, in 0.164s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05908, val loss: 0.05831, in 0.160s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06134, val loss: 0.06087, in 0.191s\n",
      "[132/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05916, val loss: 0.05748, in 0.148s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06685, val loss: 0.06581, in 0.134s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05866, val loss: 0.05788, in 0.145s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06041, val loss: 0.05997, in 0.155s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05881, val loss: 0.05714, in 0.163s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06660, val loss: 0.06557, in 0.152s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05836, val loss: 0.05760, in 0.226s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05999, val loss: 0.05954, in 0.231s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06599, val loss: 0.06497, in 0.225s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05784, val loss: 0.05623, in 0.312s\n",
      "[144/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05807, val loss: 0.05734, in 0.202s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05953, val loss: 0.05911, in 0.233s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06517, val loss: 0.06419, in 0.243s\n",
      "[129/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05762, val loss: 0.05601, in 0.221s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05754, val loss: 0.05684, in 0.241s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05902, val loss: 0.05863, in 0.247s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06451, val loss: 0.06356, in 0.226s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05684, val loss: 0.05519, in 0.210s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05697, val loss: 0.05632, in 0.244s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05848, val loss: 0.05806, in 0.235s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06419, val loss: 0.06326, in 0.220s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05591, val loss: 0.05428, in 0.283s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05813, val loss: 0.05772, in 0.196s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05663, val loss: 0.05600, in 0.250s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06359, val loss: 0.06268, in 0.204s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00735, val loss: 0.00771, in 0.570s\n",
      "Fit 200 trees in 87.597 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.717s\n",
      "Time spent finding best splits:  1.418s\n",
      "Time spent applying splits:      10.412s\n",
      "Time spent predicting:           0.591s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05539, val loss: 0.05378, in 0.236s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05601, val loss: 0.05539, in 0.217s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05709, val loss: 0.05671, in 0.247s\n",
      "[139/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06317, val loss: 0.06229, in 0.238s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05473, val loss: 0.05316, in 0.176s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05583, val loss: 0.05521, in 0.171s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05647, val loss: 0.05612, in 0.208s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06263, val loss: 0.06176, in 0.175s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05419, val loss: 0.05266, in 0.208s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05537, val loss: 0.05476, in 0.181s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05599, val loss: 0.05565, in 0.184s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06228, val loss: 0.06141, in 0.228s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05401, val loss: 0.05249, in 0.190s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05508, val loss: 0.05450, in 0.204s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05581, val loss: 0.05545, in 0.177s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06178, val loss: 0.06093, in 0.231s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00698, val loss: 0.00724, in 0.375s\n",
      "Fit 200 trees in 87.496 s, (6200 total leaves)\n",
      "Time spent computing histograms: 52.062s\n",
      "Time spent finding best splits:  1.477s\n",
      "Time spent applying splits:      10.521s\n",
      "Time spent predicting:           0.598s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05470, val loss: 0.05411, in 0.265s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05355, val loss: 0.05204, in 0.298s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00752, in 0.350s\n",
      "Fit 200 trees in 88.054 s, (6199 total leaves)\n",
      "Time spent computing histograms: 52.334s\n",
      "Time spent finding best splits:  1.544s\n",
      "Time spent applying splits:      10.507s\n",
      "Time spent predicting:           0.610s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05548, val loss: 0.05512, in 0.339s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06095, val loss: 0.06007, in 0.323s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05428, val loss: 0.05369, in 0.260s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05266, val loss: 0.05118, in 0.283s\n",
      "[153/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05500, val loss: 0.05465, in 0.213s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06068, val loss: 0.05983, in 0.225s\n",
      "[138/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05371, val loss: 0.05315, in 0.317s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05234, val loss: 0.05084, in 0.274s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05439, val loss: 0.05404, in 0.334s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06027, val loss: 0.05944, in 0.373s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05356, val loss: 0.05300, in 0.292s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05219, val loss: 0.05069, in 0.293s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05423, val loss: 0.05389, in 0.286s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06009, val loss: 0.05925, in 0.182s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05342, val loss: 0.05286, in 0.213s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05031, in 0.239s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05372, val loss: 0.05338, in 0.237s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05909, val loss: 0.05828, in 0.242s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05305, val loss: 0.05252, in 0.198s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05106, val loss: 0.04958, in 0.247s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05347, val loss: 0.05316, in 0.198s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05880, val loss: 0.05800, in 0.203s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05268, val loss: 0.05219, in 0.218s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05056, val loss: 0.04913, in 0.226s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05282, val loss: 0.05252, in 0.235s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05225, val loss: 0.05173, in 0.206s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05851, val loss: 0.05773, in 0.262s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05043, val loss: 0.04899, in 0.194s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05265, val loss: 0.05238, in 0.206s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05818, val loss: 0.05742, in 0.192s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05186, val loss: 0.05134, in 0.224s\n",
      "[152/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05239, val loss: 0.05210, in 0.171s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04966, val loss: 0.04829, in 0.261s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05146, val loss: 0.05097, in 0.209s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05757, val loss: 0.05684, in 0.233s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05202, val loss: 0.05175, in 0.210s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04931, val loss: 0.04796, in 0.266s\n",
      "[161/200] 4.825 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.05738, val loss: 0.05663, in 0.218s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05084, val loss: 0.05034, in 0.271s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05166, val loss: 0.05141, in 0.242s\n",
      "[153/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04891, val loss: 0.04760, in 0.205s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05671, val loss: 0.05597, in 0.229s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05140, val loss: 0.05116, in 0.182s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05025, val loss: 0.04977, in 0.226s\n",
      "[155/200] 0.223 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04833, val loss: 0.04709, in 0.199s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05655, val loss: 0.05584, in 0.186s\n",
      "[148/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05003, val loss: 0.04958, in 0.190s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05067, val loss: 0.05047, in 0.280s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62675, val loss: 0.62671, in 0.291s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04791, val loss: 0.04673, in 0.242s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05620, val loss: 0.05550, in 0.234s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04970, val loss: 0.04923, in 0.202s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04766, val loss: 0.04650, in 0.217s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05017, val loss: 0.04996, in 0.297s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57224, val loss: 0.57221, in 0.266s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05586, val loss: 0.05521, in 0.229s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04895, val loss: 0.04853, in 0.288s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04633, in 0.217s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04976, val loss: 0.04953, in 0.227s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05564, val loss: 0.05500, in 0.188s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52699, val loss: 0.52691, in 0.258s\n",
      "[4/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04876, val loss: 0.04836, in 0.180s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04714, val loss: 0.04603, in 0.218s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04939, val loss: 0.04918, in 0.198s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05532, val loss: 0.05469, in 0.202s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04817, val loss: 0.04779, in 0.226s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48877, val loss: 0.48863, in 0.258s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04680, val loss: 0.04569, in 0.200s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04924, val loss: 0.04899, in 0.174s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05452, val loss: 0.05391, in 0.232s\n",
      "[153/200] 4.822 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.04775, val loss: 0.04737, in 0.234s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45623, val loss: 0.45595, in 0.256s\n",
      "[6/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04660, val loss: 0.04549, in 0.196s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04895, val loss: 0.04870, in 0.223s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05419, val loss: 0.05355, in 0.189s\n",
      "[154/200] 0.215 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04720, val loss: 0.04681, in 0.267s\n",
      "[162/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04524, in 0.266s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05391, val loss: 0.05326, in 0.224s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42301, val loss: 0.42269, in 0.307s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04833, val loss: 0.04812, in 0.309s\n",
      "[161/200] 4.422 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.04674, val loss: 0.04639, in 0.232s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62680, val loss: 0.62673, in 0.302s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05324, val loss: 0.05262, in 0.231s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04612, val loss: 0.04500, in 0.259s\n",
      "[171/200] 4.479 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.04812, val loss: 0.04792, in 0.220s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39453, val loss: 0.39423, in 0.331s\n",
      "[8/200] 0.191 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04651, val loss: 0.04617, in 0.305s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05290, val loss: 0.05231, in 0.284s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57234, val loss: 0.57230, in 0.333s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04776, in 0.257s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04571, val loss: 0.04464, in 0.313s\n",
      "[172/200] 0.235 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36990, val loss: 0.36949, in 0.359s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04631, val loss: 0.04595, in 0.239s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62679, val loss: 0.62672, in 0.323s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05252, val loss: 0.05192, in 0.259s\n",
      "[158/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04548, val loss: 0.04440, in 0.282s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04749, val loss: 0.04729, in 0.302s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52714, val loss: 0.52704, in 0.321s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62676, val loss: 0.62668, in 0.311s\n",
      "[2/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04615, val loss: 0.04579, in 0.223s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34843, val loss: 0.34797, in 0.331s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05186, val loss: 0.05128, in 0.293s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04524, val loss: 0.04416, in 0.242s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57231, val loss: 0.57228, in 0.339s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04717, val loss: 0.04699, in 0.269s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48896, val loss: 0.48879, in 0.333s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57226, val loss: 0.57229, in 0.338s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04502, val loss: 0.04391, in 0.202s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04567, val loss: 0.04531, in 0.346s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05141, val loss: 0.05085, in 0.255s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04705, val loss: 0.04688, in 0.222s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32983, val loss: 0.32931, in 0.325s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52710, val loss: 0.52698, in 0.275s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45645, val loss: 0.45612, in 0.254s\n",
      "[6/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04547, val loss: 0.04510, in 0.199s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04490, val loss: 0.04379, in 0.205s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52702, val loss: 0.52697, in 0.263s\n",
      "[4/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04686, val loss: 0.04667, in 0.228s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05092, val loss: 0.05037, in 0.246s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48889, val loss: 0.48877, in 0.286s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31359, val loss: 0.31313, in 0.301s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04511, val loss: 0.04478, in 0.263s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42320, val loss: 0.42278, in 0.316s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04469, val loss: 0.04359, in 0.274s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05074, val loss: 0.05022, in 0.210s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48879, val loss: 0.48882, in 0.295s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04615, val loss: 0.04598, in 0.279s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45639, val loss: 0.45610, in 0.276s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29856, val loss: 0.29801, in 0.297s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04458, val loss: 0.04423, in 0.248s\n",
      "[170/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05022, val loss: 0.04971, in 0.252s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39468, val loss: 0.39424, in 0.289s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45628, val loss: 0.45619, in 0.265s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04408, val loss: 0.04302, in 0.298s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04583, val loss: 0.04568, in 0.229s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04432, val loss: 0.04397, in 0.221s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42314, val loss: 0.42279, in 0.294s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05009, val loss: 0.04958, in 0.204s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28573, val loss: 0.28512, in 0.285s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04393, val loss: 0.04289, in 0.186s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04542, in 0.218s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42308, val loss: 0.42288, in 0.273s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36998, val loss: 0.36948, in 0.282s\n",
      "[9/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04422, val loss: 0.04387, in 0.182s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04963, val loss: 0.04912, in 0.211s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04535, val loss: 0.04523, in 0.200s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39463, val loss: 0.39424, in 0.263s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27333, in 0.273s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04345, val loss: 0.04243, in 0.270s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04409, val loss: 0.04374, in 0.190s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39459, val loss: 0.39434, in 0.277s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34853, val loss: 0.34794, in 0.279s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04936, val loss: 0.04886, in 0.215s\n",
      "[166/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04517, val loss: 0.04507, in 0.188s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04323, val loss: 0.04221, in 0.220s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36999, val loss: 0.36959, in 0.275s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26390, val loss: 0.26312, in 0.272s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04386, val loss: 0.04354, in 0.213s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36997, val loss: 0.36977, in 0.305s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32925, in 0.326s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04485, val loss: 0.04474, in 0.278s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04904, val loss: 0.04858, in 0.295s\n",
      "[167/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04292, val loss: 0.04194, in 0.266s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04371, val loss: 0.04340, in 0.252s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34853, val loss: 0.34820, in 0.368s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25448, val loss: 0.25361, in 0.349s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04893, val loss: 0.04846, in 0.239s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04456, val loss: 0.04447, in 0.250s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34854, val loss: 0.34830, in 0.389s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31363, val loss: 0.31290, in 0.450s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04257, val loss: 0.04158, in 0.443s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04350, val loss: 0.04320, in 0.409s\n",
      "[176/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04869, val loss: 0.04823, in 0.359s\n",
      "[169/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04418, val loss: 0.04413, in 0.420s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24649, val loss: 0.24552, in 0.503s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32954, in 0.517s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04247, val loss: 0.04148, in 0.251s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32994, val loss: 0.32965, in 0.509s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04304, val loss: 0.04274, in 0.349s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29862, val loss: 0.29772, in 0.447s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04409, val loss: 0.04406, in 0.332s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04809, val loss: 0.04763, in 0.463s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04232, val loss: 0.04133, in 0.386s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31363, val loss: 0.31318, in 0.480s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23920, val loss: 0.23817, in 0.497s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04282, val loss: 0.04252, in 0.324s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04393, val loss: 0.04389, in 0.340s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31369, val loss: 0.31330, in 0.508s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28577, val loss: 0.28485, in 0.498s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04742, val loss: 0.04696, in 0.357s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04181, val loss: 0.04082, in 0.370s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23257, val loss: 0.23142, in 0.415s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04248, val loss: 0.04218, in 0.416s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29859, val loss: 0.29804, in 0.439s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04362, val loss: 0.04357, in 0.278s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04700, val loss: 0.04652, in 0.260s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29870, val loss: 0.29814, in 0.334s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27298, in 0.348s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04134, val loss: 0.04033, in 0.271s\n",
      "[187/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04231, val loss: 0.04199, in 0.198s\n",
      "[180/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04325, val loss: 0.04317, in 0.247s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22578, val loss: 0.22448, in 0.281s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28579, val loss: 0.28526, in 0.293s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04658, val loss: 0.04612, in 0.298s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28590, val loss: 0.28536, in 0.300s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26390, val loss: 0.26282, in 0.283s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04191, val loss: 0.04160, in 0.233s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04087, val loss: 0.03987, in 0.292s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04292, val loss: 0.04284, in 0.213s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22018, val loss: 0.21881, in 0.259s\n",
      "[22/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04643, val loss: 0.04594, in 0.201s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27343, in 0.286s\n",
      "[15/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04182, val loss: 0.04150, in 0.202s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04078, val loss: 0.03977, in 0.206s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27414, val loss: 0.27357, in 0.288s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04282, val loss: 0.04274, in 0.203s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25444, val loss: 0.25323, in 0.294s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04604, val loss: 0.04556, in 0.220s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21463, val loss: 0.21321, in 0.287s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04172, val loss: 0.04142, in 0.215s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26393, val loss: 0.26331, in 0.293s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04051, val loss: 0.03950, in 0.217s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04256, val loss: 0.04249, in 0.233s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26407, val loss: 0.26343, in 0.288s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24648, val loss: 0.24523, in 0.282s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04594, val loss: 0.04546, in 0.213s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04154, val loss: 0.04126, in 0.195s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20999, val loss: 0.20849, in 0.251s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04240, val loss: 0.04234, in 0.205s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04031, val loss: 0.03933, in 0.236s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25446, val loss: 0.25374, in 0.311s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25463, val loss: 0.25385, in 0.319s\n",
      "[17/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04132, val loss: 0.04104, in 0.251s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04570, val loss: 0.04523, in 0.297s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23913, val loss: 0.23788, in 0.341s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20580, val loss: 0.20428, in 0.292s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04015, val loss: 0.03917, in 0.266s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04202, val loss: 0.04199, in 0.287s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04511, in 0.214s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04101, val loss: 0.04075, in 0.245s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24645, val loss: 0.24574, in 0.343s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24669, val loss: 0.24584, in 0.310s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23253, val loss: 0.23121, in 0.298s\n",
      "[20/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04002, val loss: 0.03904, in 0.236s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20119, val loss: 0.19964, in 0.345s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04157, val loss: 0.04156, in 0.334s\n",
      "[185/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04537, val loss: 0.04493, in 0.233s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04076, val loss: 0.04050, in 0.284s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23916, val loss: 0.23836, in 0.330s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03984, val loss: 0.03887, in 0.272s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23933, val loss: 0.23851, in 0.335s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22565, val loss: 0.22420, in 0.320s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19748, val loss: 0.19591, in 0.232s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04146, val loss: 0.04144, in 0.228s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04523, val loss: 0.04477, in 0.216s\n",
      "[180/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04067, val loss: 0.04041, in 0.209s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23252, val loss: 0.23169, in 0.399s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03944, val loss: 0.03846, in 0.392s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19411, val loss: 0.19248, in 0.357s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23272, val loss: 0.23180, in 0.391s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22003, val loss: 0.21855, in 0.394s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04132, val loss: 0.04130, in 0.372s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04503, val loss: 0.04458, in 0.383s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04014, val loss: 0.03988, in 0.441s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03921, val loss: 0.03822, in 0.251s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19101, val loss: 0.18939, in 0.282s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22571, val loss: 0.22479, in 0.323s\n",
      "[21/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04481, val loss: 0.04438, in 0.281s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04088, val loss: 0.04091, in 0.326s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22590, val loss: 0.22491, in 0.372s\n",
      "[21/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21439, val loss: 0.21291, in 0.361s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03994, val loss: 0.03970, in 0.296s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03792, in 0.266s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04456, val loss: 0.04413, in 0.254s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18777, val loss: 0.18607, in 0.318s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22008, val loss: 0.21912, in 0.311s\n",
      "[22/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04066, val loss: 0.04070, in 0.248s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22026, val loss: 0.21926, in 0.295s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20974, val loss: 0.20822, in 0.294s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03973, val loss: 0.03949, in 0.236s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03877, val loss: 0.03778, in 0.208s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18501, val loss: 0.18329, in 0.235s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04418, val loss: 0.04377, in 0.273s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04035, val loss: 0.04040, in 0.266s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21529, val loss: 0.21429, in 0.294s\n",
      "[23/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03954, val loss: 0.03929, in 0.223s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03860, val loss: 0.03759, in 0.231s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20553, val loss: 0.20408, in 0.268s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21537, val loss: 0.21431, in 0.279s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04388, val loss: 0.04347, in 0.218s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18133, val loss: 0.17964, in 0.252s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04014, val loss: 0.04018, in 0.231s\n",
      "[191/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03945, val loss: 0.03920, in 0.217s\n",
      "[193/200] 1 tree, 4 leaves, max depth = 3, train loss: 0.03854, val loss: 0.03752, in 0.201s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20973, val loss: 0.20875, in 0.299s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20086, val loss: 0.19938, in 0.307s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20980, val loss: 0.20877, in 0.313s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04006, val loss: 0.04010, in 0.216s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04359, val loss: 0.04321, in 0.249s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17770, val loss: 0.17600, in 0.345s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03883, val loss: 0.03858, in 0.348s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20549, val loss: 0.20451, in 0.330s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19713, val loss: 0.19572, in 0.272s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03984, val loss: 0.03990, in 0.289s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20568, val loss: 0.20467, in 0.339s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04331, val loss: 0.04290, in 0.339s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17345, val loss: 0.17182, in 0.354s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03859, val loss: 0.03835, in 0.344s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19368, val loss: 0.19223, in 0.334s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20085, val loss: 0.19992, in 0.392s\n",
      "[26/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03963, val loss: 0.03970, in 0.319s\n",
      "[194/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04298, val loss: 0.04258, in 0.308s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20100, val loss: 0.19997, in 0.371s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17105, val loss: 0.16939, in 0.242s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03820, val loss: 0.03794, in 0.299s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19041, val loss: 0.18907, in 0.268s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03945, val loss: 0.03956, in 0.216s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19713, val loss: 0.19617, in 0.268s\n",
      "[27/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04264, val loss: 0.04226, in 0.259s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19722, val loss: 0.19616, in 0.260s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16737, val loss: 0.16575, in 0.304s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03781, val loss: 0.03758, in 0.265s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03919, val loss: 0.03931, in 0.274s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18704, val loss: 0.18571, in 0.293s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19350, val loss: 0.19257, in 0.255s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04248, val loss: 0.04210, in 0.230s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19301, val loss: 0.19201, in 0.267s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16545, val loss: 0.16381, in 0.233s\n",
      "[37/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03756, val loss: 0.03735, in 0.241s\n",
      "[198/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03896, val loss: 0.03908, in 0.238s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04235, val loss: 0.04199, in 0.214s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18316, val loss: 0.18190, in 0.256s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18956, val loss: 0.18868, in 0.268s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18970, val loss: 0.18871, in 0.221s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16109, in 0.246s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03729, val loss: 0.03707, in 0.241s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03872, val loss: 0.03886, in 0.238s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18049, val loss: 0.17920, in 0.225s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18653, val loss: 0.18566, in 0.252s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04166, val loss: 0.04132, in 0.289s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18653, val loss: 0.18552, in 0.276s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15998, val loss: 0.15848, in 0.245s\n",
      "[39/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03718, val loss: 0.03697, in 0.187s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03860, val loss: 0.03875, in 0.230s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17685, val loss: 0.17561, in 0.289s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04135, val loss: 0.04102, in 0.234s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18276, val loss: 0.18196, in 0.251s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18273, val loss: 0.18178, in 0.230s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15822, val loss: 0.15670, in 0.221s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03836, val loss: 0.03850, in 0.239s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04117, val loss: 0.04085, in 0.225s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17341, val loss: 0.17221, in 0.230s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17864, val loss: 0.17792, in 0.286s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15633, val loss: 0.15486, in 0.242s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17983, val loss: 0.17888, in 0.288s\n",
      "[32/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04088, val loss: 0.04056, in 0.252s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16912, val loss: 0.16802, in 0.273s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17726, val loss: 0.17633, in 0.207s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17604, val loss: 0.17529, in 0.251s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15388, val loss: 0.15244, in 0.239s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04066, val loss: 0.04034, in 0.281s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16682, val loss: 0.16574, in 0.265s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17352, val loss: 0.17285, in 0.280s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17388, val loss: 0.17304, in 0.312s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15159, val loss: 0.15021, in 0.314s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04026, val loss: 0.03995, in 0.248s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16456, val loss: 0.16347, in 0.248s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17047, val loss: 0.16981, in 0.245s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17012, val loss: 0.16937, in 0.307s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14963, val loss: 0.14836, in 0.290s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04000, val loss: 0.03971, in 0.273s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16184, val loss: 0.16081, in 0.305s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16800, val loss: 0.16728, in 0.229s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14797, val loss: 0.14666, in 0.245s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16724, val loss: 0.16658, in 0.338s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03967, val loss: 0.03938, in 0.270s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15982, val loss: 0.15877, in 0.253s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14658, val loss: 0.14523, in 0.210s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16512, val loss: 0.16448, in 0.242s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16506, val loss: 0.16431, in 0.278s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03956, val loss: 0.03926, in 0.199s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15796, val loss: 0.15693, in 0.200s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14464, val loss: 0.14329, in 0.249s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16259, val loss: 0.16190, in 0.250s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16136, val loss: 0.16074, in 0.265s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15521, val loss: 0.15432, in 0.269s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14264, val loss: 0.14141, in 0.242s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15953, val loss: 0.15895, in 0.230s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15980, val loss: 0.15927, in 0.270s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15358, val loss: 0.15268, in 0.261s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14132, val loss: 0.13996, in 0.265s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15693, val loss: 0.15643, in 0.313s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15625, val loss: 0.15571, in 0.307s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15122, val loss: 0.15038, in 0.260s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14008, val loss: 0.13874, in 0.268s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15452, val loss: 0.15402, in 0.229s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15515, val loss: 0.15462, in 0.268s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14938, val loss: 0.14858, in 0.271s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13820, val loss: 0.13682, in 0.252s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15276, val loss: 0.15230, in 0.253s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15264, val loss: 0.15213, in 0.264s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14706, val loss: 0.14635, in 0.247s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13662, val loss: 0.13535, in 0.239s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15126, val loss: 0.15084, in 0.224s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15072, val loss: 0.15022, in 0.241s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14539, val loss: 0.14465, in 0.282s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13566, val loss: 0.13438, in 0.241s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14899, val loss: 0.14859, in 0.312s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14886, val loss: 0.14837, in 0.301s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13389, val loss: 0.13267, in 0.211s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14394, val loss: 0.14320, in 0.227s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03834, val loss: 0.03732, in 0.292s\n",
      "Fit 200 trees in 56.081 s, (1536 total leaves)\n",
      "Time spent computing histograms: 33.027s\n",
      "Time spent finding best splits:  0.253s\n",
      "Time spent applying splits:      4.553s\n",
      "Time spent predicting:           0.466s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.14763, val loss: 0.14718, in 0.235s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14672, val loss: 0.14628, in 0.230s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14274, val loss: 0.14198, in 0.227s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13264, val loss: 0.13145, in 0.241s\n",
      "[55/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14532, val loss: 0.14492, in 0.219s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14622, val loss: 0.14579, in 0.228s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14146, val loss: 0.14056, in 0.215s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.12992, in 0.240s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14464, val loss: 0.14416, in 0.247s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14366, val loss: 0.14326, in 0.273s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13877, val loss: 0.13795, in 0.280s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12976, val loss: 0.12862, in 0.254s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14333, val loss: 0.14288, in 0.208s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14228, val loss: 0.14186, in 0.198s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12850, val loss: 0.12742, in 0.209s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13699, val loss: 0.13620, in 0.267s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14092, val loss: 0.14051, in 0.287s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14038, val loss: 0.13989, in 0.300s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12702, val loss: 0.12599, in 0.280s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13583, val loss: 0.13509, in 0.319s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13876, val loss: 0.13829, in 0.249s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12599, val loss: 0.12484, in 0.229s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13914, val loss: 0.13872, in 0.324s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13492, val loss: 0.13413, in 0.200s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13768, val loss: 0.13726, in 0.201s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12417, val loss: 0.12302, in 0.285s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13669, val loss: 0.13630, in 0.300s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13360, val loss: 0.13281, in 0.265s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13633, val loss: 0.13589, in 0.298s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03701, val loss: 0.03680, in 0.223s\n",
      "Fit 200 trees in 57.269 s, (1534 total leaves)\n",
      "Time spent computing histograms: 33.527s\n",
      "Time spent finding best splits:  0.251s\n",
      "Time spent applying splits:      4.605s\n",
      "Time spent predicting:           0.405s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.13199, val loss: 0.13112, in 0.262s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12269, val loss: 0.12160, in 0.305s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13451, in 0.310s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13525, val loss: 0.13482, in 0.268s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13052, val loss: 0.12977, in 0.299s\n",
      "[56/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12154, val loss: 0.12053, in 0.309s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03811, val loss: 0.03825, in 0.244s\n",
      "Fit 200 trees in 57.242 s, (1543 total leaves)\n",
      "Time spent computing histograms: 33.476s\n",
      "Time spent finding best splits:  0.202s\n",
      "Time spent applying splits:      4.689s\n",
      "Time spent predicting:           0.517s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.13361, val loss: 0.13320, in 0.316s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13323, val loss: 0.13287, in 0.329s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12048, val loss: 0.11944, in 0.263s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12885, val loss: 0.12817, in 0.277s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13227, val loss: 0.13190, in 0.245s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13213, val loss: 0.13166, in 0.209s\n",
      "[55/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11970, val loss: 0.11867, in 0.205s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12689, val loss: 0.12631, in 0.233s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13120, val loss: 0.13084, in 0.220s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13044, val loss: 0.13000, in 0.231s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11837, val loss: 0.11731, in 0.188s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12969, val loss: 0.12934, in 0.188s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12590, val loss: 0.12524, in 0.208s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12895, val loss: 0.12855, in 0.194s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11709, val loss: 0.11607, in 0.242s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12823, val loss: 0.12793, in 0.213s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12377, val loss: 0.12316, in 0.235s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12723, val loss: 0.12686, in 0.248s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11491, in 0.221s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12671, val loss: 0.12654, in 0.256s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12266, val loss: 0.12208, in 0.261s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12363, val loss: 0.12326, in 0.289s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11502, val loss: 0.11407, in 0.262s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12561, val loss: 0.12543, in 0.272s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12122, val loss: 0.12061, in 0.245s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11438, val loss: 0.11339, in 0.191s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12197, in 0.257s\n",
      "[60/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03950, val loss: 0.03920, in 0.208s\n",
      "Fit 200 trees in 58.079 s, (1537 total leaves)\n",
      "Time spent computing histograms: 33.650s\n",
      "Time spent finding best splits:  0.268s\n",
      "Time spent applying splits:      4.722s\n",
      "Time spent predicting:           0.507s\n",
      "Binning 0.111 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.12043, val loss: 0.11989, in 0.207s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12422, val loss: 0.12396, in 0.236s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11347, val loss: 0.11248, in 0.222s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12149, val loss: 0.12116, in 0.219s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11976, val loss: 0.11921, in 0.232s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12075, val loss: 0.12051, in 0.310s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12053, val loss: 0.12023, in 0.224s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11239, val loss: 0.11142, in 0.245s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11878, val loss: 0.11823, in 0.186s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11959, val loss: 0.11936, in 0.241s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10988, val loss: 0.10888, in 0.216s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11910, val loss: 0.11891, in 0.233s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11703, in 0.251s\n",
      "[66/200] 4.559 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11836, val loss: 0.11814, in 0.203s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10886, val loss: 0.10790, in 0.210s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11838, val loss: 0.11819, in 0.204s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11632, val loss: 0.11580, in 0.226s\n",
      "[67/200] 0.178 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10779, val loss: 0.10682, in 0.181s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11715, val loss: 0.11701, in 0.227s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11662, val loss: 0.11643, in 0.232s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11574, val loss: 0.11519, in 0.207s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10699, val loss: 0.10602, in 0.214s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11605, val loss: 0.11595, in 0.218s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62678, val loss: 0.62681, in 0.271s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11544, val loss: 0.11527, in 0.238s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11474, val loss: 0.11419, in 0.204s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10598, val loss: 0.10503, in 0.252s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11310, val loss: 0.11300, in 0.274s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57231, val loss: 0.57223, in 0.270s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11295, in 0.203s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11473, val loss: 0.11454, in 0.238s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10385, val loss: 0.10287, in 0.201s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11223, val loss: 0.11218, in 0.208s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11228, val loss: 0.11179, in 0.179s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52710, val loss: 0.52705, in 0.268s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11179, val loss: 0.11160, in 0.273s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10306, val loss: 0.10210, in 0.203s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11124, val loss: 0.11120, in 0.202s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11074, val loss: 0.11029, in 0.221s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48886, val loss: 0.48871, in 0.240s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10998, val loss: 0.10981, in 0.225s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10220, val loss: 0.10126, in 0.184s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11041, val loss: 0.11037, in 0.183s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10963, val loss: 0.10923, in 0.227s\n",
      "[73/200] 4.164 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.10929, val loss: 0.10919, in 0.181s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45635, val loss: 0.45596, in 0.249s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10080, val loss: 0.09989, in 0.233s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10939, val loss: 0.10938, in 0.220s\n",
      "[70/200] 0.159 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10817, val loss: 0.10781, in 0.236s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10807, val loss: 0.10797, in 0.221s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10027, val loss: 0.09933, in 0.191s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42318, val loss: 0.42268, in 0.284s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10837, val loss: 0.10840, in 0.242s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10753, val loss: 0.10713, in 0.172s\n",
      "[75/200] 4.201 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.10722, val loss: 0.10715, in 0.210s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62335, val loss: 0.62336, in 0.278s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09912, val loss: 0.09823, in 0.241s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10622, val loss: 0.10586, in 0.211s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10640, val loss: 0.10643, in 0.228s\n",
      "[72/200] 0.177 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10610, val loss: 0.10607, in 0.198s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39468, val loss: 0.39421, in 0.295s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56608, val loss: 0.56601, in 0.267s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09841, val loss: 0.09757, in 0.216s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10528, val loss: 0.10491, in 0.198s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10396, in 0.273s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62678, val loss: 0.62667, in 0.261s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10363, val loss: 0.10358, in 0.266s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37006, val loss: 0.36948, in 0.269s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09674, val loss: 0.09593, in 0.223s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51854, val loss: 0.51847, in 0.244s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10245, val loss: 0.10208, in 0.253s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10299, val loss: 0.10301, in 0.218s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10267, in 0.227s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57229, val loss: 0.57192, in 0.241s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34864, val loss: 0.34798, in 0.248s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09589, val loss: 0.09507, in 0.216s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47843, val loss: 0.47830, in 0.248s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10168, val loss: 0.10131, in 0.207s\n",
      "[79/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10215, val loss: 0.10218, in 0.189s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10173, val loss: 0.10165, in 0.254s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52708, val loss: 0.52648, in 0.261s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09455, val loss: 0.09377, in 0.226s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33006, val loss: 0.32931, in 0.292s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10023, val loss: 0.09989, in 0.248s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44433, val loss: 0.44403, in 0.261s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10109, val loss: 0.10111, in 0.234s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10073, val loss: 0.10068, in 0.185s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09373, val loss: 0.09294, in 0.187s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48886, val loss: 0.48808, in 0.246s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09901, val loss: 0.09872, in 0.199s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10013, val loss: 0.10018, in 0.195s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31380, val loss: 0.31305, in 0.265s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41508, val loss: 0.41460, in 0.238s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09271, val loss: 0.09194, in 0.202s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09977, val loss: 0.09980, in 0.228s\n",
      "[78/200] 4.068 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.45631, val loss: 0.45545, in 0.249s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09834, val loss: 0.09806, in 0.261s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09800, val loss: 0.09807, in 0.319s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09933, val loss: 0.09937, in 0.205s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38976, val loss: 0.38931, in 0.302s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29878, val loss: 0.29785, in 0.318s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09123, in 0.257s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/200] 0.196 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09625, val loss: 0.09591, in 0.240s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09746, val loss: 0.09749, in 0.201s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42314, val loss: 0.42211, in 0.319s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09869, val loss: 0.09867, in 0.229s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09135, val loss: 0.09058, in 0.201s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36778, val loss: 0.36725, in 0.278s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28597, val loss: 0.28492, in 0.295s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62683, val loss: 0.62658, in 0.266s\n",
      "[2/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09515, in 0.203s\n",
      "[84/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09679, val loss: 0.09681, in 0.227s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09709, val loss: 0.09712, in 0.223s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08969, val loss: 0.08888, in 0.214s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39469, val loss: 0.39361, in 0.293s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34861, val loss: 0.34800, in 0.245s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27424, val loss: 0.27316, in 0.256s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09435, in 0.218s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57241, val loss: 0.57201, in 0.238s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09665, val loss: 0.09664, in 0.174s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09612, val loss: 0.09617, in 0.221s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08854, val loss: 0.08776, in 0.205s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37005, val loss: 0.36890, in 0.252s\n",
      "[9/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09353, val loss: 0.09322, in 0.199s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33186, val loss: 0.33114, in 0.259s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09502, val loss: 0.09510, in 0.197s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26417, val loss: 0.26300, in 0.271s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52723, val loss: 0.52659, in 0.249s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09589, val loss: 0.09587, in 0.229s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08721, val loss: 0.08646, in 0.232s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09264, in 0.197s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34862, val loss: 0.34741, in 0.273s\n",
      "[10/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09512, val loss: 0.09515, in 0.194s\n",
      "[84/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09448, val loss: 0.09458, in 0.210s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31424, val loss: 0.31354, in 0.264s\n",
      "[12/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08578, in 0.182s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48905, val loss: 0.48818, in 0.235s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25453, val loss: 0.25326, in 0.252s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09172, in 0.177s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09425, val loss: 0.09431, in 0.176s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09413, in 0.181s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33004, val loss: 0.32872, in 0.256s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08579, val loss: 0.08506, in 0.209s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29802, val loss: 0.29716, in 0.272s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45654, val loss: 0.45558, in 0.253s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24659, val loss: 0.24529, in 0.268s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09127, val loss: 0.09102, in 0.240s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09363, val loss: 0.09369, in 0.256s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09331, val loss: 0.09341, in 0.278s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08481, val loss: 0.08411, in 0.262s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31369, val loss: 0.31243, in 0.321s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42336, val loss: 0.42221, in 0.324s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28427, val loss: 0.28333, in 0.327s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09042, val loss: 0.09015, in 0.289s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23926, val loss: 0.23798, in 0.332s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09211, val loss: 0.09225, in 0.198s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08339, val loss: 0.08269, in 0.236s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09165, val loss: 0.09169, in 0.308s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29867, val loss: 0.29724, in 0.302s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08997, val loss: 0.08967, in 0.209s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39491, val loss: 0.39365, in 0.281s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23258, val loss: 0.23123, in 0.249s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09156, val loss: 0.09171, in 0.242s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27166, val loss: 0.27068, in 0.299s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09029, val loss: 0.09037, in 0.190s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08218, val loss: 0.08152, in 0.221s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08826, val loss: 0.08790, in 0.200s\n",
      "[92/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09086, val loss: 0.09104, in 0.238s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28596, val loss: 0.28450, in 0.313s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08951, val loss: 0.08963, in 0.292s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37031, val loss: 0.36895, in 0.334s\n",
      "[9/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08165, val loss: 0.08097, in 0.272s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22521, val loss: 0.22375, in 0.333s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26091, val loss: 0.25979, in 0.328s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08767, val loss: 0.08731, in 0.224s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09020, val loss: 0.09036, in 0.288s\n",
      "[89/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08109, val loss: 0.08041, in 0.213s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08889, val loss: 0.08904, in 0.259s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27419, val loss: 0.27264, in 0.330s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21964, val loss: 0.21816, in 0.277s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34892, val loss: 0.34750, in 0.308s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08673, val loss: 0.08638, in 0.257s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25056, val loss: 0.24938, in 0.312s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08984, in 0.200s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08017, val loss: 0.07952, in 0.218s\n",
      "[102/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08790, val loss: 0.08804, in 0.214s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08550, val loss: 0.08519, in 0.213s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26421, val loss: 0.26260, in 0.264s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21412, val loss: 0.21270, in 0.253s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33034, val loss: 0.32881, in 0.261s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08924, val loss: 0.08938, in 0.192s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24202, val loss: 0.24085, in 0.274s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07953, val loss: 0.07890, in 0.250s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08684, val loss: 0.08700, in 0.234s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08432, in 0.276s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20932, val loss: 0.20799, in 0.291s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25471, val loss: 0.25303, in 0.328s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08796, val loss: 0.08811, in 0.280s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31410, val loss: 0.31250, in 0.315s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23406, val loss: 0.23281, in 0.368s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08620, val loss: 0.08638, in 0.297s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07883, val loss: 0.07815, in 0.325s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08408, val loss: 0.08383, in 0.271s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08753, val loss: 0.08770, in 0.257s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20509, val loss: 0.20377, in 0.309s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08540, val loss: 0.08558, in 0.205s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24677, val loss: 0.24509, in 0.356s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29910, val loss: 0.29733, in 0.343s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07827, val loss: 0.07762, in 0.216s\n",
      "[105/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08348, val loss: 0.08327, in 0.187s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22723, val loss: 0.22591, in 0.298s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08703, val loss: 0.08716, in 0.205s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08499, val loss: 0.08519, in 0.199s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20040, val loss: 0.19911, in 0.270s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07765, val loss: 0.07700, in 0.232s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08205, val loss: 0.08179, in 0.227s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23944, val loss: 0.23771, in 0.278s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28631, val loss: 0.28448, in 0.274s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22093, val loss: 0.21963, in 0.265s\n",
      "[21/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08637, val loss: 0.08649, in 0.248s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08443, val loss: 0.08462, in 0.193s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19664, val loss: 0.19532, in 0.219s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07655, val loss: 0.07589, in 0.210s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08096, val loss: 0.08078, in 0.229s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23278, val loss: 0.23116, in 0.226s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21548, val loss: 0.21425, in 0.227s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27456, val loss: 0.27258, in 0.273s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08538, val loss: 0.08553, in 0.194s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19323, val loss: 0.19180, in 0.206s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08377, val loss: 0.08398, in 0.240s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07595, val loss: 0.07531, in 0.202s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08033, val loss: 0.08017, in 0.217s\n",
      "[101/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22598, val loss: 0.22424, in 0.255s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08468, val loss: 0.08485, in 0.214s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08346, val loss: 0.08370, in 0.170s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20981, val loss: 0.20853, in 0.279s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26451, val loss: 0.26252, in 0.265s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18976, val loss: 0.18836, in 0.238s\n",
      "[29/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07515, val loss: 0.07452, in 0.215s\n",
      "[109/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07984, val loss: 0.07969, in 0.176s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08284, val loss: 0.08311, in 0.179s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08366, val loss: 0.08386, in 0.197s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22038, val loss: 0.21869, in 0.236s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20543, val loss: 0.20420, in 0.224s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07477, val loss: 0.07415, in 0.195s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18591, val loss: 0.18455, in 0.216s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25537, val loss: 0.25332, in 0.260s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07930, val loss: 0.07916, in 0.204s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08247, val loss: 0.08273, in 0.175s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08203, val loss: 0.08223, in 0.255s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21464, val loss: 0.21277, in 0.234s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07430, val loss: 0.07370, in 0.183s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07903, val loss: 0.07888, in 0.168s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18324, val loss: 0.18186, in 0.201s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20082, val loss: 0.19966, in 0.236s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24745, val loss: 0.24535, in 0.254s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08215, val loss: 0.08242, in 0.196s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08121, val loss: 0.08141, in 0.203s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18014, val loss: 0.17883, in 0.189s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07367, val loss: 0.07306, in 0.212s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20991, val loss: 0.20799, in 0.235s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07852, val loss: 0.07839, in 0.216s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19698, val loss: 0.19588, in 0.225s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08147, val loss: 0.08176, in 0.200s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24013, val loss: 0.23798, in 0.236s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08094, val loss: 0.08116, in 0.164s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07305, val loss: 0.07249, in 0.184s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07750, val loss: 0.07741, in 0.196s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20569, val loss: 0.20391, in 0.218s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17736, val loss: 0.17605, in 0.226s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19362, val loss: 0.19246, in 0.195s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08069, val loss: 0.08098, in 0.191s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23350, val loss: 0.23150, in 0.237s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08032, val loss: 0.08061, in 0.227s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07262, val loss: 0.07207, in 0.194s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17494, val loss: 0.17369, in 0.190s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07629, val loss: 0.07615, in 0.204s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20105, val loss: 0.19911, in 0.250s\n",
      "[26/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.08009, val loss: 0.08039, in 0.203s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18974, val loss: 0.18856, in 0.252s\n",
      "[28/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07236, val loss: 0.07182, in 0.172s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22669, val loss: 0.22459, in 0.236s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07894, val loss: 0.07923, in 0.251s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07536, val loss: 0.07522, in 0.207s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17170, val loss: 0.17045, in 0.216s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19730, val loss: 0.19519, in 0.185s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18649, val loss: 0.18530, in 0.194s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07939, val loss: 0.07965, in 0.225s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07183, val loss: 0.07130, in 0.215s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07809, val loss: 0.07839, in 0.213s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22103, val loss: 0.21889, in 0.244s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07466, val loss: 0.07455, in 0.213s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16945, val loss: 0.16817, in 0.209s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19390, val loss: 0.19180, in 0.204s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18121, in 0.215s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07849, val loss: 0.07878, in 0.213s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07153, val loss: 0.07098, in 0.185s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07762, val loss: 0.07793, in 0.192s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07426, val loss: 0.07418, in 0.180s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21615, val loss: 0.21415, in 0.208s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16734, val loss: 0.16601, in 0.218s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19065, val loss: 0.18847, in 0.244s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17874, val loss: 0.17757, in 0.257s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07075, val loss: 0.07021, in 0.253s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07695, val loss: 0.07724, in 0.303s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07396, val loss: 0.07388, in 0.270s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07711, val loss: 0.07741, in 0.304s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16507, val loss: 0.16382, in 0.268s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21062, val loss: 0.20841, in 0.347s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18738, val loss: 0.18511, in 0.287s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17527, val loss: 0.17411, in 0.253s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07043, val loss: 0.06988, in 0.218s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07654, val loss: 0.07685, in 0.211s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07292, val loss: 0.07287, in 0.201s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07632, val loss: 0.07665, in 0.179s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16190, val loss: 0.16068, in 0.251s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18143, in 0.197s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07597, val loss: 0.07629, in 0.182s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20644, val loss: 0.20423, in 0.225s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06988, val loss: 0.06938, in 0.197s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17194, val loss: 0.17080, in 0.211s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07237, val loss: 0.07229, in 0.208s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07515, val loss: 0.07548, in 0.258s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15997, val loss: 0.15878, in 0.194s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06950, val loss: 0.06900, in 0.166s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18099, val loss: 0.17882, in 0.197s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07493, val loss: 0.07527, in 0.193s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20255, val loss: 0.20028, in 0.194s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16974, val loss: 0.16867, in 0.198s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07195, val loss: 0.07187, in 0.178s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15724, val loss: 0.15608, in 0.198s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07458, val loss: 0.07488, in 0.223s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07469, val loss: 0.07504, in 0.187s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06829, val loss: 0.06775, in 0.207s\n",
      "[122/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17734, val loss: 0.17512, in 0.235s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16724, val loss: 0.16607, in 0.203s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19810, val loss: 0.19572, in 0.247s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07150, val loss: 0.07143, in 0.190s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07411, val loss: 0.07444, in 0.185s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07342, val loss: 0.07381, in 0.194s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15462, val loss: 0.15344, in 0.215s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06775, val loss: 0.06727, in 0.202s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16501, val loss: 0.16395, in 0.185s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19446, val loss: 0.19205, in 0.187s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17296, val loss: 0.17068, in 0.216s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07111, val loss: 0.07106, in 0.178s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15320, val loss: 0.15205, in 0.174s\n",
      "[43/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06731, val loss: 0.06683, in 0.187s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07338, val loss: 0.07375, in 0.212s\n",
      "[111/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07252, val loss: 0.07291, in 0.217s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17058, val loss: 0.16825, in 0.192s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19118, val loss: 0.18868, in 0.195s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16207, val loss: 0.16102, in 0.239s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07047, val loss: 0.07037, in 0.207s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15162, val loss: 0.15049, in 0.179s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07222, val loss: 0.07261, in 0.187s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06655, val loss: 0.06605, in 0.214s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07202, val loss: 0.07238, in 0.245s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16833, val loss: 0.16594, in 0.201s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16018, val loss: 0.15922, in 0.193s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18734, val loss: 0.18488, in 0.230s\n",
      "[30/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06995, val loss: 0.06989, in 0.214s\n",
      "[118/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14907, val loss: 0.14799, in 0.244s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06565, val loss: 0.06513, in 0.196s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07175, val loss: 0.07212, in 0.226s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07123, val loss: 0.07160, in 0.201s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16616, val loss: 0.16364, in 0.203s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15810, val loss: 0.15719, in 0.200s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06936, val loss: 0.06932, in 0.202s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18359, val loss: 0.18123, in 0.222s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14687, val loss: 0.14576, in 0.211s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07082, val loss: 0.07122, in 0.197s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07082, val loss: 0.07121, in 0.225s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06467, val loss: 0.06411, in 0.245s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15614, val loss: 0.15515, in 0.197s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16342, val loss: 0.16090, in 0.224s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18070, val loss: 0.17836, in 0.212s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06868, val loss: 0.06863, in 0.244s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14533, val loss: 0.14419, in 0.201s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06433, val loss: 0.06378, in 0.186s\n",
      "[128/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06993, val loss: 0.07034, in 0.202s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15431, val loss: 0.15338, in 0.189s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16130, val loss: 0.15871, in 0.186s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07038, val loss: 0.07077, in 0.217s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17823, val loss: 0.17579, in 0.194s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06824, val loss: 0.06821, in 0.180s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14375, val loss: 0.14259, in 0.166s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06406, val loss: 0.06351, in 0.174s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06971, val loss: 0.07011, in 0.176s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15956, val loss: 0.15692, in 0.188s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15187, val loss: 0.15102, in 0.221s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06954, val loss: 0.06996, in 0.197s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17574, val loss: 0.17330, in 0.185s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06740, val loss: 0.06735, in 0.200s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14225, val loss: 0.14114, in 0.192s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06344, val loss: 0.06291, in 0.191s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15778, val loss: 0.15509, in 0.177s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14969, in 0.164s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06854, val loss: 0.06899, in 0.221s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06849, val loss: 0.06895, in 0.185s\n",
      "[119/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06707, val loss: 0.06701, in 0.187s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17197, val loss: 0.16965, in 0.214s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13787, in 0.219s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06295, val loss: 0.06237, in 0.215s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06765, val loss: 0.06812, in 0.194s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15576, val loss: 0.15308, in 0.220s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06813, val loss: 0.06858, in 0.212s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06682, val loss: 0.06676, in 0.156s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14805, val loss: 0.14725, in 0.247s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16869, val loss: 0.16638, in 0.256s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13769, val loss: 0.13664, in 0.193s\n",
      "[51/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06268, val loss: 0.06211, in 0.171s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06708, val loss: 0.06757, in 0.189s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06764, val loss: 0.06810, in 0.201s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06601, val loss: 0.06599, in 0.198s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15393, val loss: 0.15123, in 0.216s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14655, val loss: 0.14565, in 0.190s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16639, val loss: 0.16401, in 0.194s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13634, val loss: 0.13530, in 0.195s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06198, val loss: 0.06143, in 0.210s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06707, val loss: 0.06756, in 0.178s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15259, val loss: 0.14987, in 0.180s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06624, val loss: 0.06673, in 0.211s\n",
      "[122/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06564, val loss: 0.06563, in 0.201s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14415, val loss: 0.14323, in 0.211s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16433, val loss: 0.16194, in 0.186s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13506, val loss: 0.13411, in 0.196s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06136, val loss: 0.06080, in 0.186s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06603, val loss: 0.06654, in 0.177s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06636, val loss: 0.06683, in 0.214s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14773, in 0.215s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06497, val loss: 0.06498, in 0.208s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14195, val loss: 0.14103, in 0.218s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16242, val loss: 0.16001, in 0.194s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06104, val loss: 0.06049, in 0.184s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13263, in 0.205s\n",
      "[54/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06615, val loss: 0.06661, in 0.163s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06509, val loss: 0.06562, in 0.201s\n",
      "[124/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06455, val loss: 0.06458, in 0.179s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14075, val loss: 0.13989, in 0.174s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14886, val loss: 0.14614, in 0.229s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16041, val loss: 0.15801, in 0.243s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06059, val loss: 0.06005, in 0.234s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13183, val loss: 0.13089, in 0.237s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06588, val loss: 0.06635, in 0.229s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06415, val loss: 0.06421, in 0.269s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13924, val loss: 0.13844, in 0.243s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14752, val loss: 0.14478, in 0.244s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06412, val loss: 0.06465, in 0.311s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15702, val loss: 0.15457, in 0.232s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05997, val loss: 0.05946, in 0.216s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12980, val loss: 0.12895, in 0.225s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06540, val loss: 0.06589, in 0.205s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06350, val loss: 0.06356, in 0.202s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13773, val loss: 0.13693, in 0.208s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14492, val loss: 0.14228, in 0.208s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06299, val loss: 0.06350, in 0.266s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05957, val loss: 0.05907, in 0.184s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15512, val loss: 0.15259, in 0.211s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06498, val loss: 0.06548, in 0.197s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12863, val loss: 0.12777, in 0.218s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13539, in 0.207s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06282, val loss: 0.06295, in 0.233s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14261, val loss: 0.13995, in 0.221s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05933, val loss: 0.05883, in 0.191s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06252, val loss: 0.06304, in 0.194s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06464, val loss: 0.06515, in 0.188s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15244, val loss: 0.14999, in 0.207s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12724, val loss: 0.12637, in 0.206s\n",
      "[58/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14164, val loss: 0.13894, in 0.167s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06225, val loss: 0.06239, in 0.194s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13430, val loss: 0.13342, in 0.222s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05895, val loss: 0.05846, in 0.198s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06189, val loss: 0.06247, in 0.210s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15065, val loss: 0.14819, in 0.216s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06412, val loss: 0.06459, in 0.228s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12612, val loss: 0.12526, in 0.194s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14015, val loss: 0.13742, in 0.203s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13321, val loss: 0.13234, in 0.202s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06158, val loss: 0.06175, in 0.249s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06128, val loss: 0.06186, in 0.187s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05847, val loss: 0.05799, in 0.209s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14829, val loss: 0.14582, in 0.206s\n",
      "[45/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12486, val loss: 0.12402, in 0.227s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06306, val loss: 0.06352, in 0.257s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13861, val loss: 0.13584, in 0.209s\n",
      "[52/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06128, val loss: 0.06145, in 0.170s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06112, val loss: 0.06168, in 0.209s\n",
      "[130/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05830, val loss: 0.05781, in 0.215s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12992, val loss: 0.12912, in 0.273s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14663, val loss: 0.14421, in 0.249s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12385, val loss: 0.12301, in 0.251s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06087, val loss: 0.06107, in 0.218s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06215, val loss: 0.06266, in 0.267s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13753, val loss: 0.13474, in 0.251s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05815, val loss: 0.05769, in 0.178s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06082, val loss: 0.06133, in 0.208s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12835, val loss: 0.12759, in 0.254s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14490, val loss: 0.14252, in 0.219s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06061, val loss: 0.06082, in 0.196s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12147, in 0.238s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06065, val loss: 0.06115, in 0.178s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13574, val loss: 0.13297, in 0.203s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06143, val loss: 0.06194, in 0.213s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05745, val loss: 0.05697, in 0.218s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12694, val loss: 0.12619, in 0.200s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14313, val loss: 0.14073, in 0.272s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06029, val loss: 0.06080, in 0.214s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12131, val loss: 0.12050, in 0.228s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06021, val loss: 0.06040, in 0.262s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13420, val loss: 0.13150, in 0.243s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06091, val loss: 0.06139, in 0.257s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05696, val loss: 0.05651, in 0.245s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12602, val loss: 0.12534, in 0.207s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06009, val loss: 0.06061, in 0.187s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14160, val loss: 0.13922, in 0.204s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12046, val loss: 0.11966, in 0.205s\n",
      "[64/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05998, val loss: 0.06018, in 0.183s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13326, val loss: 0.13058, in 0.221s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05989, val loss: 0.06043, in 0.232s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05643, val loss: 0.05601, in 0.227s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12424, val loss: 0.12357, in 0.200s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05976, val loss: 0.06027, in 0.200s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05978, val loss: 0.06001, in 0.195s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11914, val loss: 0.11842, in 0.237s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13218, val loss: 0.12946, in 0.222s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13759, val loss: 0.13523, in 0.287s\n",
      "[50/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05617, val loss: 0.05576, in 0.212s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12190, val loss: 0.12122, in 0.269s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05908, val loss: 0.05961, in 0.305s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05895, val loss: 0.05919, in 0.242s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11679, val loss: 0.11613, in 0.237s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05877, val loss: 0.05927, in 0.295s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13029, val loss: 0.12766, in 0.226s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12105, val loss: 0.12044, in 0.179s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13567, val loss: 0.13337, in 0.249s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05554, val loss: 0.05512, in 0.248s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05891, val loss: 0.05945, in 0.188s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05875, val loss: 0.05899, in 0.182s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11546, val loss: 0.11487, in 0.188s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05782, val loss: 0.05834, in 0.233s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12781, val loss: 0.12528, in 0.225s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13447, val loss: 0.13208, in 0.201s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11999, val loss: 0.11941, in 0.208s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05868, val loss: 0.05923, in 0.180s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05463, in 0.224s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05846, val loss: 0.05872, in 0.203s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11451, val loss: 0.11393, in 0.198s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05727, val loss: 0.05780, in 0.217s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12638, val loss: 0.12387, in 0.213s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05474, val loss: 0.05434, in 0.182s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11856, val loss: 0.11803, in 0.219s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13230, val loss: 0.12994, in 0.236s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05835, val loss: 0.05888, in 0.219s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05809, val loss: 0.05833, in 0.331s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11371, val loss: 0.11316, in 0.330s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05448, val loss: 0.05408, in 0.365s\n",
      "[151/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05803, val loss: 0.05858, in 0.352s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05648, val loss: 0.05705, in 0.391s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11649, in 0.366s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12405, val loss: 0.12157, in 0.396s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13072, val loss: 0.12843, in 0.399s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05790, val loss: 0.05813, in 0.233s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11248, val loss: 0.11192, in 0.244s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05727, val loss: 0.05785, in 0.211s\n",
      "[138/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05620, val loss: 0.05679, in 0.214s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12254, val loss: 0.12010, in 0.212s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11621, val loss: 0.11581, in 0.235s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12949, val loss: 0.12717, in 0.205s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05373, val loss: 0.05338, in 0.266s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11176, val loss: 0.11124, in 0.229s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05703, val loss: 0.05728, in 0.269s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05607, val loss: 0.05667, in 0.197s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12844, val loss: 0.12608, in 0.226s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12121, val loss: 0.11884, in 0.256s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05652, val loss: 0.05714, in 0.281s\n",
      "[139/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05333, val loss: 0.05299, in 0.278s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11411, val loss: 0.11370, in 0.316s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11072, val loss: 0.11020, in 0.249s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05667, val loss: 0.05690, in 0.272s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05576, val loss: 0.05636, in 0.266s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12021, val loss: 0.11780, in 0.250s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12698, val loss: 0.12470, in 0.265s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05302, val loss: 0.05271, in 0.213s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11269, val loss: 0.11229, in 0.202s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05585, val loss: 0.05646, in 0.304s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10952, val loss: 0.10901, in 0.202s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05628, val loss: 0.05654, in 0.212s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05533, val loss: 0.05594, in 0.194s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11935, val loss: 0.11689, in 0.191s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05284, val loss: 0.05251, in 0.191s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12598, val loss: 0.12371, in 0.215s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05556, val loss: 0.05612, in 0.195s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10844, val loss: 0.10799, in 0.196s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11114, val loss: 0.11071, in 0.245s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05591, val loss: 0.05617, in 0.214s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05505, val loss: 0.05567, in 0.201s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11768, val loss: 0.11518, in 0.224s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05227, val loss: 0.05193, in 0.228s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05520, val loss: 0.05577, in 0.222s\n",
      "[142/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12455, val loss: 0.12228, in 0.259s\n",
      "[59/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05575, val loss: 0.05601, in 0.189s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10700, in 0.248s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11007, val loss: 0.10965, in 0.249s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05445, val loss: 0.05507, in 0.244s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11618, val loss: 0.11362, in 0.225s\n",
      "[67/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05186, val loss: 0.05153, in 0.230s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05488, val loss: 0.05546, in 0.222s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12339, val loss: 0.12108, in 0.219s\n",
      "[60/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05532, val loss: 0.05558, in 0.223s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10594, val loss: 0.10553, in 0.227s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10781, val loss: 0.10746, in 0.256s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05371, val loss: 0.05434, in 0.267s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11504, val loss: 0.11253, in 0.225s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05156, val loss: 0.05125, in 0.227s\n",
      "[158/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05518, val loss: 0.05543, in 0.189s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10536, val loss: 0.10496, in 0.187s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12219, val loss: 0.11990, in 0.226s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05417, val loss: 0.05477, in 0.246s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10723, val loss: 0.10689, in 0.196s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05127, val loss: 0.05099, in 0.198s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11406, val loss: 0.11157, in 0.233s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12146, val loss: 0.11916, in 0.184s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05469, val loss: 0.05499, in 0.214s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05301, val loss: 0.05363, in 0.284s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10600, val loss: 0.10572, in 0.188s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10437, val loss: 0.10392, in 0.237s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05334, val loss: 0.05395, in 0.258s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11290, val loss: 0.11044, in 0.187s\n",
      "[70/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05455, val loss: 0.05485, in 0.193s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05068, val loss: 0.05039, in 0.262s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11968, val loss: 0.11745, in 0.245s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10461, val loss: 0.10435, in 0.218s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10333, val loss: 0.10288, in 0.230s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05220, val loss: 0.05288, in 0.261s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05283, val loss: 0.05347, in 0.208s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11174, val loss: 0.10930, in 0.190s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05424, val loss: 0.05451, in 0.201s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05052, val loss: 0.05022, in 0.204s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10403, val loss: 0.10383, in 0.194s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11846, val loss: 0.11629, in 0.222s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05174, val loss: 0.05245, in 0.216s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10190, val loss: 0.10150, in 0.238s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05239, val loss: 0.05301, in 0.231s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11084, val loss: 0.10841, in 0.218s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05380, val loss: 0.05407, in 0.225s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10286, val loss: 0.10267, in 0.193s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11697, val loss: 0.11480, in 0.193s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04991, val loss: 0.04957, in 0.231s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05136, val loss: 0.05208, in 0.227s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05212, val loss: 0.05274, in 0.215s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09917, val loss: 0.09875, in 0.281s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11001, val loss: 0.10753, in 0.221s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05352, val loss: 0.05382, in 0.218s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11559, val loss: 0.11345, in 0.206s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04962, val loss: 0.04929, in 0.219s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10149, val loss: 0.10132, in 0.256s\n",
      "[75/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05114, val loss: 0.05187, in 0.188s\n",
      "[151/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05188, val loss: 0.05250, in 0.234s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09823, val loss: 0.09788, in 0.234s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10888, val loss: 0.10634, in 0.250s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11455, val loss: 0.11247, in 0.249s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05333, val loss: 0.05362, in 0.274s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04943, val loss: 0.04911, in 0.252s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10075, val loss: 0.10057, in 0.255s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05081, val loss: 0.05152, in 0.287s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09726, val loss: 0.09691, in 0.227s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05137, val loss: 0.05200, in 0.289s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10764, val loss: 0.10513, in 0.273s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11347, val loss: 0.11150, in 0.239s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05298, val loss: 0.05330, in 0.226s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04915, val loss: 0.04882, in 0.248s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09987, val loss: 0.09970, in 0.232s\n",
      "[77/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05039, val loss: 0.05111, in 0.214s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09669, val loss: 0.09640, in 0.221s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05106, val loss: 0.05171, in 0.233s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05274, val loss: 0.05308, in 0.220s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10655, val loss: 0.10405, in 0.251s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04886, val loss: 0.04855, in 0.207s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11142, val loss: 0.10937, in 0.256s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09906, val loss: 0.09889, in 0.220s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05001, val loss: 0.05077, in 0.240s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09586, val loss: 0.09564, in 0.275s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05046, val loss: 0.05111, in 0.253s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10600, val loss: 0.10354, in 0.218s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04839, val loss: 0.04809, in 0.255s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05245, val loss: 0.05278, in 0.279s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04979, val loss: 0.05051, in 0.245s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09631, val loss: 0.09613, in 0.327s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10918, val loss: 0.10722, in 0.349s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09486, in 0.343s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05014, val loss: 0.05077, in 0.355s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10504, val loss: 0.10260, in 0.327s\n",
      "[78/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05235, val loss: 0.05268, in 0.300s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04809, val loss: 0.04779, in 0.381s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09542, val loss: 0.09529, in 0.425s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04919, val loss: 0.04994, in 0.510s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10788, val loss: 0.10593, in 0.461s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10404, val loss: 0.10164, in 0.386s\n",
      "[79/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04990, val loss: 0.05054, in 0.398s\n",
      "[154/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09442, val loss: 0.09424, in 0.435s\n",
      "[87/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04799, val loss: 0.04769, in 0.390s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05164, val loss: 0.05192, in 0.497s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04887, val loss: 0.04962, in 0.266s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10667, val loss: 0.10473, in 0.279s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09311, val loss: 0.09297, in 0.337s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10269, val loss: 0.10031, in 0.277s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04945, val loss: 0.05009, in 0.281s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09398, val loss: 0.09378, in 0.274s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04774, val loss: 0.04745, in 0.238s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05144, val loss: 0.05174, in 0.228s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04850, val loss: 0.04928, in 0.255s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10594, val loss: 0.10398, in 0.239s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09090, val loss: 0.09081, in 0.340s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10221, val loss: 0.09979, in 0.268s\n",
      "[81/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09324, val loss: 0.09309, in 0.249s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04760, val loss: 0.04730, in 0.286s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04964, in 0.357s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05129, val loss: 0.05158, in 0.276s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10536, val loss: 0.10345, in 0.294s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04807, val loss: 0.04884, in 0.337s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09020, val loss: 0.09015, in 0.301s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05096, val loss: 0.05125, in 0.281s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09961, val loss: 0.09723, in 0.387s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09091, val loss: 0.09073, in 0.398s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04856, val loss: 0.04925, in 0.311s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04709, val loss: 0.04683, in 0.319s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10467, val loss: 0.10276, in 0.254s\n",
      "[75/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04782, val loss: 0.04860, in 0.245s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08823, val loss: 0.08817, in 0.280s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05080, val loss: 0.05111, in 0.205s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09851, val loss: 0.09622, in 0.230s\n",
      "[83/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04844, val loss: 0.04914, in 0.212s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04688, val loss: 0.04663, in 0.209s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09014, val loss: 0.09000, in 0.239s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04751, val loss: 0.04830, in 0.289s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10296, val loss: 0.10102, in 0.325s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08779, val loss: 0.08775, in 0.276s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09776, val loss: 0.09549, in 0.253s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08980, val loss: 0.08966, in 0.234s\n",
      "[92/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04668, val loss: 0.04642, in 0.259s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04806, val loss: 0.04876, in 0.285s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05044, val loss: 0.05073, in 0.322s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04733, val loss: 0.04813, in 0.205s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10198, val loss: 0.10001, in 0.234s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08696, val loss: 0.08693, in 0.220s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09723, val loss: 0.09495, in 0.215s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04631, val loss: 0.04603, in 0.219s\n",
      "[175/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04866, in 0.199s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08838, val loss: 0.08825, in 0.241s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05013, val loss: 0.05045, in 0.227s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04721, val loss: 0.04802, in 0.196s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09947, val loss: 0.09752, in 0.281s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08617, val loss: 0.08616, in 0.241s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08772, val loss: 0.08764, in 0.206s\n",
      "[94/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04774, val loss: 0.04844, in 0.212s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09648, val loss: 0.09421, in 0.237s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04595, val loss: 0.04569, in 0.236s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04930, val loss: 0.04963, in 0.285s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04675, val loss: 0.04757, in 0.276s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09854, val loss: 0.09660, in 0.206s\n",
      "[79/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08568, val loss: 0.08569, in 0.246s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04743, val loss: 0.04814, in 0.250s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09578, val loss: 0.09345, in 0.312s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08703, val loss: 0.08697, in 0.333s\n",
      "[95/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04559, val loss: 0.04537, in 0.349s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04648, val loss: 0.04729, in 0.456s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04891, val loss: 0.04926, in 0.541s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09791, val loss: 0.09594, in 0.510s\n",
      "[80/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04728, val loss: 0.04799, in 0.486s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09535, val loss: 0.09307, in 0.435s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08494, val loss: 0.08496, in 0.529s\n",
      "[89/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08642, val loss: 0.08636, in 0.658s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04529, val loss: 0.04508, in 0.699s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04599, val loss: 0.04682, in 0.514s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09693, val loss: 0.09498, in 0.516s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04835, val loss: 0.04870, in 0.595s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04676, val loss: 0.04750, in 0.635s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08414, val loss: 0.08410, in 0.668s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09432, val loss: 0.09206, in 0.723s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08577, val loss: 0.08573, in 0.549s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04566, val loss: 0.04649, in 0.567s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04478, val loss: 0.04458, in 0.638s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09571, val loss: 0.09380, in 0.543s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04769, val loss: 0.04804, in 0.582s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04645, val loss: 0.04719, in 0.458s\n",
      "[165/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09371, val loss: 0.09144, in 0.417s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08520, in 0.360s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08284, val loss: 0.08282, in 0.500s\n",
      "[91/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04550, val loss: 0.04634, in 0.287s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04459, val loss: 0.04439, in 0.310s\n",
      "[180/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04784, in 0.250s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09488, val loss: 0.09302, in 0.362s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04708, in 0.273s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04520, val loss: 0.04607, in 0.341s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08458, in 0.394s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08180, val loss: 0.08179, in 0.375s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09154, val loss: 0.08930, in 0.430s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04422, val loss: 0.04405, in 0.351s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04613, val loss: 0.04687, in 0.313s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04711, val loss: 0.04746, in 0.383s\n",
      "[174/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09363, val loss: 0.09185, in 0.366s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08324, val loss: 0.08324, in 0.315s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04485, val loss: 0.04571, in 0.342s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09087, val loss: 0.08865, in 0.298s\n",
      "[92/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08094, val loss: 0.08092, in 0.334s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04382, val loss: 0.04364, in 0.347s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09319, val loss: 0.09142, in 0.285s\n",
      "[85/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04576, val loss: 0.04649, in 0.369s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04658, val loss: 0.04695, in 0.336s\n",
      "[175/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04469, val loss: 0.04556, in 0.325s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09045, val loss: 0.08822, in 0.327s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08241, val loss: 0.08240, in 0.341s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07932, val loss: 0.07933, in 0.450s\n",
      "[94/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04351, val loss: 0.04335, in 0.403s\n",
      "[183/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04632, val loss: 0.04668, in 0.410s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09211, val loss: 0.09030, in 0.469s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04550, val loss: 0.04621, in 0.444s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08748, in 0.349s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04431, val loss: 0.04519, in 0.380s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08174, val loss: 0.08170, in 0.425s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07877, val loss: 0.07882, in 0.363s\n",
      "[95/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04531, val loss: 0.04602, in 0.440s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04594, val loss: 0.04635, in 0.477s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04294, val loss: 0.04281, in 0.563s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09152, val loss: 0.08975, in 0.501s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08117, val loss: 0.08117, in 0.421s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08915, val loss: 0.08694, in 0.541s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07844, val loss: 0.07850, in 0.387s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04366, val loss: 0.04453, in 0.608s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04498, val loss: 0.04569, in 0.330s\n",
      "[171/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04278, val loss: 0.04265, in 0.339s\n",
      "[185/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04597, in 0.353s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09100, val loss: 0.08925, in 0.351s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08883, val loss: 0.08663, in 0.332s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04354, val loss: 0.04440, in 0.279s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07783, val loss: 0.07784, in 0.375s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07934, val loss: 0.07933, in 0.447s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04487, val loss: 0.04559, in 0.339s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04544, val loss: 0.04585, in 0.308s\n",
      "[179/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04256, val loss: 0.04241, in 0.323s\n",
      "[186/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09051, val loss: 0.08877, in 0.296s\n",
      "[89/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08796, val loss: 0.08573, in 0.356s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07749, val loss: 0.07749, in 0.320s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04332, val loss: 0.04419, in 0.408s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04463, val loss: 0.04534, in 0.305s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07838, val loss: 0.07838, in 0.406s\n",
      "[105/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04524, val loss: 0.04567, in 0.316s\n",
      "[180/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04245, val loss: 0.04232, in 0.315s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09003, val loss: 0.08825, in 0.322s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07696, val loss: 0.07700, in 0.287s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04234, val loss: 0.04220, in 0.251s\n",
      "[188/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04300, val loss: 0.04388, in 0.302s\n",
      "[176/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04447, val loss: 0.04518, in 0.307s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07789, val loss: 0.07789, in 0.300s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08612, val loss: 0.08391, in 0.430s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04482, val loss: 0.04524, in 0.309s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08859, val loss: 0.08688, in 0.307s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04290, val loss: 0.04377, in 0.258s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07558, val loss: 0.07561, in 0.357s\n",
      "[100/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04438, val loss: 0.04510, in 0.255s\n",
      "[175/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08556, val loss: 0.08337, in 0.257s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04196, val loss: 0.04184, in 0.317s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04459, val loss: 0.04501, in 0.299s\n",
      "[182/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07713, val loss: 0.07712, in 0.324s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08663, val loss: 0.08493, in 0.365s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07499, val loss: 0.07505, in 0.394s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04264, val loss: 0.04349, in 0.406s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04420, val loss: 0.04492, in 0.356s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08487, val loss: 0.08269, in 0.447s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07680, val loss: 0.07678, in 0.415s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04152, val loss: 0.04137, in 0.476s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04424, val loss: 0.04463, in 0.503s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08536, val loss: 0.08374, in 0.451s\n",
      "[93/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04256, val loss: 0.04342, in 0.304s\n",
      "[179/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04404, val loss: 0.04476, in 0.318s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07426, val loss: 0.07434, in 0.371s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07578, val loss: 0.07582, in 0.413s\n",
      "[109/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04407, val loss: 0.04446, in 0.346s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04118, val loss: 0.04103, in 0.414s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08307, val loss: 0.08096, in 0.468s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08468, val loss: 0.08311, in 0.348s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04216, val loss: 0.04305, in 0.327s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04352, val loss: 0.04426, in 0.340s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07384, val loss: 0.07393, in 0.300s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07475, in 0.280s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04387, val loss: 0.04425, in 0.305s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04054, val loss: 0.04039, in 0.310s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08220, val loss: 0.08013, in 0.299s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08402, val loss: 0.08250, in 0.308s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04194, val loss: 0.04283, in 0.294s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04335, val loss: 0.04409, in 0.345s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07327, val loss: 0.07339, in 0.447s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07421, val loss: 0.07425, in 0.379s\n",
      "[111/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.08173, val loss: 0.07967, in 0.397s\n",
      "[103/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04350, val loss: 0.04389, in 0.430s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04012, val loss: 0.03999, in 0.527s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08332, val loss: 0.08183, in 0.512s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04323, val loss: 0.04396, in 0.360s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04169, val loss: 0.04260, in 0.474s\n",
      "[182/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07284, val loss: 0.07298, in 0.351s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07332, val loss: 0.07340, in 0.357s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04320, val loss: 0.04359, in 0.315s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08036, val loss: 0.07830, in 0.373s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04150, val loss: 0.04241, in 0.246s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08202, val loss: 0.08063, in 0.299s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03992, val loss: 0.03981, in 0.351s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04289, val loss: 0.04361, in 0.362s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07194, val loss: 0.07205, in 0.332s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04288, val loss: 0.04330, in 0.383s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07183, val loss: 0.07190, in 0.444s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04129, val loss: 0.04220, in 0.358s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07938, val loss: 0.07735, in 0.405s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03985, val loss: 0.03974, in 0.305s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08089, val loss: 0.07950, in 0.346s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07122, val loss: 0.07135, in 0.311s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04245, val loss: 0.04319, in 0.380s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04263, val loss: 0.04306, in 0.283s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07138, val loss: 0.07146, in 0.277s\n",
      "[114/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07894, val loss: 0.07692, in 0.267s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04105, val loss: 0.04195, in 0.339s\n",
      "[185/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03963, val loss: 0.03953, in 0.345s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08017, val loss: 0.07874, in 0.351s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07022, val loss: 0.07034, in 0.394s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04183, val loss: 0.04257, in 0.453s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04242, val loss: 0.04284, in 0.373s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07861, val loss: 0.07659, in 0.338s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07059, val loss: 0.07069, in 0.368s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03953, val loss: 0.03943, in 0.284s\n",
      "[197/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07988, val loss: 0.07846, in 0.311s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04051, val loss: 0.04140, in 0.408s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06966, val loss: 0.06974, in 0.360s\n",
      "[109/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04226, val loss: 0.04269, in 0.246s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04147, val loss: 0.04222, in 0.285s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07028, val loss: 0.07040, in 0.282s\n",
      "[116/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03945, val loss: 0.03934, in 0.280s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07770, val loss: 0.07570, in 0.339s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07892, val loss: 0.07754, in 0.297s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04026, val loss: 0.04116, in 0.285s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06928, val loss: 0.06936, in 0.312s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04138, val loss: 0.04213, in 0.306s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03925, val loss: 0.03915, in 0.268s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06975, val loss: 0.06990, in 0.328s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07741, val loss: 0.07540, in 0.276s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04163, val loss: 0.04205, in 0.392s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07784, val loss: 0.07654, in 0.306s\n",
      "[102/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06893, val loss: 0.06903, in 0.431s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03980, val loss: 0.04074, in 0.625s\n",
      "[188/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04112, val loss: 0.04189, in 0.559s\n",
      "[186/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06953, val loss: 0.06967, in 0.543s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03898, val loss: 0.03890, in 0.608s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04134, val loss: 0.04180, in 0.577s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07649, val loss: 0.07447, in 0.683s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07728, val loss: 0.07599, in 0.712s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06849, val loss: 0.06859, in 0.548s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03950, val loss: 0.04042, in 0.575s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06928, val loss: 0.06942, in 0.483s\n",
      "[119/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04068, val loss: 0.04142, in 0.582s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04106, val loss: 0.04155, in 0.531s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07576, val loss: 0.07375, in 0.452s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07632, val loss: 0.07505, in 0.414s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06825, val loss: 0.06837, in 0.304s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06884, val loss: 0.06902, in 0.292s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03929, val loss: 0.04020, in 0.352s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04041, val loss: 0.04118, in 0.322s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07529, val loss: 0.07329, in 0.351s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04048, val loss: 0.04096, in 0.403s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07545, val loss: 0.07419, in 0.366s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06710, val loss: 0.06723, in 0.374s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06826, val loss: 0.06846, in 0.312s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03900, val loss: 0.03991, in 0.328s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04000, val loss: 0.04075, in 0.381s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07492, val loss: 0.07293, in 0.312s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04005, val loss: 0.04053, in 0.411s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07493, val loss: 0.07369, in 0.411s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06653, val loss: 0.06665, in 0.384s\n",
      "[115/200] 1 tree, 4 leaves, max depth = 3, train loss: 0.03893, val loss: 0.03985, in 0.361s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06725, val loss: 0.06745, in 0.472s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03980, val loss: 0.04056, in 0.410s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07417, val loss: 0.07216, in 0.407s\n",
      "[114/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06616, val loss: 0.06631, in 0.285s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03988, val loss: 0.04037, in 0.320s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07465, val loss: 0.07341, in 0.301s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03876, val loss: 0.03968, in 0.302s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06686, val loss: 0.06709, in 0.279s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03970, val loss: 0.04045, in 0.276s\n",
      "[191/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03970, val loss: 0.04020, in 0.299s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07305, val loss: 0.07105, in 0.356s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07413, val loss: 0.07288, in 0.293s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06574, val loss: 0.06589, in 0.333s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06666, val loss: 0.06690, in 0.290s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03856, val loss: 0.03947, in 0.350s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03946, val loss: 0.04020, in 0.309s\n",
      "[192/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03956, val loss: 0.04005, in 0.284s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07258, val loss: 0.07056, in 0.314s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06527, val loss: 0.06541, in 0.343s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07286, val loss: 0.07167, in 0.414s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03839, val loss: 0.03929, in 0.310s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06543, val loss: 0.06566, in 0.387s\n",
      "[125/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03923, val loss: 0.03995, in 0.286s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03946, val loss: 0.03995, in 0.243s\n",
      "[200/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07235, val loss: 0.07032, in 0.233s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06499, val loss: 0.06512, in 0.247s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07196, val loss: 0.07082, in 0.277s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03818, val loss: 0.03908, in 0.262s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03964, in 0.355s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07151, val loss: 0.06950, in 0.328s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06421, val loss: 0.06451, in 0.383s\n",
      "[126/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06463, val loss: 0.06479, in 0.316s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03811, val loss: 0.03901, in 0.277s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07116, val loss: 0.07003, in 0.311s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07110, val loss: 0.06912, in 0.285s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03855, val loss: 0.03932, in 0.312s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06331, val loss: 0.06364, in 0.317s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06375, val loss: 0.06395, in 0.267s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03803, val loss: 0.03893, in 0.259s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07044, val loss: 0.06933, in 0.352s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07053, val loss: 0.06858, in 0.332s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06280, in 0.352s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06289, val loss: 0.06309, in 0.358s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03816, val loss: 0.03891, in 0.391s\n",
      "[196/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03779, val loss: 0.03869, in 0.372s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06975, val loss: 0.06865, in 0.339s\n",
      "[113/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06225, val loss: 0.06260, in 0.303s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06255, val loss: 0.06277, in 0.305s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06954, val loss: 0.06758, in 0.381s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03794, val loss: 0.03870, in 0.324s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03740, val loss: 0.03829, in 0.360s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06891, val loss: 0.06787, in 0.331s\n",
      "[114/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06188, val loss: 0.06225, in 0.285s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06908, val loss: 0.06715, in 0.351s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03752, val loss: 0.03831, in 0.361s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06155, val loss: 0.06175, in 0.385s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06838, val loss: 0.06733, in 0.275s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06127, val loss: 0.06166, in 0.325s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06874, val loss: 0.06682, in 0.254s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06109, val loss: 0.06130, in 0.293s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03717, val loss: 0.03796, in 0.299s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06735, val loss: 0.06635, in 0.358s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06080, val loss: 0.06121, in 0.251s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06812, val loss: 0.06620, in 0.270s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03697, val loss: 0.03776, in 0.295s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06034, val loss: 0.06054, in 0.319s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06666, val loss: 0.06569, in 0.281s\n",
      "[117/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06770, val loss: 0.06581, in 0.248s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05989, val loss: 0.06030, in 0.340s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05995, val loss: 0.06014, in 0.305s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06625, val loss: 0.06531, in 0.333s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06667, val loss: 0.06487, in 0.295s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05951, val loss: 0.05992, in 0.310s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05979, val loss: 0.05999, in 0.279s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06599, val loss: 0.06505, in 0.288s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06621, val loss: 0.06441, in 0.321s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05926, val loss: 0.05968, in 0.309s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05892, val loss: 0.05909, in 0.358s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06518, val loss: 0.06426, in 0.262s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06548, val loss: 0.06372, in 0.276s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05868, val loss: 0.05909, in 0.251s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05860, val loss: 0.05879, in 0.230s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06450, val loss: 0.06363, in 0.252s\n",
      "[121/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05837, val loss: 0.05879, in 0.219s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06464, val loss: 0.06289, in 0.295s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05795, val loss: 0.05815, in 0.260s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06426, val loss: 0.06339, in 0.241s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05816, val loss: 0.05858, in 0.238s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06436, val loss: 0.06261, in 0.234s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06376, val loss: 0.06286, in 0.265s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05724, val loss: 0.05750, in 0.325s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05785, val loss: 0.05827, in 0.302s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06396, val loss: 0.06225, in 0.303s\n",
      "[131/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05715, in 0.274s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06313, val loss: 0.06224, in 0.324s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05746, val loss: 0.05788, in 0.287s\n",
      "[140/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06332, val loss: 0.06162, in 0.312s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06161, in 0.305s\n",
      "[125/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03884, val loss: 0.03875, in 0.477s\n",
      "Fit 200 trees in 59.426 s, (1529 total leaves)\n",
      "Time spent computing histograms: 33.272s\n",
      "Time spent finding best splits:  0.211s\n",
      "Time spent applying splits:      4.534s\n",
      "Time spent predicting:           0.505s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05604, val loss: 0.05629, in 0.350s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06309, val loss: 0.06139, in 0.301s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05731, in 0.369s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06182, val loss: 0.06096, in 0.309s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05663, val loss: 0.05707, in 0.223s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05526, in 0.337s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06239, val loss: 0.06075, in 0.273s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06140, val loss: 0.06058, in 0.302s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05438, val loss: 0.05460, in 0.265s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05617, val loss: 0.05658, in 0.326s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06166, val loss: 0.06001, in 0.300s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06117, val loss: 0.06035, in 0.242s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05409, val loss: 0.05432, in 0.235s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06128, val loss: 0.05961, in 0.259s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05581, val loss: 0.05620, in 0.284s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06082, val loss: 0.06001, in 0.263s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05350, val loss: 0.05371, in 0.279s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05548, val loss: 0.05588, in 0.248s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06074, val loss: 0.05905, in 0.282s\n",
      "[137/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06065, val loss: 0.05985, in 0.270s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05314, val loss: 0.05335, in 0.305s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05524, val loss: 0.05566, in 0.251s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06023, val loss: 0.05856, in 0.256s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06013, val loss: 0.05934, in 0.248s\n",
      "[131/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05286, val loss: 0.05309, in 0.219s\n",
      "[140/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05500, val loss: 0.05541, in 0.243s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05988, val loss: 0.05821, in 0.237s\n",
      "[139/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05963, val loss: 0.05885, in 0.252s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05268, val loss: 0.05293, in 0.215s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05448, val loss: 0.05490, in 0.258s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05969, val loss: 0.05801, in 0.237s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03906, val loss: 0.03956, in 0.366s\n",
      "Fit 200 trees in 59.678 s, (1527 total leaves)\n",
      "Time spent computing histograms: 33.589s\n",
      "Time spent finding best splits:  0.392s\n",
      "Time spent applying splits:      5.097s\n",
      "Time spent predicting:           0.458s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05908, val loss: 0.05831, in 0.291s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05212, val loss: 0.05236, in 0.287s\n",
      "[142/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05937, val loss: 0.05771, in 0.260s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05397, val loss: 0.05442, in 0.314s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05866, val loss: 0.05788, in 0.237s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05916, val loss: 0.05748, in 0.236s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05369, val loss: 0.05411, in 0.231s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05142, val loss: 0.05163, in 0.333s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05837, val loss: 0.05760, in 0.251s\n",
      "[135/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05345, val loss: 0.05388, in 0.244s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05881, val loss: 0.05714, in 0.291s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05093, val loss: 0.05119, in 0.331s\n",
      "[144/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05807, val loss: 0.05734, in 0.300s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05290, val loss: 0.05331, in 0.306s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05068, val loss: 0.05095, in 0.285s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03708, val loss: 0.03800, in 0.321s\n",
      "Fit 200 trees in 60.566 s, (1537 total leaves)\n",
      "Time spent computing histograms: 34.307s\n",
      "Time spent finding best splits:  0.244s\n",
      "Time spent applying splits:      4.663s\n",
      "Time spent predicting:           0.691s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05784, val loss: 0.05623, in 0.430s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05754, val loss: 0.05684, in 0.313s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05266, val loss: 0.05308, in 0.357s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05056, val loss: 0.05083, in 0.361s\n",
      "[146/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05762, val loss: 0.05601, in 0.477s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05697, val loss: 0.05632, in 0.461s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05238, val loss: 0.05280, in 0.349s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05034, val loss: 0.05061, in 0.319s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05684, val loss: 0.05519, in 0.327s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05663, val loss: 0.05600, in 0.346s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05198, val loss: 0.05243, in 0.325s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05002, val loss: 0.05030, in 0.346s\n",
      "[148/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03683, val loss: 0.03762, in 0.259s\n",
      "Fit 200 trees in 61.445 s, (1537 total leaves)\n",
      "Time spent computing histograms: 34.745s\n",
      "Time spent finding best splits:  0.295s\n",
      "Time spent applying splits:      4.871s\n",
      "Time spent predicting:           0.460s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05601, val loss: 0.05539, in 0.261s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05591, val loss: 0.05428, in 0.383s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05151, val loss: 0.05195, in 0.295s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04953, val loss: 0.04983, in 0.258s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05583, val loss: 0.05521, in 0.468s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05137, val loss: 0.05183, in 0.463s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05539, val loss: 0.05378, in 0.527s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04925, val loss: 0.04956, in 0.514s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05537, val loss: 0.05476, in 0.287s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05104, val loss: 0.05153, in 0.289s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04909, val loss: 0.04939, in 0.229s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05473, val loss: 0.05316, in 0.266s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05090, val loss: 0.05139, in 0.197s\n",
      "[159/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04886, val loss: 0.04918, in 0.199s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05508, val loss: 0.05450, in 0.273s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05419, val loss: 0.05266, in 0.279s\n",
      "[150/200] 5.548 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 6 leaves, max depth = 3, train loss: 0.05053, val loss: 0.05102, in 0.244s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05470, val loss: 0.05411, in 0.223s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04806, val loss: 0.04836, in 0.266s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05401, val loss: 0.05249, in 0.221s\n",
      "[151/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05006, val loss: 0.05055, in 0.278s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05428, val loss: 0.05369, in 0.295s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04759, val loss: 0.04788, in 0.291s\n",
      "[154/200] 0.266 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05355, val loss: 0.05204, in 0.305s\n",
      "[152/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04986, val loss: 0.05036, in 0.290s\n",
      "[162/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04739, val loss: 0.04770, in 0.276s\n",
      "[155/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05371, val loss: 0.05315, in 0.334s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62682, val loss: 0.62687, in 0.393s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05266, val loss: 0.05118, in 0.418s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04951, val loss: 0.05004, in 0.292s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05356, val loss: 0.05300, in 0.240s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04691, val loss: 0.04722, in 0.292s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05234, val loss: 0.05084, in 0.247s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57238, val loss: 0.57241, in 0.337s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04908, val loss: 0.04958, in 0.296s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05342, val loss: 0.05286, in 0.273s\n",
      "[148/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04651, val loss: 0.04680, in 0.319s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05219, val loss: 0.05069, in 0.241s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52719, val loss: 0.52720, in 0.336s\n",
      "[4/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04874, val loss: 0.04925, in 0.261s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05305, val loss: 0.05252, in 0.271s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04613, val loss: 0.04646, in 0.266s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05182, val loss: 0.05031, in 0.280s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04854, val loss: 0.04907, in 0.239s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05268, val loss: 0.05219, in 0.281s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48902, val loss: 0.48892, in 0.346s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04587, val loss: 0.04621, in 0.322s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05107, val loss: 0.04958, in 0.344s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04828, val loss: 0.04882, in 0.280s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05225, val loss: 0.05173, in 0.247s\n",
      "[151/200] 5.614 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.04548, val loss: 0.04581, in 0.228s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45654, val loss: 0.45644, in 0.307s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05056, val loss: 0.04913, in 0.242s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05186, val loss: 0.05134, in 0.287s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04801, in 0.354s\n",
      "[168/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04519, val loss: 0.04554, in 0.263s\n",
      "[161/200] 0.245 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42334, val loss: 0.42324, in 0.365s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05043, val loss: 0.04899, in 0.271s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05146, val loss: 0.05097, in 0.272s\n",
      "[153/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04501, val loss: 0.04536, in 0.231s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04696, val loss: 0.04752, in 0.294s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62677, val loss: 0.62679, in 0.363s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39488, val loss: 0.39478, in 0.330s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04966, val loss: 0.04829, in 0.333s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04434, val loss: 0.04468, in 0.278s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05084, val loss: 0.05034, in 0.306s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04646, val loss: 0.04703, in 0.318s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04931, val loss: 0.04796, in 0.290s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57227, val loss: 0.57225, in 0.378s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04411, val loss: 0.04444, in 0.312s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04632, val loss: 0.04688, in 0.234s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05025, val loss: 0.04977, in 0.307s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37026, val loss: 0.37012, in 0.376s\n",
      "[9/200] 5.614 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 6 leaves, max depth = 3, train loss: 0.04891, val loss: 0.04760, in 0.267s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52704, val loss: 0.52698, in 0.378s\n",
      "[4/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05003, val loss: 0.04958, in 0.328s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04600, val loss: 0.04661, in 0.361s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04369, val loss: 0.04402, in 0.387s\n",
      "[165/200] 0.235 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34888, val loss: 0.34872, in 0.446s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04833, val loss: 0.04709, in 0.403s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04970, val loss: 0.04923, in 0.288s\n",
      "[157/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04349, val loss: 0.04382, in 0.274s\n",
      "[166/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04566, val loss: 0.04628, in 0.341s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48880, val loss: 0.48859, in 0.404s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62675, val loss: 0.62671, in 0.441s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33027, val loss: 0.33007, in 0.437s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04791, val loss: 0.04673, in 0.344s\n",
      "[164/200] 5.503 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 7 leaves, max depth = 3, train loss: 0.04329, val loss: 0.04360, in 0.389s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04553, val loss: 0.04616, in 0.349s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04895, val loss: 0.04853, in 0.480s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45624, val loss: 0.45603, in 0.452s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57224, val loss: 0.57221, in 0.421s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04766, val loss: 0.04650, in 0.344s\n",
      "[165/200] 0.274 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04308, val loss: 0.04341, in 0.343s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31403, val loss: 0.31378, in 0.498s\n",
      "[12/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04876, val loss: 0.04836, in 0.289s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04506, val loss: 0.04570, in 0.372s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42305, val loss: 0.42283, in 0.496s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04633, in 0.433s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04295, val loss: 0.04328, in 0.410s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52699, val loss: 0.52691, in 0.538s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04817, val loss: 0.04779, in 0.489s\n",
      "[160/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04479, val loss: 0.04544, in 0.466s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62680, val loss: 0.62673, in 0.555s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29905, val loss: 0.29862, in 0.596s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04714, val loss: 0.04603, in 0.382s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39457, val loss: 0.39431, in 0.470s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04451, val loss: 0.04517, in 0.323s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48877, val loss: 0.48863, in 0.425s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04243, val loss: 0.04275, in 0.438s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04775, val loss: 0.04737, in 0.399s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57234, val loss: 0.57230, in 0.450s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28630, val loss: 0.28578, in 0.424s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04680, val loss: 0.04569, in 0.346s\n",
      "[168/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04434, val loss: 0.04500, in 0.298s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04227, val loss: 0.04259, in 0.336s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36992, val loss: 0.36963, in 0.456s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04720, val loss: 0.04681, in 0.357s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45623, val loss: 0.45595, in 0.426s\n",
      "[6/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04660, val loss: 0.04549, in 0.274s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52714, val loss: 0.52704, in 0.349s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27441, val loss: 0.27381, in 0.382s\n",
      "[15/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04210, val loss: 0.04245, in 0.250s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04403, val loss: 0.04467, in 0.334s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04674, val loss: 0.04639, in 0.278s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34850, val loss: 0.34815, in 0.341s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42301, val loss: 0.42269, in 0.323s\n",
      "[7/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04524, in 0.284s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48896, val loss: 0.48879, in 0.316s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04194, val loss: 0.04230, in 0.246s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26442, val loss: 0.26380, in 0.363s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04336, val loss: 0.04399, in 0.354s\n",
      "[180/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04651, val loss: 0.04619, in 0.299s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32948, in 0.379s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04612, val loss: 0.04500, in 0.354s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04164, val loss: 0.04201, in 0.317s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39453, val loss: 0.39423, in 0.423s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45645, val loss: 0.45612, in 0.370s\n",
      "[6/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04638, val loss: 0.04605, in 0.305s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25507, val loss: 0.25438, in 0.420s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04276, val loss: 0.04338, in 0.408s\n",
      "[181/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04155, val loss: 0.04191, in 0.283s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04571, val loss: 0.04464, in 0.347s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31362, val loss: 0.31320, in 0.405s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36990, val loss: 0.36949, in 0.443s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42320, val loss: 0.42278, in 0.436s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04589, val loss: 0.04557, in 0.419s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24698, val loss: 0.24614, in 0.399s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04109, val loss: 0.04144, in 0.354s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04235, val loss: 0.04301, in 0.417s\n",
      "[182/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04548, val loss: 0.04440, in 0.321s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29864, val loss: 0.29808, in 0.418s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04561, val loss: 0.04530, in 0.311s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34843, val loss: 0.34797, in 0.412s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39468, val loss: 0.39424, in 0.418s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04081, val loss: 0.04115, in 0.329s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04524, val loss: 0.04416, in 0.349s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04215, val loss: 0.04280, in 0.367s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23971, val loss: 0.23875, in 0.425s\n",
      "[19/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04527, val loss: 0.04498, in 0.279s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28588, val loss: 0.28528, in 0.409s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04502, val loss: 0.04391, in 0.206s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04052, val loss: 0.04087, in 0.248s\n",
      "[178/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04200, val loss: 0.04265, in 0.224s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36998, val loss: 0.36948, in 0.354s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32983, val loss: 0.32931, in 0.369s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23308, val loss: 0.23206, in 0.290s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04474, val loss: 0.04443, in 0.310s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04490, val loss: 0.04379, in 0.270s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04022, val loss: 0.04057, in 0.283s\n",
      "[179/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04181, val loss: 0.04248, in 0.298s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27403, val loss: 0.27328, in 0.426s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31359, val loss: 0.31313, in 0.408s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34853, val loss: 0.34794, in 0.457s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22674, val loss: 0.22562, in 0.426s\n",
      "[21/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04440, val loss: 0.04410, in 0.379s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04015, val loss: 0.04049, in 0.340s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04469, val loss: 0.04359, in 0.409s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04123, val loss: 0.04190, in 0.465s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26400, val loss: 0.26314, in 0.471s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29856, val loss: 0.29801, in 0.490s\n",
      "[13/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03999, val loss: 0.04034, in 0.352s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22118, val loss: 0.21991, in 0.460s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32925, in 0.533s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04404, val loss: 0.04378, in 0.435s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04408, val loss: 0.04302, in 0.474s\n",
      "[178/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04110, val loss: 0.04176, in 0.387s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03952, val loss: 0.03989, in 0.423s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25495, val loss: 0.25399, in 0.559s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21523, val loss: 0.21386, in 0.476s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04376, val loss: 0.04352, in 0.431s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28573, val loss: 0.28512, in 0.554s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04393, val loss: 0.04289, in 0.367s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31363, val loss: 0.31290, in 0.500s\n",
      "[12/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04080, val loss: 0.04148, in 0.408s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03937, val loss: 0.03974, in 0.262s\n",
      "[183/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04366, val loss: 0.04342, in 0.241s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24642, val loss: 0.24532, in 0.374s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21053, val loss: 0.20907, in 0.343s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27333, in 0.362s\n",
      "[15/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04060, val loss: 0.04128, in 0.273s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04345, val loss: 0.04243, in 0.345s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29862, val loss: 0.29772, in 0.352s\n",
      "[13/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04345, val loss: 0.04321, in 0.261s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03893, val loss: 0.03926, in 0.362s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04045, val loss: 0.04113, in 0.228s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20640, val loss: 0.20484, in 0.297s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04323, val loss: 0.04221, in 0.258s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23917, val loss: 0.23800, in 0.341s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26390, val loss: 0.26312, in 0.377s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28577, val loss: 0.28485, in 0.387s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04300, val loss: 0.04275, in 0.320s\n",
      "[175/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03873, val loss: 0.03907, in 0.292s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04005, val loss: 0.04072, in 0.321s\n",
      "[191/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04292, val loss: 0.04194, in 0.309s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23258, val loss: 0.23132, in 0.350s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20169, val loss: 0.20004, in 0.393s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04286, val loss: 0.04261, in 0.242s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25448, val loss: 0.25361, in 0.347s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03844, val loss: 0.03879, in 0.276s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27298, in 0.354s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03995, val loss: 0.04061, in 0.244s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04257, val loss: 0.04158, in 0.316s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04271, val loss: 0.04248, in 0.253s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19789, val loss: 0.19617, in 0.355s\n",
      "[27/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22614, val loss: 0.22475, in 0.371s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03825, val loss: 0.03860, in 0.301s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03975, val loss: 0.04041, in 0.263s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24649, val loss: 0.24552, in 0.364s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04247, val loss: 0.04148, in 0.241s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26390, val loss: 0.26282, in 0.370s\n",
      "[16/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04257, val loss: 0.04235, in 0.244s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19433, val loss: 0.19266, in 0.249s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22054, val loss: 0.21904, in 0.300s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03774, val loss: 0.03811, in 0.307s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03949, val loss: 0.04014, in 0.316s\n",
      "[194/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04232, val loss: 0.04133, in 0.270s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23920, val loss: 0.23817, in 0.377s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04232, val loss: 0.04210, in 0.294s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25444, val loss: 0.25323, in 0.379s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19123, val loss: 0.18952, in 0.320s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03749, val loss: 0.03790, in 0.346s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21503, val loss: 0.21335, in 0.432s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03910, val loss: 0.03975, in 0.364s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04181, val loss: 0.04082, in 0.361s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23257, val loss: 0.23142, in 0.347s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04186, val loss: 0.04163, in 0.342s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18749, val loss: 0.18581, in 0.327s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24648, val loss: 0.24523, in 0.394s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03739, val loss: 0.03781, in 0.236s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03955, in 0.254s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21041, val loss: 0.20865, in 0.335s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04134, val loss: 0.04033, in 0.324s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04163, val loss: 0.04140, in 0.345s\n",
      "[181/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22578, val loss: 0.22448, in 0.433s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18374, val loss: 0.18213, in 0.358s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03727, val loss: 0.03768, in 0.333s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23913, val loss: 0.23788, in 0.434s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03853, val loss: 0.03916, in 0.419s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20621, val loss: 0.20433, in 0.378s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04141, val loss: 0.04119, in 0.274s\n",
      "[182/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04087, val loss: 0.03987, in 0.407s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03704, val loss: 0.03746, in 0.274s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22018, val loss: 0.21881, in 0.301s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18110, val loss: 0.17944, in 0.298s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23253, val loss: 0.23121, in 0.279s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03834, val loss: 0.03896, in 0.221s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04132, val loss: 0.04109, in 0.211s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04078, val loss: 0.03977, in 0.219s\n",
      "[189/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20118, val loss: 0.19916, in 0.311s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03692, val loss: 0.03736, in 0.237s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17868, val loss: 0.17698, in 0.264s\n",
      "[33/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21463, val loss: 0.21321, in 0.354s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03820, val loss: 0.03882, in 0.273s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04108, val loss: 0.04084, in 0.272s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04051, val loss: 0.03950, in 0.274s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22565, val loss: 0.22420, in 0.379s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19759, val loss: 0.19555, in 0.318s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17624, val loss: 0.17455, in 0.313s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03651, val loss: 0.03698, in 0.365s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20999, val loss: 0.20849, in 0.376s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04095, val loss: 0.04072, in 0.341s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03770, val loss: 0.03832, in 0.431s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04031, val loss: 0.03933, in 0.381s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22003, val loss: 0.21855, in 0.388s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19404, val loss: 0.19198, in 0.323s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17275, val loss: 0.17096, in 0.353s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03604, val loss: 0.03652, in 0.354s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04086, val loss: 0.04065, in 0.241s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20580, val loss: 0.20428, in 0.310s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04015, val loss: 0.03917, in 0.230s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19017, val loss: 0.18819, in 0.297s\n",
      "[29/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21439, val loss: 0.21291, in 0.324s\n",
      "[23/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04074, val loss: 0.04054, in 0.233s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16900, val loss: 0.16726, in 0.311s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03565, val loss: 0.03616, in 0.328s\n",
      "[196/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04002, val loss: 0.03904, in 0.276s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20119, val loss: 0.19964, in 0.353s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18635, val loss: 0.18435, in 0.286s\n",
      "[30/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04067, val loss: 0.04045, in 0.269s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20974, val loss: 0.20822, in 0.351s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03542, val loss: 0.03594, in 0.263s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16533, val loss: 0.16364, in 0.375s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03984, val loss: 0.03887, in 0.338s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19748, val loss: 0.19591, in 0.319s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18356, val loss: 0.18159, in 0.320s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04032, val loss: 0.04011, in 0.315s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20553, val loss: 0.20408, in 0.350s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16350, val loss: 0.16185, in 0.251s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03525, val loss: 0.03575, in 0.337s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03944, val loss: 0.03846, in 0.283s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19411, val loss: 0.19248, in 0.329s\n",
      "[28/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18088, val loss: 0.17890, in 0.331s\n",
      "[32/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04011, val loss: 0.03989, in 0.317s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16137, val loss: 0.15974, in 0.314s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03511, val loss: 0.03563, in 0.309s\n",
      "[199/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03921, val loss: 0.03822, in 0.274s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20086, val loss: 0.19938, in 0.366s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.19101, val loss: 0.18939, in 0.263s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03988, val loss: 0.03966, in 0.255s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17824, val loss: 0.17619, in 0.278s\n",
      "[33/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03499, val loss: 0.03551, in 0.228s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15951, val loss: 0.15787, in 0.255s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03792, in 0.247s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19713, val loss: 0.19572, in 0.264s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18777, val loss: 0.18607, in 0.274s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17571, val loss: 0.17370, in 0.224s\n",
      "[34/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03967, val loss: 0.03946, in 0.238s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03877, val loss: 0.03778, in 0.244s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15717, val loss: 0.15552, in 0.291s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19368, val loss: 0.19223, in 0.277s\n",
      "[28/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03959, val loss: 0.03938, in 0.267s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18501, val loss: 0.18329, in 0.312s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17225, val loss: 0.17013, in 0.397s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03860, val loss: 0.03759, in 0.293s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15451, val loss: 0.15296, in 0.353s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19041, val loss: 0.18907, in 0.378s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18133, val loss: 0.17964, in 0.346s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03907, val loss: 0.03887, in 0.399s\n",
      "[194/200] 1 tree, 4 leaves, max depth = 3, train loss: 0.03854, val loss: 0.03752, in 0.283s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17005, val loss: 0.16792, in 0.318s\n",
      "[36/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15267, val loss: 0.15109, in 0.370s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18704, val loss: 0.18571, in 0.359s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03888, val loss: 0.03867, in 0.288s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17770, val loss: 0.17600, in 0.375s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16630, val loss: 0.16426, in 0.326s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15098, val loss: 0.14935, in 0.262s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18316, val loss: 0.18190, in 0.282s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03857, val loss: 0.03836, in 0.295s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16444, val loss: 0.16241, in 0.264s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17345, val loss: 0.17182, in 0.299s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14850, val loss: 0.14693, in 0.280s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18049, val loss: 0.17920, in 0.254s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03817, val loss: 0.03799, in 0.260s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16224, val loss: 0.16020, in 0.293s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17105, val loss: 0.16939, in 0.295s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14684, val loss: 0.14528, in 0.310s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03773, val loss: 0.03756, in 0.363s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.17685, val loss: 0.17561, in 0.431s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15986, val loss: 0.15785, in 0.350s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16737, val loss: 0.16575, in 0.374s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14536, val loss: 0.14381, in 0.321s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03747, val loss: 0.03730, in 0.306s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17341, val loss: 0.17221, in 0.320s\n",
      "[34/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.15776, val loss: 0.15582, in 0.322s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16545, val loss: 0.16381, in 0.325s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14356, val loss: 0.14207, in 0.371s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03713, val loss: 0.03695, in 0.404s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15640, val loss: 0.15445, in 0.323s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16912, val loss: 0.16802, in 0.406s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16273, val loss: 0.16109, in 0.340s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14238, val loss: 0.14079, in 0.288s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16682, val loss: 0.16574, in 0.269s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15449, val loss: 0.15254, in 0.318s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15998, val loss: 0.15848, in 0.275s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14037, val loss: 0.13881, in 0.293s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16456, val loss: 0.16347, in 0.257s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15822, val loss: 0.15670, in 0.241s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15276, val loss: 0.15076, in 0.266s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13878, val loss: 0.13723, in 0.257s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15129, val loss: 0.14925, in 0.234s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15633, val loss: 0.15486, in 0.271s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16184, val loss: 0.16081, in 0.319s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13724, val loss: 0.13579, in 0.296s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14920, val loss: 0.14709, in 0.455s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15388, val loss: 0.15244, in 0.431s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15982, val loss: 0.15877, in 0.417s\n",
      "[39/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13588, val loss: 0.13443, in 0.438s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15159, val loss: 0.15021, in 0.235s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15796, val loss: 0.15693, in 0.234s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14681, val loss: 0.14478, in 0.264s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13475, val loss: 0.13330, in 0.236s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14551, val loss: 0.14351, in 0.238s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15521, val loss: 0.15432, in 0.263s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14963, val loss: 0.14836, in 0.284s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13384, val loss: 0.13228, in 0.215s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14423, val loss: 0.14225, in 0.293s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15358, val loss: 0.15268, in 0.294s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14797, val loss: 0.14666, in 0.323s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13273, val loss: 0.13109, in 0.320s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03754, val loss: 0.03816, in 0.282s\n",
      "Fit 200 trees in 63.804 s, (1531 total leaves)\n",
      "Time spent computing histograms: 36.639s\n",
      "Time spent finding best splits:  0.305s\n",
      "Time spent applying splits:      5.007s\n",
      "Time spent predicting:           0.516s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.14260, val loss: 0.14063, in 0.364s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15122, val loss: 0.15038, in 0.357s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13127, val loss: 0.12961, in 0.314s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14658, val loss: 0.14523, in 0.360s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14116, val loss: 0.13929, in 0.298s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12998, val loss: 0.12841, in 0.311s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14464, val loss: 0.14329, in 0.311s\n",
      "[47/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14938, val loss: 0.14858, in 0.383s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13997, val loss: 0.13807, in 0.260s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12905, val loss: 0.12743, in 0.254s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14264, val loss: 0.14141, in 0.295s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14706, val loss: 0.14635, in 0.274s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13812, val loss: 0.13619, in 0.286s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12754, val loss: 0.12591, in 0.336s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14132, val loss: 0.13996, in 0.293s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14539, val loss: 0.14465, in 0.313s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13712, val loss: 0.13515, in 0.255s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12596, val loss: 0.12438, in 0.242s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14008, val loss: 0.13874, in 0.255s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03477, val loss: 0.03529, in 0.248s\n",
      "Fit 200 trees in 63.656 s, (1538 total leaves)\n",
      "Time spent computing histograms: 36.395s\n",
      "Time spent finding best splits:  0.337s\n",
      "Time spent applying splits:      4.960s\n",
      "Time spent predicting:           0.627s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.14394, val loss: 0.14320, in 0.266s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13550, val loss: 0.13357, in 0.311s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12421, val loss: 0.12269, in 0.316s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13820, val loss: 0.13682, in 0.306s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14274, val loss: 0.14198, in 0.271s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13399, val loss: 0.13201, in 0.319s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14146, val loss: 0.14056, in 0.292s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12216, val loss: 0.12067, in 0.311s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13662, val loss: 0.13535, in 0.319s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13293, val loss: 0.13097, in 0.243s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13566, val loss: 0.13438, in 0.265s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13877, val loss: 0.13795, in 0.332s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12046, val loss: 0.11902, in 0.331s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03834, val loss: 0.03732, in 0.302s\n",
      "Fit 200 trees in 64.208 s, (1534 total leaves)\n",
      "Time spent computing histograms: 37.490s\n",
      "Time spent finding best splits:  0.299s\n",
      "Time spent applying splits:      5.111s\n",
      "Time spent predicting:           0.668s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.13144, val loss: 0.12946, in 0.280s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13389, val loss: 0.13267, in 0.248s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11961, val loss: 0.11816, in 0.254s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13699, val loss: 0.13620, in 0.340s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12924, val loss: 0.12731, in 0.332s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13264, val loss: 0.13145, in 0.307s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11821, val loss: 0.11679, in 0.329s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13583, val loss: 0.13509, in 0.288s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12836, val loss: 0.12651, in 0.249s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13110, val loss: 0.12992, in 0.276s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11676, val loss: 0.11530, in 0.322s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13492, val loss: 0.13413, in 0.292s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12759, val loss: 0.12571, in 0.264s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12976, val loss: 0.12862, in 0.295s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11617, val loss: 0.11467, in 0.235s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13360, val loss: 0.13281, in 0.250s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12663, val loss: 0.12464, in 0.263s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12850, val loss: 0.12742, in 0.295s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11477, val loss: 0.11337, in 0.319s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12540, val loss: 0.12340, in 0.251s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13199, val loss: 0.13112, in 0.306s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12702, val loss: 0.12599, in 0.230s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03692, val loss: 0.03675, in 0.297s\n",
      "Fit 200 trees in 64.400 s, (1540 total leaves)\n",
      "Time spent computing histograms: 37.416s\n",
      "Time spent finding best splits:  0.280s\n",
      "Time spent applying splits:      5.430s\n",
      "Time spent predicting:           0.417s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11412, val loss: 0.11275, in 0.255s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13052, val loss: 0.12977, in 0.253s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12362, val loss: 0.12166, in 0.268s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12599, val loss: 0.12484, in 0.303s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12255, val loss: 0.12060, in 0.281s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11177, in 0.314s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12885, val loss: 0.12817, in 0.306s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12417, val loss: 0.12302, in 0.284s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11187, val loss: 0.11059, in 0.264s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12084, val loss: 0.11896, in 0.304s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12689, val loss: 0.12631, in 0.317s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12269, val loss: 0.12160, in 0.286s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11050, val loss: 0.10927, in 0.288s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12590, val loss: 0.12524, in 0.265s\n",
      "[59/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11969, val loss: 0.11777, in 0.312s\n",
      "[67/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12154, val loss: 0.12053, in 0.301s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10956, val loss: 0.10841, in 0.246s\n",
      "[74/200] 5.267 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.12377, val loss: 0.12316, in 0.276s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11846, val loss: 0.11658, in 0.260s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12048, val loss: 0.11944, in 0.237s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10882, val loss: 0.10763, in 0.237s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11510, in 0.223s\n",
      "[69/200] 0.190 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12266, val loss: 0.12208, in 0.291s\n",
      "[61/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11970, val loss: 0.11867, in 0.234s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10731, val loss: 0.10617, in 0.246s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11618, val loss: 0.11430, in 0.264s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12122, val loss: 0.12061, in 0.244s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62679, val loss: 0.62672, in 0.349s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11837, val loss: 0.11731, in 0.266s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10647, val loss: 0.10531, in 0.274s\n",
      "[77/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12043, val loss: 0.11989, in 0.277s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11363, val loss: 0.11179, in 0.333s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11709, val loss: 0.11607, in 0.288s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57231, val loss: 0.57228, in 0.322s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10545, val loss: 0.10430, in 0.245s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11976, val loss: 0.11921, in 0.246s\n",
      "[64/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11309, val loss: 0.11123, in 0.240s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11588, val loss: 0.11491, in 0.253s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52710, val loss: 0.52698, in 0.316s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10257, val loss: 0.10148, in 0.337s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11878, val loss: 0.11823, in 0.240s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11199, val loss: 0.11010, in 0.263s\n",
      "[73/200] 5.200 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11502, val loss: 0.11407, in 0.290s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10184, val loss: 0.10071, in 0.299s\n",
      "[80/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11106, val loss: 0.10917, in 0.248s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48889, val loss: 0.48877, in 0.336s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11754, val loss: 0.11703, in 0.312s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11438, val loss: 0.11339, in 0.232s\n",
      "[70/200] 0.208 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10099, val loss: 0.09986, in 0.288s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11011, val loss: 0.10824, in 0.334s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11632, val loss: 0.11580, in 0.350s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45639, val loss: 0.45610, in 0.373s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11347, val loss: 0.11248, in 0.340s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62676, val loss: 0.62668, in 0.392s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10001, val loss: 0.09892, in 0.275s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10911, val loss: 0.10728, in 0.295s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11574, val loss: 0.11519, in 0.249s\n",
      "[68/200] 5.212 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.11239, val loss: 0.11142, in 0.316s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42314, val loss: 0.42279, in 0.395s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09951, val loss: 0.09850, in 0.241s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57226, val loss: 0.57229, in 0.343s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10790, val loss: 0.10609, in 0.288s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11474, val loss: 0.11419, in 0.305s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10988, val loss: 0.10888, in 0.303s\n",
      "[73/200] 0.204 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09903, val loss: 0.09800, in 0.302s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39463, val loss: 0.39424, in 0.393s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11344, val loss: 0.11295, in 0.277s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52702, val loss: 0.52697, in 0.370s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10705, val loss: 0.10528, in 0.331s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10886, val loss: 0.10790, in 0.264s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09832, val loss: 0.09728, in 0.234s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62678, val loss: 0.62681, in 0.347s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11228, val loss: 0.11179, in 0.251s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10654, val loss: 0.10476, in 0.250s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36999, val loss: 0.36959, in 0.374s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48879, val loss: 0.48882, in 0.335s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10779, val loss: 0.10682, in 0.260s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09740, val loss: 0.09631, in 0.323s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11074, val loss: 0.11029, in 0.252s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.57231, val loss: 0.57223, in 0.316s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10699, val loss: 0.10602, in 0.201s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10358, val loss: 0.10186, in 0.302s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34853, val loss: 0.34820, in 0.299s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45628, val loss: 0.45619, in 0.280s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09677, val loss: 0.09570, in 0.217s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10963, val loss: 0.10923, in 0.275s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.52710, val loss: 0.52705, in 0.282s\n",
      "[4/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10280, val loss: 0.10108, in 0.234s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10598, val loss: 0.10503, in 0.277s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09639, val loss: 0.09530, in 0.214s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32990, val loss: 0.32954, in 0.312s\n",
      "[11/200] 4.923 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.42308, val loss: 0.42288, in 0.329s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10817, val loss: 0.10781, in 0.255s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10111, val loss: 0.09944, in 0.287s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.48886, val loss: 0.48871, in 0.309s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10385, val loss: 0.10287, in 0.266s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09537, val loss: 0.09435, in 0.308s\n",
      "[89/200] 0.209 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10753, val loss: 0.10713, in 0.265s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31363, val loss: 0.31318, in 0.376s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39459, val loss: 0.39434, in 0.363s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10306, val loss: 0.10210, in 0.243s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10019, val loss: 0.09858, in 0.292s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.45635, val loss: 0.45596, in 0.320s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09296, val loss: 0.09200, in 0.327s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10622, val loss: 0.10586, in 0.258s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.62335, val loss: 0.62336, in 0.320s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10220, val loss: 0.10126, in 0.231s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29859, val loss: 0.29804, in 0.308s\n",
      "[13/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09906, val loss: 0.09742, in 0.235s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36997, val loss: 0.36977, in 0.319s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.42318, val loss: 0.42268, in 0.294s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09151, val loss: 0.09055, in 0.248s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10528, val loss: 0.10491, in 0.210s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.56608, val loss: 0.56601, in 0.311s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10080, val loss: 0.09989, in 0.288s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09840, val loss: 0.09676, in 0.274s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28579, val loss: 0.28526, in 0.356s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34854, val loss: 0.34830, in 0.362s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.39468, val loss: 0.39421, in 0.345s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10245, val loss: 0.10208, in 0.332s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10027, val loss: 0.09933, in 0.227s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08946, val loss: 0.08854, in 0.356s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09761, val loss: 0.09601, in 0.261s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.51854, val loss: 0.51847, in 0.293s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27399, val loss: 0.27343, in 0.315s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.32994, val loss: 0.32965, in 0.309s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10168, val loss: 0.10131, in 0.251s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08832, val loss: 0.08737, in 0.240s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09912, val loss: 0.09823, in 0.283s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.37006, val loss: 0.36948, in 0.326s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09668, val loss: 0.09509, in 0.256s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.47843, val loss: 0.47830, in 0.314s\n",
      "[5/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10023, val loss: 0.09989, in 0.291s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08750, val loss: 0.08660, in 0.282s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26393, val loss: 0.26331, in 0.351s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09841, val loss: 0.09757, in 0.257s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09583, val loss: 0.09421, in 0.258s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31369, val loss: 0.31330, in 0.359s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34864, val loss: 0.34798, in 0.342s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.44433, val loss: 0.44403, in 0.326s\n",
      "[6/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09544, val loss: 0.09381, in 0.251s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09901, val loss: 0.09872, in 0.300s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08645, val loss: 0.08557, in 0.314s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09674, val loss: 0.09593, in 0.319s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25446, val loss: 0.25374, in 0.360s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29870, val loss: 0.29814, in 0.369s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33006, val loss: 0.32931, in 0.359s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.41508, val loss: 0.41460, in 0.334s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09834, val loss: 0.09806, in 0.278s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09431, val loss: 0.09266, in 0.304s\n",
      "[90/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08541, val loss: 0.08454, in 0.284s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09589, val loss: 0.09507, in 0.301s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24645, val loss: 0.24574, in 0.334s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28590, val loss: 0.28536, in 0.349s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.38976, val loss: 0.38931, in 0.289s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31380, val loss: 0.31305, in 0.350s\n",
      "[12/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09367, val loss: 0.09204, in 0.270s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09625, val loss: 0.09591, in 0.294s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08458, val loss: 0.08370, in 0.283s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09455, val loss: 0.09377, in 0.295s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23916, val loss: 0.23836, in 0.387s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09551, val loss: 0.09515, in 0.249s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08419, val loss: 0.08327, in 0.251s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.36778, val loss: 0.36725, in 0.354s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09373, val loss: 0.09294, in 0.220s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27414, val loss: 0.27357, in 0.389s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09289, val loss: 0.09128, in 0.287s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29878, val loss: 0.29785, in 0.348s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08370, val loss: 0.08278, in 0.230s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23252, val loss: 0.23169, in 0.289s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09467, val loss: 0.09435, in 0.263s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09166, val loss: 0.09009, in 0.256s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09271, val loss: 0.09194, in 0.268s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.34861, val loss: 0.34800, in 0.331s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28597, val loss: 0.28492, in 0.331s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26407, val loss: 0.26343, in 0.355s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08342, val loss: 0.08255, in 0.239s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09353, val loss: 0.09322, in 0.268s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09125, val loss: 0.08966, in 0.245s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09123, in 0.265s\n",
      "[90/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22571, val loss: 0.22479, in 0.344s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.33186, val loss: 0.33114, in 0.304s\n",
      "[11/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25463, val loss: 0.25385, in 0.358s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27424, val loss: 0.27316, in 0.374s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08212, val loss: 0.08127, in 0.277s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09297, val loss: 0.09264, in 0.277s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09135, val loss: 0.09058, in 0.260s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09016, val loss: 0.08862, in 0.300s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22008, val loss: 0.21912, in 0.329s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.31424, val loss: 0.31354, in 0.346s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08146, val loss: 0.08066, in 0.255s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09199, val loss: 0.09172, in 0.230s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26417, val loss: 0.26300, in 0.312s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08950, val loss: 0.08799, in 0.233s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24669, val loss: 0.24584, in 0.325s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08969, val loss: 0.08888, in 0.249s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21529, val loss: 0.21429, in 0.264s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08093, val loss: 0.08017, in 0.214s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09127, val loss: 0.09102, in 0.286s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08854, val loss: 0.08776, in 0.263s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.29802, val loss: 0.29716, in 0.338s\n",
      "[13/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08894, val loss: 0.08741, in 0.282s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25453, val loss: 0.25326, in 0.339s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23933, val loss: 0.23851, in 0.344s\n",
      "[19/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08065, val loss: 0.07990, in 0.244s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20973, val loss: 0.20875, in 0.356s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08832, val loss: 0.08681, in 0.229s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09042, val loss: 0.09015, in 0.294s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08721, val loss: 0.08646, in 0.288s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.28427, val loss: 0.28333, in 0.317s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23272, val loss: 0.23180, in 0.286s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24659, val loss: 0.24529, in 0.322s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07902, val loss: 0.07831, in 0.351s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08997, val loss: 0.08967, in 0.291s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20549, val loss: 0.20451, in 0.356s\n",
      "[25/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08652, val loss: 0.08578, in 0.289s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08753, val loss: 0.08598, in 0.337s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.27166, val loss: 0.27068, in 0.402s\n",
      "[15/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.22590, val loss: 0.22491, in 0.391s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07798, val loss: 0.07727, in 0.306s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23926, val loss: 0.23798, in 0.409s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08826, val loss: 0.08790, in 0.264s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08653, val loss: 0.08502, in 0.261s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08579, val loss: 0.08506, in 0.277s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20085, val loss: 0.19992, in 0.366s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07664, val loss: 0.07592, in 0.270s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08767, val loss: 0.08731, in 0.244s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22026, val loss: 0.21926, in 0.336s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08591, val loss: 0.08443, in 0.259s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.26091, val loss: 0.25979, in 0.381s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23258, val loss: 0.23123, in 0.317s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08515, val loss: 0.08444, in 0.268s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19713, val loss: 0.19617, in 0.242s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08673, val loss: 0.08638, in 0.290s\n",
      "[94/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08546, val loss: 0.08399, in 0.277s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07585, val loss: 0.07512, in 0.319s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08444, val loss: 0.08375, in 0.278s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21537, val loss: 0.21431, in 0.340s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.25056, val loss: 0.24938, in 0.380s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22521, val loss: 0.22375, in 0.390s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19350, val loss: 0.19257, in 0.341s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07519, val loss: 0.07451, in 0.303s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08550, val loss: 0.08519, in 0.335s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08303, val loss: 0.08232, in 0.327s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08339, val loss: 0.08197, in 0.417s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20980, val loss: 0.20877, in 0.414s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.24202, val loss: 0.24085, in 0.435s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21964, val loss: 0.21816, in 0.425s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18956, val loss: 0.18868, in 0.411s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07414, val loss: 0.07348, in 0.334s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08432, in 0.317s\n",
      "[96/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08250, val loss: 0.08177, in 0.307s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08233, val loss: 0.08092, in 0.288s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20568, val loss: 0.20467, in 0.390s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18653, val loss: 0.18566, in 0.332s\n",
      "[30/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.21412, val loss: 0.21270, in 0.390s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.23406, val loss: 0.23281, in 0.400s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08194, val loss: 0.08121, in 0.295s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07385, val loss: 0.07319, in 0.313s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08408, val loss: 0.08383, in 0.325s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08057, val loss: 0.07920, in 0.440s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18276, val loss: 0.18196, in 0.302s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07358, val loss: 0.07291, in 0.260s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20100, val loss: 0.19997, in 0.357s\n",
      "[26/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08348, val loss: 0.08327, in 0.264s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20932, val loss: 0.20799, in 0.295s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08043, val loss: 0.07964, in 0.299s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22723, val loss: 0.22591, in 0.377s\n",
      "[20/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08008, val loss: 0.07872, in 0.281s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19722, val loss: 0.19616, in 0.365s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07308, val loss: 0.07245, in 0.378s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08205, val loss: 0.08179, in 0.368s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17864, val loss: 0.17792, in 0.414s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07998, val loss: 0.07922, in 0.360s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20509, val loss: 0.20377, in 0.445s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07974, val loss: 0.07841, in 0.305s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.22093, val loss: 0.21963, in 0.420s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07204, val loss: 0.07142, in 0.268s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17604, val loss: 0.17529, in 0.300s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07886, val loss: 0.07814, in 0.300s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19301, val loss: 0.19201, in 0.333s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08096, val loss: 0.08078, in 0.325s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.20040, val loss: 0.19911, in 0.325s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07896, val loss: 0.07762, in 0.298s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.21548, val loss: 0.21425, in 0.297s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07110, val loss: 0.07048, in 0.287s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17352, val loss: 0.17285, in 0.274s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18970, val loss: 0.18871, in 0.279s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07818, val loss: 0.07746, in 0.287s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08033, val loss: 0.08017, in 0.280s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19664, val loss: 0.19532, in 0.262s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07838, val loss: 0.07708, in 0.280s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20981, val loss: 0.20853, in 0.365s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07062, val loss: 0.07006, in 0.279s\n",
      "[116/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07984, val loss: 0.07969, in 0.252s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17047, val loss: 0.16981, in 0.293s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07711, val loss: 0.07639, in 0.280s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18653, val loss: 0.18552, in 0.310s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19323, val loss: 0.19180, in 0.267s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07798, val loss: 0.07670, in 0.261s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06998, val loss: 0.06947, in 0.245s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20543, val loss: 0.20420, in 0.292s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07930, val loss: 0.07916, in 0.266s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07642, val loss: 0.07564, in 0.282s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18273, val loss: 0.18178, in 0.257s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07774, val loss: 0.07648, in 0.224s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16724, val loss: 0.16658, in 0.326s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18976, val loss: 0.18836, in 0.310s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06926, val loss: 0.06873, in 0.283s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07903, val loss: 0.07888, in 0.269s\n",
      "[104/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07595, val loss: 0.07518, in 0.262s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.20082, val loss: 0.19966, in 0.362s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16512, val loss: 0.16448, in 0.302s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17983, val loss: 0.17888, in 0.347s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07675, val loss: 0.07552, in 0.354s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18591, val loss: 0.18455, in 0.334s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06871, val loss: 0.06820, in 0.252s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07852, val loss: 0.07839, in 0.298s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07504, val loss: 0.07429, in 0.304s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17726, val loss: 0.17633, in 0.260s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19698, val loss: 0.19588, in 0.316s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16136, val loss: 0.16074, in 0.314s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07629, val loss: 0.07504, in 0.266s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18324, val loss: 0.18186, in 0.265s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06814, val loss: 0.06760, in 0.334s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07750, val loss: 0.07741, in 0.273s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07439, val loss: 0.07368, in 0.267s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17388, val loss: 0.17304, in 0.285s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.19362, val loss: 0.19246, in 0.287s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07559, val loss: 0.07435, in 0.265s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15953, val loss: 0.15895, in 0.278s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18014, val loss: 0.17883, in 0.299s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06767, val loss: 0.06713, in 0.325s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07629, val loss: 0.07615, in 0.303s\n",
      "[107/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.07366, val loss: 0.07294, in 0.289s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15693, val loss: 0.15643, in 0.317s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17012, val loss: 0.16937, in 0.378s\n",
      "[35/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.18974, val loss: 0.18856, in 0.389s\n",
      "[28/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07442, val loss: 0.07315, in 0.391s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17736, val loss: 0.17605, in 0.328s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07536, val loss: 0.07522, in 0.323s\n",
      "[108/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06696, val loss: 0.06642, in 0.331s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07313, val loss: 0.07239, in 0.334s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16800, val loss: 0.16728, in 0.320s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15515, val loss: 0.15462, in 0.345s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18649, val loss: 0.18530, in 0.304s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17494, val loss: 0.17369, in 0.311s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07330, val loss: 0.07207, in 0.325s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06654, val loss: 0.06603, in 0.299s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07283, val loss: 0.07209, in 0.294s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07466, val loss: 0.07455, in 0.323s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.18240, val loss: 0.18121, in 0.328s\n",
      "[30/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15276, val loss: 0.15230, in 0.356s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16506, val loss: 0.16431, in 0.384s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07274, val loss: 0.07151, in 0.350s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17170, val loss: 0.17045, in 0.373s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07233, val loss: 0.07161, in 0.284s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06582, val loss: 0.06530, in 0.310s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07426, val loss: 0.07418, in 0.310s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15126, val loss: 0.15084, in 0.346s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07247, val loss: 0.07128, in 0.330s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17874, val loss: 0.17757, in 0.401s\n",
      "[31/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16945, val loss: 0.16817, in 0.351s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07206, val loss: 0.07137, in 0.319s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16259, val loss: 0.16190, in 0.383s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07396, val loss: 0.07388, in 0.324s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06483, val loss: 0.06433, in 0.408s\n",
      "[125/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07166, val loss: 0.07098, in 0.278s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07173, val loss: 0.07056, in 0.316s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14899, val loss: 0.14859, in 0.343s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17527, val loss: 0.17411, in 0.351s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16734, val loss: 0.16601, in 0.337s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07292, val loss: 0.07287, in 0.298s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15980, val loss: 0.15927, in 0.335s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06441, val loss: 0.06392, in 0.346s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07081, val loss: 0.07016, in 0.306s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16507, val loss: 0.16382, in 0.261s\n",
      "[38/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07065, val loss: 0.06950, in 0.323s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14763, val loss: 0.14718, in 0.321s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.17194, val loss: 0.17080, in 0.361s\n",
      "[33/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07237, val loss: 0.07229, in 0.364s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15625, val loss: 0.15571, in 0.382s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06395, val loss: 0.06346, in 0.295s\n",
      "[127/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07028, val loss: 0.06915, in 0.273s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07040, val loss: 0.06976, in 0.305s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14622, val loss: 0.14579, in 0.287s\n",
      "[46/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07195, val loss: 0.07187, in 0.218s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16974, val loss: 0.16867, in 0.252s\n",
      "[34/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15452, val loss: 0.15402, in 0.244s\n",
      "[41/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16190, val loss: 0.16068, in 0.378s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06349, val loss: 0.06299, in 0.310s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06954, val loss: 0.06891, in 0.253s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06979, val loss: 0.06866, in 0.284s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14464, val loss: 0.14416, in 0.279s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07150, val loss: 0.07143, in 0.259s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16724, val loss: 0.16607, in 0.253s\n",
      "[35/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15997, val loss: 0.15878, in 0.247s\n",
      "[40/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06329, val loss: 0.06278, in 0.169s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15264, val loss: 0.15213, in 0.264s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14333, val loss: 0.14288, in 0.291s\n",
      "[48/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.07111, val loss: 0.07106, in 0.291s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06849, val loss: 0.06783, in 0.328s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16501, val loss: 0.16395, in 0.286s\n",
      "[36/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06295, val loss: 0.06243, in 0.309s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06846, val loss: 0.06737, in 0.376s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15724, val loss: 0.15608, in 0.336s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15072, val loss: 0.15022, in 0.333s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14092, val loss: 0.14051, in 0.278s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06792, val loss: 0.06726, in 0.299s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07047, val loss: 0.07037, in 0.315s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06226, val loss: 0.06176, in 0.291s\n",
      "[131/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.16207, val loss: 0.16102, in 0.360s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15462, val loss: 0.15344, in 0.291s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06777, val loss: 0.06670, in 0.313s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14886, val loss: 0.14837, in 0.314s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06767, val loss: 0.06701, in 0.231s\n",
      "[122/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06995, val loss: 0.06989, in 0.292s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06134, val loss: 0.06087, in 0.269s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06745, val loss: 0.06640, in 0.246s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.16018, val loss: 0.15922, in 0.255s\n",
      "[38/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13914, val loss: 0.13872, in 0.356s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15320, val loss: 0.15205, in 0.263s\n",
      "[43/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14672, val loss: 0.14628, in 0.304s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06716, val loss: 0.06657, in 0.324s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06679, val loss: 0.06575, in 0.271s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06936, val loss: 0.06932, in 0.299s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15810, val loss: 0.15719, in 0.277s\n",
      "[39/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15162, val loss: 0.15049, in 0.276s\n",
      "[44/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06041, val loss: 0.05997, in 0.308s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13669, val loss: 0.13630, in 0.318s\n",
      "[51/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14532, val loss: 0.14492, in 0.247s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06644, val loss: 0.06586, in 0.232s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06654, val loss: 0.06550, in 0.238s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05999, val loss: 0.05954, in 0.218s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15614, val loss: 0.15515, in 0.246s\n",
      "[40/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06868, val loss: 0.06863, in 0.288s\n",
      "[120/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14907, val loss: 0.14799, in 0.298s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13494, val loss: 0.13451, in 0.292s\n",
      "[52/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14366, val loss: 0.14326, in 0.299s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06558, val loss: 0.06503, in 0.301s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06635, val loss: 0.06534, in 0.264s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05953, val loss: 0.05911, in 0.288s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15431, val loss: 0.15338, in 0.289s\n",
      "[41/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06824, val loss: 0.06821, in 0.302s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14687, val loss: 0.14576, in 0.312s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13361, val loss: 0.13320, in 0.295s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14228, val loss: 0.14186, in 0.297s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06533, val loss: 0.06477, in 0.227s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06574, val loss: 0.06475, in 0.222s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05902, val loss: 0.05863, in 0.255s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15187, val loss: 0.15102, in 0.265s\n",
      "[42/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14533, val loss: 0.14419, in 0.232s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06740, val loss: 0.06735, in 0.282s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13227, val loss: 0.13190, in 0.277s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14038, val loss: 0.13989, in 0.307s\n",
      "[49/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06499, val loss: 0.06444, in 0.267s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06492, val loss: 0.06397, in 0.279s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.15049, val loss: 0.14969, in 0.258s\n",
      "[43/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06707, val loss: 0.06701, in 0.225s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05848, val loss: 0.05806, in 0.314s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14375, val loss: 0.14259, in 0.261s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13120, val loss: 0.13084, in 0.240s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13876, val loss: 0.13829, in 0.247s\n",
      "[50/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06425, val loss: 0.06372, in 0.255s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06426, val loss: 0.06334, in 0.260s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06682, val loss: 0.06676, in 0.228s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05813, val loss: 0.05772, in 0.231s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12969, val loss: 0.12934, in 0.216s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14225, val loss: 0.14114, in 0.250s\n",
      "[49/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.14805, val loss: 0.14725, in 0.337s\n",
      "[44/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13768, val loss: 0.13726, in 0.222s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06394, val loss: 0.06340, in 0.237s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06366, val loss: 0.06276, in 0.238s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06601, val loss: 0.06599, in 0.254s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05709, val loss: 0.05671, in 0.281s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14655, val loss: 0.14565, in 0.245s\n",
      "[45/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12823, val loss: 0.12793, in 0.284s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13895, val loss: 0.13787, in 0.328s\n",
      "[50/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06375, val loss: 0.06322, in 0.240s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13633, val loss: 0.13589, in 0.301s\n",
      "[52/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06324, val loss: 0.06237, in 0.270s\n",
      "[133/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06564, val loss: 0.06563, in 0.284s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14415, val loss: 0.14323, in 0.310s\n",
      "[46/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05647, val loss: 0.05612, in 0.339s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13769, val loss: 0.13664, in 0.262s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12671, val loss: 0.12654, in 0.317s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06336, val loss: 0.06286, in 0.261s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13525, val loss: 0.13482, in 0.261s\n",
      "[53/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06289, val loss: 0.06201, in 0.311s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06497, val loss: 0.06498, in 0.310s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13634, val loss: 0.13530, in 0.267s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06317, val loss: 0.06268, in 0.264s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05599, val loss: 0.05565, in 0.307s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14195, val loss: 0.14103, in 0.320s\n",
      "[47/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12561, val loss: 0.12543, in 0.309s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13323, val loss: 0.13287, in 0.370s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06234, val loss: 0.06146, in 0.336s\n",
      "[135/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06455, val loss: 0.06458, in 0.295s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06283, val loss: 0.06236, in 0.255s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05581, val loss: 0.05545, in 0.259s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13506, val loss: 0.13411, in 0.306s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.14075, val loss: 0.13989, in 0.267s\n",
      "[48/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12422, val loss: 0.12396, in 0.298s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13213, val loss: 0.13166, in 0.237s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06202, val loss: 0.06116, in 0.305s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06415, val loss: 0.06421, in 0.297s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06238, val loss: 0.06192, in 0.329s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05548, val loss: 0.05512, in 0.312s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.13358, val loss: 0.13263, in 0.309s\n",
      "[54/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13924, val loss: 0.13844, in 0.302s\n",
      "[49/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13044, val loss: 0.13000, in 0.360s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12075, val loss: 0.12051, in 0.439s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06178, val loss: 0.06093, in 0.296s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06217, val loss: 0.06174, in 0.234s\n",
      "[135/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06350, val loss: 0.06356, in 0.343s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13183, val loss: 0.13089, in 0.287s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13773, val loss: 0.13693, in 0.321s\n",
      "[50/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05500, val loss: 0.05465, in 0.341s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12895, val loss: 0.12855, in 0.265s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06128, val loss: 0.06046, in 0.275s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11959, val loss: 0.11936, in 0.294s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06193, val loss: 0.06151, in 0.263s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06282, val loss: 0.06295, in 0.280s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13625, val loss: 0.13539, in 0.242s\n",
      "[51/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12980, val loss: 0.12895, in 0.287s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05439, val loss: 0.05404, in 0.272s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12723, val loss: 0.12686, in 0.270s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11836, val loss: 0.11814, in 0.289s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06136, val loss: 0.06095, in 0.293s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06028, val loss: 0.05948, in 0.355s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06225, val loss: 0.06239, in 0.329s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12863, val loss: 0.12777, in 0.326s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05423, val loss: 0.05389, in 0.301s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13430, val loss: 0.13342, in 0.355s\n",
      "[52/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11715, val loss: 0.11701, in 0.280s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06071, val loss: 0.06033, in 0.278s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12363, val loss: 0.12326, in 0.400s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05947, val loss: 0.05864, in 0.323s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06158, val loss: 0.06175, in 0.313s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12724, val loss: 0.12637, in 0.297s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.13321, val loss: 0.13234, in 0.277s\n",
      "[53/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05372, val loss: 0.05338, in 0.294s\n",
      "[147/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11605, val loss: 0.11595, in 0.228s\n",
      "[65/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05998, val loss: 0.05957, in 0.240s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12197, in 0.277s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05918, val loss: 0.05833, in 0.242s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05347, val loss: 0.05316, in 0.220s\n",
      "[148/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06128, val loss: 0.06145, in 0.234s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12612, val loss: 0.12526, in 0.234s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12992, val loss: 0.12912, in 0.324s\n",
      "[54/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05969, val loss: 0.05930, in 0.253s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12149, val loss: 0.12116, in 0.229s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11310, val loss: 0.11300, in 0.391s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05869, val loss: 0.05786, in 0.296s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06087, val loss: 0.06107, in 0.322s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05282, val loss: 0.05252, in 0.341s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.12486, val loss: 0.12402, in 0.409s\n",
      "[60/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05949, val loss: 0.05910, in 0.315s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12835, val loss: 0.12759, in 0.371s\n",
      "[55/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12053, val loss: 0.12023, in 0.342s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11223, val loss: 0.11218, in 0.300s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05829, val loss: 0.05747, in 0.319s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06061, val loss: 0.06082, in 0.279s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05265, val loss: 0.05238, in 0.305s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05916, val loss: 0.05874, in 0.256s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12385, val loss: 0.12301, in 0.282s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12694, val loss: 0.12619, in 0.259s\n",
      "[56/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11910, val loss: 0.11891, in 0.278s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11124, val loss: 0.11120, in 0.231s\n",
      "[68/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05239, val loss: 0.05210, in 0.218s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05759, val loss: 0.05676, in 0.300s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06021, val loss: 0.06040, in 0.316s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05877, val loss: 0.05837, in 0.278s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12230, val loss: 0.12147, in 0.282s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12602, val loss: 0.12534, in 0.255s\n",
      "[57/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11041, val loss: 0.11037, in 0.283s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11838, val loss: 0.11819, in 0.294s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05202, val loss: 0.05175, in 0.323s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05743, val loss: 0.05659, in 0.324s\n",
      "[145/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05998, val loss: 0.06018, in 0.287s\n",
      "[138/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05823, val loss: 0.05783, in 0.281s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12424, val loss: 0.12357, in 0.268s\n",
      "[58/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12131, val loss: 0.12050, in 0.286s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10939, val loss: 0.10938, in 0.287s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11662, val loss: 0.11643, in 0.296s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05166, val loss: 0.05141, in 0.220s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05978, val loss: 0.06001, in 0.220s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05655, val loss: 0.05576, in 0.255s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05773, val loss: 0.05736, in 0.248s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12046, val loss: 0.11966, in 0.252s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12190, val loss: 0.12122, in 0.289s\n",
      "[59/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10837, val loss: 0.10840, in 0.276s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11544, val loss: 0.11527, in 0.274s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05140, val loss: 0.05116, in 0.228s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05895, val loss: 0.05919, in 0.271s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05751, val loss: 0.05713, in 0.222s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05574, val loss: 0.05497, in 0.276s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.12105, val loss: 0.12044, in 0.207s\n",
      "[60/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11914, val loss: 0.11842, in 0.250s\n",
      "[65/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11473, val loss: 0.11454, in 0.244s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10640, val loss: 0.10643, in 0.258s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05875, val loss: 0.05899, in 0.210s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05067, val loss: 0.05047, in 0.303s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05558, val loss: 0.05481, in 0.240s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11999, val loss: 0.11941, in 0.229s\n",
      "[61/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05713, val loss: 0.05675, in 0.315s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11679, val loss: 0.11613, in 0.324s\n",
      "[66/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05846, val loss: 0.05872, in 0.321s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11179, val loss: 0.11160, in 0.372s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10393, val loss: 0.10396, in 0.378s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05514, val loss: 0.05440, in 0.289s\n",
      "[149/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05689, val loss: 0.05652, in 0.235s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05017, val loss: 0.04996, in 0.336s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11856, val loss: 0.11803, in 0.354s\n",
      "[62/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11546, val loss: 0.11487, in 0.250s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05809, val loss: 0.05833, in 0.285s\n",
      "[143/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05490, val loss: 0.05420, in 0.286s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10299, val loss: 0.10301, in 0.341s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04977, val loss: 0.04953, in 0.329s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10998, val loss: 0.10981, in 0.372s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05617, val loss: 0.05577, in 0.348s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11451, val loss: 0.11393, in 0.304s\n",
      "[68/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11696, val loss: 0.11649, in 0.356s\n",
      "[63/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05790, val loss: 0.05813, in 0.257s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10215, val loss: 0.10218, in 0.234s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05454, val loss: 0.05385, in 0.302s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10929, val loss: 0.10919, in 0.238s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05599, val loss: 0.05558, in 0.230s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04939, val loss: 0.04918, in 0.257s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11371, val loss: 0.11316, in 0.227s\n",
      "[69/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11621, val loss: 0.11581, in 0.203s\n",
      "[64/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05421, val loss: 0.05354, in 0.238s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05703, val loss: 0.05728, in 0.308s\n",
      "[145/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04924, val loss: 0.04899, in 0.226s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10109, val loss: 0.10111, in 0.270s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10807, val loss: 0.10797, in 0.257s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05547, val loss: 0.05507, in 0.265s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11248, val loss: 0.11192, in 0.260s\n",
      "[70/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11411, val loss: 0.11370, in 0.281s\n",
      "[65/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05409, val loss: 0.05342, in 0.254s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10013, val loss: 0.10018, in 0.283s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05667, val loss: 0.05690, in 0.303s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04895, val loss: 0.04870, in 0.310s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10722, val loss: 0.10715, in 0.323s\n",
      "[72/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05492, val loss: 0.05453, in 0.318s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11176, val loss: 0.11124, in 0.299s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11269, val loss: 0.11229, in 0.290s\n",
      "[66/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05341, val loss: 0.05276, in 0.281s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10610, val loss: 0.10607, in 0.192s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05628, val loss: 0.05654, in 0.250s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09800, val loss: 0.09807, in 0.331s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11072, val loss: 0.11020, in 0.276s\n",
      "[72/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05456, val loss: 0.05417, in 0.288s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04833, val loss: 0.04812, in 0.323s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.11114, val loss: 0.11071, in 0.282s\n",
      "[67/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05591, val loss: 0.05617, in 0.236s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05309, val loss: 0.05245, in 0.256s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04812, val loss: 0.04792, in 0.228s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09746, val loss: 0.09749, in 0.245s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10952, val loss: 0.10901, in 0.244s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10363, val loss: 0.10358, in 0.353s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05413, val loss: 0.05379, in 0.254s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.11007, val loss: 0.10965, in 0.302s\n",
      "[68/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05575, val loss: 0.05601, in 0.247s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05253, val loss: 0.05190, in 0.327s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04776, in 0.262s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10844, val loss: 0.10799, in 0.274s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05394, val loss: 0.05361, in 0.277s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09679, val loss: 0.09681, in 0.346s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10270, val loss: 0.10267, in 0.358s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10781, val loss: 0.10746, in 0.373s\n",
      "[69/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05532, val loss: 0.05558, in 0.327s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04750, val loss: 0.04729, in 0.306s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05197, val loss: 0.05135, in 0.319s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05346, val loss: 0.05312, in 0.283s\n",
      "[156/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10741, val loss: 0.10700, in 0.316s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09612, val loss: 0.09617, in 0.270s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10173, val loss: 0.10165, in 0.295s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10723, val loss: 0.10689, in 0.276s\n",
      "[70/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05518, val loss: 0.05543, in 0.267s\n",
      "[151/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05300, val loss: 0.05269, in 0.284s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04717, val loss: 0.04699, in 0.314s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05149, val loss: 0.05089, in 0.342s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10594, val loss: 0.10553, in 0.305s\n",
      "[76/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09502, val loss: 0.09510, in 0.297s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10073, val loss: 0.10068, in 0.282s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10600, val loss: 0.10572, in 0.276s\n",
      "[71/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05469, val loss: 0.05499, in 0.350s\n",
      "[152/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05284, val loss: 0.05252, in 0.290s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04705, val loss: 0.04688, in 0.282s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10536, val loss: 0.10496, in 0.275s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05101, val loss: 0.05040, in 0.306s\n",
      "[159/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09448, val loss: 0.09458, in 0.303s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09977, val loss: 0.09980, in 0.331s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10461, val loss: 0.10435, in 0.312s\n",
      "[72/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05455, val loss: 0.05485, in 0.243s\n",
      "[153/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04686, val loss: 0.04667, in 0.240s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05272, val loss: 0.05239, in 0.254s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05066, val loss: 0.05003, in 0.255s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09404, val loss: 0.09413, in 0.260s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10437, val loss: 0.10392, in 0.333s\n",
      "[78/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09933, val loss: 0.09937, in 0.265s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10403, val loss: 0.10383, in 0.250s\n",
      "[73/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05424, val loss: 0.05451, in 0.279s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05256, val loss: 0.05223, in 0.263s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04615, val loss: 0.04598, in 0.407s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05014, val loss: 0.04954, in 0.341s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09331, val loss: 0.09341, in 0.337s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10333, val loss: 0.10288, in 0.320s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09869, val loss: 0.09867, in 0.290s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10286, val loss: 0.10267, in 0.284s\n",
      "[74/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05380, val loss: 0.05407, in 0.303s\n",
      "[155/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05216, val loss: 0.05184, in 0.289s\n",
      "[161/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04583, val loss: 0.04568, in 0.252s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09211, val loss: 0.09225, in 0.257s\n",
      "[86/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.10190, val loss: 0.10150, in 0.294s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09709, val loss: 0.09712, in 0.292s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04936, val loss: 0.04881, in 0.335s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10149, val loss: 0.10132, in 0.310s\n",
      "[75/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05352, val loss: 0.05382, in 0.286s\n",
      "[156/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05195, val loss: 0.05164, in 0.273s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09156, val loss: 0.09171, in 0.302s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04542, in 0.332s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09665, val loss: 0.09664, in 0.283s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04924, val loss: 0.04870, in 0.310s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.10075, val loss: 0.10057, in 0.347s\n",
      "[76/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09917, val loss: 0.09875, in 0.418s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05333, val loss: 0.05362, in 0.353s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05145, val loss: 0.05115, in 0.348s\n",
      "[163/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09086, val loss: 0.09104, in 0.331s\n",
      "[88/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04535, val loss: 0.04523, in 0.329s\n",
      "[171/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04846, in 0.313s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09589, val loss: 0.09587, in 0.362s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09987, val loss: 0.09970, in 0.306s\n",
      "[77/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09823, val loss: 0.09788, in 0.285s\n",
      "[82/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05298, val loss: 0.05330, in 0.316s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05098, val loss: 0.05070, in 0.339s\n",
      "[164/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04517, val loss: 0.04507, in 0.303s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09020, val loss: 0.09036, in 0.351s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04869, val loss: 0.04814, in 0.300s\n",
      "[165/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09512, val loss: 0.09515, in 0.325s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09906, val loss: 0.09889, in 0.289s\n",
      "[78/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09726, val loss: 0.09691, in 0.340s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05274, val loss: 0.05308, in 0.317s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05058, val loss: 0.05033, in 0.357s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04485, val loss: 0.04474, in 0.312s\n",
      "[173/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04850, val loss: 0.04795, in 0.276s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08968, val loss: 0.08984, in 0.297s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09425, val loss: 0.09431, in 0.262s\n",
      "[85/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09669, val loss: 0.09640, in 0.256s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09631, val loss: 0.09613, in 0.332s\n",
      "[79/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05245, val loss: 0.05278, in 0.292s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04456, val loss: 0.04447, in 0.234s\n",
      "[174/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05028, val loss: 0.05002, in 0.290s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08924, val loss: 0.08938, in 0.240s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09363, val loss: 0.09369, in 0.257s\n",
      "[86/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04810, val loss: 0.04756, in 0.284s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09542, val loss: 0.09529, in 0.231s\n",
      "[80/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09587, val loss: 0.09564, in 0.288s\n",
      "[85/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05235, val loss: 0.05268, in 0.239s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08796, val loss: 0.08811, in 0.258s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04989, val loss: 0.04966, in 0.285s\n",
      "[167/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04418, val loss: 0.04413, in 0.303s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04774, val loss: 0.04722, in 0.264s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09165, val loss: 0.09169, in 0.329s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09311, val loss: 0.09297, in 0.313s\n",
      "[81/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09509, val loss: 0.09486, in 0.284s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05164, val loss: 0.05192, in 0.290s\n",
      "[162/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04956, val loss: 0.04933, in 0.241s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08753, val loss: 0.08770, in 0.269s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04409, val loss: 0.04406, in 0.257s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04747, val loss: 0.04697, in 0.277s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09029, val loss: 0.09037, in 0.301s\n",
      "[88/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.09442, val loss: 0.09424, in 0.290s\n",
      "[87/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05144, val loss: 0.05174, in 0.276s\n",
      "[163/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09090, val loss: 0.09081, in 0.393s\n",
      "[82/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04916, val loss: 0.04892, in 0.308s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08703, val loss: 0.08716, in 0.291s\n",
      "[94/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04393, val loss: 0.04389, in 0.307s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05129, val loss: 0.05158, in 0.271s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09398, val loss: 0.09378, in 0.290s\n",
      "[88/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04668, val loss: 0.04621, in 0.426s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08951, val loss: 0.08963, in 0.340s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09020, val loss: 0.09015, in 0.251s\n",
      "[83/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04880, val loss: 0.04856, in 0.263s\n",
      "[170/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04363, val loss: 0.04357, in 0.253s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08637, val loss: 0.08649, in 0.317s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.09324, val loss: 0.09309, in 0.322s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04659, val loss: 0.04612, in 0.321s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05096, val loss: 0.05125, in 0.361s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08889, val loss: 0.08904, in 0.479s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08823, val loss: 0.08817, in 0.464s\n",
      "[84/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04827, val loss: 0.04807, in 0.482s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08538, val loss: 0.08553, in 0.426s\n",
      "[96/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04325, val loss: 0.04317, in 0.480s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04616, val loss: 0.04573, in 0.409s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05080, val loss: 0.05111, in 0.412s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08779, val loss: 0.08775, in 0.329s\n",
      "[85/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08790, val loss: 0.08804, in 0.378s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09091, val loss: 0.09073, in 0.615s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04292, val loss: 0.04284, in 0.404s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08468, val loss: 0.08485, in 0.434s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04776, in 0.442s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08684, val loss: 0.08700, in 0.284s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05044, val loss: 0.05073, in 0.416s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08696, val loss: 0.08693, in 0.344s\n",
      "[86/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04594, val loss: 0.04553, in 0.460s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.09014, val loss: 0.09000, in 0.284s\n",
      "[91/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04282, val loss: 0.04274, in 0.242s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08366, val loss: 0.08386, in 0.279s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04749, val loss: 0.04728, in 0.314s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05013, val loss: 0.05045, in 0.281s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08620, val loss: 0.08638, in 0.329s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04572, val loss: 0.04532, in 0.282s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08980, val loss: 0.08966, in 0.293s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08617, val loss: 0.08616, in 0.341s\n",
      "[87/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04256, val loss: 0.04249, in 0.322s\n",
      "[182/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04715, val loss: 0.04695, in 0.293s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08203, val loss: 0.08223, in 0.374s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08540, val loss: 0.08558, in 0.248s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08838, val loss: 0.08825, in 0.255s\n",
      "[93/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08569, val loss: 0.08569, in 0.267s\n",
      "[88/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04240, val loss: 0.04234, in 0.258s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04930, val loss: 0.04963, in 0.359s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04516, val loss: 0.04478, in 0.337s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04687, val loss: 0.04667, in 0.330s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08121, val loss: 0.08141, in 0.316s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08499, val loss: 0.08519, in 0.292s\n",
      "[95/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08772, val loss: 0.08764, in 0.255s\n",
      "[94/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04496, val loss: 0.04457, in 0.266s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08494, val loss: 0.08496, in 0.309s\n",
      "[89/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04202, val loss: 0.04199, in 0.323s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04891, val loss: 0.04926, in 0.350s\n",
      "[170/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04654, val loss: 0.04636, in 0.265s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08094, val loss: 0.08116, in 0.249s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08443, val loss: 0.08462, in 0.281s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08703, val loss: 0.08697, in 0.305s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04449, val loss: 0.04410, in 0.321s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08414, val loss: 0.08410, in 0.330s\n",
      "[90/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04835, val loss: 0.04870, in 0.298s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04634, val loss: 0.04616, in 0.275s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04157, val loss: 0.04156, in 0.365s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08032, val loss: 0.08061, in 0.321s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08377, val loss: 0.08398, in 0.294s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04435, val loss: 0.04394, in 0.282s\n",
      "[178/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08642, val loss: 0.08636, in 0.376s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04146, val loss: 0.04144, in 0.257s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08284, val loss: 0.08282, in 0.322s\n",
      "[91/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04603, val loss: 0.04586, in 0.293s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04769, val loss: 0.04804, in 0.349s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08346, val loss: 0.08370, in 0.257s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07894, val loss: 0.07923, in 0.353s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04397, val loss: 0.04353, in 0.234s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08577, val loss: 0.08573, in 0.246s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04132, val loss: 0.04130, in 0.264s\n",
      "[187/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04583, val loss: 0.04566, in 0.245s\n",
      "[179/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04784, in 0.236s\n",
      "[173/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08180, val loss: 0.08179, in 0.287s\n",
      "[92/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08284, val loss: 0.08311, in 0.292s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07809, val loss: 0.07839, in 0.294s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04387, val loss: 0.04344, in 0.267s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08522, val loss: 0.08520, in 0.273s\n",
      "[98/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04569, val loss: 0.04553, in 0.252s\n",
      "[180/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.08094, val loss: 0.08092, in 0.272s\n",
      "[93/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04088, val loss: 0.04091, in 0.302s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04711, val loss: 0.04746, in 0.286s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08247, val loss: 0.08273, in 0.207s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04378, val loss: 0.04335, in 0.194s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07762, val loss: 0.07793, in 0.236s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08461, val loss: 0.08458, in 0.254s\n",
      "[99/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04066, val loss: 0.04070, in 0.211s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04504, val loss: 0.04481, in 0.296s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08215, val loss: 0.08242, in 0.236s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07932, val loss: 0.07933, in 0.272s\n",
      "[94/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04658, val loss: 0.04695, in 0.274s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04351, val loss: 0.04307, in 0.267s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07712, val loss: 0.07741, in 0.318s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08324, val loss: 0.08324, in 0.313s\n",
      "[100/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04036, val loss: 0.04040, in 0.361s\n",
      "[190/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04632, val loss: 0.04668, in 0.304s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08147, val loss: 0.08176, in 0.332s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07877, val loss: 0.07882, in 0.331s\n",
      "[95/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04444, val loss: 0.04423, in 0.364s\n",
      "[182/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04334, val loss: 0.04290, in 0.297s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07632, val loss: 0.07665, in 0.329s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08241, val loss: 0.08240, in 0.356s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04014, val loss: 0.04018, in 0.322s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07844, val loss: 0.07850, in 0.314s\n",
      "[96/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04431, val loss: 0.04411, in 0.312s\n",
      "[183/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04594, val loss: 0.04635, in 0.332s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04280, val loss: 0.04239, in 0.328s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08069, val loss: 0.08098, in 0.359s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07515, val loss: 0.07548, in 0.324s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.08174, val loss: 0.08170, in 0.257s\n",
      "[102/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04006, val loss: 0.04010, in 0.203s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04417, val loss: 0.04397, in 0.177s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07783, val loss: 0.07784, in 0.226s\n",
      "[97/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04259, val loss: 0.04222, in 0.188s\n",
      "[185/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04556, val loss: 0.04597, in 0.232s\n",
      "[178/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.08009, val loss: 0.08039, in 0.279s\n",
      "[104/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.08117, val loss: 0.08117, in 0.219s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03984, val loss: 0.03990, in 0.208s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07458, val loss: 0.07488, in 0.253s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04544, val loss: 0.04585, in 0.196s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07749, val loss: 0.07749, in 0.212s\n",
      "[98/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04241, val loss: 0.04204, in 0.226s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04359, val loss: 0.04338, in 0.294s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07939, val loss: 0.07965, in 0.252s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07696, val loss: 0.07700, in 0.240s\n",
      "[99/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07411, val loss: 0.07444, in 0.286s\n",
      "[110/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03963, val loss: 0.03970, in 0.304s\n",
      "[194/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04524, val loss: 0.04567, in 0.282s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07934, val loss: 0.07933, in 0.354s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04348, val loss: 0.04327, in 0.269s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04208, val loss: 0.04172, in 0.312s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07849, val loss: 0.07878, in 0.314s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03945, val loss: 0.03956, in 0.233s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07338, val loss: 0.07375, in 0.238s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04482, val loss: 0.04524, in 0.254s\n",
      "[181/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04194, val loss: 0.04159, in 0.220s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07558, val loss: 0.07561, in 0.309s\n",
      "[100/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04306, val loss: 0.04286, in 0.256s\n",
      "[187/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07838, val loss: 0.07838, in 0.276s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03919, val loss: 0.03931, in 0.233s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07695, val loss: 0.07724, in 0.303s\n",
      "[107/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04179, val loss: 0.04146, in 0.241s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04459, val loss: 0.04501, in 0.269s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07789, val loss: 0.07789, in 0.231s\n",
      "[106/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07499, val loss: 0.07505, in 0.257s\n",
      "[101/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07202, val loss: 0.07238, in 0.336s\n",
      "[112/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04265, val loss: 0.04244, in 0.267s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07654, val loss: 0.07685, in 0.233s\n",
      "[108/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03896, val loss: 0.03908, in 0.268s\n",
      "[197/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04161, val loss: 0.04127, in 0.244s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07426, val loss: 0.07434, in 0.273s\n",
      "[102/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07123, val loss: 0.07160, in 0.256s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04424, val loss: 0.04463, in 0.300s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04237, val loss: 0.04218, in 0.275s\n",
      "[189/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07713, val loss: 0.07712, in 0.305s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07597, val loss: 0.07629, in 0.219s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03872, val loss: 0.03886, in 0.237s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04136, val loss: 0.04103, in 0.234s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07384, val loss: 0.07393, in 0.209s\n",
      "[103/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07082, val loss: 0.07122, in 0.214s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04230, val loss: 0.04211, in 0.206s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07680, val loss: 0.07678, in 0.230s\n",
      "[108/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04407, val loss: 0.04446, in 0.239s\n",
      "[184/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07493, val loss: 0.07527, in 0.261s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03861, val loss: 0.03875, in 0.262s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04118, val loss: 0.04087, in 0.238s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04207, val loss: 0.04188, in 0.238s\n",
      "[191/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06993, val loss: 0.07034, in 0.268s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07327, val loss: 0.07339, in 0.283s\n",
      "[104/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07578, val loss: 0.07582, in 0.256s\n",
      "[109/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04387, val loss: 0.04425, in 0.261s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07469, val loss: 0.07504, in 0.210s\n",
      "[111/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03836, val loss: 0.03850, in 0.232s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06971, val loss: 0.07011, in 0.228s\n",
      "[116/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07284, val loss: 0.07298, in 0.225s\n",
      "[105/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04180, val loss: 0.04165, in 0.247s\n",
      "[192/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04056, val loss: 0.04027, in 0.332s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07468, val loss: 0.07475, in 0.251s\n",
      "[110/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04350, val loss: 0.04389, in 0.254s\n",
      "[186/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07342, val loss: 0.07381, in 0.243s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07194, val loss: 0.07205, in 0.207s\n",
      "[106/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04140, val loss: 0.04123, in 0.219s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07421, val loss: 0.07425, in 0.176s\n",
      "[111/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04029, val loss: 0.04001, in 0.191s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06854, val loss: 0.06899, in 0.234s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04320, val loss: 0.04359, in 0.183s\n",
      "[187/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.07252, val loss: 0.07291, in 0.212s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07122, val loss: 0.07135, in 0.251s\n",
      "[107/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07332, val loss: 0.07340, in 0.265s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04103, val loss: 0.04087, in 0.279s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06813, val loss: 0.06858, in 0.282s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04007, val loss: 0.03981, in 0.286s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04288, val loss: 0.04330, in 0.298s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07222, val loss: 0.07261, in 0.254s\n",
      "[114/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04087, val loss: 0.04070, in 0.186s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07022, val loss: 0.07034, in 0.254s\n",
      "[108/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04263, val loss: 0.04306, in 0.197s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06764, val loss: 0.06810, in 0.224s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03969, val loss: 0.03945, in 0.241s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07183, val loss: 0.07190, in 0.282s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07175, val loss: 0.07212, in 0.225s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04062, val loss: 0.04044, in 0.211s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06707, val loss: 0.06756, in 0.200s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04242, val loss: 0.04284, in 0.216s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06966, val loss: 0.06974, in 0.253s\n",
      "[109/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07138, val loss: 0.07146, in 0.199s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03927, val loss: 0.03904, in 0.248s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07082, val loss: 0.07121, in 0.252s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04033, val loss: 0.04014, in 0.270s\n",
      "[197/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04226, val loss: 0.04269, in 0.218s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06928, val loss: 0.06936, in 0.229s\n",
      "[110/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06636, val loss: 0.06683, in 0.261s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07059, val loss: 0.07069, in 0.237s\n",
      "[115/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03898, val loss: 0.03878, in 0.262s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07038, val loss: 0.07077, in 0.245s\n",
      "[117/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06893, val loss: 0.06903, in 0.175s\n",
      "[111/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06615, val loss: 0.06661, in 0.180s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.07028, val loss: 0.07040, in 0.188s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04163, val loss: 0.04205, in 0.266s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03982, val loss: 0.03960, in 0.274s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03881, val loss: 0.03863, in 0.199s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06954, val loss: 0.06996, in 0.227s\n",
      "[118/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06849, val loss: 0.06859, in 0.232s\n",
      "[112/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06588, val loss: 0.06635, in 0.223s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06975, val loss: 0.06990, in 0.272s\n",
      "[117/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03872, val loss: 0.03854, in 0.224s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04134, val loss: 0.04180, in 0.253s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03945, val loss: 0.03925, in 0.268s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06849, val loss: 0.06895, in 0.228s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06825, val loss: 0.06837, in 0.184s\n",
      "[113/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06540, val loss: 0.06589, in 0.219s\n",
      "[124/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06953, val loss: 0.06967, in 0.207s\n",
      "[118/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03932, val loss: 0.03911, in 0.234s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04106, val loss: 0.04155, in 0.268s\n",
      "[194/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06765, val loss: 0.06812, in 0.246s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06498, val loss: 0.06548, in 0.231s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06710, val loss: 0.06723, in 0.271s\n",
      "[114/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06928, val loss: 0.06942, in 0.216s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06708, val loss: 0.06757, in 0.210s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04048, val loss: 0.04096, in 0.293s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06464, val loss: 0.06515, in 0.200s\n",
      "[126/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06653, val loss: 0.06665, in 0.228s\n",
      "[115/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06884, val loss: 0.06902, in 0.223s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06624, val loss: 0.06673, in 0.233s\n",
      "[122/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.06616, val loss: 0.06631, in 0.187s\n",
      "[116/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04005, val loss: 0.04053, in 0.232s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06412, val loss: 0.06459, in 0.264s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06826, val loss: 0.06846, in 0.212s\n",
      "[121/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06603, val loss: 0.06654, in 0.233s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03988, val loss: 0.04037, in 0.215s\n",
      "[197/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06574, val loss: 0.06589, in 0.260s\n",
      "[117/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06725, val loss: 0.06745, in 0.324s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06306, val loss: 0.06352, in 0.337s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06509, val loss: 0.06562, in 0.266s\n",
      "[124/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03970, val loss: 0.04020, in 0.255s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06527, val loss: 0.06541, in 0.273s\n",
      "[118/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06686, val loss: 0.06709, in 0.186s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06215, val loss: 0.06266, in 0.225s\n",
      "[129/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03956, val loss: 0.04005, in 0.195s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06499, val loss: 0.06512, in 0.202s\n",
      "[119/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06412, val loss: 0.06465, in 0.273s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06666, val loss: 0.06690, in 0.196s\n",
      "[124/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06143, val loss: 0.06194, in 0.218s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03946, val loss: 0.03995, in 0.177s\n",
      "[200/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06463, val loss: 0.06479, in 0.218s\n",
      "[120/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06299, val loss: 0.06350, in 0.315s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06543, val loss: 0.06566, in 0.310s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06091, val loss: 0.06139, in 0.256s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06375, val loss: 0.06395, in 0.245s\n",
      "[121/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06252, val loss: 0.06304, in 0.206s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06421, val loss: 0.06451, in 0.268s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05989, val loss: 0.06043, in 0.275s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06289, val loss: 0.06309, in 0.223s\n",
      "[122/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06189, val loss: 0.06247, in 0.244s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06331, val loss: 0.06364, in 0.236s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06255, val loss: 0.06277, in 0.199s\n",
      "[123/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05908, val loss: 0.05961, in 0.278s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06128, val loss: 0.06186, in 0.252s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06246, val loss: 0.06280, in 0.245s\n",
      "[128/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05891, val loss: 0.05945, in 0.208s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06155, val loss: 0.06175, in 0.250s\n",
      "[124/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06112, val loss: 0.06168, in 0.189s\n",
      "[130/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06225, val loss: 0.06260, in 0.188s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05868, val loss: 0.05923, in 0.211s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06109, val loss: 0.06130, in 0.235s\n",
      "[125/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06082, val loss: 0.06133, in 0.195s\n",
      "[131/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.06188, val loss: 0.06225, in 0.181s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05836, val loss: 0.05888, in 0.234s\n",
      "[136/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03811, val loss: 0.03825, in 0.242s\n",
      "Fit 200 trees in 67.786 s, (1542 total leaves)\n",
      "Time spent computing histograms: 38.662s\n",
      "Time spent finding best splits:  0.260s\n",
      "Time spent applying splits:      5.640s\n",
      "Time spent predicting:           0.563s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.06065, val loss: 0.06115, in 0.220s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06034, val loss: 0.06054, in 0.279s\n",
      "[126/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06127, val loss: 0.06166, in 0.284s\n",
      "[131/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05803, val loss: 0.05858, in 0.199s\n",
      "[137/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.06029, val loss: 0.06080, in 0.211s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05995, val loss: 0.06014, in 0.257s\n",
      "[127/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06080, val loss: 0.06121, in 0.240s\n",
      "[132/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05727, val loss: 0.05785, in 0.250s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.06009, val loss: 0.06061, in 0.211s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05979, val loss: 0.05999, in 0.196s\n",
      "[128/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05989, val loss: 0.06030, in 0.260s\n",
      "[133/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05652, val loss: 0.05714, in 0.246s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05976, val loss: 0.06027, in 0.207s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05892, val loss: 0.05909, in 0.277s\n",
      "[129/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05951, val loss: 0.05992, in 0.215s\n",
      "[134/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05585, val loss: 0.05646, in 0.266s\n",
      "[140/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05877, val loss: 0.05927, in 0.264s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05860, val loss: 0.05879, in 0.176s\n",
      "[130/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05926, val loss: 0.05968, in 0.159s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05556, val loss: 0.05612, in 0.155s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05782, val loss: 0.05834, in 0.215s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05795, val loss: 0.05815, in 0.203s\n",
      "[131/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05868, val loss: 0.05909, in 0.241s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05520, val loss: 0.05577, in 0.232s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05727, val loss: 0.05780, in 0.214s\n",
      "[138/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05724, val loss: 0.05750, in 0.248s\n",
      "[132/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05837, val loss: 0.05879, in 0.158s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05488, val loss: 0.05546, in 0.157s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05648, val loss: 0.05705, in 0.203s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05816, val loss: 0.05858, in 0.167s\n",
      "[138/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05688, val loss: 0.05715, in 0.187s\n",
      "[133/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03843, val loss: 0.03825, in 0.245s\n",
      "Fit 200 trees in 67.504 s, (1544 total leaves)\n",
      "Time spent computing histograms: 38.175s\n",
      "Time spent finding best splits:  0.244s\n",
      "Time spent applying splits:      5.538s\n",
      "Time spent predicting:           0.586s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05417, val loss: 0.05477, in 0.225s\n",
      "[144/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05620, val loss: 0.05679, in 0.187s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05785, val loss: 0.05827, in 0.228s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05604, val loss: 0.05629, in 0.234s\n",
      "[134/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03900, val loss: 0.03881, in 0.236s\n",
      "Fit 200 trees in 66.740 s, (1542 total leaves)\n",
      "Time spent computing histograms: 37.364s\n",
      "Time spent finding best splits:  0.312s\n",
      "Time spent applying splits:      5.479s\n",
      "Time spent predicting:           0.468s\n",
      "Binning 0.111 GB of training data: 1 tree, 7 leaves, max depth = 3, train loss: 0.05607, val loss: 0.05667, in 0.183s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05334, val loss: 0.05395, in 0.259s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05746, val loss: 0.05788, in 0.194s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05503, val loss: 0.05526, in 0.215s\n",
      "[135/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05576, val loss: 0.05636, in 0.193s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05283, val loss: 0.05347, in 0.185s\n",
      "[146/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05687, val loss: 0.05731, in 0.224s\n",
      "[141/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05438, val loss: 0.05460, in 0.212s\n",
      "[136/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05533, val loss: 0.05594, in 0.210s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05239, val loss: 0.05301, in 0.227s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05663, val loss: 0.05707, in 0.173s\n",
      "[142/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05409, val loss: 0.05432, in 0.173s\n",
      "[137/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05505, val loss: 0.05567, in 0.205s\n",
      "[144/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05212, val loss: 0.05274, in 0.199s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05617, val loss: 0.05658, in 0.258s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05350, val loss: 0.05371, in 0.246s\n",
      "[138/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05188, val loss: 0.05250, in 0.208s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05445, val loss: 0.05507, in 0.223s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05582, val loss: 0.05620, in 0.227s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05314, val loss: 0.05335, in 0.225s\n",
      "[139/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05137, val loss: 0.05200, in 0.218s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05371, val loss: 0.05434, in 0.263s\n",
      "[146/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05286, val loss: 0.05309, in 0.168s\n",
      "[140/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05548, val loss: 0.05588, in 0.194s\n",
      "[145/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05106, val loss: 0.05172, in 0.173s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03906, val loss: 0.03956, in 0.290s\n",
      "Fit 200 trees in 67.390 s, (1527 total leaves)\n",
      "Time spent computing histograms: 37.477s\n",
      "Time spent finding best splits:  0.322s\n",
      "Time spent applying splits:      5.349s\n",
      "Time spent predicting:           0.626s\n",
      "Binning 0.111 GB of training data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05268, val loss: 0.05293, in 0.151s\n",
      "[141/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05524, val loss: 0.05566, in 0.166s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05301, val loss: 0.05363, in 0.262s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05046, val loss: 0.05112, in 0.242s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05212, val loss: 0.05236, in 0.260s\n",
      "[142/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05500, val loss: 0.05541, in 0.253s\n",
      "[147/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05220, val loss: 0.05288, in 0.272s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05015, val loss: 0.05077, in 0.228s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05448, val loss: 0.05490, in 0.209s\n",
      "[148/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05142, val loss: 0.05163, in 0.259s\n",
      "[143/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05174, val loss: 0.05245, in 0.207s\n",
      "[149/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04990, val loss: 0.05054, in 0.185s\n",
      "[154/200] 3.799 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 8 leaves, max depth = 3, train loss: 0.05397, val loss: 0.05442, in 0.225s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05093, val loss: 0.05119, in 0.207s\n",
      "[144/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05136, val loss: 0.05208, in 0.240s\n",
      "[150/200] 0.167 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04945, val loss: 0.05009, in 0.253s\n",
      "[155/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05369, val loss: 0.05411, in 0.237s\n",
      "[150/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05069, val loss: 0.05095, in 0.226s\n",
      "[145/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05114, val loss: 0.05187, in 0.195s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04899, val loss: 0.04964, in 0.235s\n",
      "[156/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05345, val loss: 0.05388, in 0.173s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05056, val loss: 0.05083, in 0.194s\n",
      "[146/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05081, val loss: 0.05152, in 0.221s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61043, val loss: 0.61023, in 0.372s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04856, val loss: 0.04926, in 0.212s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05290, val loss: 0.05331, in 0.191s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05034, val loss: 0.05061, in 0.178s\n",
      "[147/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05039, val loss: 0.05111, in 0.179s\n",
      "[153/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04844, val loss: 0.04914, in 0.173s\n",
      "[158/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05266, val loss: 0.05308, in 0.188s\n",
      "[153/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.05002, val loss: 0.05030, in 0.226s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54264, val loss: 0.54221, in 0.358s\n",
      "[3/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05001, val loss: 0.05077, in 0.236s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04806, val loss: 0.04876, in 0.225s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05238, val loss: 0.05280, in 0.202s\n",
      "[154/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04953, val loss: 0.04983, in 0.205s\n",
      "[149/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04979, val loss: 0.05051, in 0.169s\n",
      "[155/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04797, val loss: 0.04866, in 0.162s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05198, val loss: 0.05243, in 0.190s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48605, val loss: 0.48544, in 0.332s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04925, val loss: 0.04956, in 0.207s\n",
      "[150/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04919, val loss: 0.04994, in 0.197s\n",
      "[156/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04774, val loss: 0.04844, in 0.182s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05151, val loss: 0.05195, in 0.206s\n",
      "[156/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04909, val loss: 0.04939, in 0.170s\n",
      "[151/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04887, val loss: 0.04962, in 0.173s\n",
      "[157/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04743, val loss: 0.04814, in 0.175s\n",
      "[162/200] 3.814 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.43740, val loss: 0.43666, in 0.346s\n",
      "[5/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05137, val loss: 0.05183, in 0.188s\n",
      "[157/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04886, val loss: 0.04918, in 0.189s\n",
      "[152/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04850, val loss: 0.04928, in 0.225s\n",
      "[158/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04728, val loss: 0.04799, in 0.205s\n",
      "[163/200] 3.814 s\n",
      "Binning 0.012 GB of validation data: 0.173 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05105, val loss: 0.05153, in 0.236s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04806, val loss: 0.04836, in 0.221s\n",
      "[153/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04807, val loss: 0.04884, in 0.203s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39582, val loss: 0.39499, in 0.375s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04677, val loss: 0.04750, in 0.217s\n",
      "[164/200] 0.148 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.05090, val loss: 0.05139, in 0.157s\n",
      "[159/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04759, val loss: 0.04788, in 0.183s\n",
      "[154/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04782, val loss: 0.04860, in 0.180s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61039, val loss: 0.61004, in 0.341s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04645, val loss: 0.04719, in 0.189s\n",
      "[165/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.05053, val loss: 0.05102, in 0.188s\n",
      "[160/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04739, val loss: 0.04770, in 0.178s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35984, val loss: 0.35878, in 0.342s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04751, val loss: 0.04830, in 0.219s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04635, val loss: 0.04708, in 0.194s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61059, val loss: 0.61043, in 0.358s\n",
      "[2/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.05006, val loss: 0.05055, in 0.247s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04691, val loss: 0.04722, in 0.236s\n",
      "[156/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04733, val loss: 0.04813, in 0.186s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54257, val loss: 0.54202, in 0.379s\n",
      "[3/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04613, val loss: 0.04687, in 0.212s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04986, val loss: 0.05036, in 0.166s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32851, val loss: 0.32744, in 0.374s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04721, val loss: 0.04802, in 0.169s\n",
      "[163/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04651, val loss: 0.04680, in 0.216s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54289, val loss: 0.54252, in 0.354s\n",
      "[3/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04576, val loss: 0.04649, in 0.195s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04951, val loss: 0.05004, in 0.201s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48546, val loss: 0.48477, in 0.343s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04613, val loss: 0.04646, in 0.200s\n",
      "[158/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04675, val loss: 0.04757, in 0.230s\n",
      "[164/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04550, val loss: 0.04621, in 0.211s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30082, val loss: 0.29971, in 0.365s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04908, val loss: 0.04958, in 0.225s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48608, val loss: 0.48554, in 0.404s\n",
      "[4/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04587, val loss: 0.04621, in 0.264s\n",
      "[159/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04648, val loss: 0.04729, in 0.263s\n",
      "[165/200] 3.907 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 6 leaves, max depth = 3, train loss: 0.04531, val loss: 0.04602, in 0.240s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43713, val loss: 0.43625, in 0.417s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04874, val loss: 0.04925, in 0.248s\n",
      "[165/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04548, val loss: 0.04581, in 0.199s\n",
      "[160/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04599, val loss: 0.04682, in 0.199s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04498, val loss: 0.04569, in 0.191s\n",
      "[171/200] 0.148 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27643, val loss: 0.27526, in 0.392s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04854, val loss: 0.04907, in 0.173s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43761, val loss: 0.43691, in 0.373s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04519, val loss: 0.04554, in 0.171s\n",
      "[161/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04566, val loss: 0.04649, in 0.185s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04487, val loss: 0.04559, in 0.178s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39560, val loss: 0.39458, in 0.349s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04828, val loss: 0.04882, in 0.208s\n",
      "[167/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04501, val loss: 0.04536, in 0.175s\n",
      "[162/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04550, val loss: 0.04634, in 0.170s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61043, val loss: 0.61026, in 0.351s\n",
      "[2/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04463, val loss: 0.04534, in 0.190s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25474, val loss: 0.25328, in 0.372s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39609, val loss: 0.39530, in 0.358s\n",
      "[6/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04434, val loss: 0.04468, in 0.237s\n",
      "[163/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04748, val loss: 0.04801, in 0.280s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04520, val loss: 0.04607, in 0.234s\n",
      "[169/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04447, val loss: 0.04518, in 0.204s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35961, val loss: 0.35860, in 0.364s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04411, val loss: 0.04444, in 0.196s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54257, val loss: 0.54208, in 0.386s\n",
      "[3/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04439, val loss: 0.04510, in 0.168s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04485, val loss: 0.04571, in 0.197s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23566, val loss: 0.23408, in 0.369s\n",
      "[12/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04696, val loss: 0.04752, in 0.223s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36029, val loss: 0.35938, in 0.366s\n",
      "[7/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04420, val loss: 0.04492, in 0.197s\n",
      "[176/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04469, val loss: 0.04556, in 0.187s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32842, val loss: 0.32725, in 0.359s\n",
      "[8/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04369, val loss: 0.04402, in 0.241s\n",
      "[165/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04646, val loss: 0.04703, in 0.217s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48586, val loss: 0.48516, in 0.355s\n",
      "[4/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04404, val loss: 0.04476, in 0.164s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21904, val loss: 0.21730, in 0.382s\n",
      "[13/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04349, val loss: 0.04382, in 0.182s\n",
      "[166/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04632, val loss: 0.04688, in 0.181s\n",
      "[171/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04431, val loss: 0.04519, in 0.247s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32882, val loss: 0.32778, in 0.396s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30109, val loss: 0.29988, in 0.383s\n",
      "[9/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04352, val loss: 0.04426, in 0.239s\n",
      "[178/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04329, val loss: 0.04360, in 0.232s\n",
      "[167/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04600, val loss: 0.04662, in 0.235s\n",
      "[172/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04366, val loss: 0.04453, in 0.244s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43728, val loss: 0.43635, in 0.386s\n",
      "[5/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04335, val loss: 0.04409, in 0.161s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20338, val loss: 0.20157, in 0.352s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30129, val loss: 0.30020, in 0.343s\n",
      "[9/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04308, val loss: 0.04341, in 0.189s\n",
      "[168/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04354, val loss: 0.04440, in 0.181s\n",
      "[174/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04566, val loss: 0.04628, in 0.221s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27628, val loss: 0.27490, in 0.351s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04323, val loss: 0.04396, in 0.192s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04295, val loss: 0.04328, in 0.170s\n",
      "[169/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04553, val loss: 0.04616, in 0.158s\n",
      "[174/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04332, val loss: 0.04419, in 0.216s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39601, val loss: 0.39486, in 0.359s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18979, val loss: 0.18786, in 0.376s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27703, val loss: 0.27593, in 0.376s\n",
      "[10/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04289, val loss: 0.04361, in 0.236s\n",
      "[181/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04506, val loss: 0.04570, in 0.261s\n",
      "[175/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04243, val loss: 0.04275, in 0.306s\n",
      "[170/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04300, val loss: 0.04388, in 0.249s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25491, val loss: 0.25344, in 0.421s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04245, val loss: 0.04319, in 0.279s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36022, val loss: 0.35890, in 0.407s\n",
      "[7/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04227, val loss: 0.04259, in 0.198s\n",
      "[171/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04479, val loss: 0.04544, in 0.228s\n",
      "[176/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04290, val loss: 0.04377, in 0.198s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25595, val loss: 0.25481, in 0.388s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17771, val loss: 0.17566, in 0.433s\n",
      "[16/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04210, val loss: 0.04245, in 0.190s\n",
      "[172/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04183, val loss: 0.04258, in 0.249s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23534, val loss: 0.23373, in 0.357s\n",
      "[12/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04451, val loss: 0.04517, in 0.200s\n",
      "[177/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04264, val loss: 0.04349, in 0.207s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32909, val loss: 0.32756, in 0.365s\n",
      "[8/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04195, val loss: 0.04230, in 0.207s\n",
      "[173/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04256, val loss: 0.04342, in 0.188s\n",
      "[179/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04434, val loss: 0.04500, in 0.201s\n",
      "[178/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04147, val loss: 0.04222, in 0.245s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16603, val loss: 0.16388, in 0.406s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23653, val loss: 0.23528, in 0.419s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21880, val loss: 0.21713, in 0.396s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04164, val loss: 0.04201, in 0.231s\n",
      "[174/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04138, val loss: 0.04213, in 0.198s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04216, val loss: 0.04305, in 0.226s\n",
      "[180/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04403, val loss: 0.04467, in 0.270s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30144, val loss: 0.29980, in 0.404s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15607, val loss: 0.15384, in 0.351s\n",
      "[18/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04155, val loss: 0.04191, in 0.195s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21957, val loss: 0.21822, in 0.373s\n",
      "[13/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04194, val loss: 0.04283, in 0.206s\n",
      "[181/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04112, val loss: 0.04189, in 0.216s\n",
      "[186/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04336, val loss: 0.04399, in 0.250s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20375, val loss: 0.20204, in 0.361s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04109, val loss: 0.04144, in 0.224s\n",
      "[176/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04169, val loss: 0.04260, in 0.199s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27690, val loss: 0.27522, in 0.361s\n",
      "[10/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04068, val loss: 0.04143, in 0.280s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14652, val loss: 0.14428, in 0.403s\n",
      "[19/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04276, val loss: 0.04338, in 0.291s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20403, val loss: 0.20269, in 0.389s\n",
      "[14/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04150, val loss: 0.04241, in 0.204s\n",
      "[183/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04081, val loss: 0.04115, in 0.223s\n",
      "[177/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04042, val loss: 0.04118, in 0.192s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18970, val loss: 0.18796, in 0.417s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04129, val loss: 0.04220, in 0.203s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04052, val loss: 0.04087, in 0.208s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25515, val loss: 0.25332, in 0.383s\n",
      "[11/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04235, val loss: 0.04301, in 0.276s\n",
      "[182/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04000, val loss: 0.04075, in 0.230s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13799, val loss: 0.13570, in 0.389s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19049, val loss: 0.18913, in 0.384s\n",
      "[15/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.04105, val loss: 0.04195, in 0.207s\n",
      "[185/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04022, val loss: 0.04057, in 0.193s\n",
      "[179/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04215, val loss: 0.04280, in 0.221s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17716, val loss: 0.17551, in 0.398s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03980, val loss: 0.04056, in 0.226s\n",
      "[190/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04015, val loss: 0.04049, in 0.165s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23588, val loss: 0.23395, in 0.371s\n",
      "[12/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04200, val loss: 0.04266, in 0.183s\n",
      "[184/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04051, val loss: 0.04140, in 0.261s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13004, val loss: 0.12767, in 0.377s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03971, val loss: 0.04045, in 0.201s\n",
      "[191/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03999, val loss: 0.04034, in 0.205s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17809, val loss: 0.17674, in 0.415s\n",
      "[16/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04181, val loss: 0.04248, in 0.235s\n",
      "[185/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.04026, val loss: 0.04116, in 0.243s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16585, val loss: 0.16412, in 0.398s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03946, val loss: 0.04020, in 0.217s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03952, val loss: 0.03989, in 0.233s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21876, val loss: 0.21669, in 0.409s\n",
      "[13/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03923, val loss: 0.03996, in 0.175s\n",
      "[193/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04123, val loss: 0.04190, in 0.251s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12201, val loss: 0.11969, in 0.414s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16688, val loss: 0.16548, in 0.386s\n",
      "[17/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03980, val loss: 0.04074, in 0.256s\n",
      "[188/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03937, val loss: 0.03974, in 0.183s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15548, val loss: 0.15378, in 0.368s\n",
      "[18/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.04110, val loss: 0.04176, in 0.188s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03964, in 0.237s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20396, val loss: 0.20181, in 0.352s\n",
      "[14/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03950, val loss: 0.04042, in 0.219s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03893, val loss: 0.03926, in 0.278s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11539, val loss: 0.11303, in 0.426s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15658, val loss: 0.15500, in 0.421s\n",
      "[18/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04080, val loss: 0.04148, in 0.259s\n",
      "[188/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03855, val loss: 0.03932, in 0.277s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03929, val loss: 0.04020, in 0.301s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03873, val loss: 0.03907, in 0.267s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14619, val loss: 0.14449, in 0.489s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04060, val loss: 0.04128, in 0.285s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18990, val loss: 0.18775, in 0.530s\n",
      "[15/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03816, val loss: 0.03891, in 0.328s\n",
      "[196/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03900, val loss: 0.03991, in 0.292s\n",
      "[191/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03844, val loss: 0.03879, in 0.255s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14732, val loss: 0.14563, in 0.456s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10884, val loss: 0.10656, in 0.486s\n",
      "[24/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04045, val loss: 0.04114, in 0.203s\n",
      "[190/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03794, val loss: 0.03870, in 0.189s\n",
      "[197/200] 1 tree, 4 leaves, max depth = 3, train loss: 0.03893, val loss: 0.03985, in 0.187s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13774, val loss: 0.13598, in 0.429s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03825, val loss: 0.03860, in 0.243s\n",
      "[187/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.04005, val loss: 0.04072, in 0.241s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17755, val loss: 0.17549, in 0.416s\n",
      "[16/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03876, val loss: 0.03968, in 0.224s\n",
      "[193/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03752, val loss: 0.03831, in 0.294s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03774, val loss: 0.03811, in 0.256s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13884, val loss: 0.13698, in 0.451s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10295, val loss: 0.10080, in 0.465s\n",
      "[25/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03995, val loss: 0.04061, in 0.211s\n",
      "[192/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03856, val loss: 0.03947, in 0.223s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12976, val loss: 0.12797, in 0.416s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03717, val loss: 0.03796, in 0.201s\n",
      "[199/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03750, val loss: 0.03790, in 0.204s\n",
      "[189/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03975, val loss: 0.04041, in 0.199s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16572, val loss: 0.16364, in 0.420s\n",
      "[17/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03839, val loss: 0.03929, in 0.227s\n",
      "[195/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03697, val loss: 0.03776, in 0.215s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03739, val loss: 0.03781, in 0.171s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13061, val loss: 0.12867, in 0.384s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09806, val loss: 0.09597, in 0.368s\n",
      "[26/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03950, val loss: 0.04014, in 0.215s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12254, val loss: 0.12076, in 0.373s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03818, val loss: 0.03908, in 0.186s\n",
      "[196/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03727, val loss: 0.03768, in 0.224s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15538, val loss: 0.15325, in 0.402s\n",
      "[18/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03910, val loss: 0.03975, in 0.263s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03811, val loss: 0.03901, in 0.214s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12335, val loss: 0.12127, in 0.407s\n",
      "[22/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03704, val loss: 0.03746, in 0.236s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09239, val loss: 0.09046, in 0.454s\n",
      "[27/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03891, val loss: 0.03955, in 0.185s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11540, val loss: 0.11364, in 0.435s\n",
      "[23/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03803, val loss: 0.03893, in 0.196s\n",
      "[198/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03692, val loss: 0.03736, in 0.159s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14614, val loss: 0.14390, in 0.369s\n",
      "[19/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03853, val loss: 0.03916, in 0.252s\n",
      "[197/200] 1 tree, 5 leaves, max depth = 3, train loss: 0.03779, val loss: 0.03869, in 0.205s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11620, val loss: 0.11415, in 0.409s\n",
      "[23/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03651, val loss: 0.03698, in 0.223s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08749, val loss: 0.08559, in 0.392s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10914, val loss: 0.10743, in 0.402s\n",
      "[24/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03834, val loss: 0.03896, in 0.220s\n",
      "[198/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03740, val loss: 0.03829, in 0.248s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13820, val loss: 0.13597, in 0.407s\n",
      "[20/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03604, val loss: 0.03652, in 0.287s\n",
      "[195/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03820, val loss: 0.03882, in 0.203s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10964, val loss: 0.10751, in 0.429s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08275, val loss: 0.08084, in 0.460s\n",
      "[29/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03565, val loss: 0.03616, in 0.236s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10257, val loss: 0.10096, in 0.432s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13056, val loss: 0.12826, in 0.389s\n",
      "[21/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03771, val loss: 0.03832, in 0.262s\n",
      "[200/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03543, val loss: 0.03594, in 0.217s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10347, val loss: 0.10141, in 0.514s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07866, val loss: 0.07686, in 0.493s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09759, val loss: 0.09598, in 0.464s\n",
      "[26/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03525, val loss: 0.03575, in 0.300s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12275, val loss: 0.12041, in 0.499s\n",
      "[22/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03511, val loss: 0.03563, in 0.193s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09794, val loss: 0.09593, in 0.404s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07481, val loss: 0.07298, in 0.406s\n",
      "[31/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03499, val loss: 0.03551, in 0.190s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09219, val loss: 0.09060, in 0.420s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11607, val loss: 0.11373, in 0.411s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09254, val loss: 0.09061, in 0.408s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07138, val loss: 0.06961, in 0.441s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08712, val loss: 0.08560, in 0.448s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10970, val loss: 0.10739, in 0.448s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08767, val loss: 0.08585, in 0.460s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06790, val loss: 0.06617, in 0.461s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08261, val loss: 0.08113, in 0.433s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10380, val loss: 0.10148, in 0.421s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08328, val loss: 0.08155, in 0.532s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06471, val loss: 0.06314, in 0.536s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07889, val loss: 0.07745, in 0.515s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09841, val loss: 0.09620, in 0.496s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07898, val loss: 0.07725, in 0.424s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07538, val loss: 0.07394, in 0.391s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06199, val loss: 0.06049, in 0.409s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09294, val loss: 0.09080, in 0.403s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07498, val loss: 0.07339, in 0.391s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07162, val loss: 0.07024, in 0.413s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05932, val loss: 0.05783, in 0.418s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08820, val loss: 0.08621, in 0.400s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07129, val loss: 0.06969, in 0.397s\n",
      "[32/200] 1 tree, 6 leaves, max depth = 3, train loss: 0.03683, val loss: 0.03762, in 0.222s\n",
      "Fit 200 trees in 61.302 s, (1533 total leaves)\n",
      "Time spent computing histograms: 34.777s\n",
      "Time spent finding best splits:  0.251s\n",
      "Time spent applying splits:      4.674s\n",
      "Time spent predicting:           0.530s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 8, train loss: 0.06806, val loss: 0.06675, in 0.393s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05664, val loss: 0.05514, in 0.393s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08341, val loss: 0.08143, in 0.384s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06807, val loss: 0.06649, in 0.410s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06530, val loss: 0.06403, in 0.415s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05426, val loss: 0.05278, in 0.427s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07913, val loss: 0.07732, in 0.439s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06514, val loss: 0.06364, in 0.444s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06228, val loss: 0.06098, in 0.462s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05216, val loss: 0.05071, in 0.474s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07512, val loss: 0.07331, in 0.467s\n",
      "[31/200] 1 tree, 7 leaves, max depth = 3, train loss: 0.03708, val loss: 0.03800, in 0.221s\n",
      "Fit 200 trees in 60.775 s, (1537 total leaves)\n",
      "Time spent computing histograms: 33.784s\n",
      "Time spent finding best splits:  0.247s\n",
      "Time spent applying splits:      4.938s\n",
      "Time spent predicting:           0.515s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06219, val loss: 0.06071, in 0.449s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05013, val loss: 0.04868, in 0.428s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05947, val loss: 0.05824, in 0.461s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07173, val loss: 0.07002, in 0.462s\n",
      "[32/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03754, val loss: 0.03816, in 0.324s\n",
      "Fit 200 trees in 60.432 s, (1529 total leaves)\n",
      "Time spent computing histograms: 34.077s\n",
      "Time spent finding best splits:  0.388s\n",
      "Time spent applying splits:      4.827s\n",
      "Time spent predicting:           0.412s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05981, val loss: 0.05842, in 0.431s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04813, val loss: 0.04672, in 0.415s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05684, val loss: 0.05567, in 0.429s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06865, val loss: 0.06698, in 0.404s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05709, val loss: 0.05574, in 0.490s\n",
      "[37/200] 1 tree, 8 leaves, max depth = 3, train loss: 0.03477, val loss: 0.03529, in 0.224s\n",
      "Fit 200 trees in 59.451 s, (1537 total leaves)\n",
      "Time spent computing histograms: 33.617s\n",
      "Time spent finding best splits:  0.294s\n",
      "Time spent applying splits:      4.957s\n",
      "Time spent predicting:           0.492s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04648, val loss: 0.04507, in 0.440s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05458, val loss: 0.05346, in 0.459s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06529, val loss: 0.06366, in 0.455s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05459, val loss: 0.05339, in 0.447s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04457, val loss: 0.04317, in 0.464s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05223, val loss: 0.05119, in 0.468s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06246, val loss: 0.06082, in 0.479s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05240, val loss: 0.05117, in 0.424s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04242, val loss: 0.04109, in 0.389s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05032, val loss: 0.04934, in 0.432s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06006, val loss: 0.05857, in 0.404s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04989, val loss: 0.04873, in 0.435s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04093, val loss: 0.03963, in 0.416s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04830, val loss: 0.04737, in 0.427s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05756, val loss: 0.05619, in 0.419s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.04694, in 0.385s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03912, val loss: 0.03789, in 0.418s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04640, val loss: 0.04547, in 0.408s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05498, val loss: 0.05370, in 0.422s\n",
      "[38/200] 4.122 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04652, val loss: 0.04540, in 0.424s\n",
      "[42/200] 0.142 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03723, val loss: 0.03607, in 0.388s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04453, val loss: 0.04367, in 0.369s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05277, val loss: 0.05160, in 0.424s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61037, val loss: 0.61013, in 0.370s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04496, val loss: 0.04387, in 0.406s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03469, in 0.424s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04280, val loss: 0.04199, in 0.369s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05043, val loss: 0.04925, in 0.422s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54248, val loss: 0.54205, in 0.368s\n",
      "[3/200] 3.955 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04355, val loss: 0.04248, in 0.369s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03451, val loss: 0.03345, in 0.373s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04126, val loss: 0.04050, in 0.368s\n",
      "[45/200] 0.151 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04835, val loss: 0.04724, in 0.385s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48586, val loss: 0.48521, in 0.350s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04195, val loss: 0.04089, in 0.407s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03951, val loss: 0.03879, in 0.386s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03335, val loss: 0.03235, in 0.416s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61053, val loss: 0.61039, in 0.384s\n",
      "[2/200] 3.992 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.04640, val loss: 0.04529, in 0.432s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43738, val loss: 0.43654, in 0.384s\n",
      "[5/200] 0.152 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03805, val loss: 0.03735, in 0.366s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04034, val loss: 0.03935, in 0.395s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03203, val loss: 0.03104, in 0.381s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54263, val loss: 0.54237, in 0.353s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04476, val loss: 0.04367, in 0.354s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39603, val loss: 0.39499, in 0.345s\n",
      "[6/200] 3.963 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03854, val loss: 0.03759, in 0.344s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03675, val loss: 0.03606, in 0.359s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61037, val loss: 0.61028, in 0.368s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.02999, in 0.360s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48606, val loss: 0.48569, in 0.373s\n",
      "[4/200] 0.148 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35998, val loss: 0.35880, in 0.350s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04267, val loss: 0.04162, in 0.430s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03713, val loss: 0.03620, in 0.348s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54261, val loss: 0.54244, in 0.356s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03558, val loss: 0.03489, in 0.365s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02993, val loss: 0.02902, in 0.368s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43743, val loss: 0.43696, in 0.337s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61042, val loss: 0.61031, in 0.324s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.32877, val loss: 0.32747, in 0.353s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04005, in 0.409s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03578, val loss: 0.03486, in 0.374s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48557, val loss: 0.48532, in 0.367s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02916, val loss: 0.02828, in 0.332s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03401, val loss: 0.03334, in 0.395s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39592, val loss: 0.39535, in 0.337s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54268, val loss: 0.54243, in 0.356s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.30130, val loss: 0.29993, in 0.317s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03958, val loss: 0.03859, in 0.314s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03444, val loss: 0.03354, in 0.300s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43723, val loss: 0.43687, in 0.307s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03305, val loss: 0.03239, in 0.301s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02758, val loss: 0.02674, in 0.360s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36002, val loss: 0.35936, in 0.323s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48560, val loss: 0.48530, in 0.334s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27719, val loss: 0.27580, in 0.352s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03760, val loss: 0.03668, in 0.357s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39564, val loss: 0.39531, in 0.355s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03186, val loss: 0.03127, in 0.370s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03285, val loss: 0.03201, in 0.506s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02648, val loss: 0.02566, in 0.478s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32905, val loss: 0.32826, in 0.451s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43726, val loss: 0.43684, in 0.471s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25605, val loss: 0.25449, in 0.469s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03613, val loss: 0.03526, in 0.528s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35981, val loss: 0.35952, in 0.489s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03080, val loss: 0.03023, in 0.530s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03175, val loss: 0.03097, in 0.456s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30170, val loss: 0.30079, in 0.415s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02499, val loss: 0.02422, in 0.526s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39573, val loss: 0.39522, in 0.438s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23690, val loss: 0.23522, in 0.439s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32856, val loss: 0.32810, in 0.448s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03368, in 0.469s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03016, val loss: 0.02943, in 0.441s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27676, val loss: 0.27575, in 0.441s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.02899, in 0.511s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02360, in 0.396s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35977, val loss: 0.35915, in 0.419s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21915, val loss: 0.21737, in 0.452s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03278, val loss: 0.03204, in 0.443s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30106, val loss: 0.30053, in 0.456s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.02815, in 0.459s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02829, val loss: 0.02776, in 0.422s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02347, val loss: 0.02275, in 0.410s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25492, val loss: 0.25398, in 0.467s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.32832, val loss: 0.32781, in 0.472s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20405, val loss: 0.20217, in 0.435s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27646, val loss: 0.27602, in 0.383s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03173, val loss: 0.03102, in 0.426s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02703, in 0.343s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23529, val loss: 0.23427, in 0.366s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02267, val loss: 0.02199, in 0.405s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02680, val loss: 0.02627, in 0.433s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30073, val loss: 0.30007, in 0.335s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18968, val loss: 0.18778, in 0.344s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25442, val loss: 0.25395, in 0.310s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03049, val loss: 0.02983, in 0.351s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02659, val loss: 0.02599, in 0.335s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21818, val loss: 0.21705, in 0.318s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27661, val loss: 0.27594, in 0.306s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02163, val loss: 0.02098, in 0.357s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02559, val loss: 0.02509, in 0.360s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17729, val loss: 0.17526, in 0.328s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23533, val loss: 0.23471, in 0.330s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02546, val loss: 0.02491, in 0.338s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02887, val loss: 0.02829, in 0.349s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20259, val loss: 0.20145, in 0.343s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25503, val loss: 0.25428, in 0.317s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02109, val loss: 0.02045, in 0.312s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02461, val loss: 0.02416, in 0.303s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16617, val loss: 0.16423, in 0.307s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21874, val loss: 0.21805, in 0.292s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02747, val loss: 0.02692, in 0.318s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18937, val loss: 0.18810, in 0.310s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02392, in 0.363s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02392, val loss: 0.02348, in 0.294s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01967, in 0.303s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23646, val loss: 0.23562, in 0.332s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15558, val loss: 0.15359, in 0.344s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20270, val loss: 0.20207, in 0.340s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02342, in 0.270s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02653, val loss: 0.02600, in 0.344s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17703, val loss: 0.17572, in 0.325s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01965, val loss: 0.01905, in 0.290s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02327, val loss: 0.02286, in 0.302s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21902, val loss: 0.21821, in 0.309s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14626, val loss: 0.14416, in 0.290s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18919, val loss: 0.18843, in 0.289s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02279, val loss: 0.02239, in 0.277s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02549, val loss: 0.02502, in 0.309s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02263, in 0.352s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01862, in 0.320s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16556, val loss: 0.16422, in 0.327s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20312, val loss: 0.20230, in 0.314s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13797, val loss: 0.13589, in 0.333s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17675, val loss: 0.17605, in 0.331s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02442, in 0.264s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02168, val loss: 0.02134, in 0.332s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18944, val loss: 0.18855, in 0.296s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15546, val loss: 0.15412, in 0.309s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02189, val loss: 0.02147, in 0.343s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01838, val loss: 0.01783, in 0.347s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12955, val loss: 0.12748, in 0.317s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16531, val loss: 0.16461, in 0.310s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02394, val loss: 0.02351, in 0.373s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02120, val loss: 0.02077, in 0.313s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14623, val loss: 0.14492, in 0.341s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17640, val loss: 0.17558, in 0.364s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01735, in 0.333s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02090, val loss: 0.02059, in 0.387s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12257, val loss: 0.12049, in 0.332s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15520, val loss: 0.15452, in 0.314s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02319, val loss: 0.02276, in 0.287s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02019, in 0.302s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01748, val loss: 0.01692, in 0.281s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16527, val loss: 0.16449, in 0.315s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.01987, in 0.305s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13789, val loss: 0.13655, in 0.335s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11546, val loss: 0.11349, in 0.329s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14630, val loss: 0.14567, in 0.327s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02239, val loss: 0.02197, in 0.352s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01975, val loss: 0.01937, in 0.339s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01961, val loss: 0.01933, in 0.320s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01621, in 0.367s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15510, val loss: 0.15429, in 0.343s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13001, val loss: 0.12862, in 0.345s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10916, val loss: 0.10724, in 0.344s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13754, val loss: 0.13681, in 0.329s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01914, val loss: 0.01876, in 0.276s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02120, in 0.321s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01635, val loss: 0.01583, in 0.313s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14588, val loss: 0.14515, in 0.312s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01870, in 0.340s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12222, val loss: 0.12093, in 0.332s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10305, val loss: 0.10116, in 0.339s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12946, val loss: 0.12880, in 0.337s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02050, in 0.299s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01850, val loss: 0.01814, in 0.363s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01531, in 0.295s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01815, in 0.296s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13755, val loss: 0.13687, in 0.338s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11481, val loss: 0.11356, in 0.347s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12209, val loss: 0.12145, in 0.320s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09785, val loss: 0.09596, in 0.334s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.01993, in 0.250s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01794, val loss: 0.01758, in 0.281s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01544, val loss: 0.01493, in 0.294s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01760, val loss: 0.01741, in 0.313s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12943, val loss: 0.12879, in 0.313s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10833, val loss: 0.10718, in 0.334s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11529, val loss: 0.11475, in 0.334s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01947, val loss: 0.01913, in 0.337s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09236, val loss: 0.09049, in 0.366s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01755, val loss: 0.01720, in 0.300s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01507, val loss: 0.01458, in 0.316s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01717, val loss: 0.01698, in 0.329s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12206, val loss: 0.12148, in 0.327s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10258, val loss: 0.10145, in 0.316s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10888, val loss: 0.10839, in 0.337s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01670, in 0.297s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08743, val loss: 0.08564, in 0.327s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01881, val loss: 0.01850, in 0.346s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01413, in 0.259s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01663, val loss: 0.01645, in 0.297s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11521, val loss: 0.11463, in 0.315s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09681, val loss: 0.09578, in 0.336s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01658, val loss: 0.01625, in 0.293s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01820, val loss: 0.01791, in 0.294s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01381, in 0.309s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10307, val loss: 0.10255, in 0.370s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08311, val loss: 0.08142, in 0.347s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01597, val loss: 0.01582, in 0.318s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10898, val loss: 0.10850, in 0.330s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09177, val loss: 0.09081, in 0.336s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01750, in 0.272s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01599, in 0.282s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01340, in 0.306s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09734, val loss: 0.09689, in 0.323s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07894, val loss: 0.07733, in 0.322s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01532, in 0.356s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10289, val loss: 0.10241, in 0.335s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01694, in 0.294s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08723, val loss: 0.08632, in 0.349s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01571, val loss: 0.01540, in 0.324s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01341, val loss: 0.01300, in 0.310s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09211, val loss: 0.09169, in 0.333s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07501, val loss: 0.07352, in 0.343s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01497, val loss: 0.01484, in 0.360s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09711, val loss: 0.09661, in 0.329s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01660, val loss: 0.01638, in 0.293s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01499, in 0.277s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08271, val loss: 0.08187, in 0.336s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01298, val loss: 0.01260, in 0.315s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08716, val loss: 0.08677, in 0.356s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07133, val loss: 0.06990, in 0.346s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01440, val loss: 0.01429, in 0.354s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09153, val loss: 0.09109, in 0.352s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01581, in 0.348s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01481, val loss: 0.01451, in 0.383s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07822, val loss: 0.07752, in 0.350s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01222, in 0.365s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08282, val loss: 0.08246, in 0.337s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06848, val loss: 0.06709, in 0.340s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01403, val loss: 0.01392, in 0.252s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01566, val loss: 0.01544, in 0.248s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08689, val loss: 0.08649, in 0.312s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01395, in 0.301s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07430, val loss: 0.07367, in 0.321s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01228, val loss: 0.01190, in 0.293s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07860, val loss: 0.07825, in 0.326s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01365, val loss: 0.01358, in 0.301s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06514, val loss: 0.06375, in 0.338s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01520, val loss: 0.01501, in 0.333s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08223, val loss: 0.08184, in 0.328s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01352, in 0.340s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01161, in 0.298s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07057, val loss: 0.06999, in 0.326s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01319, val loss: 0.01314, in 0.293s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07446, val loss: 0.07422, in 0.314s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06234, val loss: 0.06096, in 0.321s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01477, val loss: 0.01461, in 0.295s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01348, val loss: 0.01324, in 0.267s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07808, val loss: 0.07772, in 0.345s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01160, val loss: 0.01125, in 0.356s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06716, val loss: 0.06659, in 0.352s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01279, in 0.352s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07076, val loss: 0.07054, in 0.366s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05953, val loss: 0.05819, in 0.358s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01427, val loss: 0.01410, in 0.348s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01291, in 0.304s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07380, val loss: 0.07349, in 0.332s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06405, val loss: 0.06355, in 0.331s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01248, in 0.241s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01090, in 0.354s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01377, in 0.263s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06747, val loss: 0.06731, in 0.339s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05674, val loss: 0.05557, in 0.359s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01248, in 0.341s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07029, val loss: 0.06995, in 0.342s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01223, val loss: 0.01219, in 0.294s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06117, val loss: 0.06069, in 0.335s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01090, val loss: 0.01057, in 0.359s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01364, val loss: 0.01350, in 0.300s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06462, val loss: 0.06449, in 0.316s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05457, val loss: 0.05346, in 0.305s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01243, val loss: 0.01220, in 0.293s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06727, val loss: 0.06696, in 0.313s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01325, val loss: 0.01313, in 0.269s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01185, val loss: 0.01183, in 0.357s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05848, val loss: 0.05800, in 0.332s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01026, in 0.309s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06170, val loss: 0.06158, in 0.320s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05258, val loss: 0.05153, in 0.332s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01190, in 0.328s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06414, val loss: 0.06386, in 0.350s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01289, in 0.248s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01156, in 0.252s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01038, val loss: 0.01007, in 0.276s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05609, val loss: 0.05563, in 0.316s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05896, val loss: 0.05892, in 0.309s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01151, in 0.289s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05030, val loss: 0.04932, in 0.338s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01129, val loss: 0.01129, in 0.308s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06119, val loss: 0.06098, in 0.354s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01266, val loss: 0.01260, in 0.358s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01011, val loss: 0.00981, in 0.310s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05376, val loss: 0.05330, in 0.388s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05648, val loss: 0.05654, in 0.397s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01138, val loss: 0.01121, in 0.403s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01103, in 0.331s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04848, val loss: 0.04753, in 0.422s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01234, val loss: 0.01228, in 0.330s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00993, val loss: 0.00962, in 0.327s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05833, val loss: 0.05818, in 0.361s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05141, val loss: 0.05096, in 0.335s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05386, val loss: 0.05399, in 0.317s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01086, val loss: 0.01086, in 0.263s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01093, in 0.319s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01206, val loss: 0.01202, in 0.309s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04676, val loss: 0.04582, in 0.346s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00966, val loss: 0.00936, in 0.346s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05576, val loss: 0.05556, in 0.347s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.04918, in 0.346s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01093, val loss: 0.01077, in 0.289s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05174, val loss: 0.05186, in 0.361s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01054, val loss: 0.01057, in 0.347s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00920, in 0.293s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01166, in 0.338s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04509, val loss: 0.04420, in 0.339s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05360, val loss: 0.05341, in 0.358s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01048, in 0.303s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04756, val loss: 0.04719, in 0.380s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04979, val loss: 0.04994, in 0.380s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01025, val loss: 0.01028, in 0.391s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04206, in 0.324s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01133, val loss: 0.01130, in 0.344s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00892, in 0.367s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05153, val loss: 0.05139, in 0.347s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01054, val loss: 0.01039, in 0.255s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04584, val loss: 0.04547, in 0.324s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01004, val loss: 0.01007, in 0.262s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04780, val loss: 0.04798, in 0.321s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01112, val loss: 0.01110, in 0.278s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00871, in 0.282s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04152, val loss: 0.04073, in 0.336s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01013, in 0.305s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04936, val loss: 0.04926, in 0.385s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04393, val loss: 0.04352, in 0.351s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00976, val loss: 0.00982, in 0.337s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04607, val loss: 0.04625, in 0.341s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00851, in 0.330s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01080, val loss: 0.01080, in 0.368s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04004, val loss: 0.03926, in 0.332s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00983, in 0.369s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04760, val loss: 0.04754, in 0.337s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00956, val loss: 0.00963, in 0.261s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04229, val loss: 0.04190, in 0.337s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01058, in 0.244s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04452, val loss: 0.04471, in 0.308s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03822, val loss: 0.03748, in 0.261s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00830, in 0.322s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.00953, in 0.319s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04567, val loss: 0.04563, in 0.316s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00931, val loss: 0.00938, in 0.311s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04014, val loss: 0.03982, in 0.313s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01029, val loss: 0.01031, in 0.309s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00818, in 0.255s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03693, val loss: 0.03621, in 0.281s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04223, val loss: 0.04243, in 0.312s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00954, val loss: 0.00942, in 0.240s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00916, val loss: 0.00925, in 0.229s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04411, val loss: 0.04406, in 0.296s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01007, val loss: 0.01009, in 0.254s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00794, in 0.264s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03843, val loss: 0.03813, in 0.295s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03527, val loss: 0.03459, in 0.289s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04055, val loss: 0.04073, in 0.294s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00917, in 0.327s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00894, val loss: 0.00902, in 0.320s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04211, val loss: 0.04214, in 0.346s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00774, in 0.318s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03671, val loss: 0.03645, in 0.320s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.00982, in 0.344s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03388, val loss: 0.03322, in 0.306s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03851, val loss: 0.03872, in 0.313s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00887, in 0.282s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00901, val loss: 0.00891, in 0.318s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03997, val loss: 0.04002, in 0.272s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03287, val loss: 0.03225, in 0.247s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00758, in 0.280s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00957, val loss: 0.00962, in 0.278s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03541, val loss: 0.03519, in 0.326s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03691, val loss: 0.03715, in 0.303s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00870, in 0.290s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00866, in 0.303s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.00951, in 0.242s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03202, val loss: 0.03141, in 0.304s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00741, in 0.287s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03828, val loss: 0.03846, in 0.336s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03437, val loss: 0.03417, in 0.297s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03531, val loss: 0.03557, in 0.306s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00837, val loss: 0.00847, in 0.295s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00847, in 0.309s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00727, in 0.230s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00930, in 0.274s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03069, val loss: 0.03012, in 0.315s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03652, val loss: 0.03675, in 0.300s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03331, val loss: 0.03312, in 0.277s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03425, val loss: 0.03450, in 0.271s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00826, in 0.283s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00915, in 0.285s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00828, in 0.330s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00710, in 0.364s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02965, val loss: 0.02914, in 0.299s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03207, val loss: 0.03192, in 0.295s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03520, val loss: 0.03544, in 0.320s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03288, val loss: 0.03312, in 0.312s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00808, in 0.289s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.00892, in 0.332s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02886, val loss: 0.02840, in 0.264s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00811, val loss: 0.00804, in 0.356s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03111, val loss: 0.03102, in 0.285s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00691, in 0.340s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03425, in 0.305s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03200, val loss: 0.03227, in 0.278s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00790, in 0.349s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00861, val loss: 0.00869, in 0.303s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00680, in 0.257s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02792, val loss: 0.02751, in 0.340s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00793, in 0.318s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03115, val loss: 0.03144, in 0.285s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02983, val loss: 0.02978, in 0.331s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03296, val loss: 0.03327, in 0.321s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00842, val loss: 0.00852, in 0.274s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00770, in 0.310s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00666, in 0.258s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02726, val loss: 0.02688, in 0.266s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03020, val loss: 0.03048, in 0.286s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03194, val loss: 0.03226, in 0.274s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02857, val loss: 0.02856, in 0.318s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00778, val loss: 0.00773, in 0.346s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00836, in 0.294s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00652, in 0.275s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00755, in 0.280s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02647, val loss: 0.02614, in 0.257s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02934, val loss: 0.02963, in 0.259s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02763, in 0.232s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00756, in 0.248s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03055, val loss: 0.03089, in 0.315s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02536, val loss: 0.02502, in 0.285s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00820, in 0.302s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00738, in 0.324s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00654, val loss: 0.00635, in 0.345s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02667, val loss: 0.02664, in 0.328s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02818, val loss: 0.02849, in 0.512s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.03006, in 0.442s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00745, val loss: 0.00740, in 0.529s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00727, in 0.413s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00624, in 0.467s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02577, in 0.414s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00787, val loss: 0.00798, in 0.519s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02436, val loss: 0.02401, in 0.531s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02716, val loss: 0.02746, in 0.311s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02857, val loss: 0.02897, in 0.319s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00724, in 0.326s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00710, in 0.303s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00770, val loss: 0.00781, in 0.258s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00611, in 0.304s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02483, val loss: 0.02481, in 0.312s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02352, val loss: 0.02315, in 0.324s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02659, val loss: 0.02690, in 0.279s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02785, val loss: 0.02826, in 0.276s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00709, val loss: 0.00707, in 0.282s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00768, in 0.265s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00681, val loss: 0.00694, in 0.326s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00607, val loss: 0.00593, in 0.320s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02268, val loss: 0.02231, in 0.287s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02390, val loss: 0.02392, in 0.335s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02521, val loss: 0.02552, in 0.301s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02684, val loss: 0.02728, in 0.329s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00689, val loss: 0.00688, in 0.269s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00736, val loss: 0.00750, in 0.344s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00667, val loss: 0.00680, in 0.340s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02137, in 0.327s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02329, val loss: 0.02336, in 0.310s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00593, val loss: 0.00581, in 0.354s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02422, val loss: 0.02455, in 0.359s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02599, val loss: 0.02646, in 0.324s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00673, val loss: 0.00673, in 0.339s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00731, in 0.341s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00667, in 0.329s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02251, in 0.280s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02090, val loss: 0.02059, in 0.292s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02324, val loss: 0.02359, in 0.277s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00664, val loss: 0.00664, in 0.256s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02517, val loss: 0.02562, in 0.286s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00567, in 0.349s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02159, in 0.287s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00694, val loss: 0.00708, in 0.326s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00656, in 0.331s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02455, val loss: 0.02503, in 0.289s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00649, val loss: 0.00651, in 0.299s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01999, in 0.364s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02242, val loss: 0.02277, in 0.370s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00552, in 0.333s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00686, val loss: 0.00700, in 0.264s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02082, val loss: 0.02082, in 0.324s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00641, in 0.303s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00640, in 0.379s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01941, val loss: 0.01914, in 0.323s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02357, in 0.352s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00548, val loss: 0.00539, in 0.302s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02205, in 0.338s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00671, val loss: 0.00685, in 0.324s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00623, val loss: 0.00626, in 0.262s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02033, val loss: 0.02039, in 0.330s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02216, val loss: 0.02262, in 0.292s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.01855, in 0.307s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00628, in 0.318s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02126, val loss: 0.02165, in 0.275s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00529, in 0.333s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00612, val loss: 0.00613, in 0.275s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01945, val loss: 0.01953, in 0.312s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00653, val loss: 0.00668, in 0.373s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02142, val loss: 0.02194, in 0.338s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02055, val loss: 0.02094, in 0.322s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01798, in 0.354s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00615, in 0.347s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00521, val loss: 0.00513, in 0.380s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00601, val loss: 0.00603, in 0.290s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01877, val loss: 0.01884, in 0.304s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00637, val loss: 0.00651, in 0.350s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02130, in 0.331s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01973, val loss: 0.02009, in 0.314s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01752, val loss: 0.01730, in 0.346s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00505, in 0.290s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00584, val loss: 0.00602, in 0.417s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00588, in 0.379s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01822, val loss: 0.01829, in 0.314s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00625, val loss: 0.00640, in 0.295s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02000, val loss: 0.02050, in 0.302s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01886, val loss: 0.01922, in 0.342s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01696, val loss: 0.01674, in 0.358s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00574, val loss: 0.00593, in 0.307s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00499, val loss: 0.00492, in 0.396s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00575, val loss: 0.00578, in 0.332s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00615, val loss: 0.00631, in 0.311s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01757, val loss: 0.01767, in 0.377s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01929, val loss: 0.01977, in 0.353s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00580, in 0.250s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01826, val loss: 0.01863, in 0.347s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01635, in 0.309s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00484, in 0.297s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00564, val loss: 0.00567, in 0.241s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01705, val loss: 0.01714, in 0.288s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00601, val loss: 0.00616, in 0.343s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.01906, in 0.266s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00573, in 0.308s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01603, val loss: 0.01585, in 0.287s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01779, in 0.343s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00559, in 0.280s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00474, in 0.351s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01666, in 0.310s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00602, in 0.366s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01822, in 0.357s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00543, val loss: 0.00562, in 0.317s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00546, val loss: 0.00549, in 0.278s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01530, in 0.343s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00472, val loss: 0.00467, in 0.264s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01687, val loss: 0.01725, in 0.346s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01600, val loss: 0.01611, in 0.339s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00577, val loss: 0.00592, in 0.308s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01696, val loss: 0.01742, in 0.352s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00550, in 0.345s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00538, in 0.344s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01667, in 0.315s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01498, val loss: 0.01481, in 0.368s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00456, in 0.339s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01574, in 0.322s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00566, val loss: 0.00582, in 0.334s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01643, val loss: 0.01690, in 0.355s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01457, val loss: 0.01439, in 0.291s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00521, val loss: 0.00540, in 0.380s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00444, in 0.314s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01616, in 0.334s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00527, in 0.382s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01520, in 0.366s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00560, val loss: 0.00577, in 0.321s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01639, in 0.354s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01407, in 0.359s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00511, val loss: 0.00531, in 0.366s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00517, in 0.391s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00435, in 0.423s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01560, in 0.422s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01469, val loss: 0.01482, in 0.318s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00549, val loss: 0.00567, in 0.370s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01596, in 0.286s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01392, val loss: 0.01373, in 0.268s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00431, in 0.246s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00500, val loss: 0.00521, in 0.316s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00507, in 0.276s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01505, in 0.282s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01436, val loss: 0.01450, in 0.266s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00538, val loss: 0.00557, in 0.314s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01355, val loss: 0.01338, in 0.305s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01551, in 0.375s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00510, in 0.302s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00422, in 0.337s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01467, in 0.319s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00494, val loss: 0.00498, in 0.367s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01410, in 0.393s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01312, in 0.286s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00550, in 0.308s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01514, in 0.280s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00476, val loss: 0.00497, in 0.317s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00415, val loss: 0.00413, in 0.338s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00484, in 0.302s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01423, in 0.362s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01378, in 0.331s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00540, in 0.295s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01415, val loss: 0.01458, in 0.339s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01286, val loss: 0.01273, in 0.412s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00491, in 0.352s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00405, val loss: 0.00404, in 0.351s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01395, in 0.315s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00470, val loss: 0.00475, in 0.382s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01345, val loss: 0.01365, in 0.283s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00529, in 0.344s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01379, val loss: 0.01420, in 0.281s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01258, val loss: 0.01245, in 0.274s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00485, in 0.296s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01353, in 0.312s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00395, val loss: 0.00395, in 0.328s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00466, in 0.334s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01337, in 0.321s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00501, val loss: 0.00520, in 0.377s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01212, in 0.342s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01348, val loss: 0.01387, in 0.355s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00455, val loss: 0.00478, in 0.333s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00388, in 0.332s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01308, in 0.351s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01286, val loss: 0.01306, in 0.299s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00457, in 0.356s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01311, val loss: 0.01348, in 0.310s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00510, in 0.329s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01192, val loss: 0.01182, in 0.367s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00470, in 0.342s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01261, val loss: 0.01283, in 0.307s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00381, val loss: 0.00381, in 0.355s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01237, val loss: 0.01275, in 0.352s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00447, in 0.358s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01314, in 0.339s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01176, val loss: 0.01167, in 0.306s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00500, in 0.353s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00460, in 0.306s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01243, val loss: 0.01265, in 0.297s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00372, in 0.319s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01237, in 0.392s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00439, in 0.410s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01237, val loss: 0.01276, in 0.361s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00467, val loss: 0.00487, in 0.339s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01143, val loss: 0.01135, in 0.359s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00453, in 0.323s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01239, in 0.330s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00366, val loss: 0.00366, in 0.343s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01165, val loss: 0.01201, in 0.293s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00448, in 0.294s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00461, val loss: 0.00482, in 0.321s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00430, in 0.387s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01121, val loss: 0.01113, in 0.339s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01238, in 0.398s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01181, val loss: 0.01204, in 0.377s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00358, in 0.338s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01169, in 0.338s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01102, in 0.272s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00440, in 0.373s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00422, in 0.377s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00475, in 0.411s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01203, in 0.355s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01154, val loss: 0.01177, in 0.436s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01139, in 0.420s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00348, val loss: 0.00350, in 0.522s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00467, in 0.461s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01071, val loss: 0.01064, in 0.589s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00430, in 0.540s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00414, in 0.526s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01125, val loss: 0.01166, in 0.509s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01115, val loss: 0.01138, in 0.511s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01111, in 0.520s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00344, in 0.467s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00421, in 0.369s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00457, in 0.408s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01039, val loss: 0.01034, in 0.409s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00397, val loss: 0.00403, in 0.418s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01094, val loss: 0.01136, in 0.452s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01107, in 0.380s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00339, in 0.390s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01080, in 0.496s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01014, val loss: 0.01010, in 0.527s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00385, val loss: 0.00410, in 0.586s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00446, in 0.616s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01099, in 0.544s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00390, val loss: 0.00397, in 0.585s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01053, val loss: 0.01077, in 0.569s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00332, in 0.541s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01009, val loss: 0.01047, in 0.609s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00993, val loss: 0.00989, in 0.446s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00400, in 0.447s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00438, in 0.472s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00392, in 0.499s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01069, in 0.615s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01057, in 0.634s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00328, in 0.620s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00992, val loss: 0.01031, in 0.593s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00394, in 0.626s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00961, val loss: 0.00957, in 0.743s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01010, val loss: 0.01049, in 0.526s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00431, in 0.712s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01016, val loss: 0.01041, in 0.435s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00385, in 0.693s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00323, in 0.545s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00967, val loss: 0.01004, in 0.419s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00363, val loss: 0.00387, in 0.528s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00997, val loss: 0.01036, in 0.432s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00935, val loss: 0.00931, in 0.541s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00400, val loss: 0.00422, in 0.530s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00369, val loss: 0.00377, in 0.492s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00990, val loss: 0.01014, in 0.585s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.00982, in 0.528s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00315, in 0.544s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00973, val loss: 0.01011, in 0.375s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00381, in 0.445s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00916, val loss: 0.00913, in 0.411s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00371, in 0.399s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00391, val loss: 0.00413, in 0.416s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00994, in 0.391s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00310, in 0.325s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00966, in 0.345s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00376, in 0.336s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00988, in 0.399s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00894, val loss: 0.00892, in 0.377s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00409, in 0.336s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00362, in 0.379s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.00971, in 0.320s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00301, val loss: 0.00306, in 0.367s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00903, val loss: 0.00940, in 0.441s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00369, in 0.367s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00969, in 0.336s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00380, val loss: 0.00403, in 0.335s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00868, in 0.372s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00951, in 0.333s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00301, in 0.305s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00357, in 0.400s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00366, in 0.285s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00875, val loss: 0.00913, in 0.350s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00952, in 0.303s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00395, in 0.317s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00854, val loss: 0.00854, in 0.337s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00895, val loss: 0.00920, in 0.376s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00350, in 0.335s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00296, in 0.364s\n",
      "[144/200] 1 tree, 29 leaves, max depth = 10, train loss: 0.00906, val loss: 0.00945, in 0.271s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00363, in 0.334s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00890, in 0.374s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00391, in 0.308s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00838, in 0.328s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00872, val loss: 0.00898, in 0.341s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00290, in 0.328s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00333, val loss: 0.00344, in 0.342s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00928, in 0.328s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00357, in 0.317s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00385, in 0.298s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00869, in 0.362s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00819, in 0.397s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00339, in 0.333s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00851, val loss: 0.00878, in 0.358s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00279, val loss: 0.00284, in 0.404s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00898, in 0.365s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00351, in 0.351s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00846, in 0.352s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00378, in 0.400s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00833, val loss: 0.00861, in 0.345s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00797, in 0.389s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00332, in 0.389s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00280, in 0.326s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00346, in 0.336s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00878, in 0.351s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00787, val loss: 0.00826, in 0.315s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00370, in 0.352s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00277, in 0.615s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00856, in 0.675s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00845, in 0.770s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00775, val loss: 0.00776, in 0.765s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00313, val loss: 0.00327, in 0.776s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00773, val loss: 0.00813, in 0.664s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00340, in 0.760s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00338, val loss: 0.00363, in 0.620s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00272, in 0.409s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00843, in 0.341s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00799, in 0.308s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00806, val loss: 0.00834, in 0.352s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00308, val loss: 0.00320, in 0.328s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00335, in 0.398s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00753, val loss: 0.00756, in 0.451s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00356, in 0.414s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00788, val loss: 0.00827, in 0.332s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00266, in 0.364s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00315, in 0.347s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00783, val loss: 0.00812, in 0.378s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00740, val loss: 0.00779, in 0.382s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00350, in 0.309s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00329, in 0.349s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00732, val loss: 0.00737, in 0.354s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00811, in 0.317s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00256, val loss: 0.00262, in 0.337s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00800, in 0.297s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00310, in 0.335s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00726, in 0.269s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00344, in 0.338s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00325, in 0.327s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00723, val loss: 0.00761, in 0.411s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00292, val loss: 0.00305, in 0.299s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00749, val loss: 0.00786, in 0.398s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00257, in 0.378s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00752, val loss: 0.00782, in 0.373s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00337, in 0.342s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00748, in 0.330s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00319, in 0.368s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00703, val loss: 0.00709, in 0.429s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00736, val loss: 0.00774, in 0.300s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00299, in 0.320s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00737, val loss: 0.00767, in 0.296s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00735, in 0.302s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00245, val loss: 0.00251, in 0.433s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00315, in 0.334s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00691, in 0.337s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00333, in 0.394s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00765, in 0.327s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00295, in 0.347s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00718, val loss: 0.00748, in 0.407s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00309, in 0.297s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00716, in 0.384s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00240, val loss: 0.00246, in 0.412s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00325, in 0.363s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00668, val loss: 0.00676, in 0.401s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00706, val loss: 0.00742, in 0.314s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00293, in 0.362s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00701, val loss: 0.00731, in 0.356s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00304, in 0.366s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00662, val loss: 0.00700, in 0.380s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00663, in 0.306s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00243, in 0.394s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00320, in 0.395s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00290, in 0.321s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00688, val loss: 0.00724, in 0.411s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00298, in 0.312s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00689, val loss: 0.00720, in 0.369s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00690, in 0.364s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00231, val loss: 0.00239, in 0.322s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00638, val loss: 0.00646, in 0.415s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00316, in 0.368s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00711, in 0.316s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00285, in 0.388s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00293, in 0.320s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00674, val loss: 0.00706, in 0.363s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00681, in 0.286s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00622, val loss: 0.00630, in 0.344s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00235, in 0.377s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00310, in 0.372s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00694, in 0.378s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00279, in 0.369s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00289, in 0.347s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00630, val loss: 0.00669, in 0.301s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00660, val loss: 0.00692, in 0.349s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00620, in 0.308s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00306, in 0.315s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00232, in 0.362s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00637, val loss: 0.00678, in 0.391s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00256, val loss: 0.00286, in 0.370s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00259, val loss: 0.00275, in 0.405s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00615, val loss: 0.00653, in 0.424s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00672, in 0.411s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00614, in 0.363s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00303, in 0.369s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00228, in 0.390s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00625, val loss: 0.00666, in 0.352s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00254, val loss: 0.00270, in 0.362s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00643, in 0.334s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00281, in 0.422s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00608, in 0.318s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00628, val loss: 0.00659, in 0.408s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00225, in 0.326s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00298, in 0.353s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00653, in 0.332s\n",
      "[109/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00636, in 0.294s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00267, in 0.355s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00247, val loss: 0.00277, in 0.373s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00597, in 0.419s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00215, val loss: 0.00223, in 0.333s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00609, val loss: 0.00639, in 0.441s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00266, val loss: 0.00295, in 0.457s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00599, val loss: 0.00638, in 0.376s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00585, val loss: 0.00625, in 0.406s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00264, in 0.404s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00243, val loss: 0.00274, in 0.420s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00569, val loss: 0.00581, in 0.421s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00219, in 0.439s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00290, in 0.333s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00583, val loss: 0.00621, in 0.329s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00592, val loss: 0.00623, in 0.423s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00615, in 0.373s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00243, val loss: 0.00259, in 0.356s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00238, val loss: 0.00269, in 0.348s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00561, val loss: 0.00574, in 0.340s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00286, in 0.348s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00215, in 0.393s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00577, val loss: 0.00606, in 0.372s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00571, val loss: 0.00611, in 0.308s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00239, val loss: 0.00255, in 0.310s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00567, val loss: 0.00606, in 0.475s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00265, in 0.384s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00548, val loss: 0.00562, in 0.403s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00282, in 0.388s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00211, in 0.387s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00600, in 0.327s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00565, val loss: 0.00594, in 0.429s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00235, val loss: 0.00252, in 0.374s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00552, val loss: 0.00591, in 0.428s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00230, val loss: 0.00261, in 0.384s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00551, in 0.376s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00549, val loss: 0.00587, in 0.334s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00232, val loss: 0.00249, in 0.364s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00207, in 0.460s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00248, val loss: 0.00277, in 0.488s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00553, val loss: 0.00583, in 0.409s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00541, val loss: 0.00580, in 0.420s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00257, in 0.347s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00540, in 0.405s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00573, in 0.383s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00244, val loss: 0.00273, in 0.374s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00204, in 0.387s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00543, val loss: 0.00574, in 0.382s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00228, val loss: 0.00245, in 0.499s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00570, in 0.441s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00254, in 0.455s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00529, in 0.446s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00562, in 0.448s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00239, val loss: 0.00268, in 0.428s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00200, in 0.455s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00560, in 0.435s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00526, val loss: 0.00564, in 0.302s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00220, val loss: 0.00251, in 0.374s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00241, in 0.463s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00521, in 0.380s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00511, val loss: 0.00550, in 0.402s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00235, val loss: 0.00264, in 0.396s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00519, val loss: 0.00551, in 0.397s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00197, in 0.431s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00552, in 0.439s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00247, in 0.401s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00237, in 0.410s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00492, val loss: 0.00509, in 0.445s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00500, val loss: 0.00539, in 0.429s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00231, val loss: 0.00260, in 0.347s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00195, in 0.325s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00502, val loss: 0.00539, in 0.352s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00508, val loss: 0.00538, in 0.423s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00234, in 0.351s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00243, in 0.387s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00501, in 0.352s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00493, val loss: 0.00532, in 0.337s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00256, in 0.351s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00191, in 0.350s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00526, in 0.318s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00533, in 0.341s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00241, in 0.318s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00229, in 0.357s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00526, in 0.295s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00490, in 0.358s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00252, in 0.343s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00516, in 0.305s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00188, in 0.350s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00485, val loss: 0.00523, in 0.342s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00206, val loss: 0.00238, in 0.340s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00225, in 0.350s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00520, in 0.374s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00480, in 0.442s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00248, in 0.531s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00506, in 0.504s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00184, in 0.518s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00474, val loss: 0.00512, in 0.504s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00204, val loss: 0.00222, in 0.529s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00509, in 0.399s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00235, in 0.560s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00470, in 0.414s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00245, in 0.386s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00498, in 0.382s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00506, in 0.351s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00180, in 0.436s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00220, in 0.337s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00199, val loss: 0.00232, in 0.401s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00497, in 0.446s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00462, in 0.408s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00459, val loss: 0.00498, in 0.410s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00485, in 0.457s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00213, val loss: 0.00240, in 0.472s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00178, in 0.442s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00217, in 0.434s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00227, in 0.388s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00450, val loss: 0.00490, in 0.397s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00455, in 0.454s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00492, in 0.418s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00237, in 0.427s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00177, in 0.400s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00476, in 0.505s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00215, in 0.478s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00192, val loss: 0.00224, in 0.519s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00440, val loss: 0.00480, in 0.486s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00427, val loss: 0.00448, in 0.407s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00445, val loss: 0.00483, in 0.372s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00206, val loss: 0.00234, in 0.387s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00174, in 0.436s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00465, in 0.397s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00212, in 0.400s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00432, val loss: 0.00472, in 0.417s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00222, in 0.445s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00441, in 0.403s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00436, val loss: 0.00474, in 0.396s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00230, in 0.368s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00172, in 0.347s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00458, in 0.412s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00209, in 0.387s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00220, in 0.378s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00464, in 0.394s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00412, val loss: 0.00435, in 0.374s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00465, in 0.363s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00227, in 0.409s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00422, val loss: 0.00450, in 0.350s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00170, in 0.430s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00206, in 0.417s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00183, val loss: 0.00217, in 0.324s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00452, in 0.385s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00428, in 0.368s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00421, val loss: 0.00457, in 0.380s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00223, in 0.391s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00436, in 0.346s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00168, in 0.377s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00185, val loss: 0.00204, in 0.384s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00405, val loss: 0.00445, in 0.316s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00180, val loss: 0.00214, in 0.419s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00419, in 0.328s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00411, val loss: 0.00447, in 0.343s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00220, in 0.385s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00154, val loss: 0.00164, in 0.345s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00400, val loss: 0.00428, in 0.411s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00439, in 0.403s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00201, in 0.418s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00212, in 0.390s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00391, val loss: 0.00413, in 0.389s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00438, in 0.358s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00216, in 0.382s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00420, in 0.394s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00150, val loss: 0.00161, in 0.425s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00432, in 0.288s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00404, in 0.309s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00178, val loss: 0.00198, in 0.327s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00210, in 0.354s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00431, in 0.396s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00214, in 0.354s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00412, in 0.410s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00197, in 0.323s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00158, in 0.415s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00425, in 0.368s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00396, in 0.364s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00206, in 0.360s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00424, in 0.347s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00211, in 0.371s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00405, in 0.301s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00155, in 0.319s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00194, in 0.347s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00203, in 0.313s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00389, in 0.355s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00380, val loss: 0.00416, in 0.401s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00418, in 0.383s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00143, val loss: 0.00153, in 0.355s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00207, in 0.437s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00400, in 0.407s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00192, in 0.370s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00201, in 0.372s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00383, in 0.376s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00412, in 0.356s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00410, in 0.414s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00366, val loss: 0.00394, in 0.347s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00151, in 0.379s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00403, in 0.287s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00203, in 0.391s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00189, in 0.383s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00198, in 0.352s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00355, val loss: 0.00377, in 0.364s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00359, val loss: 0.00402, in 0.390s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00383, in 0.347s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00149, in 0.371s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00201, in 0.386s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00371, in 0.344s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00187, in 0.388s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00359, val loss: 0.00396, in 0.423s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00195, in 0.416s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00396, in 0.380s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00377, in 0.312s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00146, in 0.314s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00392, in 0.299s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00366, in 0.338s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00185, in 0.334s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00159, val loss: 0.00193, in 0.304s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00198, in 0.391s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00390, in 0.378s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00369, in 0.339s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00145, in 0.307s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00184, in 0.292s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00359, in 0.342s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00191, in 0.332s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00384, in 0.379s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00196, in 0.367s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00365, in 0.328s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00132, val loss: 0.00143, in 0.338s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00385, in 0.364s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00182, in 0.363s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00351, in 0.342s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00189, in 0.374s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00166, val loss: 0.00193, in 0.341s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00339, val loss: 0.00378, in 0.389s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00358, in 0.367s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00130, val loss: 0.00141, in 0.371s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00380, in 0.378s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00179, in 0.344s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00346, in 0.340s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00186, in 0.373s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00372, in 0.354s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00164, val loss: 0.00191, in 0.355s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00324, val loss: 0.00351, in 0.364s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00375, in 0.388s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00139, in 0.408s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00342, in 0.331s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00176, in 0.388s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00368, in 0.309s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00189, in 0.331s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00150, val loss: 0.00184, in 0.393s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00345, in 0.358s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00137, in 0.310s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00322, val loss: 0.00369, in 0.346s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00336, in 0.378s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00154, val loss: 0.00174, in 0.343s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00361, in 0.335s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00187, in 0.324s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00181, in 0.328s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00313, val loss: 0.00340, in 0.342s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00124, val loss: 0.00135, in 0.343s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00332, in 0.282s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00361, in 0.391s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00185, in 0.346s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00173, in 0.381s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00356, in 0.378s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00144, val loss: 0.00179, in 0.341s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00132, in 0.281s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00335, in 0.331s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00328, in 0.323s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00183, in 0.305s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00352, in 0.306s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00354, in 0.352s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00170, in 0.318s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00177, in 0.339s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00119, val loss: 0.00130, in 0.333s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00332, in 0.322s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00301, val loss: 0.00323, in 0.334s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00181, in 0.340s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00349, in 0.360s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00348, in 0.385s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00168, in 0.383s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00175, in 0.363s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00117, val loss: 0.00128, in 0.330s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00325, in 0.342s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00294, val loss: 0.00316, in 0.378s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00344, in 0.311s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00179, in 0.357s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00342, in 0.299s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00166, in 0.316s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00173, in 0.356s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00292, val loss: 0.00320, in 0.322s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00115, val loss: 0.00126, in 0.399s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00310, in 0.362s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00177, in 0.339s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00165, in 0.330s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00336, in 0.361s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00337, in 0.392s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00171, in 0.296s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00315, in 0.309s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00113, val loss: 0.00125, in 0.278s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00285, val loss: 0.00307, in 0.262s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00176, in 0.270s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00333, in 0.272s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00162, in 0.344s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00333, in 0.317s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00170, in 0.326s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00309, in 0.302s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00111, val loss: 0.00122, in 0.389s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00302, in 0.371s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00173, in 0.364s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00327, in 0.354s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00161, in 0.294s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00328, in 0.315s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00167, in 0.328s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00305, in 0.313s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00109, val loss: 0.00120, in 0.287s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00297, in 0.304s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00142, val loss: 0.00171, in 0.319s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00324, in 0.307s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00137, val loss: 0.00159, in 0.329s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00165, in 0.311s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00324, in 0.362s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00299, in 0.336s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00169, in 0.344s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00291, in 0.390s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00157, in 0.314s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00320, in 0.379s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00164, in 0.347s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00320, in 0.350s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00268, val loss: 0.00295, in 0.311s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00289, in 0.289s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00155, in 0.324s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00137, val loss: 0.00167, in 0.365s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00314, in 0.336s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00127, val loss: 0.00162, in 0.335s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00315, in 0.331s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00292, in 0.361s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00285, in 0.351s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00154, in 0.375s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00166, in 0.395s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00308, in 0.387s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00311, in 0.377s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00289, in 0.351s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00280, in 0.371s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00152, in 0.332s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00304, in 0.298s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00163, in 0.363s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00302, in 0.394s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00254, val loss: 0.00282, in 0.383s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00276, in 0.396s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00162, in 0.300s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00300, in 0.322s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00297, in 0.307s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00249, val loss: 0.00278, in 0.333s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00294, in 0.316s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00159, in 0.326s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00249, val loss: 0.00271, in 0.349s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00292, in 0.372s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00276, in 0.317s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00290, in 0.293s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00245, val loss: 0.00267, in 0.303s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00157, in 0.320s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00272, in 0.295s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00250, val loss: 0.00289, in 0.364s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00285, in 0.332s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00241, val loss: 0.00264, in 0.355s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00239, val loss: 0.00268, in 0.338s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00245, val loss: 0.00285, in 0.368s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00281, in 0.340s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00260, in 0.345s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00262, in 0.351s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00281, in 0.331s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00278, in 0.369s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00256, in 0.342s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00230, val loss: 0.00259, in 0.365s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00277, in 0.349s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00231, val loss: 0.00254, in 0.302s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00273, in 0.349s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00256, in 0.306s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00273, in 0.347s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00252, in 0.292s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00220, val loss: 0.00268, in 0.325s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00222, val loss: 0.00251, in 0.334s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00229, val loss: 0.00269, in 0.328s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00248, in 0.317s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00265, in 0.340s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00249, in 0.321s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00265, in 0.390s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00222, val loss: 0.00245, in 0.319s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00213, val loss: 0.00262, in 0.370s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00246, in 0.341s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00222, val loss: 0.00263, in 0.262s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00242, in 0.295s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00260, in 0.283s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00214, val loss: 0.00244, in 0.314s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00218, val loss: 0.00258, in 0.360s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00238, in 0.333s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00257, in 0.347s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00242, in 0.294s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00215, val loss: 0.00255, in 0.338s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00235, in 0.373s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00204, val loss: 0.00252, in 0.278s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00238, in 0.328s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00107, val loss: 0.00118, in 0.367s\n",
      "Fit 200 trees in 78.910 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.920s\n",
      "Time spent finding best splits:  1.350s\n",
      "Time spent applying splits:      9.708s\n",
      "Time spent predicting:           0.607s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00252, in 0.347s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00232, in 0.347s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00249, in 0.336s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00204, val loss: 0.00236, in 0.314s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00248, in 0.312s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00205, val loss: 0.00228, in 0.342s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00197, val loss: 0.00245, in 0.382s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00233, in 0.410s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00160, in 0.390s\n",
      "Fit 200 trees in 78.040 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.604s\n",
      "Time spent finding best splits:  1.316s\n",
      "Time spent applying splits:      9.660s\n",
      "Time spent predicting:           0.417s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00246, in 0.426s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00224, in 0.363s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00194, val loss: 0.00242, in 0.349s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00230, in 0.341s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00201, val loss: 0.00243, in 0.431s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00221, in 0.427s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00238, in 0.402s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00227, in 0.395s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00151, in 0.359s\n",
      "Fit 200 trees in 78.443 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.564s\n",
      "Time spent finding best splits:  1.340s\n",
      "Time spent applying splits:      9.726s\n",
      "Time spent predicting:           0.594s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00239, in 0.441s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00235, in 0.473s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00218, in 0.501s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00223, in 0.483s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00236, in 0.473s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00214, in 0.490s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00231, in 0.507s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00218, in 0.491s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00233, in 0.402s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00211, in 0.414s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00182, val loss: 0.00228, in 0.405s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00185, val loss: 0.00216, in 0.379s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00230, in 0.507s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00178, val loss: 0.00224, in 0.456s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00208, in 0.509s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00183, val loss: 0.00214, in 0.477s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00155, in 0.335s\n",
      "Fit 200 trees in 78.165 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.012s\n",
      "Time spent finding best splits:  1.372s\n",
      "Time spent applying splits:      9.825s\n",
      "Time spent predicting:           0.629s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00227, in 0.423s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00221, in 0.506s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00179, val loss: 0.00210, in 0.469s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00204, in 0.531s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00184, val loss: 0.00224, in 0.473s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00219, in 0.328s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00202, in 0.350s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00207, in 0.453s\n",
      "[179/200] 4.295 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.00171, val loss: 0.00216, in 0.317s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00220, in 0.381s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00199, in 0.371s\n",
      "[182/200] 0.221 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00204, in 0.396s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00214, in 0.332s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00217, in 0.377s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00197, in 0.306s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61044, val loss: 0.61030, in 0.330s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00202, in 0.393s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00212, in 0.349s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00196, in 0.293s\n",
      "[184/200] 4.263 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.00175, val loss: 0.00215, in 0.327s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54272, val loss: 0.54236, in 0.389s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00210, in 0.357s\n",
      "[181/200] 0.217 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00198, in 0.495s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00193, in 0.434s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00212, in 0.430s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48569, val loss: 0.48523, in 0.382s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00207, in 0.368s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.60970, val loss: 0.60966, in 0.370s\n",
      "[2/200] 4.302 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00196, in 0.380s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00209, in 0.377s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00191, in 0.436s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43740, val loss: 0.43679, in 0.360s\n",
      "[5/200] 0.155 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00205, in 0.412s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54120, val loss: 0.54115, in 0.399s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00193, in 0.413s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00207, in 0.419s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00187, in 0.431s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39591, val loss: 0.39520, in 0.394s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61043, val loss: 0.61023, in 0.371s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48420, val loss: 0.48413, in 0.347s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00204, in 0.368s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00191, in 0.388s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00205, in 0.396s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00186, in 0.391s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35995, val loss: 0.35913, in 0.395s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54264, val loss: 0.54221, in 0.411s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43515, val loss: 0.43500, in 0.390s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00201, in 0.402s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00188, in 0.357s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00201, in 0.343s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00160, val loss: 0.00183, in 0.372s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48605, val loss: 0.48544, in 0.355s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32843, val loss: 0.32762, in 0.377s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39315, val loss: 0.39298, in 0.347s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00198, in 0.340s\n",
      "[186/200] 4.081 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00186, in 0.386s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00198, in 0.329s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00182, in 0.338s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43740, val loss: 0.43666, in 0.384s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30093, val loss: 0.30003, in 0.392s\n",
      "[9/200] 0.168 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00196, in 0.376s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35732, val loss: 0.35708, in 0.406s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00184, in 0.428s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00195, in 0.436s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00180, in 0.415s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39582, val loss: 0.39499, in 0.374s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27617, val loss: 0.27529, in 0.385s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61039, val loss: 0.61004, in 0.372s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00192, in 0.380s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32583, val loss: 0.32549, in 0.386s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00151, val loss: 0.00182, in 0.342s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00193, in 0.389s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00154, val loss: 0.00178, in 0.425s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35984, val loss: 0.35878, in 0.397s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25490, val loss: 0.25383, in 0.403s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54257, val loss: 0.54202, in 0.410s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00191, in 0.418s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.29781, val loss: 0.29739, in 0.399s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00180, in 0.392s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00191, in 0.445s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00177, in 0.416s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32851, val loss: 0.32744, in 0.396s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23592, val loss: 0.23481, in 0.403s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48546, val loss: 0.48477, in 0.378s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27328, val loss: 0.27290, in 0.385s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00188, in 0.424s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00178, in 0.332s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00189, in 0.427s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30082, val loss: 0.29971, in 0.438s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00174, in 0.453s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21851, val loss: 0.21725, in 0.452s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43713, val loss: 0.43625, in 0.439s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25189, val loss: 0.25148, in 0.422s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00175, in 0.446s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00141, val loss: 0.00186, in 0.524s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00187, in 0.383s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00172, in 0.413s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27643, val loss: 0.27526, in 0.419s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39560, val loss: 0.39458, in 0.421s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20335, val loss: 0.20211, in 0.443s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23298, val loss: 0.23257, in 0.446s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00173, in 0.453s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00184, in 0.434s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00184, in 0.376s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00146, val loss: 0.00170, in 0.414s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25474, val loss: 0.25328, in 0.414s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35961, val loss: 0.35860, in 0.491s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18957, val loss: 0.18822, in 0.488s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21592, val loss: 0.21536, in 0.504s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00182, in 0.461s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00183, in 0.517s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00170, in 0.581s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00168, in 0.540s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23566, val loss: 0.23408, in 0.557s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32842, val loss: 0.32725, in 0.478s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17723, val loss: 0.17592, in 0.468s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20054, val loss: 0.19996, in 0.492s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00140, val loss: 0.00182, in 0.438s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00168, in 0.475s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00135, val loss: 0.00180, in 0.570s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00166, in 0.399s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21904, val loss: 0.21730, in 0.462s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30109, val loss: 0.29988, in 0.454s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16565, val loss: 0.16439, in 0.480s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18669, val loss: 0.18608, in 0.438s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00165, in 0.410s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00178, in 0.434s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00180, in 0.490s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00164, in 0.407s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20338, val loss: 0.20157, in 0.422s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27628, val loss: 0.27490, in 0.411s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15528, val loss: 0.15407, in 0.423s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17424, val loss: 0.17367, in 0.420s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00163, in 0.461s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00176, in 0.439s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00179, in 0.438s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00162, in 0.375s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18979, val loss: 0.18786, in 0.426s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25491, val loss: 0.25344, in 0.418s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14618, val loss: 0.14505, in 0.420s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16288, val loss: 0.16231, in 0.406s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00161, in 0.395s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00178, in 0.378s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00175, in 0.388s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17771, val loss: 0.17566, in 0.428s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23534, val loss: 0.23373, in 0.436s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13773, val loss: 0.13665, in 0.427s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15218, val loss: 0.15168, in 0.424s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00127, val loss: 0.00172, in 0.443s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00176, in 0.453s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00158, in 0.484s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16603, val loss: 0.16388, in 0.403s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21880, val loss: 0.21713, in 0.389s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14281, val loss: 0.14238, in 0.390s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12980, val loss: 0.12873, in 0.402s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00124, val loss: 0.00170, in 0.359s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00127, val loss: 0.00155, in 0.341s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00173, in 0.374s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.15607, val loss: 0.15384, in 0.398s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20375, val loss: 0.20204, in 0.413s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13408, val loss: 0.13371, in 0.474s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12231, val loss: 0.12131, in 0.489s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00122, val loss: 0.00167, in 0.529s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00172, in 0.552s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14652, val loss: 0.14428, in 0.695s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.18970, val loss: 0.18796, in 0.707s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12656, val loss: 0.12624, in 0.670s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11539, val loss: 0.11442, in 0.676s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00171, in 0.554s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13799, val loss: 0.13570, in 0.531s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17716, val loss: 0.17551, in 0.564s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11925, val loss: 0.11886, in 0.549s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10898, val loss: 0.10821, in 0.583s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13004, val loss: 0.12767, in 0.603s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16585, val loss: 0.16412, in 0.582s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11345, val loss: 0.11310, in 0.557s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10341, val loss: 0.10268, in 0.586s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12201, val loss: 0.11969, in 0.679s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15548, val loss: 0.15378, in 0.666s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10735, val loss: 0.10698, in 0.689s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09756, val loss: 0.09683, in 0.681s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11539, val loss: 0.11303, in 0.493s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14619, val loss: 0.14449, in 0.506s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10162, val loss: 0.10131, in 0.496s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09203, val loss: 0.09137, in 0.509s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10884, val loss: 0.10656, in 0.501s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13774, val loss: 0.13598, in 0.459s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09574, val loss: 0.09543, in 0.506s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08703, val loss: 0.08637, in 0.486s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10295, val loss: 0.10080, in 0.451s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12976, val loss: 0.12797, in 0.463s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09088, val loss: 0.09059, in 0.448s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08281, val loss: 0.08212, in 0.461s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.09806, val loss: 0.09597, in 0.479s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12254, val loss: 0.12076, in 0.475s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08607, val loss: 0.08583, in 0.487s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07860, val loss: 0.07790, in 0.483s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09239, val loss: 0.09046, in 0.455s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11540, val loss: 0.11364, in 0.441s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08202, val loss: 0.08182, in 0.444s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07468, val loss: 0.07395, in 0.453s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10914, val loss: 0.10743, in 0.593s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08749, val loss: 0.08559, in 0.605s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07803, val loss: 0.07788, in 0.613s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07121, val loss: 0.07048, in 0.648s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08275, val loss: 0.08084, in 0.538s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10257, val loss: 0.10096, in 0.560s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.07434, val loss: 0.07421, in 0.520s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06772, val loss: 0.06696, in 0.510s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09759, val loss: 0.09598, in 0.457s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07866, val loss: 0.07686, in 0.480s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07028, val loss: 0.07014, in 0.512s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06460, val loss: 0.06391, in 0.514s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07481, val loss: 0.07298, in 0.728s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09219, val loss: 0.09060, in 0.821s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06145, val loss: 0.06079, in 0.801s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06690, val loss: 0.06674, in 1.005s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00137, val loss: 0.00161, in 0.350s\n",
      "Fit 200 trees in 78.001 s, (6200 total leaves)\n",
      "Time spent computing histograms: 46.125s\n",
      "Time spent finding best splits:  1.338s\n",
      "Time spent applying splits:      9.608s\n",
      "Time spent predicting:           0.626s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.06408, val loss: 0.06395, in 0.783s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07138, val loss: 0.06961, in 1.169s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08712, val loss: 0.08560, in 1.092s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05886, val loss: 0.05823, in 0.874s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06790, val loss: 0.06617, in 0.552s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08261, val loss: 0.08113, in 0.557s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06112, val loss: 0.06097, in 0.563s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05614, val loss: 0.05561, in 0.563s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07889, val loss: 0.07745, in 0.545s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05402, val loss: 0.05348, in 0.545s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06471, val loss: 0.06314, in 0.582s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05815, val loss: 0.05802, in 0.610s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07538, val loss: 0.07394, in 0.623s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05551, val loss: 0.05546, in 0.669s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06199, val loss: 0.06049, in 0.722s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05167, val loss: 0.05118, in 0.772s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04993, val loss: 0.04940, in 0.402s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07162, val loss: 0.07024, in 0.585s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00153, in 0.589s\n",
      "Fit 200 trees in 78.509 s, (6200 total leaves)\n",
      "Time spent computing histograms: 45.915s\n",
      "Time spent finding best splits:  1.370s\n",
      "Time spent applying splits:      9.846s\n",
      "Time spent predicting:           0.551s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.05343, val loss: 0.05347, in 0.496s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05932, val loss: 0.05783, in 0.602s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04796, val loss: 0.04744, in 0.531s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00120, val loss: 0.00166, in 0.660s\n",
      "Fit 200 trees in 78.497 s, (6199 total leaves)\n",
      "Time spent computing histograms: 46.051s\n",
      "Time spent finding best splits:  1.231s\n",
      "Time spent applying splits:      9.815s\n",
      "Time spent predicting:           0.627s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 8, train loss: 0.06806, val loss: 0.06675, in 0.557s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00169, in 0.568s\n",
      "Fit 200 trees in 78.434 s, (6198 total leaves)\n",
      "Time spent computing histograms: 45.936s\n",
      "Time spent finding best splits:  1.375s\n",
      "Time spent applying splits:      9.692s\n",
      "Time spent predicting:           0.556s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 9, train loss: 0.05078, val loss: 0.05083, in 0.641s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05664, val loss: 0.05514, in 0.592s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04625, val loss: 0.04584, in 0.582s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06530, val loss: 0.06403, in 0.568s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04872, val loss: 0.04875, in 0.584s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05426, val loss: 0.05278, in 0.590s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04427, val loss: 0.04390, in 0.451s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06228, val loss: 0.06098, in 0.458s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04631, val loss: 0.04639, in 0.431s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05216, val loss: 0.05071, in 0.410s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04218, val loss: 0.04186, in 0.409s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05947, val loss: 0.05824, in 0.462s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04458, val loss: 0.04467, in 0.431s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05013, val loss: 0.04868, in 0.452s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04068, val loss: 0.04039, in 0.437s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05684, val loss: 0.05567, in 0.417s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04281, in 0.394s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04813, val loss: 0.04672, in 0.412s\n",
      "[41/200] 5.099 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.03925, val loss: 0.03900, in 0.393s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04124, in 0.382s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05458, val loss: 0.05346, in 0.424s\n",
      "[38/200] 0.206 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04648, val loss: 0.04507, in 0.430s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03779, val loss: 0.03759, in 0.333s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03959, val loss: 0.03980, in 0.363s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61059, val loss: 0.61043, in 0.372s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05223, val loss: 0.05119, in 0.434s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04457, val loss: 0.04317, in 0.433s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03653, val loss: 0.03637, in 0.445s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03872, in 0.428s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54289, val loss: 0.54252, in 0.485s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05032, val loss: 0.04934, in 0.552s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04242, val loss: 0.04109, in 0.471s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03472, val loss: 0.03458, in 0.403s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03677, val loss: 0.03712, in 0.447s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48608, val loss: 0.48554, in 0.370s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04830, val loss: 0.04737, in 0.410s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04093, val loss: 0.03963, in 0.403s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03355, val loss: 0.03341, in 0.387s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43761, val loss: 0.43691, in 0.346s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03573, in 0.400s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04640, val loss: 0.04547, in 0.380s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03235, val loss: 0.03220, in 0.336s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03912, val loss: 0.03789, in 0.380s\n",
      "[46/200] 4.272 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.39609, val loss: 0.39530, in 0.337s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03428, val loss: 0.03466, in 0.328s\n",
      "[49/200] 4.249 s\n",
      "Binning 0.012 GB of validation data: 4.921 s\n",
      "Binning 0.012 GB of validation data: 0.139 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04453, val loss: 0.04367, in 0.360s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03122, val loss: 0.03111, in 0.367s\n",
      "[52/200] 0.146 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03723, val loss: 0.03607, in 0.361s\n",
      "[47/200] 0.146 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36029, val loss: 0.35938, in 0.365s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03330, in 0.359s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04280, val loss: 0.04199, in 0.350s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61037, val loss: 0.61013, in 0.362s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61053, val loss: 0.61039, in 0.378s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03581, val loss: 0.03469, in 0.390s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02992, val loss: 0.02982, in 0.444s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61043, val loss: 0.61026, in 0.386s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32882, val loss: 0.32778, in 0.347s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03178, val loss: 0.03215, in 0.387s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54248, val loss: 0.54205, in 0.374s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04126, val loss: 0.04050, in 0.405s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02909, val loss: 0.02900, in 0.322s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54263, val loss: 0.54237, in 0.371s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03451, val loss: 0.03345, in 0.402s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54257, val loss: 0.54208, in 0.364s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30129, val loss: 0.30020, in 0.354s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02972, val loss: 0.03008, in 0.401s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48586, val loss: 0.48521, in 0.346s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02809, val loss: 0.02805, in 0.324s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03951, val loss: 0.03879, in 0.363s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48606, val loss: 0.48569, in 0.350s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48586, val loss: 0.48516, in 0.347s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03335, val loss: 0.03235, in 0.376s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27703, val loss: 0.27593, in 0.342s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02816, val loss: 0.02854, in 0.396s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43738, val loss: 0.43654, in 0.352s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03805, val loss: 0.03735, in 0.342s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43743, val loss: 0.43696, in 0.340s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02702, val loss: 0.02696, in 0.370s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43728, val loss: 0.43635, in 0.342s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25595, val loss: 0.25481, in 0.338s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03203, val loss: 0.03104, in 0.387s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39603, val loss: 0.39499, in 0.396s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02696, val loss: 0.02738, in 0.461s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03675, val loss: 0.03606, in 0.463s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39592, val loss: 0.39535, in 0.555s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02541, val loss: 0.02538, in 0.805s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39601, val loss: 0.39486, in 0.735s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03093, val loss: 0.02999, in 0.735s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23653, val loss: 0.23528, in 0.812s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02604, val loss: 0.02646, in 1.091s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35998, val loss: 0.35880, in 1.104s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03558, val loss: 0.03489, in 1.074s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36002, val loss: 0.35936, in 0.999s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.36022, val loss: 0.35890, in 0.770s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02463, val loss: 0.02464, in 0.938s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21957, val loss: 0.21822, in 0.935s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02993, val loss: 0.02902, in 0.986s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.32877, val loss: 0.32747, in 0.551s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32905, val loss: 0.32826, in 0.509s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02472, val loss: 0.02510, in 0.625s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32909, val loss: 0.32756, in 0.513s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03401, val loss: 0.03334, in 0.587s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02916, val loss: 0.02828, in 0.353s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02324, val loss: 0.02326, in 0.499s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.20403, val loss: 0.20269, in 0.418s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.30130, val loss: 0.29993, in 0.444s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30170, val loss: 0.30079, in 0.424s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03305, val loss: 0.03239, in 0.394s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02375, val loss: 0.02416, in 0.435s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30144, val loss: 0.29980, in 0.421s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02234, val loss: 0.02234, in 0.364s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.19049, val loss: 0.18913, in 0.420s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02758, val loss: 0.02674, in 0.478s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27719, val loss: 0.27580, in 0.387s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02357, in 0.369s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27676, val loss: 0.27575, in 0.403s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03186, val loss: 0.03127, in 0.406s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27690, val loss: 0.27522, in 0.403s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02154, val loss: 0.02154, in 0.424s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17809, val loss: 0.17674, in 0.411s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02648, val loss: 0.02566, in 0.415s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25605, val loss: 0.25449, in 0.384s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02228, val loss: 0.02274, in 0.396s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.25492, val loss: 0.25398, in 0.393s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.25515, val loss: 0.25332, in 0.407s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03080, val loss: 0.03023, in 0.450s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02082, val loss: 0.02078, in 0.376s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16688, val loss: 0.16548, in 0.432s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02499, val loss: 0.02422, in 0.459s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23690, val loss: 0.23522, in 0.397s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23529, val loss: 0.23427, in 0.426s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23588, val loss: 0.23395, in 0.410s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02122, val loss: 0.02167, in 0.486s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02952, val loss: 0.02899, in 0.451s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02026, val loss: 0.02025, in 0.418s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15658, val loss: 0.15500, in 0.477s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02435, val loss: 0.02360, in 0.448s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21915, val loss: 0.21737, in 0.495s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21818, val loss: 0.21705, in 0.461s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21876, val loss: 0.21669, in 0.512s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02053, val loss: 0.02100, in 0.498s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02829, val loss: 0.02776, in 0.483s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02347, val loss: 0.02275, in 0.447s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01955, val loss: 0.01958, in 0.649s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14732, val loss: 0.14563, in 0.489s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20405, val loss: 0.20217, in 0.526s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20259, val loss: 0.20145, in 0.535s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20396, val loss: 0.20181, in 0.465s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02030, in 0.473s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02680, val loss: 0.02627, in 0.557s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01886, val loss: 0.01892, in 0.404s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02267, val loss: 0.02199, in 0.448s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13884, val loss: 0.13698, in 0.431s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18968, val loss: 0.18778, in 0.395s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18937, val loss: 0.18810, in 0.362s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01970, in 0.352s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18990, val loss: 0.18775, in 0.391s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01827, val loss: 0.01833, in 0.285s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02559, val loss: 0.02509, in 0.388s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02163, val loss: 0.02098, in 0.366s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13061, val loss: 0.12867, in 0.359s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.17729, val loss: 0.17526, in 0.337s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01857, val loss: 0.01905, in 0.341s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17703, val loss: 0.17572, in 0.351s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17755, val loss: 0.17549, in 0.347s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01748, in 0.375s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02461, val loss: 0.02416, in 0.311s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02109, val loss: 0.02045, in 0.327s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12335, val loss: 0.12127, in 0.333s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16617, val loss: 0.16423, in 0.346s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01819, val loss: 0.01869, in 0.314s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16556, val loss: 0.16422, in 0.351s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16572, val loss: 0.16364, in 0.387s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02392, val loss: 0.02348, in 0.330s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01689, val loss: 0.01699, in 0.355s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01967, in 0.333s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11620, val loss: 0.11415, in 0.384s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01746, val loss: 0.01796, in 0.316s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15558, val loss: 0.15359, in 0.372s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15546, val loss: 0.15412, in 0.343s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15538, val loss: 0.15325, in 0.326s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02327, val loss: 0.02286, in 0.313s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01965, val loss: 0.01905, in 0.358s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01636, val loss: 0.01646, in 0.382s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10964, val loss: 0.10751, in 0.388s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01691, val loss: 0.01742, in 0.348s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.14626, val loss: 0.14416, in 0.360s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14623, val loss: 0.14492, in 0.368s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02279, val loss: 0.02239, in 0.329s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14614, val loss: 0.14390, in 0.361s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01609, in 0.295s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01862, in 0.318s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01623, val loss: 0.01673, in 0.346s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10347, val loss: 0.10141, in 0.375s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13797, val loss: 0.13589, in 0.343s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13789, val loss: 0.13655, in 0.339s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13820, val loss: 0.13597, in 0.340s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02168, val loss: 0.02134, in 0.367s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01560, in 0.370s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01838, val loss: 0.01783, in 0.376s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01586, val loss: 0.01635, in 0.298s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09794, val loss: 0.09593, in 0.348s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12955, val loss: 0.12748, in 0.349s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13001, val loss: 0.12862, in 0.329s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13056, val loss: 0.12826, in 0.340s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01508, val loss: 0.01522, in 0.266s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02090, val loss: 0.02059, in 0.373s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01789, val loss: 0.01735, in 0.328s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01529, val loss: 0.01576, in 0.292s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12257, val loss: 0.12049, in 0.336s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09254, val loss: 0.09061, in 0.366s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12222, val loss: 0.12093, in 0.352s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02018, val loss: 0.01987, in 0.303s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01465, val loss: 0.01480, in 0.355s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12275, val loss: 0.12041, in 0.361s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01748, val loss: 0.01692, in 0.295s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01472, val loss: 0.01518, in 0.338s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11546, val loss: 0.11349, in 0.353s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08767, val loss: 0.08585, in 0.353s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11481, val loss: 0.11356, in 0.362s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01961, val loss: 0.01933, in 0.330s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01423, in 0.339s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11607, val loss: 0.11373, in 0.348s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01673, val loss: 0.01621, in 0.377s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01426, val loss: 0.01472, in 0.340s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10916, val loss: 0.10724, in 0.359s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08328, val loss: 0.08155, in 0.364s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10833, val loss: 0.10718, in 0.350s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01367, val loss: 0.01384, in 0.316s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01895, val loss: 0.01870, in 0.357s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10970, val loss: 0.10739, in 0.359s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01635, val loss: 0.01583, in 0.326s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01377, val loss: 0.01424, in 0.320s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10305, val loss: 0.10116, in 0.362s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01354, in 0.322s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07898, val loss: 0.07725, in 0.368s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01837, val loss: 0.01815, in 0.308s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10258, val loss: 0.10145, in 0.355s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01531, in 0.300s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10380, val loss: 0.10148, in 0.334s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01372, in 0.348s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01320, in 0.275s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09785, val loss: 0.09596, in 0.347s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01760, val loss: 0.01741, in 0.347s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01544, val loss: 0.01493, in 0.319s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07498, val loss: 0.07339, in 0.373s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09681, val loss: 0.09578, in 0.357s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09841, val loss: 0.09620, in 0.348s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01342, in 0.288s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01272, in 0.346s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01507, val loss: 0.01458, in 0.310s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01717, val loss: 0.01698, in 0.340s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09236, val loss: 0.09049, in 0.374s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09177, val loss: 0.09081, in 0.354s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07129, val loss: 0.06969, in 0.378s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09294, val loss: 0.09080, in 0.366s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01252, val loss: 0.01296, in 0.391s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01462, val loss: 0.01413, in 0.269s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01215, val loss: 0.01237, in 0.371s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01663, val loss: 0.01645, in 0.303s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08743, val loss: 0.08564, in 0.340s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08723, val loss: 0.08632, in 0.351s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06807, val loss: 0.06649, in 0.334s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01264, in 0.293s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08820, val loss: 0.08621, in 0.331s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01428, val loss: 0.01381, in 0.294s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01597, val loss: 0.01582, in 0.323s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01182, val loss: 0.01205, in 0.365s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01223, in 0.265s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08311, val loss: 0.08142, in 0.354s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08271, val loss: 0.08187, in 0.359s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06514, val loss: 0.06364, in 0.355s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08341, val loss: 0.08143, in 0.357s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01383, val loss: 0.01340, in 0.342s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01175, in 0.275s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01148, val loss: 0.01189, in 0.288s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01532, in 0.372s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07894, val loss: 0.07733, in 0.343s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07822, val loss: 0.07752, in 0.359s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06219, val loss: 0.06071, in 0.363s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07913, val loss: 0.07732, in 0.359s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01341, val loss: 0.01300, in 0.310s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01127, val loss: 0.01168, in 0.276s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01118, val loss: 0.01142, in 0.342s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01497, val loss: 0.01484, in 0.387s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07501, val loss: 0.07352, in 0.359s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05981, val loss: 0.05842, in 0.340s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07430, val loss: 0.07367, in 0.365s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07512, val loss: 0.07331, in 0.351s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01298, val loss: 0.01260, in 0.339s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01094, val loss: 0.01115, in 0.282s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01092, val loss: 0.01132, in 0.349s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01440, val loss: 0.01429, in 0.335s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07133, val loss: 0.06990, in 0.360s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07057, val loss: 0.06999, in 0.346s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05709, val loss: 0.05574, in 0.371s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01076, val loss: 0.01098, in 0.280s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07173, val loss: 0.07002, in 0.359s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01259, val loss: 0.01222, in 0.353s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01097, in 0.363s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01403, val loss: 0.01392, in 0.264s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06848, val loss: 0.06709, in 0.358s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05459, val loss: 0.05339, in 0.354s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06865, val loss: 0.06698, in 0.346s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01228, val loss: 0.01190, in 0.297s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06716, val loss: 0.06659, in 0.370s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01050, val loss: 0.01074, in 0.377s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01072, in 0.314s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01365, val loss: 0.01358, in 0.330s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06514, val loss: 0.06375, in 0.352s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01022, val loss: 0.01044, in 0.295s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01161, in 0.323s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01004, val loss: 0.01041, in 0.275s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06405, val loss: 0.06355, in 0.353s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05240, val loss: 0.05117, in 0.364s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.06529, val loss: 0.06366, in 0.361s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01319, val loss: 0.01314, in 0.325s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.01020, in 0.293s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06234, val loss: 0.06096, in 0.350s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01160, val loss: 0.01125, in 0.349s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00997, val loss: 0.01020, in 0.366s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06246, val loss: 0.06082, in 0.348s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04989, val loss: 0.04873, in 0.351s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06117, val loss: 0.06069, in 0.358s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01279, in 0.340s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.01000, in 0.286s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00972, val loss: 0.00994, in 0.320s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05953, val loss: 0.05819, in 0.371s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.06006, val loss: 0.05857, in 0.345s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04806, val loss: 0.04694, in 0.346s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01124, val loss: 0.01090, in 0.394s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05848, val loss: 0.05800, in 0.356s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01248, in 0.286s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.00985, in 0.263s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00950, val loss: 0.00973, in 0.318s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01223, val loss: 0.01219, in 0.304s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05674, val loss: 0.05557, in 0.360s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04652, val loss: 0.04540, in 0.358s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05756, val loss: 0.05619, in 0.365s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05609, val loss: 0.05563, in 0.365s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01090, val loss: 0.01057, in 0.385s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00963, in 0.321s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.00955, in 0.311s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05457, val loss: 0.05346, in 0.346s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04496, val loss: 0.04387, in 0.333s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01185, val loss: 0.01183, in 0.377s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01026, in 0.320s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05376, val loss: 0.05330, in 0.343s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05498, val loss: 0.05370, in 0.369s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00938, in 0.322s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00904, val loss: 0.00927, in 0.393s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01157, val loss: 0.01156, in 0.281s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05258, val loss: 0.05153, in 0.343s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04355, val loss: 0.04248, in 0.340s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01038, val loss: 0.01007, in 0.317s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05277, val loss: 0.05160, in 0.346s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05141, val loss: 0.05096, in 0.359s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00875, val loss: 0.00912, in 0.370s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00909, in 0.306s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01129, val loss: 0.01129, in 0.313s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01011, val loss: 0.00981, in 0.278s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04195, val loss: 0.04089, in 0.329s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05030, val loss: 0.04932, in 0.362s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00891, in 0.268s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04954, val loss: 0.04918, in 0.347s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05043, val loss: 0.04925, in 0.351s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00870, val loss: 0.00893, in 0.298s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01102, val loss: 0.01103, in 0.298s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00993, val loss: 0.00962, in 0.314s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04034, val loss: 0.03935, in 0.351s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00874, in 0.311s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04848, val loss: 0.04753, in 0.372s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04756, val loss: 0.04719, in 0.351s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04835, val loss: 0.04724, in 0.352s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01086, val loss: 0.01086, in 0.296s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00879, in 0.318s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00966, val loss: 0.00936, in 0.379s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03854, val loss: 0.03759, in 0.309s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00857, in 0.335s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04676, val loss: 0.04582, in 0.369s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04584, val loss: 0.04547, in 0.352s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04640, val loss: 0.04529, in 0.370s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00840, val loss: 0.00864, in 0.278s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01054, val loss: 0.01057, in 0.356s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00920, in 0.288s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00833, in 0.276s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03713, val loss: 0.03620, in 0.343s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04509, val loss: 0.04420, in 0.350s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04393, val loss: 0.04352, in 0.352s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04476, val loss: 0.04367, in 0.348s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00815, val loss: 0.00839, in 0.395s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01025, val loss: 0.01028, in 0.374s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00892, in 0.352s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00774, val loss: 0.00807, in 0.329s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03578, val loss: 0.03486, in 0.317s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04288, val loss: 0.04206, in 0.291s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04229, val loss: 0.04190, in 0.344s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04267, val loss: 0.04162, in 0.365s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00830, in 0.313s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01004, val loss: 0.01007, in 0.289s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00871, in 0.293s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03444, val loss: 0.03354, in 0.322s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00754, val loss: 0.00787, in 0.337s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04152, val loss: 0.04073, in 0.340s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04014, val loss: 0.03982, in 0.326s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00803, in 0.311s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04005, in 0.345s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00976, val loss: 0.00982, in 0.321s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00878, val loss: 0.00851, in 0.302s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00733, val loss: 0.00765, in 0.317s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03285, val loss: 0.03201, in 0.346s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04004, val loss: 0.03926, in 0.340s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03843, val loss: 0.03813, in 0.376s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00956, val loss: 0.00963, in 0.310s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00767, val loss: 0.00791, in 0.359s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03958, val loss: 0.03859, in 0.372s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00857, val loss: 0.00830, in 0.383s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00748, in 0.369s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03175, val loss: 0.03097, in 0.353s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03822, val loss: 0.03748, in 0.318s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03671, val loss: 0.03645, in 0.339s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03760, val loss: 0.03668, in 0.299s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00773, in 0.335s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00846, val loss: 0.00818, in 0.268s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00931, val loss: 0.00938, in 0.363s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03016, val loss: 0.02943, in 0.331s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00732, in 0.341s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03693, val loss: 0.03621, in 0.300s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00916, val loss: 0.00925, in 0.260s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00754, in 0.301s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00794, in 0.324s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03541, val loss: 0.03519, in 0.357s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03613, val loss: 0.03526, in 0.346s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00684, val loss: 0.00718, in 0.302s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.02815, in 0.314s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03527, val loss: 0.03459, in 0.327s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00894, val loss: 0.00902, in 0.365s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00736, in 0.355s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00798, val loss: 0.00774, in 0.334s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03437, val loss: 0.03417, in 0.335s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03446, val loss: 0.03368, in 0.336s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00670, val loss: 0.00703, in 0.309s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02703, in 0.301s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03388, val loss: 0.03322, in 0.323s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00887, in 0.313s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03331, val loss: 0.03312, in 0.293s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00781, val loss: 0.00758, in 0.323s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03278, val loss: 0.03204, in 0.321s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00722, in 0.347s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00660, val loss: 0.00695, in 0.295s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02659, val loss: 0.02599, in 0.340s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03287, val loss: 0.03225, in 0.287s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00762, val loss: 0.00741, in 0.285s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00866, in 0.330s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03207, val loss: 0.03192, in 0.320s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03173, val loss: 0.03102, in 0.342s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00680, val loss: 0.00707, in 0.347s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03202, val loss: 0.03141, in 0.307s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02546, val loss: 0.02491, in 0.325s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00641, val loss: 0.00675, in 0.382s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00727, in 0.270s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03111, val loss: 0.03102, in 0.307s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00663, val loss: 0.00690, in 0.281s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00837, val loss: 0.00847, in 0.357s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03049, val loss: 0.02983, in 0.368s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00659, in 0.323s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03069, val loss: 0.03012, in 0.350s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02445, val loss: 0.02392, in 0.369s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00676, in 0.294s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00729, val loss: 0.00710, in 0.386s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00817, val loss: 0.00826, in 0.284s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02983, val loss: 0.02978, in 0.338s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02887, val loss: 0.02829, in 0.339s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02965, val loss: 0.02914, in 0.309s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02393, val loss: 0.02342, in 0.286s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00644, in 0.337s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00808, in 0.330s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02857, val loss: 0.02856, in 0.338s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00634, val loss: 0.00662, in 0.347s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00691, in 0.349s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02886, val loss: 0.02840, in 0.287s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02747, val loss: 0.02692, in 0.322s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02263, in 0.321s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00596, val loss: 0.00628, in 0.345s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00680, in 0.257s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02767, val loss: 0.02763, in 0.266s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00790, in 0.352s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00621, val loss: 0.00649, in 0.350s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02653, val loss: 0.02600, in 0.319s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02792, val loss: 0.02751, in 0.326s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02189, val loss: 0.02147, in 0.360s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00612, in 0.370s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00666, in 0.302s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02667, val loss: 0.02664, in 0.347s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00639, in 0.283s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00770, in 0.354s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02726, val loss: 0.02688, in 0.343s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02549, val loss: 0.02502, in 0.353s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02120, val loss: 0.02077, in 0.338s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00569, val loss: 0.00604, in 0.359s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00652, in 0.336s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02583, val loss: 0.02577, in 0.318s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00626, in 0.381s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00743, val loss: 0.00755, in 0.345s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02647, val loss: 0.02614, in 0.294s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02487, val loss: 0.02442, in 0.298s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02061, val loss: 0.02019, in 0.320s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00557, val loss: 0.00591, in 0.343s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02483, val loss: 0.02481, in 0.339s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00654, val loss: 0.00635, in 0.392s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00588, val loss: 0.00616, in 0.282s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02536, val loss: 0.02502, in 0.316s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00738, in 0.356s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.02394, val loss: 0.02351, in 0.391s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01975, val loss: 0.01937, in 0.345s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00624, in 0.322s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00599, in 0.319s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00542, val loss: 0.00577, in 0.384s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02390, val loss: 0.02392, in 0.370s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00715, val loss: 0.00727, in 0.277s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02436, val loss: 0.02401, in 0.382s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02319, val loss: 0.02276, in 0.300s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01914, val loss: 0.01876, in 0.292s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00559, val loss: 0.00586, in 0.295s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02329, val loss: 0.02336, in 0.304s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00611, in 0.331s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00562, in 0.376s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00710, in 0.334s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02239, val loss: 0.02197, in 0.351s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02352, val loss: 0.02315, in 0.367s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01850, val loss: 0.01814, in 0.353s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02246, val loss: 0.02251, in 0.300s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00607, val loss: 0.00593, in 0.328s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00548, val loss: 0.00576, in 0.370s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00681, val loss: 0.00694, in 0.358s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00515, val loss: 0.00548, in 0.376s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02268, val loss: 0.02231, in 0.306s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02160, val loss: 0.02120, in 0.334s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01794, val loss: 0.01758, in 0.323s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02158, val loss: 0.02159, in 0.282s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00565, in 0.329s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00593, val loss: 0.00581, in 0.383s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00508, val loss: 0.00542, in 0.322s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00667, val loss: 0.00680, in 0.357s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02088, val loss: 0.02050, in 0.295s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02171, val loss: 0.02137, in 0.339s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01755, val loss: 0.01720, in 0.303s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02082, val loss: 0.02082, in 0.374s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00554, in 0.349s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00531, in 0.341s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02031, val loss: 0.01993, in 0.324s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00567, in 0.417s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00667, in 0.389s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01701, val loss: 0.01670, in 0.362s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02090, val loss: 0.02059, in 0.374s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02033, val loss: 0.02039, in 0.327s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00519, val loss: 0.00546, in 0.350s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01947, val loss: 0.01913, in 0.339s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00521, in 0.380s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00563, val loss: 0.00552, in 0.350s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01658, val loss: 0.01625, in 0.297s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00656, in 0.349s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02029, val loss: 0.01999, in 0.344s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01945, val loss: 0.01953, in 0.333s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00539, in 0.259s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00548, val loss: 0.00539, in 0.314s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00510, in 0.320s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01599, in 0.331s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01881, val loss: 0.01850, in 0.391s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01941, val loss: 0.01914, in 0.349s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00507, val loss: 0.00533, in 0.287s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01877, val loss: 0.01884, in 0.303s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00640, in 0.402s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00529, in 0.340s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01820, val loss: 0.01791, in 0.297s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01571, val loss: 0.01540, in 0.337s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00501, in 0.353s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01883, val loss: 0.01855, in 0.294s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00521, in 0.304s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01822, val loss: 0.01829, in 0.303s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00628, in 0.325s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01777, val loss: 0.01750, in 0.310s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01532, val loss: 0.01499, in 0.317s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00458, val loss: 0.00491, in 0.364s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00521, val loss: 0.00513, in 0.382s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00486, val loss: 0.00513, in 0.336s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01823, val loss: 0.01798, in 0.377s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01757, val loss: 0.01767, in 0.386s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00615, in 0.374s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01718, val loss: 0.01694, in 0.319s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00505, in 0.300s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00451, val loss: 0.00484, in 0.306s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01481, val loss: 0.01451, in 0.396s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01752, val loss: 0.01730, in 0.342s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00501, in 0.364s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01705, val loss: 0.01714, in 0.330s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00584, val loss: 0.00602, in 0.391s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00481, in 0.256s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01660, val loss: 0.01638, in 0.305s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00499, val loss: 0.00492, in 0.375s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01423, val loss: 0.01395, in 0.343s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01657, val loss: 0.01666, in 0.286s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01696, val loss: 0.01674, in 0.337s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00465, val loss: 0.00491, in 0.354s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00574, val loss: 0.00593, in 0.303s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00476, in 0.276s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01605, val loss: 0.01581, in 0.364s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00484, in 0.333s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01653, val loss: 0.01635, in 0.329s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00580, in 0.280s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01600, val loss: 0.01611, in 0.372s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01378, val loss: 0.01352, in 0.396s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00483, in 0.375s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00464, in 0.307s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01566, val loss: 0.01544, in 0.270s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01603, val loss: 0.01585, in 0.301s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00474, in 0.358s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01348, val loss: 0.01324, in 0.291s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01560, val loss: 0.01574, in 0.310s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00573, in 0.321s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00474, in 0.344s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00453, in 0.344s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01520, val loss: 0.01501, in 0.366s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00472, val loss: 0.00467, in 0.276s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01545, val loss: 0.01530, in 0.326s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01291, in 0.312s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00543, val loss: 0.00562, in 0.316s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01520, in 0.332s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00437, val loss: 0.00463, in 0.367s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00442, in 0.385s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01477, val loss: 0.01461, in 0.320s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00456, in 0.332s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01469, val loss: 0.01482, in 0.313s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01498, val loss: 0.01481, in 0.377s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01272, val loss: 0.01248, in 0.368s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00550, in 0.347s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00457, in 0.291s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00436, in 0.297s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01427, val loss: 0.01410, in 0.371s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00444, in 0.323s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01436, val loss: 0.01450, in 0.298s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01457, val loss: 0.01439, in 0.311s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01243, val loss: 0.01220, in 0.354s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00521, val loss: 0.00540, in 0.418s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00429, in 0.317s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00421, val loss: 0.00448, in 0.395s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01391, val loss: 0.01377, in 0.296s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01424, val loss: 0.01407, in 0.278s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00435, in 0.377s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01395, val loss: 0.01410, in 0.375s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01211, val loss: 0.01190, in 0.364s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00511, val loss: 0.00531, in 0.327s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00411, val loss: 0.00438, in 0.281s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00421, in 0.371s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01364, val loss: 0.01350, in 0.338s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01392, val loss: 0.01373, in 0.292s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00431, in 0.273s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01360, val loss: 0.01378, in 0.372s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01151, in 0.421s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00500, val loss: 0.00521, in 0.410s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00430, in 0.457s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00417, in 0.411s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01325, val loss: 0.01313, in 0.409s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01355, val loss: 0.01338, in 0.452s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00422, in 0.474s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01345, val loss: 0.01365, in 0.405s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00489, val loss: 0.00510, in 0.391s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01299, val loss: 0.01289, in 0.330s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01138, val loss: 0.01121, in 0.453s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00394, val loss: 0.00421, in 0.394s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01327, val loss: 0.01312, in 0.290s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00408, in 0.425s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00415, val loss: 0.00413, in 0.356s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01315, val loss: 0.01337, in 0.326s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00476, val loss: 0.00497, in 0.335s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01266, val loss: 0.01260, in 0.355s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01093, in 0.368s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00386, val loss: 0.00414, in 0.400s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00401, in 0.371s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01286, val loss: 0.01273, in 0.414s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01286, val loss: 0.01306, in 0.297s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00405, val loss: 0.00404, in 0.348s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00491, in 0.366s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01093, val loss: 0.01077, in 0.305s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01234, val loss: 0.01228, in 0.368s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00380, val loss: 0.00408, in 0.321s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01258, val loss: 0.01245, in 0.309s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00394, in 0.352s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01261, val loss: 0.01283, in 0.324s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00395, val loss: 0.00395, in 0.341s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00485, in 0.307s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01064, val loss: 0.01048, in 0.324s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01206, val loss: 0.01202, in 0.331s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01243, val loss: 0.01265, in 0.290s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01224, val loss: 0.01212, in 0.339s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00401, in 0.363s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00387, in 0.334s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00388, in 0.323s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01054, val loss: 0.01039, in 0.269s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00455, val loss: 0.00478, in 0.344s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01216, val loss: 0.01239, in 0.309s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01170, val loss: 0.01166, in 0.381s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00396, in 0.385s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01192, val loss: 0.01182, in 0.388s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00381, val loss: 0.00381, in 0.358s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00346, val loss: 0.00380, in 0.414s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01026, val loss: 0.01013, in 0.319s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00470, in 0.350s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01176, val loss: 0.01167, in 0.276s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01133, val loss: 0.01130, in 0.355s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01181, val loss: 0.01204, in 0.397s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00389, in 0.317s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00372, val loss: 0.00372, in 0.327s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00373, in 0.319s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00460, in 0.301s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00995, val loss: 0.00983, in 0.410s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01112, val loss: 0.01110, in 0.302s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01154, val loss: 0.01177, in 0.331s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01143, val loss: 0.01135, in 0.373s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00354, val loss: 0.00381, in 0.354s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00366, val loss: 0.00366, in 0.348s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00368, in 0.346s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00430, val loss: 0.00453, in 0.323s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00964, val loss: 0.00953, in 0.376s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01121, val loss: 0.01113, in 0.325s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01080, val loss: 0.01080, in 0.383s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01115, val loss: 0.01138, in 0.350s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00376, in 0.352s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00358, in 0.347s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00360, in 0.383s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00448, in 0.290s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00954, val loss: 0.00942, in 0.298s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01110, val loss: 0.01102, in 0.288s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01058, in 0.323s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01107, in 0.356s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00368, in 0.354s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00350, in 0.331s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00440, in 0.369s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00348, val loss: 0.00350, in 0.425s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00927, val loss: 0.00917, in 0.422s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01029, val loss: 0.01031, in 0.346s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01071, val loss: 0.01064, in 0.393s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01053, val loss: 0.01077, in 0.376s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00362, in 0.376s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00342, in 0.350s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00344, in 0.310s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00430, in 0.369s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01007, val loss: 0.01009, in 0.341s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00901, val loss: 0.00891, in 0.380s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01039, val loss: 0.01034, in 0.338s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01057, in 0.323s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00332, val loss: 0.00357, in 0.300s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00339, in 0.330s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00335, in 0.351s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00421, in 0.299s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00880, val loss: 0.00870, in 0.451s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01014, val loss: 0.01010, in 0.467s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01016, val loss: 0.01041, in 0.424s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00978, val loss: 0.00982, in 0.504s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00328, val loss: 0.00354, in 0.457s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00329, in 0.466s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00332, in 0.505s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00385, val loss: 0.00410, in 0.526s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00993, val loss: 0.00989, in 0.369s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00346, in 0.369s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00957, val loss: 0.00962, in 0.391s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00847, in 0.441s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00991, val loss: 0.01015, in 0.423s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00325, in 0.332s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00328, in 0.336s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00400, in 0.344s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.00951, in 0.275s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00961, val loss: 0.00957, in 0.406s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00321, in 0.330s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00969, val loss: 0.00995, in 0.358s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00315, val loss: 0.00341, in 0.383s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00835, val loss: 0.00828, in 0.381s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00394, in 0.307s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00323, in 0.383s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00930, in 0.368s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00944, val loss: 0.00971, in 0.382s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00935, val loss: 0.00931, in 0.394s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00337, in 0.378s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00315, in 0.410s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00363, val loss: 0.00387, in 0.384s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00811, val loss: 0.00804, in 0.446s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00315, in 0.376s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00910, val loss: 0.00915, in 0.301s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00918, val loss: 0.00947, in 0.328s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00916, val loss: 0.00913, in 0.351s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00330, in 0.367s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00793, in 0.330s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00310, in 0.334s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00308, in 0.393s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00357, val loss: 0.00381, in 0.369s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00886, val loss: 0.00892, in 0.403s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00902, val loss: 0.00930, in 0.349s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00323, in 0.339s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00894, val loss: 0.00892, in 0.370s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00303, in 0.311s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00301, val loss: 0.00306, in 0.339s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00376, in 0.326s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00778, val loss: 0.00773, in 0.392s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00861, val loss: 0.00869, in 0.319s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00879, val loss: 0.00906, in 0.383s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00315, in 0.352s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00301, in 0.355s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00871, val loss: 0.00868, in 0.400s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00300, in 0.398s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00369, in 0.396s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00761, val loss: 0.00756, in 0.368s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00842, val loss: 0.00852, in 0.376s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00860, val loss: 0.00888, in 0.342s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00341, val loss: 0.00366, in 0.313s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00854, val loss: 0.00854, in 0.357s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00296, in 0.375s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00312, in 0.418s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00294, in 0.393s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00745, val loss: 0.00740, in 0.403s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00826, val loss: 0.00836, in 0.342s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00840, val loss: 0.00869, in 0.358s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00308, in 0.301s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00363, in 0.321s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00838, in 0.320s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00290, in 0.331s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00290, in 0.329s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00724, in 0.377s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00820, in 0.337s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00822, val loss: 0.00851, in 0.371s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00357, in 0.354s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00303, in 0.365s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00284, in 0.338s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00279, val loss: 0.00284, in 0.390s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00819, in 0.405s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00709, val loss: 0.00707, in 0.327s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00787, val loss: 0.00798, in 0.394s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00809, val loss: 0.00839, in 0.309s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00351, in 0.334s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00299, in 0.340s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00280, in 0.339s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00796, val loss: 0.00797, in 0.377s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00250, val loss: 0.00280, in 0.406s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00689, val loss: 0.00688, in 0.333s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00770, val loss: 0.00781, in 0.301s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00789, val loss: 0.00819, in 0.355s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00318, val loss: 0.00346, in 0.350s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00277, in 0.308s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00265, val loss: 0.00293, in 0.421s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00673, val loss: 0.00673, in 0.348s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00756, val loss: 0.00768, in 0.296s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00775, val loss: 0.00776, in 0.388s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00276, in 0.395s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00766, val loss: 0.00795, in 0.350s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00272, in 0.371s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00340, in 0.395s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00664, val loss: 0.00664, in 0.297s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00288, in 0.363s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00736, val loss: 0.00750, in 0.399s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00241, val loss: 0.00271, in 0.385s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00753, val loss: 0.00756, in 0.427s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00742, val loss: 0.00772, in 0.360s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00649, val loss: 0.00651, in 0.327s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00266, in 0.374s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00305, val loss: 0.00334, in 0.394s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00283, in 0.408s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00265, in 0.372s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00732, val loss: 0.00737, in 0.362s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00731, in 0.400s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00757, in 0.349s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00641, in 0.336s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00256, val loss: 0.00262, in 0.370s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00329, in 0.360s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00279, in 0.339s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00720, val loss: 0.00726, in 0.302s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00232, val loss: 0.00261, in 0.370s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00694, val loss: 0.00708, in 0.367s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00623, val loss: 0.00626, in 0.304s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00705, val loss: 0.00734, in 0.430s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00325, in 0.343s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00257, in 0.426s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00247, val loss: 0.00275, in 0.393s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00686, val loss: 0.00700, in 0.313s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00257, in 0.367s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00703, val loss: 0.00709, in 0.437s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00612, val loss: 0.00613, in 0.315s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00690, val loss: 0.00719, in 0.410s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00321, in 0.423s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00270, in 0.448s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00671, val loss: 0.00685, in 0.442s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00245, val loss: 0.00251, in 0.529s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00685, val loss: 0.00691, in 0.426s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00252, in 0.445s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00601, val loss: 0.00603, in 0.397s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00671, val loss: 0.00701, in 0.393s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00316, in 0.341s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00265, in 0.355s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00653, val loss: 0.00668, in 0.407s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00248, in 0.389s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00668, val loss: 0.00676, in 0.398s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00588, in 0.392s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00240, val loss: 0.00246, in 0.406s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00311, in 0.386s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00653, val loss: 0.00684, in 0.402s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00262, in 0.368s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00637, val loss: 0.00651, in 0.368s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00663, in 0.335s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00575, val loss: 0.00578, in 0.361s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00244, in 0.394s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00243, in 0.429s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00306, in 0.421s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00639, val loss: 0.00671, in 0.412s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00564, val loss: 0.00567, in 0.315s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00257, in 0.415s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00625, val loss: 0.00640, in 0.349s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00638, val loss: 0.00646, in 0.450s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00231, val loss: 0.00239, in 0.359s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00240, in 0.418s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00629, val loss: 0.00661, in 0.339s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00272, val loss: 0.00301, in 0.348s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00555, val loss: 0.00559, in 0.314s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00252, in 0.313s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00615, val loss: 0.00631, in 0.318s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00235, in 0.322s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00622, val loss: 0.00630, in 0.363s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00235, in 0.372s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00616, val loss: 0.00648, in 0.387s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00546, val loss: 0.00549, in 0.310s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00297, in 0.391s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00247, in 0.355s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00601, val loss: 0.00616, in 0.404s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00620, in 0.315s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00206, val loss: 0.00233, in 0.347s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00232, in 0.378s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00294, in 0.284s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00538, in 0.348s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00601, val loss: 0.00634, in 0.381s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00215, val loss: 0.00243, in 0.340s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00614, in 0.277s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00587, val loss: 0.00602, in 0.352s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00202, val loss: 0.00230, in 0.351s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00228, in 0.346s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00259, val loss: 0.00289, in 0.418s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00598, val loss: 0.00608, in 0.306s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00619, in 0.370s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00527, in 0.404s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00240, in 0.378s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00577, val loss: 0.00592, in 0.337s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00225, in 0.296s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00226, in 0.387s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00284, in 0.365s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00571, val loss: 0.00602, in 0.338s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00517, in 0.344s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00566, val loss: 0.00582, in 0.338s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00237, in 0.377s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00586, val loss: 0.00597, in 0.398s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00215, val loss: 0.00223, in 0.321s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00223, in 0.352s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00560, val loss: 0.00592, in 0.314s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00507, in 0.309s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00560, val loss: 0.00577, in 0.292s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00250, val loss: 0.00280, in 0.358s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00569, val loss: 0.00581, in 0.374s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00233, in 0.382s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00219, in 0.410s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00220, in 0.350s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00247, val loss: 0.00278, in 0.325s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00494, val loss: 0.00498, in 0.373s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00548, val loss: 0.00580, in 0.387s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00549, val loss: 0.00567, in 0.382s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00561, val loss: 0.00574, in 0.311s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00201, val loss: 0.00229, in 0.400s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00215, in 0.351s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00218, in 0.358s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00243, val loss: 0.00274, in 0.386s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00484, in 0.379s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00569, in 0.391s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00538, val loss: 0.00557, in 0.387s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00548, val loss: 0.00562, in 0.414s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00227, in 0.356s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00214, in 0.312s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00211, in 0.385s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00550, in 0.299s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00470, val loss: 0.00475, in 0.363s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00560, in 0.354s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00238, val loss: 0.00269, in 0.395s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00551, in 0.307s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00195, val loss: 0.00224, in 0.318s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00211, in 0.338s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00207, in 0.356s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00520, val loss: 0.00540, in 0.294s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00466, in 0.328s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00540, in 0.342s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00232, val loss: 0.00265, in 0.372s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00514, val loss: 0.00546, in 0.384s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00191, val loss: 0.00221, in 0.327s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00208, in 0.294s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00204, in 0.353s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00510, val loss: 0.00529, in 0.371s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00457, in 0.368s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00219, in 0.344s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00537, in 0.359s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00529, in 0.407s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00206, in 0.390s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00228, val loss: 0.00260, in 0.416s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00200, in 0.366s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00501, val loss: 0.00520, in 0.363s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00443, val loss: 0.00447, in 0.345s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00498, val loss: 0.00531, in 0.305s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00216, in 0.328s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00504, val loss: 0.00521, in 0.323s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00203, in 0.340s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00223, val loss: 0.00256, in 0.362s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00197, in 0.349s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00490, val loss: 0.00510, in 0.315s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00213, in 0.341s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00434, val loss: 0.00439, in 0.393s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00201, in 0.342s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00486, val loss: 0.00517, in 0.405s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00492, val loss: 0.00509, in 0.405s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00195, in 0.308s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00220, val loss: 0.00253, in 0.399s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00500, in 0.354s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00199, in 0.339s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00479, val loss: 0.00512, in 0.341s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00210, in 0.404s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00425, val loss: 0.00430, in 0.429s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00483, val loss: 0.00501, in 0.383s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00249, in 0.350s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00191, in 0.375s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00467, val loss: 0.00487, in 0.341s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00197, in 0.322s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00503, in 0.346s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00177, val loss: 0.00206, in 0.334s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00416, val loss: 0.00422, in 0.319s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00473, val loss: 0.00490, in 0.358s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00246, in 0.356s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00188, in 0.358s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00461, val loss: 0.00482, in 0.302s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00204, in 0.330s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00194, in 0.375s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00460, val loss: 0.00493, in 0.351s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00414, in 0.367s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00462, val loss: 0.00480, in 0.330s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00209, val loss: 0.00243, in 0.378s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00184, in 0.369s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00475, in 0.369s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00201, in 0.358s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00397, val loss: 0.00403, in 0.320s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00191, in 0.380s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00447, val loss: 0.00480, in 0.413s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00470, in 0.343s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00206, val loss: 0.00240, in 0.316s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00444, val loss: 0.00467, in 0.303s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00180, in 0.356s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00196, in 0.332s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00188, in 0.327s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00390, val loss: 0.00397, in 0.389s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00462, in 0.362s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00438, val loss: 0.00471, in 0.380s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00457, in 0.321s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00202, val loss: 0.00237, in 0.386s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00178, in 0.365s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00194, in 0.321s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00159, val loss: 0.00186, in 0.328s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00392, in 0.340s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00427, val loss: 0.00459, in 0.305s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00455, in 0.332s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00177, in 0.268s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00424, val loss: 0.00446, in 0.410s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00234, in 0.380s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00191, in 0.344s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00184, in 0.342s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00418, val loss: 0.00450, in 0.349s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00427, val loss: 0.00448, in 0.361s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00377, val loss: 0.00385, in 0.395s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00417, val loss: 0.00438, in 0.316s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00174, in 0.387s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00197, val loss: 0.00232, in 0.319s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00188, in 0.289s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00155, val loss: 0.00182, in 0.305s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00369, val loss: 0.00377, in 0.303s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00408, val loss: 0.00437, in 0.360s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00441, in 0.340s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00172, in 0.311s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00431, in 0.375s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00194, val loss: 0.00229, in 0.356s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00180, in 0.311s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00157, val loss: 0.00185, in 0.403s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00412, val loss: 0.00435, in 0.319s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00399, val loss: 0.00428, in 0.333s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00371, in 0.356s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00170, in 0.351s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00400, val loss: 0.00422, in 0.326s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00227, in 0.366s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00150, val loss: 0.00178, in 0.307s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00183, in 0.307s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00428, in 0.307s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00392, val loss: 0.00420, in 0.309s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00362, in 0.334s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00168, in 0.358s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00222, in 0.304s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00391, val loss: 0.00413, in 0.357s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00148, val loss: 0.00177, in 0.332s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00153, val loss: 0.00181, in 0.369s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00419, in 0.303s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00385, val loss: 0.00413, in 0.325s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00154, val loss: 0.00164, in 0.302s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00357, in 0.383s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00387, val loss: 0.00409, in 0.296s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00183, val loss: 0.00219, in 0.377s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00174, in 0.376s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00150, val loss: 0.00178, in 0.399s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00391, val loss: 0.00413, in 0.390s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00378, val loss: 0.00406, in 0.366s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00350, in 0.421s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00380, val loss: 0.00403, in 0.432s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00150, val loss: 0.00161, in 0.552s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00216, in 0.521s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00172, in 0.496s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00382, val loss: 0.00404, in 0.448s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[135/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00148, val loss: 0.00176, in 0.486s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00370, val loss: 0.00398, in 0.538s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00333, val loss: 0.00344, in 0.455s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00395, in 0.479s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00158, in 0.503s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00178, val loss: 0.00214, in 0.439s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00170, in 0.418s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00396, in 0.429s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00174, in 0.503s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00363, val loss: 0.00392, in 0.547s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00339, in 0.501s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00391, in 0.455s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00155, in 0.486s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00211, in 0.499s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00167, in 0.526s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00389, in 0.565s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00172, in 0.553s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00385, in 0.410s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00332, in 0.481s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00356, val loss: 0.00383, in 0.514s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00143, val loss: 0.00153, in 0.412s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00208, in 0.401s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00165, in 0.371s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00362, val loss: 0.00383, in 0.352s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00170, in 0.366s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00378, in 0.388s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00377, in 0.340s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00313, val loss: 0.00327, in 0.381s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00205, in 0.338s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00163, in 0.409s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00151, in 0.422s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00355, val loss: 0.00377, in 0.438s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00168, in 0.445s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00370, in 0.516s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00308, val loss: 0.00320, in 0.505s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00343, val loss: 0.00372, in 0.564s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00168, val loss: 0.00204, in 0.627s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00149, in 0.576s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00161, in 0.600s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00350, val loss: 0.00371, in 0.538s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00166, in 0.469s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00338, val loss: 0.00363, in 0.462s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00365, in 0.390s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00315, in 0.455s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00201, in 0.374s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00146, in 0.382s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00159, in 0.446s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00345, val loss: 0.00366, in 0.407s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00164, in 0.435s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00332, val loss: 0.00360, in 0.405s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00310, in 0.415s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00331, val loss: 0.00356, in 0.482s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00144, in 0.366s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00198, in 0.455s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00156, in 0.351s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00337, val loss: 0.00359, in 0.388s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00134, val loss: 0.00162, in 0.414s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00292, val loss: 0.00305, in 0.319s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00350, in 0.321s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00326, val loss: 0.00354, in 0.394s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00142, in 0.363s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00154, in 0.368s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00159, val loss: 0.00195, in 0.397s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00351, in 0.355s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00133, val loss: 0.00160, in 0.374s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00299, in 0.405s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00319, val loss: 0.00344, in 0.412s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00322, val loss: 0.00351, in 0.418s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00140, in 0.409s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00153, in 0.413s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00325, val loss: 0.00346, in 0.446s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00192, in 0.538s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00157, in 0.448s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00282, val loss: 0.00295, in 0.413s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00337, in 0.461s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00316, val loss: 0.00346, in 0.479s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00127, val loss: 0.00138, in 0.425s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00321, val loss: 0.00342, in 0.420s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00123, val loss: 0.00151, in 0.529s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00154, val loss: 0.00190, in 0.451s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00155, in 0.576s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00293, in 0.641s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00342, in 0.530s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00136, in 0.525s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00333, in 0.604s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00149, in 0.540s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00336, in 0.671s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00186, in 0.658s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00153, in 0.493s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00274, val loss: 0.00290, in 0.426s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00336, in 0.452s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00123, val loss: 0.00134, in 0.510s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00300, val loss: 0.00325, in 0.547s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00119, val loss: 0.00147, in 0.526s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00332, in 0.434s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00124, val loss: 0.00151, in 0.584s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00332, in 0.540s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00184, in 0.686s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00133, in 0.637s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00285, in 0.770s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00320, in 0.788s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00328, in 0.729s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00117, val loss: 0.00145, in 0.767s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00123, val loss: 0.00149, in 0.673s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00298, val loss: 0.00328, in 0.674s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00182, in 0.630s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00119, val loss: 0.00130, in 0.540s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00279, in 0.572s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00316, in 0.464s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00301, val loss: 0.00323, in 0.508s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00116, val loss: 0.00143, in 0.519s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00117, val loss: 0.00128, in 0.490s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00293, val loss: 0.00323, in 0.584s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00180, in 0.573s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00259, val loss: 0.00275, in 0.537s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00114, val loss: 0.00141, in 0.397s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00310, in 0.583s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00294, val loss: 0.00316, in 0.523s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00290, val loss: 0.00320, in 0.392s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00115, val loss: 0.00126, in 0.513s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00178, in 0.447s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00254, val loss: 0.00270, in 0.466s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00279, val loss: 0.00306, in 0.430s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00310, in 0.587s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00283, val loss: 0.00312, in 0.643s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00267, in 0.612s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00113, val loss: 0.00124, in 0.696s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00303, in 0.559s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00176, in 0.701s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00285, val loss: 0.00307, in 0.553s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00298, in 0.754s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00278, val loss: 0.00308, in 0.932s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00137, val loss: 0.00174, in 0.847s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00264, in 0.916s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00110, val loss: 0.00121, in 1.036s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00302, in 1.195s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00305, in 0.880s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00243, val loss: 0.00259, in 0.839s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00266, val loss: 0.00295, in 1.089s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00172, in 1.012s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00108, val loss: 0.00119, in 0.931s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00297, in 0.624s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00239, val loss: 0.00255, in 0.552s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00290, in 0.573s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00300, in 0.736s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00170, in 0.598s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00291, in 0.769s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00235, val loss: 0.00252, in 0.585s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00286, in 0.732s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00296, in 0.728s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00168, in 0.743s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00289, in 0.553s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00232, val loss: 0.00249, in 0.558s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00292, in 0.413s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00282, in 0.529s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00167, in 0.532s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00285, in 0.464s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00228, val loss: 0.00245, in 0.576s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00257, val loss: 0.00287, in 0.551s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00165, in 0.458s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00248, val loss: 0.00277, in 0.571s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00280, in 0.592s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00241, in 0.576s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00282, in 0.577s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00163, in 0.519s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00244, val loss: 0.00273, in 0.487s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00276, in 0.550s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00237, in 0.490s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00239, val loss: 0.00268, in 0.476s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00247, val loss: 0.00277, in 0.564s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00249, val loss: 0.00271, in 0.488s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00234, in 0.473s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00235, val loss: 0.00264, in 0.456s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00272, in 0.468s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00245, val loss: 0.00267, in 0.406s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00229, in 0.488s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00231, val loss: 0.00260, in 0.506s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00238, val loss: 0.00268, in 0.560s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00241, val loss: 0.00264, in 0.619s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00225, in 0.610s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00256, in 0.524s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00235, val loss: 0.00265, in 0.462s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00260, in 0.478s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00204, val loss: 0.00222, in 0.489s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00252, in 0.479s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00230, val loss: 0.00260, in 0.484s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00234, val loss: 0.00256, in 0.470s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00220, in 0.405s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00256, in 0.455s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00248, in 0.526s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00231, val loss: 0.00254, in 0.413s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00217, in 0.471s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00245, in 0.491s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00148, in 0.521s\n",
      "Fit 200 trees in 85.190 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.316s\n",
      "Time spent finding best splits:  1.612s\n",
      "Time spent applying splits:      10.279s\n",
      "Time spent predicting:           0.653s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00252, in 0.605s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00252, in 0.458s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00215, in 0.596s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00250, in 0.503s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00213, val loss: 0.00240, in 0.607s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00248, in 0.490s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00113, val loss: 0.00140, in 0.505s\n",
      "Fit 200 trees in 85.115 s, (6200 total leaves)\n",
      "Time spent computing histograms: 50.519s\n",
      "Time spent finding best splits:  1.458s\n",
      "Time spent applying splits:      10.577s\n",
      "Time spent predicting:           0.580s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00212, in 0.513s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00237, in 0.516s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00217, val loss: 0.00247, in 0.540s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00222, val loss: 0.00245, in 0.539s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00209, in 0.543s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00213, val loss: 0.00243, in 0.415s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00206, val loss: 0.00234, in 0.446s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00242, in 0.417s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00206, in 0.469s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00238, in 0.408s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00230, in 0.425s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00210, val loss: 0.00239, in 0.455s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00185, val loss: 0.00204, in 0.522s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00227, in 0.518s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00207, val loss: 0.00237, in 0.573s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00235, in 0.599s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00106, val loss: 0.00117, in 0.787s\n",
      "Fit 200 trees in 87.829 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.701s\n",
      "Time spent finding best splits:  1.590s\n",
      "Time spent applying splits:      10.581s\n",
      "Time spent predicting:           0.783s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00201, in 0.664s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00223, in 0.665s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00234, in 0.677s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00232, in 0.675s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00178, val loss: 0.00198, in 0.522s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00220, in 0.604s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00205, val loss: 0.00228, in 0.581s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00199, val loss: 0.00229, in 0.604s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00197, in 0.467s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00224, in 0.466s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00216, in 0.551s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00225, in 0.561s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00194, in 0.609s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00214, in 0.624s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00221, in 0.694s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00223, in 0.677s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00192, in 0.566s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00211, in 0.612s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00220, in 0.530s\n",
      "[175/200] 5.642 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00218, in 0.711s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00189, in 0.677s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00162, in 0.457s\n",
      "Fit 200 trees in 88.708 s, (6200 total leaves)\n",
      "Time spent computing histograms: 51.946s\n",
      "Time spent finding best splits:  1.524s\n",
      "Time spent applying splits:      10.917s\n",
      "Time spent predicting:           0.636s\n",
      "Binning 0.111 GB of training data: 1 tree, 31 leaves, max depth = 9, train loss: 0.00187, val loss: 0.00217, in 0.578s\n",
      "[176/200] 0.400 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00214, in 0.623s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00207, in 0.773s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00187, in 0.761s\n",
      "[182/200] 5.951 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00183, val loss: 0.00214, in 0.757s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61037, val loss: 0.61028, in 0.684s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00211, in 0.688s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00203, in 0.761s\n",
      "[178/200] 0.305 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00185, in 0.627s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54261, val loss: 0.54244, in 0.680s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00212, in 0.757s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00208, in 0.727s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00201, in 0.748s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61042, val loss: 0.61031, in 0.642s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00184, in 0.538s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48557, val loss: 0.48532, in 0.607s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00209, in 0.691s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00204, in 0.694s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54268, val loss: 0.54243, in 0.646s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00182, in 0.641s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00198, in 0.684s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43723, val loss: 0.43687, in 0.573s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00202, in 0.506s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00176, val loss: 0.00206, in 0.551s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.48560, val loss: 0.48530, in 0.566s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00179, in 0.574s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00196, in 0.661s\n",
      "[181/200] 6.345 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 9, train loss: 0.39564, val loss: 0.39531, in 0.620s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00199, in 0.622s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00203, in 0.691s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43726, val loss: 0.43684, in 0.612s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00176, in 0.657s\n",
      "[187/200] 0.304 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00166, val loss: 0.00193, in 0.643s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35981, val loss: 0.35952, in 0.566s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00174, val loss: 0.00197, in 0.536s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00201, in 0.579s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.39573, val loss: 0.39522, in 0.558s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00154, val loss: 0.00174, in 0.592s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61044, val loss: 0.61030, in 0.533s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00164, val loss: 0.00191, in 0.547s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32856, val loss: 0.32810, in 0.567s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00196, in 0.476s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00198, in 0.500s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35977, val loss: 0.35915, in 0.575s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.54272, val loss: 0.54236, in 0.580s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00189, in 0.565s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00173, in 0.625s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30106, val loss: 0.30053, in 0.561s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00193, in 0.576s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00195, in 0.602s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.32832, val loss: 0.32781, in 0.617s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48569, val loss: 0.48523, in 0.580s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00187, in 0.601s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00170, in 0.640s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27646, val loss: 0.27602, in 0.614s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00191, in 0.689s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00192, in 0.626s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30073, val loss: 0.30007, in 0.604s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43740, val loss: 0.43679, in 0.595s\n",
      "[5/200] 6.200 s\n",
      "Binning 0.012 GB of validation data: 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00185, in 0.624s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00168, in 0.654s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25442, val loss: 0.25395, in 0.586s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00187, in 0.614s\n",
      "[187/200] 0.206 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00160, val loss: 0.00190, in 0.558s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.27661, val loss: 0.27594, in 0.544s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00183, in 0.491s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39591, val loss: 0.39520, in 0.585s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00166, in 0.510s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23533, val loss: 0.23471, in 0.573s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.60970, val loss: 0.60966, in 0.594s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00186, in 0.640s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00188, in 0.597s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25503, val loss: 0.25428, in 0.602s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.35995, val loss: 0.35913, in 0.588s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00181, in 0.636s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00165, in 0.605s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21874, val loss: 0.21805, in 0.606s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54120, val loss: 0.54115, in 0.596s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00160, val loss: 0.00183, in 0.571s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00186, in 0.634s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23646, val loss: 0.23562, in 0.580s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32843, val loss: 0.32762, in 0.663s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00179, in 0.656s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00162, in 0.657s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20270, val loss: 0.20207, in 0.668s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00182, in 0.540s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00185, in 0.494s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48420, val loss: 0.48413, in 0.588s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.21902, val loss: 0.21821, in 0.597s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00177, in 0.526s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.30093, val loss: 0.30003, in 0.539s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00161, in 0.490s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18919, val loss: 0.18843, in 0.570s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00181, in 0.573s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00156, val loss: 0.00180, in 0.606s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.43515, val loss: 0.43500, in 0.580s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20312, val loss: 0.20230, in 0.612s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00176, in 0.529s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27617, val loss: 0.27529, in 0.624s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00137, val loss: 0.00159, in 0.614s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17675, val loss: 0.17605, in 0.600s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.39315, val loss: 0.39298, in 0.557s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00154, val loss: 0.00178, in 0.609s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00150, val loss: 0.00179, in 0.643s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18944, val loss: 0.18855, in 0.531s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00173, in 0.560s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00157, in 0.462s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25490, val loss: 0.25383, in 0.493s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35732, val loss: 0.35708, in 0.492s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.16531, val loss: 0.16461, in 0.536s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00176, in 0.513s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00177, in 0.561s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17640, val loss: 0.17558, in 0.573s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00142, val loss: 0.00171, in 0.554s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.23592, val loss: 0.23481, in 0.591s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00155, in 0.613s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32583, val loss: 0.32549, in 0.601s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15520, val loss: 0.15452, in 0.599s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00173, in 0.536s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00174, in 0.634s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16527, val loss: 0.16449, in 0.634s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00169, in 0.624s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00154, in 0.596s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.21851, val loss: 0.21725, in 0.629s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00170, in 0.578s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.29781, val loss: 0.29739, in 0.612s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14630, val loss: 0.14567, in 0.599s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00172, in 0.548s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15510, val loss: 0.15429, in 0.548s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00152, in 0.523s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20335, val loss: 0.20211, in 0.523s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00137, val loss: 0.00167, in 0.623s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.27328, val loss: 0.27290, in 0.516s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00168, in 0.539s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13754, val loss: 0.13681, in 0.552s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00146, val loss: 0.00170, in 0.525s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.14588, val loss: 0.14515, in 0.514s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18957, val loss: 0.18822, in 0.493s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00166, in 0.545s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00166, in 0.478s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25189, val loss: 0.25148, in 0.504s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12946, val loss: 0.12880, in 0.516s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00168, in 0.484s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13755, val loss: 0.13687, in 0.537s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17723, val loss: 0.17592, in 0.512s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00163, in 0.528s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00164, in 0.477s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.23298, val loss: 0.23257, in 0.495s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00166, in 0.446s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12209, val loss: 0.12145, in 0.536s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12943, val loss: 0.12879, in 0.553s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16565, val loss: 0.16439, in 0.594s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00162, in 0.505s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00162, in 0.521s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21592, val loss: 0.21536, in 0.521s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00164, in 0.511s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11529, val loss: 0.11475, in 0.578s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12206, val loss: 0.12148, in 0.583s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00159, in 0.518s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.15528, val loss: 0.15407, in 0.544s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00133, val loss: 0.00160, in 0.545s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.20054, val loss: 0.19996, in 0.524s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00162, in 0.510s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10888, val loss: 0.10839, in 0.578s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11521, val loss: 0.11463, in 0.518s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00157, in 0.511s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.14618, val loss: 0.14505, in 0.542s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.18669, val loss: 0.18608, in 0.568s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00158, in 0.571s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10307, val loss: 0.10255, in 0.577s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10898, val loss: 0.10850, in 0.599s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13773, val loss: 0.13665, in 0.555s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.17424, val loss: 0.17367, in 0.532s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09734, val loss: 0.09689, in 0.588s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10289, val loss: 0.10241, in 0.534s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.12980, val loss: 0.12873, in 0.550s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.16288, val loss: 0.16231, in 0.551s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09211, val loss: 0.09169, in 0.474s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12231, val loss: 0.12131, in 0.467s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09711, val loss: 0.09661, in 0.522s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.15218, val loss: 0.15168, in 0.447s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08716, val loss: 0.08677, in 0.579s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11539, val loss: 0.11442, in 0.570s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09153, val loss: 0.09109, in 0.564s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14281, val loss: 0.14238, in 0.516s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08282, val loss: 0.08246, in 0.486s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10898, val loss: 0.10821, in 0.529s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08689, val loss: 0.08649, in 0.518s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.13408, val loss: 0.13371, in 0.510s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07860, val loss: 0.07825, in 0.517s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10341, val loss: 0.10268, in 0.504s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08223, val loss: 0.08184, in 0.518s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.12656, val loss: 0.12624, in 0.471s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07446, val loss: 0.07422, in 0.528s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09756, val loss: 0.09683, in 0.497s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07808, val loss: 0.07772, in 0.514s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11925, val loss: 0.11886, in 0.504s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07076, val loss: 0.07054, in 0.546s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09203, val loss: 0.09137, in 0.508s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07380, val loss: 0.07349, in 0.519s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11345, val loss: 0.11310, in 5.295s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06747, val loss: 0.06731, in 4.979s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07029, val loss: 0.06995, in 4.876s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08703, val loss: 0.08637, in 4.928s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10735, val loss: 0.10698, in 0.417s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06462, val loss: 0.06449, in 0.359s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08281, val loss: 0.08212, in 0.356s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06727, val loss: 0.06696, in 0.362s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.10162, val loss: 0.10131, in 0.264s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07860, val loss: 0.07790, in 0.257s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06170, val loss: 0.06158, in 0.267s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06414, val loss: 0.06386, in 0.519s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09574, val loss: 0.09543, in 0.341s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.07468, val loss: 0.07395, in 0.349s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05896, val loss: 0.05892, in 0.362s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06119, val loss: 0.06098, in 0.285s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09088, val loss: 0.09059, in 0.275s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07121, val loss: 0.07048, in 0.262s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05648, val loss: 0.05654, in 0.252s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05833, val loss: 0.05818, in 0.248s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.08607, val loss: 0.08583, in 0.249s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06772, val loss: 0.06696, in 0.268s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05386, val loss: 0.05399, in 0.271s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05576, val loss: 0.05556, in 0.316s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.08202, val loss: 0.08182, in 0.326s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05174, val loss: 0.05186, in 0.317s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06460, val loss: 0.06391, in 0.330s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05360, val loss: 0.05341, in 0.343s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07803, val loss: 0.07788, in 0.345s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06145, val loss: 0.06079, in 0.350s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04979, val loss: 0.04994, in 0.360s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05153, val loss: 0.05139, in 0.392s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.07434, val loss: 0.07421, in 0.371s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04780, val loss: 0.04798, in 0.330s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05886, val loss: 0.05823, in 0.352s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04936, val loss: 0.04926, in 0.316s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07028, val loss: 0.07014, in 0.306s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04607, val loss: 0.04625, in 0.295s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05614, val loss: 0.05561, in 0.346s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04760, val loss: 0.04754, in 0.293s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04452, val loss: 0.04471, in 0.304s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06690, val loss: 0.06674, in 0.313s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05402, val loss: 0.05348, in 0.272s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04567, val loss: 0.04563, in 0.244s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04223, val loss: 0.04243, in 0.240s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06408, val loss: 0.06395, in 0.252s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05167, val loss: 0.05118, in 0.258s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04411, val loss: 0.04406, in 0.249s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04055, val loss: 0.04073, in 0.260s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06112, val loss: 0.06097, in 0.258s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04993, val loss: 0.04940, in 0.234s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04211, val loss: 0.04214, in 0.279s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03851, val loss: 0.03872, in 0.253s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04796, val loss: 0.04744, in 0.260s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05815, val loss: 0.05802, in 0.289s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03997, val loss: 0.04002, in 0.258s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03691, val loss: 0.03715, in 0.268s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04625, val loss: 0.04584, in 0.300s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05551, val loss: 0.05546, in 0.297s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03828, val loss: 0.03846, in 0.282s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03531, val loss: 0.03557, in 0.280s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04427, val loss: 0.04390, in 0.246s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05343, val loss: 0.05347, in 0.271s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03425, val loss: 0.03450, in 0.220s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03652, val loss: 0.03675, in 0.248s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04218, val loss: 0.04186, in 0.244s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05078, val loss: 0.05083, in 0.294s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03520, val loss: 0.03544, in 0.254s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03288, val loss: 0.03312, in 0.264s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04068, val loss: 0.04039, in 0.265s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04872, val loss: 0.04875, in 0.298s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03200, val loss: 0.03227, in 0.234s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03397, val loss: 0.03425, in 0.262s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03925, val loss: 0.03900, in 0.264s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04631, val loss: 0.04639, in 0.275s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03115, val loss: 0.03144, in 0.233s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03296, val loss: 0.03327, in 0.248s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03779, val loss: 0.03759, in 0.248s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04458, val loss: 0.04467, in 0.325s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03020, val loss: 0.03048, in 0.311s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03194, val loss: 0.03226, in 0.301s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03653, val loss: 0.03637, in 0.316s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02934, val loss: 0.02963, in 0.255s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04266, val loss: 0.04281, in 0.281s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03055, val loss: 0.03089, in 0.320s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03472, val loss: 0.03458, in 0.282s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04108, val loss: 0.04124, in 0.276s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02818, val loss: 0.02849, in 0.321s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02969, val loss: 0.03006, in 0.243s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03355, val loss: 0.03341, in 0.265s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03959, val loss: 0.03980, in 0.217s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02716, val loss: 0.02746, in 0.237s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02857, val loss: 0.02897, in 0.245s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03235, val loss: 0.03220, in 0.233s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03848, val loss: 0.03872, in 0.212s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02659, val loss: 0.02690, in 0.232s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02785, val loss: 0.02826, in 0.218s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03122, val loss: 0.03111, in 0.256s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03677, val loss: 0.03712, in 0.280s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02521, val loss: 0.02552, in 0.249s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02684, val loss: 0.02728, in 0.264s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02992, val loss: 0.02982, in 0.281s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03539, val loss: 0.03573, in 0.261s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02599, val loss: 0.02646, in 0.228s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02422, val loss: 0.02455, in 0.253s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02909, val loss: 0.02900, in 0.203s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03428, val loss: 0.03466, in 0.221s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02324, val loss: 0.02359, in 0.211s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02517, val loss: 0.02562, in 0.228s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02809, val loss: 0.02805, in 0.209s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02455, val loss: 0.02503, in 0.210s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03291, val loss: 0.03330, in 0.244s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02242, val loss: 0.02277, in 0.266s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02702, val loss: 0.02696, in 0.263s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03178, val loss: 0.03215, in 0.250s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02309, val loss: 0.02357, in 0.261s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02167, val loss: 0.02205, in 0.250s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02541, val loss: 0.02538, in 0.264s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02216, val loss: 0.02262, in 0.199s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02126, val loss: 0.02165, in 0.176s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02972, val loss: 0.03008, in 0.260s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02463, val loss: 0.02464, in 0.234s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02142, val loss: 0.02194, in 0.273s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02055, val loss: 0.02094, in 0.274s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02816, val loss: 0.02854, in 0.282s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02324, val loss: 0.02326, in 0.288s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02079, val loss: 0.02130, in 0.225s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01973, val loss: 0.02009, in 0.226s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02696, val loss: 0.02738, in 0.260s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02234, val loss: 0.02234, in 0.225s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02000, val loss: 0.02050, in 0.226s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01886, val loss: 0.01922, in 0.261s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02604, val loss: 0.02646, in 0.247s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02154, val loss: 0.02154, in 0.321s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01929, val loss: 0.01977, in 0.315s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01826, val loss: 0.01863, in 0.300s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02472, val loss: 0.02510, in 0.318s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02082, val loss: 0.02078, in 0.231s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01860, val loss: 0.01906, in 0.225s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01779, in 0.281s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02375, val loss: 0.02416, in 0.253s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02026, val loss: 0.02025, in 0.262s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01776, val loss: 0.01822, in 0.250s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01687, val loss: 0.01725, in 0.262s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02314, val loss: 0.02357, in 0.233s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01955, val loss: 0.01958, in 0.281s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01696, val loss: 0.01742, in 0.274s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01628, val loss: 0.01667, in 0.225s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02228, val loss: 0.02274, in 0.233s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01886, val loss: 0.01892, in 0.235s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01643, val loss: 0.01690, in 0.258s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01579, val loss: 0.01616, in 0.244s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02122, val loss: 0.02167, in 0.270s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01827, val loss: 0.01833, in 0.212s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01639, in 0.216s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01523, val loss: 0.01560, in 0.272s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02053, val loss: 0.02100, in 0.244s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01552, val loss: 0.01596, in 0.224s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01742, val loss: 0.01748, in 0.282s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01505, in 0.222s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01982, val loss: 0.02030, in 0.239s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01689, val loss: 0.01699, in 0.251s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01506, val loss: 0.01551, in 0.280s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01430, val loss: 0.01467, in 0.226s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01922, val loss: 0.01970, in 0.235s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01470, val loss: 0.01514, in 0.209s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01636, val loss: 0.01646, in 0.281s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01386, val loss: 0.01423, in 0.279s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01857, val loss: 0.01905, in 0.246s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01415, val loss: 0.01458, in 0.264s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01595, val loss: 0.01609, in 0.222s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01356, val loss: 0.01395, in 0.220s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01819, val loss: 0.01869, in 0.240s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01379, val loss: 0.01420, in 0.228s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01546, val loss: 0.01560, in 0.312s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01317, val loss: 0.01353, in 0.265s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01746, val loss: 0.01796, in 0.256s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01348, val loss: 0.01387, in 0.265s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01508, val loss: 0.01522, in 0.212s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01270, val loss: 0.01308, in 0.244s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01691, val loss: 0.01742, in 0.236s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01311, val loss: 0.01348, in 0.231s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01465, val loss: 0.01480, in 0.255s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01237, val loss: 0.01275, in 0.264s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01623, val loss: 0.01673, in 0.258s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01275, val loss: 0.01314, in 0.235s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01408, val loss: 0.01423, in 0.261s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01586, val loss: 0.01635, in 0.232s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01237, in 0.272s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01237, val loss: 0.01276, in 0.268s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01367, val loss: 0.01384, in 0.233s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01165, val loss: 0.01201, in 0.224s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01529, val loss: 0.01576, in 0.235s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01334, val loss: 0.01354, in 0.246s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01198, val loss: 0.01238, in 0.309s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01169, in 0.242s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01472, val loss: 0.01518, in 0.265s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01302, val loss: 0.01320, in 0.204s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01162, val loss: 0.01203, in 0.270s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01103, val loss: 0.01139, in 0.237s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01426, val loss: 0.01472, in 0.263s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01253, val loss: 0.01272, in 0.259s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01125, val loss: 0.01166, in 0.258s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01074, val loss: 0.01111, in 0.258s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01377, val loss: 0.01424, in 0.247s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01215, val loss: 0.01237, in 0.278s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01094, val loss: 0.01136, in 0.291s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01041, val loss: 0.01080, in 0.296s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01326, val loss: 0.01372, in 0.290s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01182, val loss: 0.01205, in 0.299s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01057, val loss: 0.01099, in 0.250s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01296, val loss: 0.01342, in 0.237s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.01009, val loss: 0.01047, in 0.294s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01151, val loss: 0.01175, in 0.201s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00992, val loss: 0.01031, in 0.206s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01028, val loss: 0.01069, in 0.262s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01252, val loss: 0.01296, in 0.278s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01118, val loss: 0.01142, in 0.265s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01010, val loss: 0.01049, in 0.220s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00967, val loss: 0.01004, in 0.222s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01221, val loss: 0.01264, in 0.226s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01094, val loss: 0.01115, in 0.232s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00997, val loss: 0.01036, in 0.225s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00946, val loss: 0.00982, in 0.269s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01183, val loss: 0.01223, in 0.244s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01076, val loss: 0.01098, in 0.229s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00973, val loss: 0.01011, in 0.223s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00966, in 0.228s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01148, val loss: 0.01189, in 0.217s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01050, val loss: 0.01074, in 0.295s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01127, val loss: 0.01168, in 0.220s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00949, val loss: 0.00988, in 0.289s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00903, val loss: 0.00940, in 0.308s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01022, val loss: 0.01044, in 0.257s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00929, val loss: 0.00969, in 0.252s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01092, val loss: 0.01132, in 0.293s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00875, val loss: 0.00913, in 0.278s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00912, val loss: 0.00952, in 0.233s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00997, val loss: 0.01020, in 0.287s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01058, val loss: 0.01097, in 0.292s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00852, val loss: 0.00890, in 0.283s\n",
      "[93/200] 1 tree, 29 leaves, max depth = 10, train loss: 0.00906, val loss: 0.00945, in 0.191s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00972, val loss: 0.00994, in 0.250s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01032, val loss: 0.01072, in 0.233s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00830, val loss: 0.00869, in 0.260s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00928, in 0.238s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00950, val loss: 0.00973, in 0.240s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01004, val loss: 0.01041, in 0.223s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00808, val loss: 0.00846, in 0.242s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00858, val loss: 0.00898, in 0.244s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00933, val loss: 0.00955, in 0.265s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00982, val loss: 0.01020, in 0.228s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00787, val loss: 0.00826, in 0.246s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00839, val loss: 0.00878, in 0.262s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00963, val loss: 0.01000, in 0.249s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00904, val loss: 0.00927, in 0.329s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00773, val loss: 0.00813, in 0.239s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00819, val loss: 0.00856, in 0.221s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00947, val loss: 0.00985, in 0.217s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00909, in 0.241s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00760, val loss: 0.00799, in 0.224s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00805, val loss: 0.00843, in 0.240s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00924, val loss: 0.00963, in 0.295s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00870, val loss: 0.00893, in 0.271s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00788, val loss: 0.00827, in 0.249s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00740, val loss: 0.00779, in 0.296s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00900, val loss: 0.00938, in 0.240s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00879, in 0.237s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00771, val loss: 0.00811, in 0.255s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00723, val loss: 0.00761, in 0.304s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00840, val loss: 0.00864, in 0.235s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00875, val loss: 0.00912, in 0.327s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00749, val loss: 0.00786, in 0.327s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00748, in 0.294s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00856, val loss: 0.00891, in 0.284s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00815, val loss: 0.00839, in 0.376s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00736, val loss: 0.00774, in 0.289s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00735, in 0.270s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00838, val loss: 0.00874, in 0.257s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00807, val loss: 0.00830, in 0.242s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00727, val loss: 0.00765, in 0.209s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00716, in 0.284s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00820, val loss: 0.00857, in 0.295s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00706, val loss: 0.00742, in 0.289s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00780, val loss: 0.00803, in 0.317s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00662, val loss: 0.00700, in 0.323s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00799, val loss: 0.00833, in 0.218s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00767, val loss: 0.00791, in 0.232s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00688, val loss: 0.00724, in 0.283s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00651, val loss: 0.00690, in 0.238s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00774, val loss: 0.00807, in 0.260s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00748, val loss: 0.00773, in 0.275s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00672, val loss: 0.00711, in 0.253s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00641, val loss: 0.00681, in 0.238s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00754, val loss: 0.00787, in 0.268s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00728, val loss: 0.00754, in 0.227s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00630, val loss: 0.00669, in 0.217s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00655, val loss: 0.00694, in 0.274s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00733, val loss: 0.00765, in 0.260s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00710, val loss: 0.00736, in 0.289s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00615, val loss: 0.00653, in 0.254s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00637, val loss: 0.00678, in 0.281s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00716, val loss: 0.00748, in 0.265s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00695, val loss: 0.00722, in 0.308s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00604, val loss: 0.00643, in 0.287s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00625, val loss: 0.00666, in 0.258s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00699, val loss: 0.00732, in 0.287s\n",
      "[99/200] 1 tree, 30 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00636, in 0.204s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00613, val loss: 0.00653, in 0.222s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00680, val loss: 0.00707, in 0.263s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00684, val loss: 0.00718, in 0.247s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00599, val loss: 0.00638, in 0.235s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00585, val loss: 0.00625, in 0.263s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00663, val loss: 0.00690, in 0.218s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00670, val loss: 0.00703, in 0.240s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00583, val loss: 0.00621, in 0.240s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00648, val loss: 0.00676, in 0.228s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00576, val loss: 0.00615, in 0.235s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00660, val loss: 0.00695, in 0.223s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00571, val loss: 0.00611, in 0.216s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00634, val loss: 0.00662, in 0.276s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00567, val loss: 0.00606, in 0.301s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00600, in 0.214s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00641, val loss: 0.00675, in 0.305s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00621, val loss: 0.00649, in 0.264s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00552, val loss: 0.00591, in 0.266s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00549, val loss: 0.00587, in 0.225s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00626, val loss: 0.00659, in 0.249s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00639, in 0.208s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00541, val loss: 0.00580, in 0.252s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00573, in 0.432s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00611, val loss: 0.00644, in 0.438s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00597, val loss: 0.00626, in 0.447s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00531, val loss: 0.00570, in 0.434s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00523, val loss: 0.00562, in 0.280s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00588, val loss: 0.00616, in 0.211s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00596, val loss: 0.00628, in 0.280s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00526, val loss: 0.00564, in 0.207s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00511, val loss: 0.00550, in 0.251s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00599, in 0.240s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00579, val loss: 0.00612, in 0.281s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00513, val loss: 0.00552, in 0.272s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00559, val loss: 0.00586, in 0.226s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00500, val loss: 0.00539, in 0.268s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00569, val loss: 0.00604, in 0.239s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00502, val loss: 0.00539, in 0.244s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00493, val loss: 0.00532, in 0.247s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00548, val loss: 0.00576, in 0.285s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00557, val loss: 0.00591, in 0.264s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00533, in 0.248s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00526, in 0.206s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00537, val loss: 0.00565, in 0.234s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00485, val loss: 0.00523, in 0.269s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00542, val loss: 0.00577, in 0.293s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00480, val loss: 0.00520, in 0.229s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00527, val loss: 0.00554, in 0.247s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00474, val loss: 0.00512, in 0.277s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00529, val loss: 0.00562, in 0.291s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00509, in 0.234s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00519, val loss: 0.00546, in 0.255s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00506, in 0.244s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00515, val loss: 0.00548, in 0.292s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00457, val loss: 0.00497, in 0.302s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00539, in 0.221s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00459, val loss: 0.00498, in 0.265s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00507, val loss: 0.00533, in 0.245s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00508, val loss: 0.00542, in 0.279s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00450, val loss: 0.00490, in 0.268s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00453, val loss: 0.00492, in 0.213s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00521, in 0.226s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00497, val loss: 0.00531, in 0.233s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00440, val loss: 0.00480, in 0.267s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00445, val loss: 0.00483, in 0.225s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00486, val loss: 0.00513, in 0.240s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00521, in 0.270s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00432, val loss: 0.00472, in 0.248s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00436, val loss: 0.00474, in 0.260s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00475, val loss: 0.00501, in 0.271s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00477, val loss: 0.00510, in 0.235s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00424, val loss: 0.00464, in 0.247s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00428, val loss: 0.00465, in 0.242s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00465, val loss: 0.00491, in 0.271s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00468, val loss: 0.00501, in 0.268s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00413, val loss: 0.00452, in 0.268s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00421, val loss: 0.00457, in 0.282s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00405, val loss: 0.00445, in 0.247s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00456, val loss: 0.00483, in 0.310s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00458, val loss: 0.00491, in 0.319s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00411, val loss: 0.00447, in 0.245s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00398, val loss: 0.00439, in 0.304s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00451, val loss: 0.00484, in 0.274s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00447, val loss: 0.00474, in 0.304s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00402, val loss: 0.00438, in 0.278s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00448, val loss: 0.00481, in 0.205s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00432, in 0.206s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00437, val loss: 0.00463, in 0.276s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00431, in 0.304s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00442, val loss: 0.00476, in 0.207s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00457, in 0.206s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00389, val loss: 0.00425, in 0.244s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00424, in 0.223s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00431, val loss: 0.00464, in 0.238s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00421, val loss: 0.00448, in 0.280s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00418, in 0.278s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00380, val loss: 0.00416, in 0.291s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00453, in 0.251s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00411, val loss: 0.00438, in 0.217s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00412, in 0.230s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00410, in 0.278s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00409, val loss: 0.00442, in 0.293s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00403, in 0.202s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00430, in 0.264s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00359, val loss: 0.00402, in 0.267s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00403, val loss: 0.00436, in 0.220s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00394, val loss: 0.00421, in 0.255s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00359, val loss: 0.00396, in 0.284s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00353, val loss: 0.00396, in 0.276s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00396, val loss: 0.00429, in 0.225s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00392, in 0.217s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00386, val loss: 0.00414, in 0.275s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00390, in 0.270s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00388, val loss: 0.00421, in 0.270s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00346, val loss: 0.00384, in 0.273s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00380, val loss: 0.00408, in 0.247s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00383, val loss: 0.00417, in 0.228s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00385, in 0.290s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00374, val loss: 0.00401, in 0.246s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00339, val loss: 0.00378, in 0.280s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00375, val loss: 0.00408, in 0.274s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00380, in 0.248s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00334, val loss: 0.00372, in 0.265s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00368, val loss: 0.00396, in 0.277s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00367, val loss: 0.00401, in 0.273s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00375, in 0.279s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00329, val loss: 0.00368, in 0.208s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00389, in 0.212s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00394, in 0.239s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00322, val loss: 0.00369, in 0.264s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00323, val loss: 0.00361, in 0.259s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00354, val loss: 0.00381, in 0.276s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00354, val loss: 0.00387, in 0.248s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00361, in 0.305s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00317, val loss: 0.00356, in 0.294s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00349, val loss: 0.00376, in 0.281s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00346, val loss: 0.00380, in 0.311s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00307, val loss: 0.00354, in 0.297s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00314, val loss: 0.00352, in 0.262s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00342, val loss: 0.00368, in 0.246s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00340, val loss: 0.00373, in 0.230s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00302, val loss: 0.00349, in 0.249s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00362, in 0.261s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00309, val loss: 0.00348, in 0.320s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00335, val loss: 0.00368, in 0.256s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00332, val loss: 0.00357, in 0.216s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00344, in 0.280s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00342, in 0.232s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00327, val loss: 0.00360, in 0.280s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00328, val loss: 0.00354, in 0.232s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00336, in 0.264s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00337, in 0.308s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00350, in 0.218s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00320, val loss: 0.00346, in 0.230s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00294, val loss: 0.00333, in 0.222s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00286, val loss: 0.00333, in 0.302s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00312, val loss: 0.00342, in 0.287s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00315, val loss: 0.00341, in 0.293s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00288, val loss: 0.00327, in 0.309s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00328, in 0.234s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00306, val loss: 0.00335, in 0.276s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00311, val loss: 0.00337, in 0.260s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00324, in 0.254s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00324, in 0.270s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00300, val loss: 0.00329, in 0.260s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00304, val loss: 0.00330, in 0.306s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00320, in 0.306s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00295, val loss: 0.00325, in 0.214s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00270, val loss: 0.00320, in 0.295s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00296, val loss: 0.00323, in 0.272s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00314, in 0.358s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00321, in 0.351s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00266, val loss: 0.00315, in 0.349s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00289, val loss: 0.00315, in 0.371s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00308, in 0.292s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00262, val loss: 0.00311, in 0.286s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00284, val loss: 0.00315, in 0.334s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00312, in 0.277s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00304, in 0.228s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00302, in 0.278s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00277, val loss: 0.00308, in 0.302s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00281, val loss: 0.00308, in 0.218s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00300, in 0.247s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00258, val loss: 0.00297, in 0.241s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00273, val loss: 0.00303, in 0.239s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00275, val loss: 0.00303, in 0.259s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00294, in 0.242s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00253, val loss: 0.00292, in 0.300s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00269, val loss: 0.00300, in 0.273s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00271, val loss: 0.00299, in 0.264s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00290, in 0.240s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00250, val loss: 0.00289, in 0.290s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00264, val loss: 0.00294, in 0.280s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00265, val loss: 0.00293, in 0.306s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00285, in 0.258s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00245, val loss: 0.00285, in 0.281s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00261, val loss: 0.00290, in 0.245s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00260, val loss: 0.00288, in 0.281s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00281, in 0.269s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00281, in 0.244s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00284, in 0.240s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00278, in 0.278s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00255, val loss: 0.00283, in 0.286s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00277, in 0.289s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00250, val loss: 0.00280, in 0.307s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00251, val loss: 0.00279, in 0.261s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00273, in 0.298s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00273, in 0.271s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00246, val loss: 0.00276, in 0.319s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00220, val loss: 0.00268, in 0.246s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00247, val loss: 0.00275, in 0.289s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00229, val loss: 0.00269, in 0.253s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00241, val loss: 0.00271, in 0.286s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00265, in 0.249s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00242, val loss: 0.00270, in 0.252s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00225, val loss: 0.00265, in 0.324s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00265, in 0.297s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00237, val loss: 0.00265, in 0.298s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00213, val loss: 0.00262, in 0.341s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00222, val loss: 0.00263, in 0.242s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00232, val loss: 0.00261, in 0.259s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00260, in 0.229s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00262, in 0.263s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00218, val loss: 0.00258, in 0.268s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00227, val loss: 0.00257, in 0.262s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00257, in 0.276s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00257, in 0.271s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00215, val loss: 0.00255, in 0.282s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00223, val loss: 0.00252, in 0.253s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00204, val loss: 0.00252, in 0.215s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00252, in 0.226s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00252, in 0.243s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00201, val loss: 0.00249, in 0.251s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00219, val loss: 0.00247, in 0.257s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00248, in 0.286s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00248, in 0.262s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00197, val loss: 0.00245, in 0.316s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00215, val loss: 0.00243, in 0.302s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00216, val loss: 0.00244, in 0.321s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00246, in 0.296s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00194, val loss: 0.00242, in 0.234s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00240, in 0.284s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00212, val loss: 0.00240, in 0.262s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00201, val loss: 0.00243, in 0.275s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00191, val loss: 0.00238, in 0.269s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00209, val loss: 0.00235, in 0.259s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00237, in 0.332s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00239, in 0.384s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00188, val loss: 0.00235, in 0.368s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00206, val loss: 0.00233, in 0.363s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00233, in 0.354s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00195, val loss: 0.00236, in 0.269s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00231, in 0.274s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00202, val loss: 0.00230, in 0.262s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00201, val loss: 0.00229, in 0.290s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00233, in 0.255s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00182, val loss: 0.00228, in 0.298s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00226, in 0.342s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00198, val loss: 0.00227, in 0.283s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00230, in 0.289s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00178, val loss: 0.00224, in 0.261s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00223, in 0.271s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00195, val loss: 0.00224, in 0.261s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00227, in 0.269s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00221, in 0.335s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00193, val loss: 0.00220, in 0.444s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00191, val loss: 0.00221, in 0.439s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00184, val loss: 0.00224, in 0.428s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00219, in 0.338s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00190, val loss: 0.00218, in 0.260s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00219, in 0.250s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00171, val loss: 0.00216, in 0.317s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00220, in 0.363s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00187, val loss: 0.00214, in 0.300s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00186, val loss: 0.00216, in 0.308s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00214, in 0.278s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00177, val loss: 0.00217, in 0.364s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00213, in 0.323s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00211, in 0.346s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00212, in 0.286s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00175, val loss: 0.00215, in 0.230s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00182, val loss: 0.00208, in 0.251s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00180, val loss: 0.00210, in 0.325s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00210, in 0.268s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00212, in 0.319s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00179, val loss: 0.00206, in 0.281s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00177, val loss: 0.00206, in 0.246s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00162, val loss: 0.00207, in 0.238s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00169, val loss: 0.00209, in 0.259s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00176, val loss: 0.00203, in 0.289s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00175, val loss: 0.00204, in 0.277s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00205, in 0.308s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00207, in 0.305s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00201, in 0.311s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00201, in 0.353s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00204, in 0.287s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00205, in 0.312s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00172, val loss: 0.00199, in 0.238s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00196, in 0.256s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00201, in 0.262s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00201, in 0.235s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00170, val loss: 0.00197, in 0.259s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00166, val loss: 0.00194, in 0.232s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00198, in 0.269s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00198, in 0.285s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00191, in 0.308s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00167, val loss: 0.00194, in 0.364s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00196, in 0.294s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00195, in 0.360s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00188, in 0.297s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00164, val loss: 0.00191, in 0.351s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00192, in 0.321s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00153, val loss: 0.00193, in 0.236s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00161, val loss: 0.00188, in 0.239s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00157, val loss: 0.00185, in 0.310s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00191, in 0.259s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00191, in 0.300s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00155, val loss: 0.00183, in 0.261s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00159, val loss: 0.00186, in 0.297s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00143, val loss: 0.00188, in 0.325s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00148, val loss: 0.00189, in 0.349s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00157, val loss: 0.00184, in 0.337s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00153, val loss: 0.00181, in 0.375s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00141, val loss: 0.00186, in 0.378s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00187, in 0.257s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00155, val loss: 0.00182, in 0.329s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00150, val loss: 0.00178, in 0.400s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00184, in 0.463s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00184, in 0.519s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00152, val loss: 0.00180, in 0.430s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00148, val loss: 0.00176, in 0.406s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00183, in 0.252s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00182, in 0.261s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00150, val loss: 0.00178, in 0.231s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00174, in 0.277s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00140, val loss: 0.00182, in 0.250s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00135, val loss: 0.00180, in 0.296s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00148, val loss: 0.00177, in 0.274s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00172, in 0.267s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00180, in 0.296s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00178, in 0.279s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00146, val loss: 0.00174, in 0.340s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00170, in 0.307s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00179, in 0.342s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00176, in 0.332s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00144, val loss: 0.00172, in 0.334s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00168, in 0.371s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00178, in 0.315s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00175, in 0.321s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00142, val loss: 0.00170, in 0.247s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00166, in 0.208s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00176, in 0.257s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00127, val loss: 0.00172, in 0.258s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00139, val loss: 0.00167, in 0.222s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00164, in 0.249s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00173, in 0.266s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00124, val loss: 0.00170, in 0.253s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00165, in 0.238s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00134, val loss: 0.00162, in 0.268s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00130, val loss: 0.00172, in 0.231s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00122, val loss: 0.00167, in 0.242s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00135, val loss: 0.00163, in 0.251s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00133, val loss: 0.00160, in 0.199s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00171, in 0.200s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00133, val loss: 0.00161, in 0.278s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00157, in 0.275s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00131, val loss: 0.00159, in 0.263s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00155, in 0.269s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00156, in 0.199s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00153, in 0.215s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00154, in 0.242s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00124, val loss: 0.00151, in 0.268s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00125, val loss: 0.00153, in 0.255s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00123, val loss: 0.00149, in 0.238s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00123, val loss: 0.00151, in 0.257s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00149, in 0.252s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00119, val loss: 0.00147, in 0.253s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00117, val loss: 0.00145, in 0.253s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00116, val loss: 0.00143, in 0.242s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00114, val loss: 0.00141, in 0.397s\n",
      "[200/200] \n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([125.01686218,  66.81399124, 111.13575008,  90.01933317,\n",
      "        60.44952655,  64.67389865,  80.24593968,  85.34041715]), 'std_fit_time': array([31.19798362,  4.50388765,  5.99122914,  5.18562145,  2.66481746,\n",
      "        3.1410966 ,  2.73892503,  8.26373743]), 'mean_score_time': array([2.87887516, 3.30489647, 5.17607193, 4.35002422, 3.82507615,\n",
      "       3.20855761, 5.54701879, 4.69384794]), 'std_score_time': array([0.16405615, 0.27527859, 0.44432163, 0.79113883, 0.3489021 ,\n",
      "       0.43059483, 1.2653323 , 1.16153311]), 'param_clf_GBC__learning_rate': masked_array(data=[0.05, 0.05, 0.05, 0.05, 0.1, 0.1, 0.1, 0.1],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_GBC__max_depth': masked_array(data=[3, 3, 10, 10, 3, 3, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_GBC__min_samples_leaf': masked_array(data=[1, 3, 1, 3, 1, 3, 1, 3],\n",
      "             mask=[False, False, False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.05, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 3, 'clf_GBC__min_samples_leaf': 3}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}, {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 3}], 'split0_test_accuracy': array([0.97644642, 0.97644642, 0.99787397, 0.99787397, 0.99042091,\n",
      "       0.99042091, 0.99892504, 0.99890115]), 'split1_test_accuracy': array([0.97833357, 0.97833357, 0.99911614, 0.99911614, 0.99290526,\n",
      "       0.99273804, 0.99995222, 0.99992834]), 'split2_test_accuracy': array([0.97845301, 0.97845301, 0.99892504, 0.99892504, 0.99211696,\n",
      "       0.99211696, 0.99985667, 0.99985667]), 'split3_test_accuracy': array([0.9776886 , 0.9776886 , 0.99904448, 0.99904448, 0.99135254,\n",
      "       0.99178252, 0.99985667, 0.99985667]), 'split4_test_accuracy': array([0.9772825 , 0.9772825 , 0.99890115, 0.99890115, 0.99058812,\n",
      "       0.99075534, 0.9998089 , 0.9998089 ]), 'split5_test_accuracy': array([0.97787917, 0.97787917, 0.99868613, 0.99871002, 0.99159122,\n",
      "       0.99159122, 0.99980889, 0.99976111]), 'split6_test_accuracy': array([0.97752084, 0.97752084, 0.99904446, 0.99911612, 0.99175844,\n",
      "       0.99175844, 0.99990445, 0.99990445]), 'split7_test_accuracy': array([0.97685196, 0.97685196, 0.99875779, 0.99875779, 0.99190177,\n",
      "       0.99190177, 0.99983278, 0.99983278]), 'split8_test_accuracy': array([0.97785528, 0.97785528, 0.99892501, 0.99892501, 0.99206899,\n",
      "       0.99206899, 0.99992833, 0.99992833]), 'split9_test_accuracy': array([0.86087289, 0.86584171, 0.92150211, 0.92114379, 0.88053319,\n",
      "       0.88053319, 0.92795203, 0.92795203]), 'mean_test_accuracy': array([0.96591842, 0.96641531, 0.99107763, 0.99105135, 0.98052374,\n",
      "       0.98056674, 0.9925826 , 0.99257304]), 'std_test_accuracy': array([0.03502005, 0.03352962, 0.02319428, 0.02330502, 0.03333734,\n",
      "       0.03335048, 0.02154541, 0.02154229]), 'rank_test_accuracy': array([8, 7, 3, 4, 6, 5, 1, 2], dtype=int32), 'split0_test_precision': array([0.95793534, 0.95793534, 0.99832624, 0.99832624, 0.98502103,\n",
      "       0.98502103, 0.99990426, 0.99990425]), 'split1_test_precision': array([0.96082854, 0.96082854, 0.99871103, 0.99871103, 0.9877086 ,\n",
      "       0.98738185, 0.99995222, 0.99990445]), 'split2_test_precision': array([0.96122139, 0.96122139, 0.99842497, 0.99842497, 0.98732081,\n",
      "       0.98732081, 0.99971343, 0.99971343]), 'split3_test_precision': array([0.96023015, 0.96023015, 0.99866329, 0.99866329, 0.98472923,\n",
      "       0.98556536, 0.99971343, 0.99971343]), 'split4_test_precision': array([0.95888838, 0.95888838, 0.99832975, 0.99832975, 0.98429468,\n",
      "       0.9844826 , 0.99961794, 0.99961794]), 'split5_test_precision': array([0.9590179 , 0.9590179 , 0.99804361, 0.99809124, 0.98478138,\n",
      "       0.98478138, 0.99961792, 0.99957016]), 'split6_test_precision': array([0.95920055, 0.95920055, 0.99866323, 0.99875865, 0.98583904,\n",
      "       0.98583904, 0.99985668, 0.99985668]), 'split7_test_precision': array([0.95771612, 0.95771612, 0.9981865 , 0.9981865 , 0.98602653,\n",
      "       0.98602653, 0.99976114, 0.99976114]), 'split8_test_precision': array([0.95981794, 0.95981794, 0.99832975, 0.99832975, 0.98644436,\n",
      "       0.98644436, 0.99985669, 0.99985669]), 'split9_test_precision': array([0.95292636, 0.95425961, 0.99774317, 0.99779748, 0.98442917,\n",
      "       0.98442917, 0.99972104, 0.99972104]), 'mean_test_precision': array([0.95877827, 0.95891159, 0.99834216, 0.99836189, 0.98565948,\n",
      "       0.98572921, 0.99977147, 0.99976192]), 'std_test_precision': array([0.00222919, 0.00188914, 0.00028668, 0.00028285, 0.00114727,\n",
      "       0.001027  , 0.00011016, 0.00011064]), 'rank_test_precision': array([8, 7, 4, 3, 6, 5, 1, 2], dtype=int32), 'split0_test_recall': array([0.99665552, 0.99665552, 0.99741997, 0.99741997, 0.99598662,\n",
      "       0.99598662, 0.99794553, 0.99789775]), 'split1_test_recall': array([0.99732441, 0.99732441, 0.99952222, 0.99952222, 0.9982322 ,\n",
      "       0.9982322 , 0.99995222, 0.99995222]), 'split2_test_recall': array([0.99713344, 0.99713344, 0.99942669, 0.99942669, 0.99703789,\n",
      "       0.99703789, 1.        , 1.        ]), 'split3_test_recall': array([0.99665568, 0.99665568, 0.99942669, 0.99942669, 0.99818451,\n",
      "       0.99818451, 1.        , 1.        ]), 'split4_test_recall': array([0.99732454, 0.99732454, 0.99947446, 0.99947446, 0.99708566,\n",
      "       0.99722899, 1.        , 1.        ]), 'split5_test_recall': array([0.99842332, 0.99842332, 0.9993311 , 0.9993311 , 0.99861443,\n",
      "       0.99861443, 1.        , 0.99995222]), 'split6_test_recall': array([0.99746775, 0.99746775, 0.99942666, 0.99947444, 0.99784998,\n",
      "       0.99784998, 0.99995222, 0.99995222]), 'split7_test_recall': array([0.99775442, 0.99775442, 0.9993311 , 0.9993311 , 0.99794553,\n",
      "       0.99794553, 0.99990444, 0.99990444]), 'split8_test_recall': array([0.99746775, 0.99746775, 0.99952222, 0.99952222, 0.99784998,\n",
      "       0.99784998, 1.        , 1.        ]), 'split9_test_recall': array([0.7592451 , 0.76851409, 0.84491161, 0.84414716, 0.77329193,\n",
      "       0.77329193, 0.85613951, 0.85613951]), 'mean_test_recall': array([0.97354519, 0.97447209, 0.98377927, 0.9837076 , 0.97520787,\n",
      "       0.97522221, 0.98538939, 0.98537984]), 'std_test_recall': array([0.07143501, 0.06865438, 0.04629315, 0.04652409, 0.06730916,\n",
      "       0.06731384, 0.04308756, 0.04308455]), 'rank_test_recall': array([8, 7, 3, 4, 6, 5, 1, 2], dtype=int32), 'split0_test_roc_auc': array([0.99791387, 0.99791386, 0.99996096, 0.99996096, 0.99969096,\n",
      "       0.99969096, 0.99998656, 0.99998649]), 'split1_test_roc_auc': array([0.99863266, 0.99863265, 0.99999607, 0.99999607, 0.9998822 ,\n",
      "       0.99987668, 0.99999996, 0.99999995]), 'split2_test_roc_auc': array([0.99827768, 0.9982776 , 0.99999614, 0.99999614, 0.99980297,\n",
      "       0.99980297, 1.        , 1.        ]), 'split3_test_roc_auc': array([0.99831105, 0.99831104, 0.99999539, 0.99999539, 0.9997746 ,\n",
      "       0.99978211, 0.99999997, 0.99999997]), 'split4_test_roc_auc': array([0.99780856, 0.99780845, 0.99999545, 0.99999545, 0.9997946 ,\n",
      "       0.99979155, 0.99999999, 0.99999999]), 'split5_test_roc_auc': array([0.99808877, 0.99808877, 0.99999413, 0.99999424, 0.99980666,\n",
      "       0.99980666, 0.99999992, 0.99999987]), 'split6_test_roc_auc': array([0.99828189, 0.99828189, 0.99999531, 0.99999571, 0.99983999,\n",
      "       0.99983998, 0.99999997, 0.99999997]), 'split7_test_roc_auc': array([0.9983235 , 0.9983235 , 0.99997779, 0.99997779, 0.99983011,\n",
      "       0.99983011, 0.99998908, 0.99998908]), 'split8_test_roc_auc': array([0.99828658, 0.99828658, 0.99999626, 0.99999626, 0.9998229 ,\n",
      "       0.99982289, 0.99999995, 0.99999995]), 'split9_test_roc_auc': array([0.97584692, 0.97634831, 0.992006  , 0.99248443, 0.98898766,\n",
      "       0.98898774, 0.99757645, 0.99757645]), 'mean_test_roc_auc': array([0.99597715, 0.99602727, 0.99919135, 0.99923924, 0.99872326,\n",
      "       0.99872317, 0.99975519, 0.99975517]), 'std_test_roc_auc': array([0.00671366, 0.00656332, 0.00239514, 0.00225163, 0.00324554,\n",
      "       0.00324546, 0.00072626, 0.00072626]), 'rank_test_roc_auc': array([8, 7, 4, 3, 5, 6, 1, 2], dtype=int32), 'split0_test_f1': array([0.97691191, 0.97691191, 0.9978729 , 0.9978729 , 0.99047348,\n",
      "       0.99047348, 0.99892393, 0.9989    ]), 'split1_test_f1': array([0.97873637, 0.97873637, 0.99911646, 0.99911646, 0.99294252,\n",
      "       0.99277738, 0.99995222, 0.99992833]), 'split2_test_f1': array([0.97884814, 0.97884814, 0.99892558, 0.99892558, 0.99215556,\n",
      "       0.99215556, 0.99985669, 0.99985669]), 'split3_test_f1': array([0.9781039 , 0.9781039 , 0.99904484, 0.99904484, 0.99141122,\n",
      "       0.9918348 , 0.99985669, 0.99985669]), 'split4_test_f1': array([0.97772886, 0.97772886, 0.99890178, 0.99890178, 0.99064888,\n",
      "       0.9908148 , 0.99980893, 0.99980893]), 'split5_test_f1': array([0.97832397, 0.97832397, 0.99868694, 0.99871079, 0.99164967,\n",
      "       0.99164967, 0.99980892, 0.99976115]), 'split6_test_f1': array([0.97795995, 0.97795995, 0.9990448 , 0.99911642, 0.99180814,\n",
      "       0.99180814, 0.99990445, 0.99990445]), 'split7_test_f1': array([0.97732538, 0.97732538, 0.99875848, 0.99875848, 0.99195023,\n",
      "       0.99195023, 0.99983279, 0.99983279]), 'split8_test_f1': array([0.97828073, 0.97828073, 0.99892563, 0.99892563, 0.99211439,\n",
      "       0.99211439, 0.99992834, 0.99992834]), 'split9_test_f1': array([0.8451311 , 0.85137352, 0.91498939, 0.91456376, 0.86617966,\n",
      "       0.86617966, 0.92237607, 0.92237607]), 'mean_test_f1': array([0.96473503, 0.96535927, 0.99042668, 0.99039366, 0.97913337,\n",
      "       0.97917581, 0.9920249 , 0.99201534]), 'std_test_f1': array([0.03987195, 0.03799941, 0.02514802, 0.02527894, 0.03765747,\n",
      "       0.03767058, 0.02321803, 0.02321491]), 'rank_test_f1': array([8, 7, 3, 4, 6, 5, 1, 2], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST AOC-RUC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82244) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binning 0.124 GB of training data: 1.565 s\n",
      "Binning 0.014 GB of validation data: 0.049 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61035, val loss: 0.61031, in 0.153s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54238, val loss: 0.54239, in 0.137s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48524, val loss: 0.48501, in 0.114s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43670, val loss: 0.43641, in 0.101s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.39523, val loss: 0.39494, in 0.109s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35949, val loss: 0.35902, in 0.124s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32831, val loss: 0.32794, in 0.120s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30101, val loss: 0.30050, in 0.141s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27653, val loss: 0.27597, in 0.110s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25482, val loss: 0.25418, in 0.156s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23566, val loss: 0.23497, in 0.141s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21893, val loss: 0.21818, in 0.149s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20326, val loss: 0.20237, in 0.111s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18931, val loss: 0.18833, in 0.200s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17689, val loss: 0.17582, in 0.145s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16551, val loss: 0.16452, in 0.133s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15542, val loss: 0.15446, in 0.120s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14650, val loss: 0.14561, in 0.133s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13823, val loss: 0.13746, in 0.114s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13038, val loss: 0.12962, in 0.128s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12323, val loss: 0.12258, in 0.125s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11671, val loss: 0.11603, in 0.139s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11039, val loss: 0.10969, in 0.105s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10430, val loss: 0.10367, in 0.136s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09898, val loss: 0.09831, in 0.142s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09400, val loss: 0.09337, in 0.123s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08903, val loss: 0.08845, in 0.127s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08396, val loss: 0.08342, in 0.112s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08037, val loss: 0.07989, in 0.120s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07591, val loss: 0.07540, in 0.136s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07196, val loss: 0.07151, in 0.108s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06866, val loss: 0.06823, in 0.132s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06531, val loss: 0.06495, in 0.144s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06210, val loss: 0.06181, in 0.127s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05971, val loss: 0.05934, in 0.133s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05711, val loss: 0.05673, in 0.119s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05456, val loss: 0.05418, in 0.142s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05214, val loss: 0.05190, in 0.144s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05029, val loss: 0.05010, in 0.196s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04823, val loss: 0.04804, in 0.391s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04639, val loss: 0.04620, in 0.352s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04465, val loss: 0.04445, in 0.371s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04255, val loss: 0.04238, in 0.420s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04107, val loss: 0.04093, in 0.508s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03929, val loss: 0.03920, in 0.306s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03770, val loss: 0.03764, in 0.400s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03630, in 0.507s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03478, val loss: 0.03472, in 0.330s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03349, val loss: 0.03344, in 0.498s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03149, in 0.353s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.02989, in 0.419s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.02884, in 0.738s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02807, val loss: 0.02809, in 0.507s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02698, val loss: 0.02701, in 0.488s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02587, val loss: 0.02594, in 0.325s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02503, val loss: 0.02511, in 0.387s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02384, val loss: 0.02394, in 0.538s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02299, in 0.453s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02207, val loss: 0.02221, in 0.407s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02138, val loss: 0.02154, in 0.457s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02066, val loss: 0.02079, in 0.447s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02009, in 0.879s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.01949, in 0.455s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01872, val loss: 0.01892, in 0.402s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01815, val loss: 0.01834, in 0.642s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01769, in 0.405s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01698, in 0.351s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01652, in 0.417s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01604, in 0.502s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01530, val loss: 0.01551, in 0.452s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01490, val loss: 0.01511, in 0.472s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01456, in 0.450s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01413, in 0.471s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01379, in 0.334s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01322, val loss: 0.01351, in 0.461s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01315, in 0.365s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01254, val loss: 0.01283, in 0.479s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01225, val loss: 0.01258, in 0.537s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01194, val loss: 0.01226, in 0.274s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01159, val loss: 0.01189, in 0.404s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01163, in 0.397s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01106, val loss: 0.01136, in 0.329s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01115, in 0.416s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01056, val loss: 0.01085, in 0.329s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01033, val loss: 0.01060, in 0.327s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01034, in 0.454s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01009, in 0.400s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00987, in 0.323s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00968, in 0.421s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00947, in 0.324s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00923, in 0.478s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00913, in 0.446s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00894, in 0.329s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00871, in 0.500s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00821, val loss: 0.00847, in 0.547s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00811, val loss: 0.00837, in 0.253s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00814, in 0.649s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00777, val loss: 0.00803, in 0.494s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00758, val loss: 0.00784, in 0.452s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00739, val loss: 0.00766, in 0.367s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00754, in 0.302s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00713, val loss: 0.00742, in 0.533s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00725, in 1.025s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00707, in 0.488s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00665, val loss: 0.00694, in 0.338s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00681, in 3.396s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00669, in 3.612s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00653, in 3.349s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00639, in 2.528s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00595, val loss: 0.00624, in 3.190s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00583, val loss: 0.00612, in 0.890s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00602, in 0.671s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00594, in 0.758s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00582, in 1.072s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00567, in 0.778s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00556, in 0.908s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00545, in 0.897s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00535, in 0.802s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00527, in 0.595s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00518, in 0.920s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00478, val loss: 0.00511, in 0.843s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00502, in 2.446s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00496, in 3.719s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00486, in 2.290s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00441, val loss: 0.00476, in 2.899s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00469, in 2.279s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00426, val loss: 0.00462, in 2.185s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00455, in 2.646s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00446, in 1.140s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00442, in 2.083s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00438, in 0.695s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00393, val loss: 0.00431, in 0.452s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00421, in 0.578s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00376, val loss: 0.00412, in 0.535s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00408, in 0.654s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00365, val loss: 0.00401, in 0.459s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00397, in 0.301s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00355, val loss: 0.00391, in 0.821s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00387, in 1.101s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00380, in 1.414s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00373, in 0.989s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00367, in 1.066s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00323, val loss: 0.00361, in 1.288s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00316, val loss: 0.00354, in 0.786s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00309, val loss: 0.00347, in 0.967s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00342, in 0.794s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00335, in 2.017s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00329, in 2.002s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00324, in 1.470s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00320, in 0.451s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00316, in 0.498s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00311, in 0.505s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00307, in 0.375s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00303, in 0.543s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00258, val loss: 0.00298, in 0.497s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00252, val loss: 0.00292, in 0.539s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00288, in 0.368s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00244, val loss: 0.00284, in 0.275s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00240, val loss: 0.00280, in 0.352s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00276, in 0.358s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00273, in 0.289s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00269, in 0.227s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00265, in 0.150s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00260, in 0.178s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00217, val loss: 0.00257, in 0.218s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00214, val loss: 0.00254, in 0.148s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00251, in 0.189s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00248, in 0.116s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00244, in 0.222s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00242, in 0.114s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00238, in 0.108s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00235, in 0.153s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00192, val loss: 0.00232, in 0.200s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00229, in 0.134s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00186, val loss: 0.00225, in 0.116s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00223, in 0.118s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00220, in 0.176s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00178, val loss: 0.00217, in 0.134s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00176, val loss: 0.00215, in 0.139s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00213, in 0.121s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00210, in 0.129s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00208, in 0.121s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00205, in 0.145s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00203, in 0.136s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00200, in 0.116s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00198, in 0.105s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00156, val loss: 0.00197, in 0.140s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00153, val loss: 0.00194, in 0.098s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00192, in 0.241s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00191, in 0.172s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00188, in 0.173s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00186, in 0.125s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00142, val loss: 0.00183, in 0.257s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00182, in 0.139s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00180, in 0.153s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00178, in 0.181s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00177, in 0.457s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00175, in 0.337s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00173, in 0.224s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00172, in 0.230s\n",
      "Fit 200 trees in 117.057 s, (6200 total leaves)\n",
      "Time spent computing histograms: 48.070s\n",
      "Time spent finding best splits:  20.141s\n",
      "Time spent applying splits:      28.142s\n",
      "Time spent predicting:           1.049s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69771\n",
      "           1       0.35      0.16      0.22        43\n",
      "\n",
      "    accuracy                           1.00     69814\n",
      "   macro avg       0.67      0.58      0.61     69814\n",
      "weighted avg       1.00      1.00      1.00     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8712\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9993\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.2222\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n",
      "Binning 0.124 GB of training data: 1.744 s\n",
      "Binning 0.014 GB of validation data: 0.047 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61035, val loss: 0.61031, in 0.117s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54238, val loss: 0.54239, in 0.172s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48524, val loss: 0.48501, in 0.122s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43670, val loss: 0.43641, in 0.131s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.39523, val loss: 0.39494, in 0.146s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35949, val loss: 0.35902, in 0.168s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32831, val loss: 0.32794, in 0.136s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30101, val loss: 0.30050, in 0.120s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27653, val loss: 0.27597, in 0.142s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25482, val loss: 0.25418, in 0.154s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23566, val loss: 0.23497, in 0.172s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21893, val loss: 0.21818, in 0.139s\n",
      "[13/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20326, val loss: 0.20237, in 0.172s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18931, val loss: 0.18833, in 0.145s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17689, val loss: 0.17582, in 0.182s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16551, val loss: 0.16452, in 0.170s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15542, val loss: 0.15446, in 0.170s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14650, val loss: 0.14561, in 0.190s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13823, val loss: 0.13746, in 0.270s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13038, val loss: 0.12962, in 0.180s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12323, val loss: 0.12258, in 0.150s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11671, val loss: 0.11603, in 0.154s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11039, val loss: 0.10969, in 0.158s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10430, val loss: 0.10367, in 0.241s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09898, val loss: 0.09831, in 0.133s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09400, val loss: 0.09337, in 0.125s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08903, val loss: 0.08845, in 0.151s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08396, val loss: 0.08342, in 0.173s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08037, val loss: 0.07989, in 0.139s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07591, val loss: 0.07540, in 0.132s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07196, val loss: 0.07151, in 0.158s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06866, val loss: 0.06823, in 0.184s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06531, val loss: 0.06495, in 0.138s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06210, val loss: 0.06181, in 0.142s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05971, val loss: 0.05934, in 0.156s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05711, val loss: 0.05673, in 0.130s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05456, val loss: 0.05418, in 0.144s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05214, val loss: 0.05190, in 0.160s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05029, val loss: 0.05010, in 0.167s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04823, val loss: 0.04804, in 0.199s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04639, val loss: 0.04620, in 0.169s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04465, val loss: 0.04445, in 0.282s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04255, val loss: 0.04238, in 0.228s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04107, val loss: 0.04093, in 0.171s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03929, val loss: 0.03920, in 0.136s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03770, val loss: 0.03764, in 0.104s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03630, in 0.116s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03478, val loss: 0.03472, in 0.154s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03349, val loss: 0.03344, in 0.114s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03149, in 0.126s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.02989, in 0.129s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.02884, in 0.142s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02807, val loss: 0.02809, in 0.113s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02698, val loss: 0.02701, in 0.124s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02587, val loss: 0.02594, in 0.143s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02503, val loss: 0.02511, in 0.211s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02384, val loss: 0.02394, in 0.304s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02299, in 0.196s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02207, val loss: 0.02221, in 0.185s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02138, val loss: 0.02154, in 0.184s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02066, val loss: 0.02079, in 0.140s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02009, in 0.100s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.01949, in 0.118s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01872, val loss: 0.01892, in 0.169s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01815, val loss: 0.01834, in 0.108s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01769, in 0.142s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01698, in 0.116s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01652, in 0.151s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01604, in 0.118s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01530, val loss: 0.01551, in 0.114s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01490, val loss: 0.01511, in 0.117s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01456, in 0.144s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01413, in 0.137s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01379, in 0.152s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01322, val loss: 0.01351, in 0.113s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01315, in 0.164s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01254, val loss: 0.01283, in 0.100s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01225, val loss: 0.01258, in 0.137s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01194, val loss: 0.01226, in 0.134s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01159, val loss: 0.01189, in 0.123s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01163, in 0.139s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01106, val loss: 0.01136, in 0.117s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01115, in 0.136s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01056, val loss: 0.01085, in 0.133s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01033, val loss: 0.01060, in 0.106s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01034, in 0.180s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01009, in 0.230s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00987, in 0.134s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00968, in 0.142s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00947, in 0.136s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00923, in 0.171s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00913, in 0.137s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00894, in 0.201s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00871, in 0.166s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00821, val loss: 0.00847, in 0.178s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00811, val loss: 0.00837, in 0.167s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00814, in 0.155s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00777, val loss: 0.00803, in 0.101s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00758, val loss: 0.00784, in 0.156s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00739, val loss: 0.00766, in 0.147s\n",
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00754, in 0.108s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00713, val loss: 0.00742, in 0.190s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00725, in 0.203s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00707, in 0.371s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00665, val loss: 0.00694, in 0.171s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00681, in 0.125s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00669, in 0.177s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00653, in 0.270s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00639, in 0.165s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00595, val loss: 0.00624, in 0.162s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00583, val loss: 0.00612, in 0.125s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00602, in 0.149s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00594, in 0.337s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00582, in 0.153s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00567, in 0.223s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00556, in 0.126s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00545, in 0.136s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00535, in 0.092s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00527, in 0.119s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00518, in 0.429s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00478, val loss: 0.00511, in 0.095s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00502, in 0.125s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00496, in 0.119s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00486, in 0.119s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00441, val loss: 0.00476, in 0.098s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00469, in 0.103s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00426, val loss: 0.00462, in 0.129s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00455, in 0.127s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00446, in 0.126s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00442, in 0.105s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00438, in 0.121s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00393, val loss: 0.00431, in 0.139s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00421, in 0.127s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00376, val loss: 0.00412, in 0.114s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00408, in 0.115s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00365, val loss: 0.00401, in 0.142s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00397, in 0.094s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00355, val loss: 0.00391, in 0.116s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00387, in 0.115s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00380, in 0.162s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00373, in 0.127s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00367, in 0.140s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00323, val loss: 0.00361, in 0.146s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00316, val loss: 0.00354, in 0.128s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00309, val loss: 0.00347, in 0.123s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00342, in 0.129s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00335, in 0.132s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00329, in 0.173s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00324, in 0.141s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00320, in 0.133s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00316, in 0.144s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00311, in 0.131s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00307, in 0.154s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00303, in 0.123s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00258, val loss: 0.00298, in 0.131s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00252, val loss: 0.00292, in 0.137s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00288, in 0.130s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00244, val loss: 0.00284, in 0.149s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00240, val loss: 0.00280, in 0.325s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00276, in 0.142s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00273, in 0.128s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00269, in 0.113s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00265, in 0.098s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00260, in 0.108s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00217, val loss: 0.00257, in 0.115s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00214, val loss: 0.00254, in 0.116s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00251, in 0.122s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00248, in 0.104s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00244, in 0.109s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00242, in 0.089s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00238, in 0.107s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00235, in 0.189s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00192, val loss: 0.00232, in 0.146s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00229, in 0.102s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00186, val loss: 0.00225, in 0.120s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00223, in 0.093s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00220, in 0.123s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00178, val loss: 0.00217, in 0.150s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00176, val loss: 0.00215, in 0.147s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00213, in 0.122s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00210, in 0.117s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00208, in 0.151s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00205, in 0.165s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00203, in 0.125s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00200, in 0.095s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00198, in 0.126s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00156, val loss: 0.00197, in 0.125s\n",
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00153, val loss: 0.00194, in 0.112s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00192, in 0.120s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00191, in 0.129s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00188, in 0.120s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00186, in 0.114s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00142, val loss: 0.00183, in 0.129s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00182, in 0.128s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00180, in 0.146s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00178, in 0.201s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00177, in 0.116s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00175, in 0.127s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00173, in 0.121s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00172, in 0.137s\n",
      "Fit 200 trees in 32.296 s, (6200 total leaves)\n",
      "Time spent computing histograms: 14.120s\n",
      "Time spent finding best splits:  1.632s\n",
      "Time spent applying splits:      4.686s\n",
      "Time spent predicting:           0.401s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69771\n",
      "           1       0.35      0.16      0.22        43\n",
      "\n",
      "    accuracy                           1.00     69814\n",
      "   macro avg       0.67      0.58      0.61     69814\n",
      "weighted avg       1.00      1.00      1.00     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.8712\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9993\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.2222\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON Gradient Boosting Classifier's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_GBC__learning_rate': 0.1, 'clf_GBC__max_depth': 10, 'clf_GBC__min_samples_leaf': 1}\n",
      "Binning 0.124 GB of training data: 1.523 s\n",
      "Binning 0.014 GB of validation data: 0.058 s\n",
      "Fitting gradient boosted rounds:\n",
      "[1/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.61035, val loss: 0.61031, in 0.113s\n",
      "[2/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.54238, val loss: 0.54239, in 0.374s\n",
      "[3/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.48524, val loss: 0.48501, in 0.454s\n",
      "[4/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.43670, val loss: 0.43641, in 0.322s\n",
      "[5/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.39523, val loss: 0.39494, in 0.351s\n",
      "[6/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.35949, val loss: 0.35902, in 0.432s\n",
      "[7/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.32831, val loss: 0.32794, in 0.287s\n",
      "[8/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.30101, val loss: 0.30050, in 0.403s\n",
      "[9/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.27653, val loss: 0.27597, in 0.348s\n",
      "[10/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.25482, val loss: 0.25418, in 0.452s\n",
      "[11/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.23566, val loss: 0.23497, in 0.548s\n",
      "[12/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.21893, val loss: 0.21818, in 0.503s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.20326, val loss: 0.20237, in 0.429s\n",
      "[14/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.18931, val loss: 0.18833, in 0.344s\n",
      "[15/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.17689, val loss: 0.17582, in 0.429s\n",
      "[16/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.16551, val loss: 0.16452, in 0.451s\n",
      "[17/200] 1 tree, 31 leaves, max depth = 7, train loss: 0.15542, val loss: 0.15446, in 0.406s\n",
      "[18/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.14650, val loss: 0.14561, in 0.355s\n",
      "[19/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.13823, val loss: 0.13746, in 0.447s\n",
      "[20/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.13038, val loss: 0.12962, in 0.416s\n",
      "[21/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.12323, val loss: 0.12258, in 0.371s\n",
      "[22/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.11671, val loss: 0.11603, in 0.422s\n",
      "[23/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.11039, val loss: 0.10969, in 0.669s\n",
      "[24/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.10430, val loss: 0.10367, in 0.500s\n",
      "[25/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.09898, val loss: 0.09831, in 0.406s\n",
      "[26/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.09400, val loss: 0.09337, in 0.314s\n",
      "[27/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08903, val loss: 0.08845, in 0.417s\n",
      "[28/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08396, val loss: 0.08342, in 0.567s\n",
      "[29/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.08037, val loss: 0.07989, in 0.356s\n",
      "[30/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07591, val loss: 0.07540, in 0.556s\n",
      "[31/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.07196, val loss: 0.07151, in 0.638s\n",
      "[32/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06866, val loss: 0.06823, in 0.451s\n",
      "[33/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06531, val loss: 0.06495, in 0.443s\n",
      "[34/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.06210, val loss: 0.06181, in 0.471s\n",
      "[35/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05971, val loss: 0.05934, in 0.284s\n",
      "[36/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05711, val loss: 0.05673, in 0.212s\n",
      "[37/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.05456, val loss: 0.05418, in 1.094s\n",
      "[38/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05214, val loss: 0.05190, in 0.621s\n",
      "[39/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.05029, val loss: 0.05010, in 0.346s\n",
      "[40/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04823, val loss: 0.04804, in 0.339s\n",
      "[41/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04639, val loss: 0.04620, in 0.358s\n",
      "[42/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04465, val loss: 0.04445, in 0.492s\n",
      "[43/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04255, val loss: 0.04238, in 0.442s\n",
      "[44/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.04107, val loss: 0.04093, in 0.294s\n",
      "[45/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03929, val loss: 0.03920, in 0.428s\n",
      "[46/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03770, val loss: 0.03764, in 0.398s\n",
      "[47/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03633, val loss: 0.03630, in 0.297s\n",
      "[48/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03478, val loss: 0.03472, in 1.741s\n",
      "[49/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03349, val loss: 0.03344, in 0.991s\n",
      "[50/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.03151, val loss: 0.03149, in 0.263s\n",
      "[51/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02989, val loss: 0.02989, in 0.231s\n",
      "[52/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02883, val loss: 0.02884, in 0.204s\n",
      "[53/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02807, val loss: 0.02809, in 0.178s\n",
      "[54/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02698, val loss: 0.02701, in 0.217s\n",
      "[55/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02587, val loss: 0.02594, in 0.323s\n",
      "[56/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02503, val loss: 0.02511, in 0.289s\n",
      "[57/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02384, val loss: 0.02394, in 0.293s\n",
      "[58/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02288, val loss: 0.02299, in 0.194s\n",
      "[59/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02207, val loss: 0.02221, in 0.176s\n",
      "[60/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02138, val loss: 0.02154, in 0.273s\n",
      "[61/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.02066, val loss: 0.02079, in 0.199s\n",
      "[62/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01996, val loss: 0.02009, in 0.180s\n",
      "[63/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01932, val loss: 0.01949, in 0.221s\n",
      "[64/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01872, val loss: 0.01892, in 0.215s\n",
      "[65/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01815, val loss: 0.01834, in 0.336s\n",
      "[66/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01750, val loss: 0.01769, in 0.179s\n",
      "[67/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01678, val loss: 0.01698, in 0.201s\n",
      "[68/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01632, val loss: 0.01652, in 0.200s\n",
      "[69/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01582, val loss: 0.01604, in 0.230s\n",
      "[70/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01530, val loss: 0.01551, in 0.169s\n",
      "[71/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01490, val loss: 0.01511, in 0.219s\n",
      "[72/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01433, val loss: 0.01456, in 0.222s\n",
      "[73/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01388, val loss: 0.01413, in 0.328s\n",
      "[74/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01351, val loss: 0.01379, in 0.217s\n",
      "[75/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01322, val loss: 0.01351, in 0.184s\n",
      "[76/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01284, val loss: 0.01315, in 0.225s\n",
      "[77/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01254, val loss: 0.01283, in 0.197s\n",
      "[78/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01225, val loss: 0.01258, in 0.326s\n",
      "[79/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01194, val loss: 0.01226, in 0.176s\n",
      "[80/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01159, val loss: 0.01189, in 0.203s\n",
      "[81/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01134, val loss: 0.01163, in 0.201s\n",
      "[82/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01106, val loss: 0.01136, in 0.225s\n",
      "[83/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01084, val loss: 0.01115, in 0.175s\n",
      "[84/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01056, val loss: 0.01085, in 0.201s\n",
      "[85/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01033, val loss: 0.01060, in 0.428s\n",
      "[86/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.01005, val loss: 0.01034, in 0.409s\n",
      "[87/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00981, val loss: 0.01009, in 0.345s\n",
      "[88/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00959, val loss: 0.00987, in 0.206s\n",
      "[89/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00940, val loss: 0.00968, in 0.284s\n",
      "[90/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00920, val loss: 0.00947, in 0.219s\n",
      "[91/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00897, val loss: 0.00923, in 0.238s\n",
      "[92/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00887, val loss: 0.00913, in 0.212s\n",
      "[93/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00869, val loss: 0.00894, in 0.247s\n",
      "[94/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00845, val loss: 0.00871, in 0.637s\n",
      "[95/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00821, val loss: 0.00847, in 0.392s\n",
      "[96/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00811, val loss: 0.00837, in 0.179s\n",
      "[97/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00790, val loss: 0.00814, in 0.319s\n",
      "[98/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00777, val loss: 0.00803, in 0.205s\n",
      "[99/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00758, val loss: 0.00784, in 0.217s\n",
      "[100/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00739, val loss: 0.00766, in 0.230s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[101/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00726, val loss: 0.00754, in 0.220s\n",
      "[102/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00713, val loss: 0.00742, in 0.176s\n",
      "[103/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00697, val loss: 0.00725, in 0.457s\n",
      "[104/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00678, val loss: 0.00707, in 0.300s\n",
      "[105/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00665, val loss: 0.00694, in 0.218s\n",
      "[106/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00652, val loss: 0.00681, in 0.233s\n",
      "[107/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00640, val loss: 0.00669, in 0.204s\n",
      "[108/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00624, val loss: 0.00653, in 0.665s\n",
      "[109/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00610, val loss: 0.00639, in 0.345s\n",
      "[110/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00595, val loss: 0.00624, in 0.310s\n",
      "[111/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00583, val loss: 0.00612, in 0.235s\n",
      "[112/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00572, val loss: 0.00602, in 0.263s\n",
      "[113/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00562, val loss: 0.00594, in 0.236s\n",
      "[114/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00550, val loss: 0.00582, in 0.350s\n",
      "[115/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00535, val loss: 0.00567, in 0.333s\n",
      "[116/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00524, val loss: 0.00556, in 0.249s\n",
      "[117/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00512, val loss: 0.00545, in 0.362s\n",
      "[118/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00503, val loss: 0.00535, in 0.258s\n",
      "[119/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00495, val loss: 0.00527, in 0.290s\n",
      "[120/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00487, val loss: 0.00518, in 0.271s\n",
      "[121/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00478, val loss: 0.00511, in 0.325s\n",
      "[122/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00469, val loss: 0.00502, in 0.304s\n",
      "[123/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00463, val loss: 0.00496, in 0.237s\n",
      "[124/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00452, val loss: 0.00486, in 0.301s\n",
      "[125/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00441, val loss: 0.00476, in 0.271s\n",
      "[126/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00435, val loss: 0.00469, in 0.279s\n",
      "[127/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00426, val loss: 0.00462, in 0.238s\n",
      "[128/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00419, val loss: 0.00455, in 0.241s\n",
      "[129/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00410, val loss: 0.00446, in 0.241s\n",
      "[130/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00406, val loss: 0.00442, in 0.240s\n",
      "[131/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00401, val loss: 0.00438, in 0.237s\n",
      "[132/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00393, val loss: 0.00431, in 0.215s\n",
      "[133/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00384, val loss: 0.00421, in 0.226s\n",
      "[134/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00376, val loss: 0.00412, in 0.206s\n",
      "[135/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00371, val loss: 0.00408, in 0.152s\n",
      "[136/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00365, val loss: 0.00401, in 0.221s\n",
      "[137/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00361, val loss: 0.00397, in 0.297s\n",
      "[138/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00355, val loss: 0.00391, in 0.218s\n",
      "[139/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00351, val loss: 0.00387, in 0.184s\n",
      "[140/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00343, val loss: 0.00380, in 0.255s\n",
      "[141/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00336, val loss: 0.00373, in 0.223s\n",
      "[142/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00330, val loss: 0.00367, in 0.199s\n",
      "[143/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00323, val loss: 0.00361, in 0.228s\n",
      "[144/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00316, val loss: 0.00354, in 0.195s\n",
      "[145/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00309, val loss: 0.00347, in 0.254s\n",
      "[146/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00303, val loss: 0.00342, in 0.186s\n",
      "[147/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00297, val loss: 0.00335, in 0.212s\n",
      "[148/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00291, val loss: 0.00329, in 0.193s\n",
      "[149/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00285, val loss: 0.00324, in 0.239s\n",
      "[150/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00280, val loss: 0.00320, in 0.201s\n",
      "[151/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00276, val loss: 0.00316, in 0.180s\n",
      "[152/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00272, val loss: 0.00311, in 0.226s\n",
      "[153/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00267, val loss: 0.00307, in 0.206s\n",
      "[154/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00263, val loss: 0.00303, in 0.181s\n",
      "[155/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00258, val loss: 0.00298, in 0.219s\n",
      "[156/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00252, val loss: 0.00292, in 0.210s\n",
      "[157/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00248, val loss: 0.00288, in 0.320s\n",
      "[158/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00244, val loss: 0.00284, in 0.236s\n",
      "[159/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00240, val loss: 0.00280, in 0.574s\n",
      "[160/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00236, val loss: 0.00276, in 0.192s\n",
      "[161/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00233, val loss: 0.00273, in 0.210s\n",
      "[162/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00229, val loss: 0.00269, in 0.181s\n",
      "[163/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00224, val loss: 0.00265, in 0.162s\n",
      "[164/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00220, val loss: 0.00260, in 0.174s\n",
      "[165/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00217, val loss: 0.00257, in 0.180s\n",
      "[166/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00214, val loss: 0.00254, in 0.148s\n",
      "[167/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00211, val loss: 0.00251, in 0.186s\n",
      "[168/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00208, val loss: 0.00248, in 0.180s\n",
      "[169/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00205, val loss: 0.00244, in 0.190s\n",
      "[170/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00203, val loss: 0.00242, in 0.236s\n",
      "[171/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00199, val loss: 0.00238, in 0.178s\n",
      "[172/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00196, val loss: 0.00235, in 0.172s\n",
      "[173/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00192, val loss: 0.00232, in 0.180s\n",
      "[174/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00189, val loss: 0.00229, in 0.171s\n",
      "[175/200] 1 tree, 31 leaves, max depth = 8, train loss: 0.00186, val loss: 0.00225, in 0.175s\n",
      "[176/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00184, val loss: 0.00223, in 0.151s\n",
      "[177/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00181, val loss: 0.00220, in 0.178s\n",
      "[178/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00178, val loss: 0.00217, in 0.172s\n",
      "[179/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00176, val loss: 0.00215, in 0.193s\n",
      "[180/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00173, val loss: 0.00213, in 0.178s\n",
      "[181/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00171, val loss: 0.00210, in 0.136s\n",
      "[182/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00168, val loss: 0.00208, in 0.184s\n",
      "[183/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00165, val loss: 0.00205, in 0.167s\n",
      "[184/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00163, val loss: 0.00203, in 0.158s\n",
      "[185/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00160, val loss: 0.00200, in 0.164s\n",
      "[186/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00158, val loss: 0.00198, in 0.155s\n",
      "[187/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00156, val loss: 0.00197, in 0.165s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[188/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00153, val loss: 0.00194, in 0.141s\n",
      "[189/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00151, val loss: 0.00192, in 0.154s\n",
      "[190/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00149, val loss: 0.00191, in 0.165s\n",
      "[191/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00147, val loss: 0.00188, in 0.126s\n",
      "[192/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00145, val loss: 0.00186, in 0.136s\n",
      "[193/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00142, val loss: 0.00183, in 0.200s\n",
      "[194/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00140, val loss: 0.00182, in 0.144s\n",
      "[195/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00138, val loss: 0.00180, in 0.185s\n",
      "[196/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00136, val loss: 0.00178, in 0.161s\n",
      "[197/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00134, val loss: 0.00177, in 0.166s\n",
      "[198/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00132, val loss: 0.00175, in 0.201s\n",
      "[199/200] 1 tree, 31 leaves, max depth = 9, train loss: 0.00131, val loss: 0.00173, in 0.149s\n",
      "[200/200] 1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00172, in 0.171s\n",
      "Fit 200 trees in 60.428 s, (6200 total leaves)\n",
      "Time spent computing histograms: 26.524s\n",
      "Time spent finding best splits:  7.807s\n",
      "Time spent applying splits:      12.032s\n",
      "Time spent predicting:           0.551s\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     69771\n",
      "           1       0.35      0.16      0.22        43\n",
      "\n",
      "    accuracy                           1.00     69814\n",
      "   macro avg       0.67      0.58      0.61     69814\n",
      "weighted avg       1.00      1.00      1.00     69814\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.8712\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.9993\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.2222\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00128, val loss: 0.00151, in 0.563s\n",
      "Fit 200 trees in 92.455 s, (6200 total leaves)\n",
      "Time spent computing histograms: 53.412s\n",
      "Time spent finding best splits:  1.730s\n",
      "Time spent applying splits:      11.334s\n",
      "Time spent predicting:           0.705s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00137, val loss: 0.00161, in 0.490s\n",
      "Fit 200 trees in 91.581 s, (6200 total leaves)\n",
      "Time spent computing histograms: 53.736s\n",
      "Time spent finding best splits:  1.624s\n",
      "Time spent applying splits:      11.473s\n",
      "Time spent predicting:           0.723s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00155, in 0.503s\n",
      "Fit 200 trees in 92.289 s, (6200 total leaves)\n",
      "Time spent computing histograms: 53.521s\n",
      "Time spent finding best splits:  1.655s\n",
      "Time spent applying splits:      11.290s\n",
      "Time spent predicting:           0.645s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00129, val loss: 0.00156, in 0.514s\n",
      "Fit 200 trees in 92.141 s, (6200 total leaves)\n",
      "Time spent computing histograms: 54.780s\n",
      "Time spent finding best splits:  1.565s\n",
      "Time spent applying splits:      10.819s\n",
      "Time spent predicting:           0.792s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00120, val loss: 0.00166, in 0.251s\n",
      "Fit 200 trees in 75.801 s, (6199 total leaves)\n",
      "Time spent computing histograms: 40.792s\n",
      "Time spent finding best splits:  1.223s\n",
      "Time spent applying splits:      8.052s\n",
      "Time spent predicting:           0.449s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00126, val loss: 0.00169, in 0.285s\n",
      "Fit 200 trees in 75.313 s, (6198 total leaves)\n",
      "Time spent computing histograms: 39.985s\n",
      "Time spent finding best splits:  1.141s\n",
      "Time spent applying splits:      7.954s\n",
      "Time spent predicting:           0.488s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00121, val loss: 0.00148, in 0.259s\n",
      "Fit 200 trees in 74.336 s, (6200 total leaves)\n",
      "Time spent computing histograms: 39.283s\n",
      "Time spent finding best splits:  1.351s\n",
      "Time spent applying splits:      8.060s\n",
      "Time spent predicting:           0.503s\n",
      "1 tree, 31 leaves, max depth = 10, train loss: 0.00113, val loss: 0.00140, in 0.368s\n",
      "Fit 200 trees in 73.367 s, (6200 total leaves)\n",
      "Time spent computing histograms: 38.072s\n",
      "Time spent finding best splits:  1.148s\n",
      "Time spent applying splits:      7.844s\n",
      "Time spent predicting:           0.439s\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "# class sklearn.ensemble.GradientBoostingClassifier(*, loss='log_loss', learning_rate=0.1, n_estimators=100, subsample=1.0, criterion='friedman_mse', min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_depth=3, min_impurity_decrease=0.0, init=None, random_state=None, max_features=None, verbose=0, max_leaf_nodes=None, warm_start=False, validation_fraction=0.1, n_iter_no_change=None, tol=0.0001, ccp_alpha=0.0)\n",
    "clf_GBC = HistGradientBoostingClassifier(\n",
    "    loss='log_loss',\n",
    "    learning_rate=0.05,\n",
    "    max_iter=200,\n",
    "    max_leaf_nodes=31,\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=1,\n",
    "    l2_regularization=1.0,\n",
    "    max_bins=255,\n",
    "    categorical_features=None,\n",
    "    early_stopping='auto',\n",
    "    validation_fraction=0.1,\n",
    "    n_iter_no_change=10,\n",
    "    tol=1e-7,\n",
    "    verbose=1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# estimator details for GradientBoostingr.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_GBC_pipeline = Pipeline([\n",
    "    ('clf_GBC', \n",
    "     clf_GBC) # GradientBoostingClassifier\n",
    "])\n",
    "\n",
    "# Parameter details for GradientBoostingr.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_GBC_param_grid = {\n",
    "    # The number of boosting stages to perform. Gradient boosting is fairly robust to over-fitting so a large number usually results in better performance. Values must be in the range [1, inf).\n",
    "#     'clf_GBC__n_estimators': [50, \n",
    "#                               100], \n",
    "    # Learning rate shrinks the contribution of each tree by learning_rate.\n",
    "    'clf_GBC__learning_rate': [0.05,\n",
    "                               0.1],\n",
    "    # Maximum depth of the individual regression estimators. \n",
    "    'clf_GBC__max_depth': [3, \n",
    "                           10],  \n",
    "    # The minimum number of samples required to split an internal node.\n",
    "#     'clf_GBC__min_samples_split': [2, \n",
    "#                                    5], \n",
    "    # The minimum number of samples required to be at a leaf node.\n",
    "    'clf_GBC__min_samples_leaf': [1, \n",
    "                                  3]  \n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_GBC_pipeline,\n",
    "                                   param_grid=clf_GBC_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                    y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST AOC-RUC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_GBC_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_GBC_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON Gradient Boosting Classifier's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_GBC_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                       y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f03914",
   "metadata": {},
   "source": [
    "# Model-5: SVC (AUC ROC + Accurcay + F1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a130643",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Python(82868) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82869) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82870) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82872) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82873) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82874) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82875) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n",
      "Python(82876) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.154985, rho = -0.947447\n",
      "nSV = 3118, nBSV = 2998\n",
      "Total nSV = 3118\n",
      "WARN: libsvm Solver reached max_iterobj = -31.140452, rho = -0.873834\n",
      "nSV = 3120, nBSV = 2999\n",
      "Total nSV = 3120\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.122895, rho = -0.903247\n",
      "nSV = 3116, nBSV = 3000\n",
      "Total nSV = 3116\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.315925, rho = -0.903027\n",
      "nSV = 3138, nBSV = 2999\n",
      "Total nSV = 3138\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.315883, rho = -0.893270\n",
      "nSV = 3139, nBSV = 2999\n",
      "Total nSV = 3139\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.291720, rho = -0.874234\n",
      "nSV = 3137, nBSV = 2999\n",
      "Total nSV = 3137\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.336428, rho = -0.937120\n",
      "nSV = 3138, nBSV = 2999\n",
      "Total nSV = 3138\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.174123, rho = -0.949433\n",
      "nSV = 3120, nBSV = 2998\n",
      "Total nSV = 3120\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.070783, rho = -0.899191\n",
      "nSV = 3112, nBSV = 2999\n",
      "Total nSV = 3112\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "WARN: libsvm Solver reached max_iterobj = -31.281173, rho = -0.934668\n",
      "nSV = 3132, nBSV = 3000\n",
      "Total nSV = 3132\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.158428, rho = -0.897618\n",
      "nSV = 3121, nBSV = 3000\n",
      "Total nSV = 3121\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.217806, rho = -0.882608\n",
      "nSV = 3129, nBSV = 2999\n",
      "Total nSV = 3129\n",
      "WARN: libsvm Solver reached max_iterWARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.966871, rho = -0.833369\n",
      "nSV = 3103, nBSV = 2999\n",
      "Total nSV = 3103\n",
      "obj = -31.177826, rho = -0.880112\n",
      "nSV = 3125, nBSV = 2999\n",
      "Total nSV = 3125\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.214709, rho = -0.885767\n",
      "nSV = 3128, nBSV = 3000\n",
      "Total nSV = 3128\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.415327, rho = -0.969107\n",
      "nSV = 3143, nBSV = 3000\n",
      "Total nSV = 3143\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.324092, rho = -0.960306\n",
      "nSV = 3136, nBSV = 2999\n",
      "Total nSV = 3136\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.927735, rho = -0.789905\n",
      "nSV = 3103, nBSV = 2998\n",
      "Total nSV = 3103\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.138602, rho = -0.811791\n",
      "nSV = 3125, nBSV = 3000\n",
      "Total nSV = 3125\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.319570, rho = -0.926060\n",
      "nSV = 3136, nBSV = 2999\n",
      "Total nSV = 3136\n",
      "WARN: libsvm Solver reached max_iterWARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.259677, rho = -0.848120\n",
      "nSV = 3134, nBSV = 3000\n",
      "Total nSV = 3134\n",
      "obj = -31.288331, rho = -0.866282\n",
      "nSV = 3136, nBSV = 3000\n",
      "Total nSV = 3136\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.480036, rho = -0.949524\n",
      "nSV = 3151, nBSV = 2999\n",
      "Total nSV = 3151\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.301501, rho = -0.865334\n",
      "nSV = 3139, nBSV = 3000\n",
      "Total nSV = 3139\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.137044, rho = -0.843748\n",
      "nSV = 3122, nBSV = 2999\n",
      "Total nSV = 3122\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.973672, rho = -0.965315\n",
      "nSV = 3099, nBSV = 2999\n",
      "Total nSV = 3099\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.017775, rho = -0.861574\n",
      "nSV = 3108, nBSV = 2999\n",
      "Total nSV = 3108\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.138307, rho = -0.870103\n",
      "nSV = 3122, nBSV = 3000\n",
      "Total nSV = 3122\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.380527, rho = -0.940587\n",
      "nSV = 3140, nBSV = 3000\n",
      "Total nSV = 3140\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.360950, rho = -0.872269\n",
      "nSV = 3144, nBSV = 3000\n",
      "Total nSV = 3144\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.101639, rho = -0.782810\n",
      "nSV = 3122, nBSV = 2999\n",
      "Total nSV = 3122\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.196630, rho = -0.853277\n",
      "nSV = 3128, nBSV = 2999\n",
      "Total nSV = 3128\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.990663, rho = -0.895948\n",
      "nSV = 3104, nBSV = 3000\n",
      "Total nSV = 3104\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.091200, rho = -0.885151\n",
      "nSV = 3115, nBSV = 2999\n",
      "Total nSV = 3115\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.133671, rho = -0.902698\n",
      "nSV = 3118, nBSV = 2997\n",
      "Total nSV = 3118\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.078421, rho = -0.853093\n",
      "nSV = 3114, nBSV = 3000\n",
      "Total nSV = 3114\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -30.984056, rho = -0.837880\n",
      "nSV = 3107, nBSV = 2999\n",
      "Total nSV = 3107\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.077399, rho = -0.860693\n",
      "nSV = 3115, nBSV = 3000\n",
      "Total nSV = 3115\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.135974, rho = -0.829961\n",
      "nSV = 3122, nBSV = 2998\n",
      "Total nSV = 3122\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.111358, rho = -0.835347\n",
      "nSV = 3120, nBSV = 3000\n",
      "Total nSV = 3120\n",
      "Line search fails in two-class probability estimates\n",
      "Line search fails in two-class probability estimates\n",
      "Line search fails in two-class probability estimates\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -47.323880, rho = 0.974169\n",
      "nSV = 4728, nBSV = 2510\n",
      "Total nSV = 4728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -52.023203, rho = 0.973251\n",
      "nSV = 5198, nBSV = 2676\n",
      "Total nSV = 5198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.132364, rho = 0.966231\n",
      "nSV = 5314, nBSV = 2872\n",
      "Total nSV = 5314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -48.750762, rho = 0.984215\n",
      "nSV = 4874, nBSV = 2880\n",
      "Total nSV = 4874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -52.379005, rho = 0.979206\n",
      "nSV = 5239, nBSV = 2782\n",
      "Total nSV = 5239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -51.374297, rho = 0.980264\n",
      "nSV = 5136, nBSV = 2781\n",
      "Total nSV = 5136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.354709, rho = 0.963959\n",
      "nSV = 5337, nBSV = 2885\n",
      "Total nSV = 5337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.643381, rho = 0.984450\n",
      "nSV = 5364, nBSV = 2939\n",
      "Total nSV = 5364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.025991, rho = -0.900319\n",
      "nSV = 3108, nBSV = 3000\n",
      "Total nSV = 3108\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.191661, rho = -0.841616\n",
      "nSV = 3127, nBSV = 2999\n",
      "Total nSV = 3127\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3092.886740, rho = -0.904086\n",
      "nSV = 3090, nBSV = 2987\n",
      "Total nSV = 3090\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3140.272956, rho = -0.645215\n",
      "nSV = 3156, nBSV = 2992\n",
      "Total nSV = 3156\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3168.846887, rho = -0.078190\n",
      "nSV = 3145, nBSV = 2988\n",
      "Total nSV = 3145\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3106.561198, rho = -0.369517\n",
      "nSV = 3110, nBSV = 2992\n",
      "Total nSV = 3110\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3070.366569, rho = -0.874580\n",
      "nSV = 3102, nBSV = 2987\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3106.681614, rho = -0.462757\n",
      "nSV = 3121, nBSV = 2989\n",
      "Total nSV = 3121\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.149135, rho = -0.863334\n",
      "nSV = 3123, nBSV = 3000\n",
      "Total nSV = 3123\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3131.753403, rho = -0.162810\n",
      "nSV = 3144, nBSV = 2988\n",
      "Total nSV = 3144\n",
      "WARN: libsvm Solver reached max_iterWARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3181.792150, rho = -0.510755\n",
      "nSV = 3177, nBSV = 2990\n",
      "Total nSV = 3177\n",
      "obj = -3020.220872, rho = -1.240042\n",
      "nSV = 3079, nBSV = 2993\n",
      "Total nSV = 3079\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "WARN: libsvm Solver reached max_iterobj = -3073.853258, rho = -0.504656\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "nSV = 3131, nBSV = 2993\n",
      "Total nSV = 3131\n",
      "obj = -3161.485092, rho = -0.576566\n",
      "nSV = 3167, nBSV = 2990\n",
      "Total nSV = 3167\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3175.345882, rho = -0.445477\n",
      "nSV = 3181, nBSV = 2990\n",
      "Total nSV = 3181\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.259175, rho = -0.840889\n",
      "nSV = 3135, nBSV = 3000\n",
      "Total nSV = 3135\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.175303, rho = -0.869970\n",
      "nSV = 3126, nBSV = 2998\n",
      "Total nSV = 3126\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3057.375540, rho = -0.942922\n",
      "nSV = 3085, nBSV = 2986\n",
      "Total nSV = 3085\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3107.015591, rho = -1.024865\n",
      "nSV = 3123, nBSV = 2996\n",
      "Total nSV = 3123\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3146.037146, rho = -0.839447\n",
      "nSV = 3151, nBSV = 2991\n",
      "Total nSV = 3151\n",
      "WARN: libsvm Solver reached max_iterWARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3138.908889, rho = -0.562847\n",
      "nSV = 3165, nBSV = 2994\n",
      "Total nSV = 3165\n",
      "obj = -3119.760795, rho = -0.577654\n",
      "nSV = 3128, nBSV = 2994\n",
      "Total nSV = 3128\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3133.231344, rho = -0.642966\n",
      "nSV = 3126, nBSV = 2989\n",
      "Total nSV = 3126\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.383154, rho = -0.863104\n",
      "nSV = 3147, nBSV = 3000\n",
      "Total nSV = 3147\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.066328, rho = -0.890337\n",
      "nSV = 3113, nBSV = 3000\n",
      "Total nSV = 3113\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3068.507936, rho = -0.646759\n",
      "nSV = 3090, nBSV = 2991\n",
      "Total nSV = 3090\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3123.894723, rho = -0.519969\n",
      "nSV = 3131, nBSV = 2990\n",
      "Total nSV = 3131\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3176.449638, rho = -0.414463\n",
      "nSV = 3168, nBSV = 2990\n",
      "Total nSV = 3168\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3177.431094, rho = -0.666145\n",
      "nSV = 3172, nBSV = 2992\n",
      "Total nSV = 3172\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3051.395421, rho = -0.923101\n",
      "nSV = 3065, nBSV = 2988\n",
      "Total nSV = 3065\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3106.150417, rho = -0.744219\n",
      "nSV = 3115, nBSV = 2995\n",
      "Total nSV = 3115\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.279920, rho = -0.908244\n",
      "nSV = 3132, nBSV = 2999\n",
      "Total nSV = 3132\n",
      "................WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.048833, rho = -0.907224\n",
      "nSV = 3111, nBSV = 3000\n",
      "Total nSV = 3111\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3092.635838, rho = -1.320117\n",
      "nSV = 3077, nBSV = 2990\n",
      "Total nSV = 3077\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3075.080741, rho = -0.983961\n",
      "nSV = 3077, nBSV = 2988\n",
      "Total nSV = 3077\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3070.534276, rho = -1.089284\n",
      "nSV = 3103, nBSV = 2991\n",
      "Total nSV = 3103\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -2994.115809, rho = -1.085295\n",
      "nSV = 3062, nBSV = 2986\n",
      "Total nSV = 3062\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3141.502964, rho = -0.584470\n",
      "nSV = 3082, nBSV = 2992\n",
      "Total nSV = 3082\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3087.213374, rho = -0.841677\n",
      "nSV = 3081, nBSV = 2988\n",
      "Total nSV = 3081\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.117708, rho = -0.937580\n",
      "nSV = 3116, nBSV = 3000\n",
      "Total nSV = 3116\n",
      "Line search fails in two-class probability estimates\n",
      "...............WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.243573, rho = 0.965756\n",
      "nSV = 5324, nBSV = 2866\n",
      "Total nSV = 5324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5595.242608, rho = -0.373429\n",
      "nSV = 5598, nBSV = 2995\n",
      "Total nSV = 5598\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5534.091100, rho = 0.237853\n",
      "WARN: libsvm Solver reached max_iternSV = 5522, nBSV = 2964\n",
      "Total nSV = 5522\n",
      "\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5576.928037, rho = -0.252848\n",
      "nSV = 5579, nBSV = 2971\n",
      "Total nSV = 5579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5524.953831, rho = -0.193930\n",
      "nSV = 5512, nBSV = 2963\n",
      "Total nSV = 5512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5552.997236, rho = -0.221845\n",
      "nSV = 5553, nBSV = 2973\n",
      "Total nSV = 5553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -53.098506, rho = 0.944072\n",
      "nSV = 5310, nBSV = 2794\n",
      "Total nSV = 5310\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5576.488838, rho = -0.232961\n",
      "nSV = 5578, nBSV = 2985\n",
      "Total nSV = 5578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]...[LibSVM][LibSVM]....WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3051.794594, rho = -0.921640\n",
      "nSV = 3123, nBSV = 2989\n",
      "Total nSV = 3123\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3117.101040, rho = -0.499073\n",
      "nSV = 3137, nBSV = 2992\n",
      "Total nSV = 3137\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3151.748733, rho = -0.702803\n",
      "nSV = 3162, nBSV = 2987\n",
      "Total nSV = 3162\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3172.275347, rho = -0.789957\n",
      "nSV = 3174, nBSV = 2987\n",
      "Total nSV = 3174\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3079.429919, rho = -0.761997\n",
      "nSV = 3102, nBSV = 2988\n",
      "Total nSV = 3102\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3079.756741, rho = -1.098641\n",
      "nSV = 3107, nBSV = 2990\n",
      "Total nSV = 3107\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3051.153699, rho = -0.862594\n",
      "nSV = 3092, nBSV = 2992\n",
      "Total nSV = 3092\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3171.172594, rho = -0.326527\n",
      "nSV = 3178, nBSV = 2983\n",
      "Total nSV = 3178\n",
      "........WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3114.257885, rho = -0.266319\n",
      "nSV = 3128, nBSV = 2989\n",
      "Total nSV = 3128\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3115.120624, rho = -0.674002\n",
      "nSV = 3123, nBSV = 2994\n",
      "Total nSV = 3123\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3118.814669, rho = -0.143898\n",
      "nSV = 3134, nBSV = 2991\n",
      "Total nSV = 3134\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3166.116532, rho = -0.817755\n",
      "nSV = 3176, nBSV = 2984\n",
      "Total nSV = 3176\n",
      ".......WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3115.449153, rho = -0.559421\n",
      "nSV = 3123, nBSV = 2993\n",
      "Total nSV = 3123\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3129.781525, rho = -0.722146\n",
      "nSV = 3127, nBSV = 2993\n",
      "Total nSV = 3127\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3139.010252, rho = -0.523359\n",
      "nSV = 3140, nBSV = 2992\n",
      "Total nSV = 3140\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3162.390980, rho = -0.674850\n",
      "nSV = 3172, nBSV = 2984\n",
      "Total nSV = 3172\n",
      ".......WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3047.104416, rho = -0.864204\n",
      "nSV = 3078, nBSV = 2987\n",
      "Total nSV = 3078\n",
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3086.978995, rho = -0.444440\n",
      "nSV = 3078, nBSV = 2991\n",
      "Total nSV = 3078\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3000.380505, rho = -1.371165\n",
      "nSV = 3064, nBSV = 2992\n",
      "Total nSV = 3064\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3167.312134, rho = -0.948063\n",
      "nSV = 3174, nBSV = 2985\n",
      "Total nSV = 3174\n",
      "....Line search fails in two-class probability estimates\n",
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5527.739787, rho = 0.200573\n",
      "nSV = 5526, nBSV = 2981\n",
      "Total nSV = 5526\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5572.866628, rho = 0.039931\n",
      "nSV = 5528, nBSV = 2916\n",
      "Total nSV = 5528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5533.987351, rho = -0.164020\n",
      "nSV = 5539, nBSV = 2960\n",
      "Total nSV = 5539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5511.545690, rho = -0.581641\n",
      "nSV = 5506, nBSV = 2937\n",
      "Total nSV = 5506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The clf_grid_search's results are: \n",
      " {'mean_fit_time': array([6081.45028167, 8304.11931527]), 'std_fit_time': array([1727.17086943, 1601.23250786]), 'mean_score_time': array([ 67.72027514, 113.47927582]), 'std_score_time': array([30.32089366, 50.9838032 ]), 'param_clf_csv__C': masked_array(data=[0.01, 1],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_clf_csv__kernel': masked_array(data=['linear', 'linear'],\n",
      "             mask=[False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'clf_csv__C': 0.01, 'clf_csv__kernel': 'linear'}, {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}], 'split0_test_accuracy': array([0.49997611, 0.53934356]), 'split1_test_accuracy': array([0.49997611, 0.53757584]), 'split2_test_accuracy': array([0.5       , 0.59368879]), 'split3_test_accuracy': array([0.5       , 0.53325211]), 'split4_test_accuracy': array([0.5       , 0.54672495]), 'split5_test_accuracy': array([0.49998806, 0.53799479]), 'split6_test_accuracy': array([0.49998806, 0.53402929]), 'split7_test_accuracy': array([0.49998806, 0.5268866 ]), 'split8_test_accuracy': array([0.49998806, 0.56716275]), 'split9_test_accuracy': array([0.49998806, 0.61756766]), 'mean_test_accuracy': array([0.49998925, 0.55342264]), 'std_test_accuracy': array([8.36082493e-06, 2.85378171e-02]), 'rank_test_accuracy': array([2, 1], dtype=int32), 'split0_test_precision': array([0.49997611, 0.52048589]), 'split1_test_precision': array([0.49997611, 0.51950953]), 'split2_test_precision': array([0.5       , 0.55204352]), 'split3_test_precision': array([0.5       , 0.51719792]), 'split4_test_precision': array([0.5       , 0.52450759]), 'split5_test_precision': array([0.49998806, 0.51974174]), 'split6_test_precision': array([0.49998806, 0.51770704]), 'split7_test_precision': array([0.49998806, 0.51380876]), 'split8_test_precision': array([0.49998806, 0.53599324]), 'split9_test_precision': array([0.49998806, 0.57788118]), 'mean_test_precision': array([0.49998925, 0.52988764]), 'std_test_precision': array([8.36082493e-06, 1.93066038e-02]), 'rank_test_precision': array([2, 1], dtype=int32), 'split0_test_recall': array([1.        , 0.99904443]), 'split1_test_recall': array([1., 1.]), 'split2_test_recall': array([1.        , 0.99378912]), 'split3_test_recall': array([1., 1.]), 'split4_test_recall': array([1., 1.]), 'split5_test_recall': array([1., 1.]), 'split6_test_recall': array([1.        , 0.99460105]), 'split7_test_recall': array([1., 1.]), 'split8_test_recall': array([1., 1.]), 'split9_test_recall': array([1.        , 0.87228858]), 'mean_test_recall': array([1.        , 0.98597232]), 'std_test_recall': array([0.        , 0.03796193]), 'rank_test_recall': array([1, 2], dtype=int32), 'split0_test_roc_auc': array([0.77051967, 0.83662558]), 'split1_test_roc_auc': array([0.74574847, 0.7371542 ]), 'split2_test_roc_auc': array([0.63187166, 0.7933579 ]), 'split3_test_roc_auc': array([0.81836753, 0.79055763]), 'split4_test_roc_auc': array([0.78272238, 0.75618363]), 'split5_test_roc_auc': array([0.55127345, 0.74406903]), 'split6_test_roc_auc': array([0.78509566, 0.60713868]), 'split7_test_roc_auc': array([0.78197675, 0.6503949 ]), 'split8_test_roc_auc': array([0.80922324, 0.72817828]), 'split9_test_roc_auc': array([0.72426432, 0.68260539]), 'mean_test_roc_auc': array([0.74010631, 0.73262652]), 'std_test_roc_auc': array([0.08066947, 0.0660285 ]), 'rank_test_roc_auc': array([1, 2], dtype=int32), 'split0_test_f1': array([0.66664543, 0.68440691]), 'split1_test_f1': array([0.66664543, 0.68378581]), 'split2_test_f1': array([0.66666667, 0.7097985 ]), 'split3_test_f1': array([0.66666667, 0.68178043]), 'split4_test_f1': array([0.66666667, 0.68810099]), 'split5_test_f1': array([0.66665605, 0.68398693]), 'split6_test_f1': array([0.66665605, 0.68096173]), 'split7_test_f1': array([0.66665605, 0.67882916]), 'split8_test_f1': array([0.66665605, 0.69791094]), 'split9_test_f1': array([0.66665605, 0.6952002 ]), 'mean_test_f1': array([0.66665711, 0.68847616]), 'std_test_f1': array([7.43195670e-06, 9.17652553e-03]), 'rank_test_f1': array([2, 1], dtype=int32)}\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST AOC-RUC PARAMETER:\n",
      "\n",
      "The Best Parameters for AUC-ROC:\n",
      " {'clf_csv__C': 0.01, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM].[LibSVM][LibSVM][LibSVM].WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.514889, rho = -0.943938\n",
      "nSV = 3156, nBSV = 3000\n",
      "Total nSV = 3156\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.170751, rho = -0.907098\n",
      "nSV = 3121, nBSV = 3000\n",
      "Total nSV = 3121\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.234803, rho = -0.909632\n",
      "nSV = 3128, nBSV = 3000\n",
      "Total nSV = 3128\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.309418, rho = -0.914721\n",
      "nSV = 3135, nBSV = 2999\n",
      "Total nSV = 3135\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -31.315275, rho = -0.897207\n",
      "nSV = 3138, nBSV = 2999\n",
      "Total nSV = 3138\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -46.851179, rho = 0.943449\n",
      "nSV = 4690, nBSV = 2823\n",
      "Total nSV = 4690\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     69771\n",
      "           1       0.00      1.00      0.00        43\n",
      "\n",
      "    accuracy                           0.00     69814\n",
      "   macro avg       0.00      0.50      0.00     69814\n",
      "weighted avg       0.00      0.00      0.00     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.5498\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.0006\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0012\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST ACCURACY PARAMETER:\n",
      "\n",
      "The Best Parameters for ACCURACY:\n",
      " {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3097.290758, rho = -0.808296\n",
      "nSV = 3112, nBSV = 2990\n",
      "Total nSV = 3112\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3083.604813, rho = -0.762507\n",
      "nSV = 3092, nBSV = 2987\n",
      "Total nSV = 3092\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3159.886628, rho = -1.025236\n",
      "nSV = 3168, nBSV = 2987\n",
      "Total nSV = 3168\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3144.436389, rho = -0.500758\n",
      "nSV = 3150, nBSV = 2988\n",
      "Total nSV = 3150\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3132.765951, rho = -0.491975\n",
      "nSV = 3146, nBSV = 2986\n",
      "Total nSV = 3146\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5607.445407, rho = -0.028508\n",
      "nSV = 5608, nBSV = 2992\n",
      "Total nSV = 5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08     69771\n",
      "           1       0.00      1.00      0.00        43\n",
      "\n",
      "    accuracy                           0.04     69814\n",
      "   macro avg       0.50      0.52      0.04     69814\n",
      "weighted avg       1.00      0.04      0.08     69814\n",
      "\n",
      "\n",
      "[TEST DATA] The AUC-ROC Score of the best model parameters:\n",
      " 0.7153\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.0396\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0013\n",
      "\n",
      "\n",
      "****************************************************************************************\n",
      "\n",
      "BASED ON SVC's BEST F1 PARAMETER:\n",
      "\n",
      "The Best Parameters for F1:\n",
      " {'clf_csv__C': 1, 'clf_csv__kernel': 'linear'}\n",
      "[LibSVM]..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3097.290758, rho = -0.808296\n",
      "nSV = 3112, nBSV = 2990\n",
      "Total nSV = 3112\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3083.604813, rho = -0.762507\n",
      "nSV = 3092, nBSV = 2987\n",
      "Total nSV = 3092\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3159.886628, rho = -1.025236\n",
      "nSV = 3168, nBSV = 2987\n",
      "Total nSV = 3168\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3144.436389, rho = -0.500758\n",
      "nSV = 3150, nBSV = 2988\n",
      "Total nSV = 3150\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -3132.765951, rho = -0.491975\n",
      "nSV = 3146, nBSV = 2986\n",
      "Total nSV = 3146\n",
      "..WARN: libsvm Solver reached max_iter\n",
      "optimization finished, #iter = 3000\n",
      "obj = -5607.445407, rho = -0.028508\n",
      "nSV = 5608, nBSV = 2992\n",
      "Total nSV = 5608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/sklearn/svm/_base.py:297: ConvergenceWarning: Solver terminated early (max_iter=3000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.04      0.08     69771\n",
      "           1       0.00      1.00      0.00        43\n",
      "\n",
      "    accuracy                           0.04     69814\n",
      "   macro avg       0.50      0.52      0.04     69814\n",
      "weighted avg       1.00      0.04      0.08     69814\n",
      "\n",
      "\n",
      "The AUC-ROC Score of the best model parameters:\n",
      " 0.7153\n",
      "\n",
      "[TEST DATA] The accuracy Score of the best model parameters:\n",
      " 0.0396\n",
      "\n",
      "[TEST DATA] The F1 Score of the best model parameters:\n",
      " 0.0013\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "# class sklearn.svm.SVC(*, C=1.0, kernel='rbf', degree=3, gamma='scale', coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape='ovr', break_ties=False, random_state=None)\n",
    "clf_csv = SVC(class_weight='balanced',\n",
    "              degree=3, \n",
    "              coef0=0.0, \n",
    "              shrinking=True, \n",
    "              tol=0.001, \n",
    "              cache_size=700, \n",
    "              verbose=1, \n",
    "              max_iter=3000, \n",
    "              decision_function_shape='ovr', \n",
    "              break_ties=False,\n",
    "              probability=True, \n",
    "              random_state=42)\n",
    "\n",
    "# estimator details for pipeline.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\n",
    "clf_csv_pipeline = Pipeline([\n",
    "    ('clf_csv', \n",
    "     clf_csv) # SVC\n",
    "])\n",
    "\n",
    "# Parameter details for SVC.\n",
    "# param_grid : dict or list of dictionaries\n",
    "clf_csv_param_grid = {\n",
    "    # Regularization parameter. \n",
    "    'clf_csv__C': [0.01, 1],\n",
    "    # Specifies the kernel type to be used in the algorithm. If none is given, ‘rbf’ will be used. But, rbf takes too much time to run. So, I used linear.\n",
    "    'clf_csv__kernel': ['linear'],  \n",
    "    # Kernel coefficient for ‘rbf’, ‘poly’ and ‘sigmoid’. if ‘auto’, uses 1 / n_features.\n",
    "}\n",
    "\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "# class sklearn.model_selection.GridSearchCV(estimator, param_grid, *, scoring=None, n_jobs=None, refit=True, cv=None, verbose=0, pre_dispatch='2*n_jobs', error_score=nan, return_train_score=False)\n",
    "clf_grid_search = GridSearchCV(estimator=clf_csv_pipeline,\n",
    "                                   param_grid=clf_csv_param_grid, \n",
    "                                   scoring=metrics_score_list, \n",
    "                                   cv=10, \n",
    "                                   n_jobs=-1,\n",
    "                                   refit=False, \n",
    "                                   verbose=1, \n",
    "                                   pre_dispatch='2*n_jobs', \n",
    "                                   return_train_score=False)\n",
    "\n",
    "# fit(X, y=None, **params)\n",
    "clf_grid_search.fit(X_train, # X\n",
    "                        y_train) # y\n",
    "\n",
    "# cv_results_dict of numpy (masked) ndarrays : A dict with keys as column headers and values as columns, that can be imported into a pandas DataFrame.\n",
    "tempResCV = clf_grid_search.cv_results_\n",
    "print(\"\\n The clf_grid_search's results are: \\n\", clf_grid_search.cv_results_)\n",
    "\n",
    "# AOC-RUC\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST AOC-RUC PARAMETER:\")\n",
    "tempo_mapping_roc_auc = clf_grid_search.cv_results_['params'][tempResCV['mean_test_roc_auc'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for AUC-ROC:\\n {tempo_mapping_roc_auc}\")\n",
    "\n",
    "tempo_mapping_roc_auc_model = clf_csv_pipeline.set_params(**tempo_mapping_roc_auc).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_roc_auc_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_roc_auc_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# ACCURACY\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST ACCURACY PARAMETER:\")\n",
    "tempo_mapping_accuracy = clf_grid_search.cv_results_['params'][tempResCV['mean_test_accuracy'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for ACCURACY:\\n {tempo_mapping_accuracy}\")\n",
    "\n",
    "tempo_mapping_accuracy_model = clf_csv_pipeline.set_params(**tempo_mapping_accuracy).fit(X_train, # X\n",
    "                                                                                 y_train) # y\n",
    "tempYPred = tempo_mapping_accuracy_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_accuracy_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\n[TEST DATA] The AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")\n",
    "\n",
    "\n",
    "# F1\n",
    "print(\"\\n\\n****************************************************************************************\")\n",
    "print(\"\\nBASED ON SVC's BEST F1 PARAMETER:\")\n",
    "tempo_mapping_f1 = clf_grid_search.cv_results_['params'][tempResCV['mean_test_f1'].argmax()]\n",
    "print(f\"\\nThe Best Parameters for F1:\\n {tempo_mapping_f1}\")\n",
    "\n",
    "tempo_mapping_f1_model = clf_csv_pipeline.set_params(**tempo_mapping_f1).fit(X_train, # X\n",
    "                                                                             y_train) # y\n",
    "tempYPred = tempo_mapping_f1_model.predict(X_test)\n",
    "tempYPred_probability = tempo_mapping_f1_model.predict_proba(X_test)[:,\n",
    "                                                                     # Probability of the positive class (class 1)\n",
    "                                                                     1]\n",
    "# Classification report.\n",
    "# sklearn.metrics.classification_report(y_true, tempYPred, *, labels=None, target_names=None, sample_weight=None, digits=2, output_dict=False, zero_division='warn')\n",
    "print(classification_report(y_test, # y_true : 1d\n",
    "                            tempYPred, # tempYPred : 1d\n",
    "                            labels=None, \n",
    "                            target_names=None, \n",
    "                            sample_weight=None, \n",
    "                            digits=2, \n",
    "                            output_dict=False, \n",
    "                            zero_division='warn'))\n",
    "# Get the roc_auc_score.\n",
    "# https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html\n",
    "tmpAucRocScore = roc_auc_score(y_test, \n",
    "                               tempYPred_probability,\n",
    "                               average='micro', \n",
    "                               sample_weight=None, \n",
    "                               max_fpr=None, \n",
    "                               multi_class='raise', \n",
    "                               labels=None)\n",
    "print(f\"\\nThe AUC-ROC Score of the best model parameters:\\n {tmpAucRocScore:.4f}\")\n",
    "# Test data calculations.\n",
    "tmpAccuracyScore = accuracy_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The accuracy Score of the best model parameters:\\n {tmpAccuracyScore:.4f}\")\n",
    "tmpF1Score = f1_score(y_test, tempYPred)\n",
    "print(f\"\\n[TEST DATA] The F1 Score of the best model parameters:\\n {tmpF1Score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "21424ea5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    69771\n",
       "1       43\n",
       "Name: Is Laundering, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5be951",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
